//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// JAVA //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// Eclipse :
// Ctrl + Shift + / : comment in or out the selection.
// Ctrl + Shift + S : ouvre le menu pour générer les getters & setters, constructeur, toString() & hashCode() & equals() overrides.
// Ctrl + Shift + T : ouvre le menu 'Open Type', utile pour retrouver la classe associée à l'élément sélectionné.
// Ctrl + 1 : ouvrir le menu contextuel d'Eclipse.
// Ctrl + O : affiche les méthodes de l'objet sélectionné.
// Alt + Shift + M : pour extraire du code dans une méthode.
// Alt + Shift + T > Extract Method : pour extraire du code dans une méthode.
// Alt + Shift + S > Override / Implement Methods : pour sélectionner des méthodes héritées de la SuperClass à surcharger.
// Alt + Entrée : En ayant un dossier sélectionné dans le package explorer, permet d'ouvrir la fenêtre propriétés du dossier dans lequel nous avons un bouton pour ouvrir le dossier dans explorer.
// Git : create new project in Eclipse > right-clic on the project > teams > share project > create new repository (local) with the same title > first commit.
// --> On GitHub, create new repository > copy hyperlink > push on Eclipse while pasting hyperlink > Done.
// -----------
// Deffinitions :
// - Classpath : Classpath est un paramètre passé à une machine virtuelle Java qui définit le chemin d'accès au répertoire où se trouvent les classes et les packages Java afin qu'elle les exécute.
// - JAR : En informatique, un fichier JAR est un fichier ZIP utilisé pour distribuer un ensemble de classes Java.
// Ce format est utilisé pour stocker les définitions des classes, ainsi que des métadonnées, constituant l'ensemble d'un programme.
// -----------
// CommandPrompt :
// cd : change directory (cd .. pour remonter dans le dossier père).
// dir : équivalent de 'ls' en linux. Liste les repértoires et fichiers du dossier courant.
// cls : clear console.
// where java : Echo l'emplacement du JDK.
// java -version : Use this command to determine which version of Java is installed on your device.
// javac -version : Use javac -version to determine the Java compiler version.
// whereis : whereis is your main search tool in Java. Use this command to find components within a directory.
// main : This command is your starting point and is used to declare or instantiate new classes.
// class : Through class you define methods and properties of an object.
// public : Through public, other classes can also access the program.
// object : With object you assign an object to a variable.
// static : With static you ensure that changes of the variable of an object are also taken over for the other objects of a class.
// -----------
// Git :
//      - Repository :
// git init : Initialize a new Git repository.
// git clone [repository-url] : Clone a repository from an url.
//      - Basics :
// git status : Show changes status.
// git add [file] : Add changes to staging.
// git commit -m "Message" : Commit changes with a message.
// git log : View commit history.
//      - Branching :
// git branch : List branches.
// git branch [branch name] : Create a new branch.
// git checkout [branch name] : Switch to a branch.
// git merge [branch name] : Merge changes from a branch.
// git branch -d [branch name] : Delete a branch.
//      - Remote repository :
// git remote : List remotes.
// git remote add [name] [url] : Add a remote.
// git push [remote] [branch] : Push changes from a remote.
// git pull [remote] [branch] : Pull changes from a remote.
//      - Undoing changes :
// git pull : Fetch and merge changes.
// git fetch : Fetch changes without merging.
// git reset --hard [HARD] : Discard changes.
// git revert [commit-hash] : Revert changes in a commit.
//      - Submodules :
// git submodule add [link to submodule repository] : Adds a submodule to the repository.
// git pull --recurse-submodules : Pulls all changes in all submodules.
// git config submodule.recurse true : Configures submodules to recurse.
// git submodule update --init : Updates all content of all submodules in the repository.
// -----------
// Maven :
// mvn archetype:generate -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.1 : créé un projet Maven de type 'Quick Start' dans le répertoire dans lequel nous nous trouvons.
// mvn package : compile, teste et archive le projet Java situé dans le répertoire dans lequel nous nous trouvons.
// mvn clean package : compile, teste, retire les dépendances inutiles et archive le projet Java situé dans le répertoire dans lequel nous nous trouvons.
// mvn package -P[cible] : compile, teste et archive le projet Java situé dans le répertoire dans lequel nous nous trouvons en utilisant le profil 'cible'.
// mvn test : compile et teste l'ensemble des tests Java du projet situé dans le répertoire dans lequel nous nous trouvons.
// mvn spring-boot:run : lance l'application Spring située du projet Java situé dans le répertoire dans lequel nous nous trouvons.
// java -cp target/mon-appli-1.0-SNAPSHOT.jar org.exemple.demo.App : exécute l'application Maven.
// java -jar target/mon-appli-1.0-SNAPSHOT.jar : exécute l'application Maven si celle-ci contiens un 'build' dans son pom.xml.
// -----------
// Gradle :
// sh gradlew run : (Linux) Exécute le projet Gradle situé dans le répertoire courant.
// ./gradlew run : (Windows) Exécute le projet Gradle situé dans le répertoire courant.
// -----------
// GlassFish :
// asadmin start-domain [nomDeDomaine] : Démarre le serveur d'application GlassFish ayant le nom de domaine choisi, 'domain1' par défaut. A lancer dans 'glassfish5\glassfish\bin'.
// asadmin stop-domain [nomDeDomaine] : Stoppe le serveur d'application GlassFish ayant le nom de domaine choisi.
// -----------
// VisualVM & JConsole :
// visualvm.exe --jdkhome "C:\Users\Emile\Desktop\JAVA\java-util\jdk08" : Exécute VisualVM (il faut se trouver dans le répertoire où se trouve le fichier visualvm.exe) en spécifiant un JDK.
// jconsole : Exécute Jconsole dans le dossier bin du JDK ciblé.
// -----------
// WsImport :
// wsimport -version : Retourne la version courante de WsImport (installé avec Java).
// wsimport -Xnocompile [cheminDeDestinationDesClasses] -p generated.ageservice [url.wsdl] : génère les classes sans les compiler dans le dossier src/main/java à partir du contrat fourni en url.
// -----------
// Zipkin :
// java -jar /chemin/vers/zipkin-server-2.6.1-exec.jar : Lancer Zipkin, accessible une fois lancé via 'http://localhost:9411'.
// -----------
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Première partie : Introducion /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : Introduction ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Installer un poste de développement Java //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Fonctionnement :
//      BDD : SQL ou NoSQL.
//      Processus métiers --> communique avec la database en JDBC.
//      Services : SOAP ou REST.
//      Standalone : swing, Java FX, application client, IHM --> protocoles moins orientés web.
//      Applications mobile ou dans un navigateur --> qui communique en http.
//      JRE : Java Runtime Environment : Runtime.
//      JDK : Java Development Kit : Development.
//      Java SE : Standart Edition (Client).
//      Java EE : Entreprise Edition (Serveur), maintenant obsolète passé à Eclipse.
//      Jakarta EE : Partie Eclipse, pas Oracle.
//      Language et synthaxe (très proche du C).
//          --> Write once, run everywhere --> Binaire JAVA indépendant de la machine et de l'OS (il est portable).
//  - Compilation et exécution :
//      Cycle de vie de son développement à son execution.
//          --> Code Java.java en UTF-8 (car plus portable).
//          --> Compilation.
//          --> Fichier binaire .class --> contient du byte code.
//      Ceci est un language intermédiairer qui ne corespond à aucun processeur.
//      Mais celui-ci pourra être executé via une machine virtuelle sur différents OS.
//          --> Execution dans une JVM : Java Virtual Machine.
//      Celle-ci est dédiée et va lire les fichiers .class.
//      En s'appuyant sur un ensemble de bibliothèque standarts (en .class aussi).
//      Le compilateur et le .class sont toujours les mêmes.
//      C'est le JVM qui va être adaptabble à l'OS de la machine, d'où la portabilité.
//          --> Dans le JDK, j'ai aussi la JRE et donc la JVM.
//  - Invocation du compilateur et execution.
//      Fichier : Main.java.
//      En ligne de commande : $ javac Main.java.
//          --> C'est l'invocation du compilateur qui va créer : Main.class en byte code.
//                  $ java Main (sans le .class)
//          --> Ceci va lancer la machine virtuelle
//                  Path : $ JAVA_HOME/bin
//                  $ java -version
//          --> Ceci va demander la version.
//  - Première classe Java :
//                  public class Main {
//                      public static void main(String [] args){
//                          System.out.println("Hello Java World !");
//                      }
//                  }
//      --> Ici, Main est la classe, et main est la méthode.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : Configurer un environnement de travail avec Git et Eclipse /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Installer un poste de développement Java //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - First we need a JDK --> https://adoptopenjdk.net.
//      JDK : Java Development Kit, in order to develop applications.
//      JRE : Java Runtime Environment, in order to run Java applications.
//          - Si on est administrateur de la machine, on peux télécharger et installer directement le .msi.
//          - Dans le cas ou on est pas administrateur :
//              On commence par télécharger le .zip.
//              Une fois terminé, on le colle dans le dossier souhaité et on extrait son contenu et on ne touche plus à rien dans ce dossier.
//  - Maintenant on a un peu de configuration à faire :
//      Dans une invite de commande on tape : java -version.
//      Aucune version n'existe.
//      On sauvegarde les données ci-dessous dans un .bat :
//                  echo Setting Java 16
//                  @echo off
//                  set JAVA_HOME=C:\Users\Emile\Desktop\JAVA\Java\OpenJDK16U-jdk_x64_windows_hotspot_16.0.2_7\jdk-16.0.2+7
//                  set PATH=%JAVA_HOME%\bin;%PATH%
//      On sauvegarde le fichier.
//      En ouvrant l'invite de commande on se dirige dans le dossier de destination : Desktop\JAVA\Java.
//      Si on tape : dir Java16.bat, le fichier existe bel et bien.
//      Si on tape ensuite java16, il nous réponds Setting Java 16.
//      En tapant : java -version, nous avons bien la dernière version installée.
//      Ce fichier .bat executé est purement local à l'invite de commande ouverte.
// Donc si il y a une autre version de Java quelque part sur le poste, et que je veux utiliser une version spécifique, il faut agir comme ceci.
// C'est une technique pour travailler vraiment en local.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Installer et configurer Eclipse sur un poste Java /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On va sur eclipse.org > Download > Download Packages.
// On choisit : Eclipse IDE for Enterprise Java and Web Developers.
// On reçoit un .zip qu'on va déplacer dans le même répertoire que pour le JDK.
// Comme ça on pourra y stocker plusieurs versions de java et plusieurs versions d'Eclipse si besoin.
// Ainsi on peux toujours installer Java dans la version qu'on veux en utilisant le .bat.
// On extrait le .zip ici de sortes à garder le même nom de dossier et de pouvoir conserver le numéro de version.
// Si on va dans le dossier extrati et qu'on double-clic sur eclipse.exe, la première chose qu'il va nous demander c'est quelle est la version de Java ?
// Si je suis passé par le .bat, aucune version de Java n'est installée, et aucun JAV_HOME ni PATH configuré.
// Dans ce cas là il suffit de conserver la fenêtre de commande ouverte (celle ou le .bat à été lancé), de naviguer dans le bon dossier et de lancer le .exe.
// Une fois le répertoire de stockage des projets Eclipse choisi, Eclipse IDE s'ouvre.
// On clique sur "Hide" l'écran d'acceuil, et on arrive sur ce que l'on appelle une "Perspective Eclipse".
// Tout en haut à droite on peux voir le petit bouton carré qui nous dit qu'on est sur la perspective Java EE.
// On ne va pas faire de Java EE tout de suite donc on va cliquer sur le petit bouton d'a coté : "Open Perspective".
// On sélectionne la perspective Java et on la charge, ç anous amène à un arrangement de vues Eclipse.
// --> On a le package explorer à gauche.
// --> On a le outline à droite, mais on peut le glisser à gauche sous le package explorer.
// --> Enfin en bas on à trois vues superposées : Problems, Javadox & Declaration.
// --> Problems : Eclipse va nous transmettre toutes les erreurs qu'il va rencontrer.
// On va créer un nouveau projet en cliquant sur Create a Java project dans le package explorer.
// On rentre un titre, on vérifies bien qu'on est dans le bon JRE avec notre version de Java.
// On sélectionne "Use project folder as root for sources and class files".
// On décoche Module et on clique sur Next, puis Finish.
// Maintenant on a notre nouveau projet dans package explorer, si c'est project explorer, c'est qu'on est en vue Java EE.
// A présent on clique droit sur le projet et on clique sur propriétés.
// Le bouton à droite de "Location" ouvre une fenètre contenant le projet (si on veux le copier sur un autre dossier).
// En cliquant sur le "Java Build Path" on peut voir dans libraries, quel JRE on utilise.
// Une fois le JRE sélectionné on peut cliquer sur edit et en sélectionner un autre si nécessaire, c'est le point d'entrée.
// Maintenant on ferme et on clique droit sur le projet dans le package explorer > New > Source folder qu'on appelle src.
// A présent on peut créer notre première classe.
// --> Soit on fait bouton droit sur le dossier "src" > New > Class.
// --> Soit on clique sur le bouton vert "C" de la barre d'outils.
// Avec l'un ou l'autre une fenêtre s'affiche, avec le Source folder.
// On rentre le nom du package : org.vitu.hello.
// On rentre le nom de la classe : HelloWorld.
// On coche la case "public static void main(String[] args)" pour générer automatiquement la méthode "Main".
// La classe est créée et affichée dans l'éditeur.
// On peux modifier les préférences dans l'éditeur en faisant clic droit sur l'éditeur > préférences.
// En recherchant "color" on peut modifier color and font si on le souhaite.
// On tape "syso"+ ctrl + espace et ça nous imprime System.out.println().
// On y met "Hello World!" clic doirt sur la classe dans le package explorer > Run as > Java Application.
// Une quatrième vue s'ajoute aux trois vues du bas avec la console qui nous imprime notre message.
// Java est très chatouilleux sur la méthode "main", ça ne peut pas être "Main" !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser Eclipse pour créer un premier Bean User //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On va se créer une class User.
// On commence par créer un nouveau package dans hello qu'on va appeler model.
// Les packages sont comme des répertoires (ce sont des répertoires dans l'explorateur de fichiers).
// Dans le package explorer, en cliquant sur les trois petits points et package presentation > Hierarchical.
// Cela ressemble plus à un explorateur de fichiers comme ça.
// On va donc créer une nouvelle class dans notre nouveau package, qu'on nomme User.
// On va y créer deux champs : TOUJOURS PRIVES lorsqu'ils sont dans une classe "name" & "age".
//                  package org.vitu.hello.model;
//                  public class User {
//                      private String name;
// 	                    private int age;
//                  }
// Si je veux faire de cette classe un "bean", on a plusieurs possibilités :
//      --> Le plus simple c'est d'utiliser les générateurs de code d'Eclipse
// Alt + Shift + s : Generate getter and setters, hash code ....
// Sinon clic droit sur le code > source, qui ouvre le même menu.
// On commence par générer le getter and setter.
// On ouvre la fenêtre a partir du menu précédent, on sélectionne "name" & "age" et on clic sur generate.
// On fait la même chose pour générer toString(), en cliquant sur generate lorsque "name" & "age" sont sélectionnés.
// Le code est généré, c'est une surcharge de la méthode "toString()" de la classe object.
// Pour savoir si c'est vraiment une surcharge, Eclipse nous aide un peu, à droite des numéros de lignes on a un triangle vert.
// En cliquant sur le triangle vert, il nous ouvre la class "Object", dans un autre onglet pour nous expliquer de quoi il s'agit.
// On a aussi un "@override" en gris clair au dessus de la méhode qui nous indique qu'on fait une surcharge.
// On génère aussi hashCode() & equals(),  quand on surcharge equals(), on doit impérativement surcharger hashCode().
// Si on veut créer des User, il nous faut des constructeurs donc on génère le constructor en début de code après la déclaration des variables.
// On créé le constructeur qui prends le nom et l'age, on peut enlever le super();.
// Si on fait ça, on détruit le constructeur vide par défaut qui se trouve dans "User".
// Donc pour le remettre on regénère un constructeur, mais sans paramètres pour avoir juste public User(){}.
// Cette classe est maintenant quasiment un bean, il ne manque qu'une chose.
//                  package org.vitu.hello.model;
//                  import java.util.Objects;
//                  public class User {
// 	                    private String name;
// 	                    private int age;
// 	                    public User() {
// 	                    }
// 	                    public User(String name, int age) {
// 		                    this.name = name;
// 		                    this.age = age;
// 	                    }
// 	                    public String getName() {
// 		                    return name;
// 	                    }
// 	                    public void setName(String name) {
// 		                    this.name = name;
// 	                    }
// 	                    public int getAge() {
// 		                    return age;
// 	                    }
// 	                    public void setAge(int age) {
// 		                    this.age = age;
// 	                    }
// 	                    @Override
// 	                    public String toString() {
// 	            	        return "User [name=" + name + ", age=" + age + "]";
// 	                    }
// 	                   @Override
// 	                    public int hashCode() {
// 		                    return Objects.hash(age, name);
// 	                    }
// 	                    @Override
// 	                    public boolean equals(Object obj) {
// 		                    if (this == obj)
// 		            	        return true;
// 		                    if (obj == null)
// 		            	        return false;
// 		                    if (getClass() != obj.getClass())
// 		            	        return false;
// 		                    User other = (User) obj;
// 		                    return age == other.age && Objects.equals(name, other.name);
// 	                    }
//                  }
// Dans la classe HelloWorld, on ajoute un new User, mais il ne reconnaît pas la classe donc il faut l'importer.
// Seul le package java.lang est importé par défaut dans toutes les classes.
// Si on survole l'erreur sur User, on peut cliquer sur "import User" directement.
// Si on clique sur la croix rouge près des numéros de ligne à gauche, on peut aussi double cliquer sur import User, et il le fait automatiquement.
//                  package org.vitu.hello;
//                  import org.vitu.hello.model.User;
//                  public class HelloWorld {
// 	                    public static void main(String[] args) {
// 		                    System.out.println("Hello World!");
// 		                    User u1 = new User();
// 	                    }
//                  }
// Si on veut rajouter les paramètres à notre user, en clic droit sur les parenthèses de User().
// Eclipse nous dit qu'il connaît deux constructeurs.
// On ajoute les paramètres et on ajoute 3 users, dont deux avec les mêmes paramètres.
// On println les 3 users :
//                 package org.vitu.hello;
//                 import org.vitu.hello.model.User;
//                 public class HelloWorld {
//                     public static void main(String[] args) {
//                         System.out.println("Hello World!");
//                         User u1 = new User("Kylian", 20);
//                         User u2 = new User("Michel", 62);
//                         User u3 = new User("Kylian", 20);
//                         System.out.println("U1 = " + u1);
//                         System.out.println("U2 = " + u2);
//                         System.out.println("U3 = " + u3);
//                     }
//                 }
// On obtiens :
//                  Hello World!
//                  U1 = User [name=Kylian, age=20]
//                  U2 = User [name=Michel, age=62]
//                  U3 = User [name=Kylian, age=20]
// Car notre user à la forme d'un objet avec deux paramètres.
// On fait des tests :
//                  System.out.println("U1 == U2 : " + (u1 == u2));
//                  System.out.println("U1 == U3 : " + (u1 == u3));
// Là on utilise "==" donc on compare les "pointeurs" ou "adresses".
// Comme u1 et u2 sont deux new Users, même si ils ont les mêmes valeurs de paramètres, ils ne sont pas égaux.
// Par contre si on utilise la méthode equals, qui permet de comparer les objets de manière applicative.
//                  System.out.println("U1 equals U2 : " + (u1.equals(u2)));
//                  System.out.println("U1 equals U3 : " + (u1 .equals(u3)));
// On obtient :
//                  U1 equals U2 : false
//                  U1 equals U3 : true
// Pourtant on a une contrainte, deux objets qui sont égaux avec equals() doivent avoir le même hashCode().
// Donc on va vérifier que U1 et U3 ont bien le même hashCode().
//                  U1 hashCode = -2032711899
//                  U2 hashCode = -1990497589
//                  U3 hashCode = -2032711899
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Installer un poste de développement Java avec Eclipse en tant qu'administrateur ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lancer Eclipse de cette façon là n'est quand même pas la plus pratique.
// Quand on est administrateur sur une machine, on va pouvoir modifier les variables d'environnement.
// Notamment les variables JAVA_HOME et PATH.
// Dans la recherche windows, on recherche les variables d'environnement windows.
// On clic sur Environment Variables.
// On créé une nouvelle variable : JAVA_HOME, avec pour valeur :
// C:\Users\Emile\Desktop\JAVA\Java\OpenJDK16U-jdk_x64_windows_hotspot_16.0.2_7\jdk-16.0.2+7.
// Puis on va modifier la valeur Path déjà existante dans la liste.
// Et on rajoute une ligne avec : %JAVA_HOME%\bin.
// Puis ok, ok, ok, et maintenant pour cet utilisateur les variables sont bonnes.
// Donc si on refait : java -version de n'import où avec cet utilisateur et on aura la bonne version de java.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Configurer la gestion d'un projet Java avec Eclipse et Git ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment utiliser Git pour faire deux choses.
// Faire des backup de nos projets Java et projets Eclipse en local.
// Sauvegarder ces projets locaux vers des remote repositories et pour pouvoir interagir avec ces remote repositories.
// Git est maintenant la norme en gestion de code source, Git est intégré à Eclipse.
// C'est un utilitaire développé par Linus Torval, qui a aussi développé le noyau Linux.
// On retourne dans Eclipse, et en clic droit sur notre first-project dans le package explorer > close project.
// Cela permet de fermer le projet et tous les fichiers qui y étaient apparentés et étaient ouverts.
// Pour le rouvrir il suffit de faire clic droit > open project.
// On va créer un nouveau projet que l'on va appeler : salle.tp.project.
// On l'appelle ainsi comme si on était sur une machine en salle de tp et qu'on ne peut pas apporter notre projet chez nous.
// Git va nous permettre de sauvegarder les fichiers de ce projet et ce de façon incrémentale.
// Ainsi, les nouvelles sauvegardes n'écrasent jamais la première.
// Tout d'abord il faut qu'on signifie à Eclipse que ce projet là, on veut qu'il soit gérer par Git.
// Clic droit sur le projet dans le package explorer > Team > Share project.
// On coche > Use or create repository in parent folder or project, puis on sélectionne le projet.
// On clique sur "Create repository" puis "Finish".
// Maintenant, dans notre package explorer, sur le pictoframme du projet on a un petit cylindre doré surmonté par un J.
// Alt + Entrée : On ouvre les propriétés du projet, puis on clique sur le bouton : Show in explorer à droite de la "Location".
// En ouvrant le répertoire du projet il y a un dossier caché .git.
// C'est dans ce dossier que Git va garder tous les élements dont il va avoir besoin pour travailler.
// On va ouvrir la vue "Navigator" : Window > Show view > Navigator (Deprecated).
// Elle arrive dans le quadri onglets du bas mais on peut la glisser à coté du package explorer.
// Cette vue nous permet d'afficher les projets avec plus d'éléments que le package explorer.
// On a le dossier ".Settings", ainsi que les fichiers ".classpath" et ".project" qui sont à Eclipse.
// On a le dossier "src" dans lequel on ajoute une classe : org.vitu.model, on créé une classe nommée "User".
// Le fichier User.java est bien créé dans le répertoire "src", et on y trouve le fichier User.class dans le répertoire "bin".
// Le répertoire "bin" contient la compilation des classes Java.
// On ne va pas backup tous les fichiers dans Git, en effet ça ne sert à rien de backuper les fichiers compilés.
// Les fichiers compilés, on peut toujours les reconstituer à partir du code source.
// Par contre on doit absolument backuper le code source.
// Idem, on a pas besoin de backup les fichiers et dossiers Eclipse : .settings, .classpath & .project.
// En effet, Eclipse est capable de recréer ça tout seul.
// En regardant le fichier .gitignore, on voit tous les éléments que Git ne va pas prendre en compte.
// Donc on va y ajouter les fichiers et dossiers devant être ignorés comme ci-après :
//                  /bin/
//                  /.settings/
//                  .classpath
//                  .project
// Les dossiers dans ce fichier doivent être entourés de slash "/".
// RAPPEL : Clic droit sur le projet > Team > Remote > Configure Push to UpStream > Change > Rentrer les informations, mot de passe = token GitHub (avec repositories coché) > Save and Push.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Sauvegarder une première version avec un Commit ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On peut retourner dans le package explorer, et on va faire une première sauvegarde en l'état de notre projet.
// On ne va pas encore sauvegarder la classe Java, mais d'abord sauvegarder le .gitignore.
// Si on va dans le package explorer et qu'on clic droit sur notre projet, dans l'onglet "Teams", on peut voir qu'il y a beaucoup plus de possibilités qu'avant.
//                  Ctrl + # : Commit
// On clique sur Commit, et Git va demander à Eclipse d'ouvrir la vue "Git Staging" dans la vue inférieure droite.
// Dans la partie en haut à droite on a tous les fichiers succeptibles d'être sauvegardés par Git (nouveaux fichiers ou fichiers ayant subi une modification).
// On y trouve le .gitignore et le User.java, si on ne veux sauvegarder que le .gitignore, on le fait glisser dans la fenètre du dessous "Staged changes".
// Un petit plus vert s'ajoute sur le fichier .gitignore, et on peut le retrouver aussi dans le Navigator.
// On ajoute ensuite l'auteur et le commiter (moi), puis on met un commentaire dans le Commit message.
// L'adresse e-mail est mise par défaut la mienne de GitHub, on peut la retrouver dans les settings de GitHub.
// Si ce n'est pas le cas, dans Eclipse > Window > Preferences, filtre sur Git > configuration.
// Maintenant on commit notre User class puis on retourne dans l'explorer.
// On ajoute un private String name plus les getter and setter, on sauvegarde.
// Maintenant un petit chevron ">" est apparu devant signifiant que le fichier pris en charge par Git n'est pas backuped.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Examiner l'hustorique des Commits Git dans Eclipse ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment assister à l'évolution des commits en temps réel ou pouvoir les retrouver ?
// Window > Show view > Other > on tape "History", on la sélectionne puis "Open".
// Nos 4 commits s'affichent sur cette vue là, dans la partie haute, la branche principale et les 4 commits.
// En dessous à gauche, le commit sélectionné, avec son code de hashage, auteur, commiter, sa branche et son message de commitment.
// En dessous à droite le ou les fichiers qui ont été commited dans le commit sélectionné.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Revenir à un ancien commit par un checkout ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour revenir sur un commit, on fait clic droit sur le commit souhaité dans l'History, puis cliquer sur checkout.
// On retrouve ainsi la classe User telle qu'elle était à ce moment-là.
// Le marqueur head montre le commit spécifique qu'on est en train de regarder.
// Master est une branche.
// Si des commits disparaissent, il faut cliquer sur le bouton en haut à droite de la fenètre "history" en forme de fourche fléchée.
// Ca nous permet de choisir si on veut voir juste le commit actuel et son commit parent, ou le refs/Heads.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Configurer un repository Git sur le Cloud et l'opération Push /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// BitBucket vs GitHub.
// On va sur GitHub et on créé notre repository, puis on copie l'url proposé.
// Maintenant sur Eclipse on va dire à notre repository local de se connecter à GitHub.
// Clic droit sur le projet > Team > Show in repository View.
// Dedans on voit qu'on à des branches, une branche locale, la Master.
// Puis on a une branche vide qui est "Remote Tracking", et c'est là qu'on va mettre notre commit.
// On clic droit sur "Remotes" (petit cylindre doré), puis "Create remote" (ou plutôt declare remote).
// On va laisser le mot origin, c'est généralement le nom cloud associé à un repository local.
// Ensuite, soit on Push soit on Fetch, nous on veux Push.
// On fait finish, il nous demande de mettre un URI, celui-ci se met tout seul quand on clic sur change.
// On peut aussi mettre un mot de passe si besoin etc.
// Il nous manque les refs mappings, on clique sur "Advanced".
// On entre mot de passe et id GitHub.
// Si ça ne marche pas : GitHub > Settings > Developper Settings > Tokens > Generate new token avec tout coché.
// On met l'id GitHub et on colle le token à la place du mot de passe.
// Une fois dedans on clique sur All Branches et sur All tags, puis Finish.
// On clique sur "Save", maintenant dans le dossier Remote de la fenètre Git Repositories, on à le dossier origin avec le push et le pull.
// On a donc notre opération de push que l'on vient de configurer et l'opération de fetch que l'on a pas encore configuré.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Publier des commits locaux vers un repository cloud ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans la fenètre Git Repositories > Remotes > origin > dossier avec la flêche rouge (push).
// On rentre identifiant GittHub et mot de passe (mot de passe  = token pour le moment), une fenêtre s'ouvre.
// Dans la fenêtre on a le résumé, il nous indique qu'il à créé une nouvelle branche "Master", et qu'il l'a pushed dans le remote repository choisit.
// On peut close la fenêtre, le push à réussi.
// On peut vérifier sur GitHub que les fichiers sont biens sur GitHub.
// Aussi si on va dans l'horloge avec la flêche dans GitHub on a la liste de tous les commits, et on retrouve bien les mêmes ID que dans Eclipse.
// Maintenant on peut rajouter un autre integer salary à l'objet name, et y ajouter son getter et son setter.
// On retourne dans le Git Staging dans l'un des onglets du bas, on déplace les unstaged changes aux Staged changes, on ajoute un message.
// Maintenant soit on peut faire un commit (en local, et il sera uploadé sur le cloud quand on l'aura pushed).
// Soit un commit and push, pour l'enregistrer en local et dans le cloud, ce qu'on va faire.
// Il ne nous redemande pas le mot de passe et nous affiche la fenêtre des actions comme précédemment.
// Attetion, si le User.java est sélectionné, on aura pas tous les commits dans l'onglet history, il faut sélectionner le dossier du projet pour tous les avoirs.
// On va créer une deuxième branche à présent : clic droit dans l'onglet "history" sur le Master Head Branch > Create Branch.
// Une fenêtre s'ouvre, on y rentre le nom de la nouvelle branche et on clic sur Finish.
// En faisant ça la branche à été créée en local mais pas pushed donc on ne la retrouve pas sur GitHub.
// Il faut donc lui dire de le faire donc dans la fenêtre "Git Repositories", il faut faire clic droit sur l'action push flêche rouge > Configure push.
// Une fenêtre s'ouvre, comme on a des étoiles, il est dans une situation ou il commit tout en local et il push tout en remote.
// On click sur Save and Push et il nous ouvre la fenêtre du résultat du push.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Rapatrier des commits d'un repository cloud localement ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On va créer un nouveau projet et supposer que c'est notre "home-project".
// Clic droit sur le projet > Team > Share > cocher Use or create repository > clic sur create repository > Finish.
// Le repository est créé, mais on y ajoute rien, pour ne pas créer de conflits avec le repository qu'on va pull.
// Même le .gitignore fait partie du remote repository, donc on ne veut pas le créer.
// Si on raffraichis l'onglet "History", on peut voir qu'il n'y a rien dedans non plus.
// En faisant "clone" dans GitHub on peut récupérer l'URI nécéssaire pour connecter notre nouveau projet au remote repository existant.
//                  https://github.com/EmileVitu/java-apside-tutorial.git
// Maintenant dans l'onglet Git Repositories > clic droit Remote > Create remote > on laisse le titre origin > on coche "fetch".
// On ajoute l'URI > Finish > advanced (pour lui dire de tout récupérer) > On supprime tout > All Branches > All Tags > Finish sans cocher force update.
// Save > Dans l'onglet Git Repository > Remotes > Origin > clic droit > fetch > il nous confirme qu'il a bien récupéré deux branches Master et salle-tp.
// Pourtant maintenant rien ne s'affiche dans Eclipse, il a récupéré les branches en local mais ne les a pas mis à jour dans Eclipse.
// Clic droit sur le projet > Team > Merge > une fenêtre s'ouvre.
// On voit que les branches sont bien dans le dossier remote, mais on a rien dans le dossier local.
// On sélectionne une branche et on clique sur merge, puis cancel sur le .gitignore, qu'on va tout de suite effacer dans le navigator.
// On doit à présent refaire l'action merge avec la Master branch pour enfin obtenir la fenêtre "Merge Result".
// Puis on peut faire la même chose avec la branche salle-tp, même si cela ne sert pas à grand chose, ce coup-ci on arrive directement à la fenêtre "Merge result".
// A présent on a bien les 5 commits (avec les mêmes ID) qui se trouven dans l'onglet "History".
// Maintenant dans la fenêtre History, si on veut faire un checkout sur la branche master / origine-salle / origin-master / Head, il nous demande ce qu'on veut checkouter.
// On choisit Master > Check out as new local branch > Ca ne fonctionne pas parce qu'elle existe déjà locallement.
// Donc on recommence et cette fois-ci on utilise salle_tp, puis Finish.
// Maintenant en local on a master et salle_tp (qui sont en vert dans l'onglet History).
// A présent si on regarde le contenu dans home-project de User.java dans le package explorer, on à tout ce qu'il nous faut.
// Cela-dit, on est chez nous, donc on va se créer une branche : clic droit sur le master dans l'onglet history, et on l'appelle "home".
// Elle s'ajoute à présent en vert dans l'history, mais aussi en gras, car c'est sur cette branche qu'on travaille.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Echanger des commits entre deux repositorys locaux et un repository cloud /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On rajoute une méthode toSting() qui prends nome, age et salaire.
// On retourne dans l'onglet Git Staging, et on va commit la méthode toString().
// En retournant dans l'historique, on remarque que le commit est allé dans la branche home, et les branches master eet salle_tp sont restées derrière.
// En naviguant sur GitHub, on constate que la branche Home a été créée, et est un commit en avance sur les deux autres branches.
// Maintenant on referme tous les projets (clic droit > close project dans le package explorer), et on réouvre salle.tp.
// Dans l'hstorique de salle.tp, on a juste les branches master et salle.tp, et le dernier commit est l'ajout de la propriété salary.
// On retourne dans Git Repositories pour faire un Fetch, mais comme celui-ci n'a pas été configuré ça ne fonctionne pas, donc on fait configure fetch.
// On séléctionne toutes les branches et tous les tags (il n'y a pas encore de tags mais on les mets quand même par précaution), Finish, save.
// On fait fetch, il à récupéré les trois branches, si le dernier commit ne s'affiche pas, c'est que les paramètres ne le permettent pas.
// Pour l'afficher, dans l'historique, on clique dessus et on affiche tous les commits.
// On clic droit sur le commit qui n'y est pas puis merge. Maintenant, salle_tp est bien dans la même ligne que origine/home, on est donc bien à jour.
// On remarque que la branche master et la branche salle_tp sont en retard du dernier commit.
// On ajoute une méthode hashCode() et une méthode equals() qui vont porter uniquement sur le nom et l'age, on la commit and push dans Git Staging.
// Donc la branche salle_tp s'est alignée sur la branche origin/salle_tp, et on les retrouve bien sur GitHub.
// On ferme le projet salle_tp, car on rentre à la maison, et on ouvre le projet home-project, sur lequel on va faire un fetch.
// On ajoute "remotes" à partir du bouton "wich commits to show", puis on merge la dernière branche.
// Maintenant home est bien alignée avec origin/salle_tp, on peut voir que origin/home est en retard.
// On va donc faire un push de home-project, et à présent les deux sont alignés.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Résoudre un conflit entre deux branches désynchronisées ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Imaginons qu'on rajoute une erreur dans le User class du home-project :
//                  public void increaseSalary(int amount) {
//                      this.salary += amount;
//                  }
// Après on le commit and push dans le Git Staging.
// En regardant l'historique on peut voir que home et origin/home sont en avance sur origin/salle_TP qui est aussi en avance sur master, salle_tp et origin/master.
// On peut maintenant fermer le projet, puis ouvrir le projet salle_tp, et par erreur on oublie de fetch et on continue de travailler.
//                  public void oneMoreYear() {
//                      this.age++;
//                  }
// Maintenant on commit and push, tout se passe bien car on travaille sur deux branches différentes à la maison et en salle_tp.
// En fermant ce projet puis rouvrant home-project, puis on fait notre fetch, une nouvelle branche sur le schema dans history apparaît.
// On remarque qu'il y a une bifurcation entre la branche salle_tp et la branche home.
// On clic droit sur le Added oneMoreYear(), qui est le commit manquant à notre branche home, mais on remarque en résultat un conflit, on clique sur Ok.
// Il nous ajoute des points rouges à la place des disques en or de git dans le package explorer, et dans User.java, puis dans le fichier User.java qui est source du conflit on à ça :
//                  <<<<<<< HEAD
//                      public void increaseSalary(int amount) {
//                          this.salary += amount;
//                  =======
//                      public void oneMoreYear() {
//                          this.age++;
//                  >>>>>>> refs/remotes/origin/salle_tp
// Il nous dit que la partie supérieure vient de "Head", et la partie inférieure vient de "salle_tp".
// Pour résoudre ce problème, Eclipse peut nous aider, on va clic droit sur User.java dans le package explorer > Teams > Merge tool.
// Ca nous sépare l'écran en deux avec les deux sources du conflit, il faut qu'on sélectionne ce qu'on veut prendre et ce qu'on veut laisser.
// Nous on veut les deux, à noter que d'un côté on a la version en local et de l'autre la version remote.
// On clique sur le carré rouge entre les deux conflits, celui-ci se transforme en flêche allant du remote vers le local.
// Le code est ajouté sur la partie locale, on a à présent les deux méthodes, on ferme la fenêtre et on sauvegarde.
// Maintenant il nous faut refaire un commit (le commentaire est mis automatiquement).
// Si on regarde dans "history", la bifurcation a été refusionnée avec la branche principale, ce que nous souhaitions.
// A présent on referme le projet home et on réouvre le projet salle_tp, puis on fait un fetch, puis on merge le dernier commit.
// Maintenant on a rattrappé l'erreur, salle_tp et home ont tous deux la totalité des propriétés ajoutées.
// On peut donc faire un push, ce qui va nous mettre à jour le dossier remote origin/salle_tp avec les autres branches.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Partager et effacer un repository BitBucket ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans Github Access > Collaborators, nous pouvons partager un repository.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Seconde Partie : Le traitement des données en Java ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : API Collection /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Traiter des données en mémoire avec l'API Collection //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On travaille pour une entreprise qui doit envoyer un e-mail avec un code promotionnel à chaque client dont l'anniversaire est demain.
// Comment traiter ce problème en Java ?
// On doit d'abord récupérer les données clients, puis les stocker en mémoire.
// Les traiter, c'est à dire trouver les clients qui ont un e-mail et dont l'anniversaire est demain.
// Leur envoyer un e-mail.
// Ces 4 étapes définissent un processus métier.
//      I. Où peut-on récupérer les données ?
//              --> Dans une BdD, dans ce cas nous devons utiliser l'API "JDBC" du JDK.
//              --> Via des services, web ou "Rest" ou l'on va se servir du client http du JDK.
//              --> On peut les chercher directement sur le disque auquel cas on va utiliser "Java IO".
//          Java propose des API pour aller chercher des données des trois manières citées précédemment.
//      II. Comment fait-on pour stocker ces données en mémoire ?
//          Tout passe par l'API "Collection" : elle s'occuppe de stocker et d'organiser des données en mémoire de manière efficace.
//          Elle offre aussi des services d'accès à ces données.
//      III. Pour traiter les données en mémoire ?
//          Se fait principalement via l'API Stream depuis Java 8.
//      IV. L'envoi d'e-mail ?
//          Peut se faire en utilisant le même type d'API que celles utilisées pour récupérer les données client.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Limitations du traitement de données à l'aide de tableaux simples /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quelles alternatives pourrait-on avoir à la place de l'API collection.
// On pourrait utiliser des tableaux simples, un peu comme des arrays.
// Le problème est qu'on aurait des difficultés à gérer l'index lors d'ajout ou de suppression d'objets dans l'array.
// On aurait donc trois problèmes principaux :
//      --> Gérer l'index.
//      --> Gérer la saturation du tableau et la fonction d'élargissement de celui-ci.
//      --> Gérer l'effacement des objets qui amènent à des trous dans mon tableai.
// Tout ça est apporté sur étagère par l'API collection.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Opérations de base disponibles sur une Collection /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'API Collection apporte un certain nombre de notions à connaître, qu'et ce qu'un collection.
// --> On peut représenter ça par un sac dans lequel on peut ajouter et retirer des objets.
// --> On peut tester si un objet est présent dedans (boolean).
// --> Quel est le cardinal de la collection, c'est à dire le nombre total d'objets y figurant.
// --> On peut itérer les objets de la collection, c'est à dire balayer les objets de la collection sans ordre en particulier.
// --> Une collection a une taille extensible.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Présentation de l'interface collection et de ses méthodes /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Collection<String>
// Collection<int>...
//      --> .add(String s)
//      --> .addAll(Collection<String> c)
// Cette opération va ajouter tous les objets de la collection entre parenthèses à la collection dans laquelle je suis : opération d'union.
//      --> .remove(Object o)
//      --> .removeAll(Collection<String> c)
//      --> .contains(Object o)
//      --> .containsAll(Collection c)
//      --> .size()
//      --> .clear()
//      --> .retainAll(Collection c)
// Cette méthode va conserver dans la collection dans laquelle je suis, tous les éléments de la collection entre parenthèses.
// Cette méthode sert donc d'opération d'intersection entre deux collections.
//      --> .toArray(...)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// List et Set ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'une Collection à l'aide de l'implémentation ArrayList //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons maintenant créer une nouvelle collection :
//                  Collection<String> c = new ArrayList<String><>;
// ArrayList est une classe qui contient un corps de méthodes pour chacune des méthodes définies dans Collection.
// LinkedList<String><>; est une autre interface d'implémentation pour collection.
// La différence est que ArrayList est construite sur un tableau, et LinkedList est construite sur une liste chaînée.
// Maintenant on peut ajouter des éléments à notre collection :
//                  c.add("one");
//                  c.add("two");
//                  c.add("three");
// On peut également faire des remove :
// c.remove("four"); --> ceci ne va pas altérrer notre collection car "four" ne fait pas partie de la collection
// c.remove("one"); --> cela va retirer "one" de la collection
// Si on veut afficher le nombre d'élements on peut faire :
//                  c.size(); --> returs 2
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Itérer sur les éléments d'une Collection : pattern Iterator et pattern ForEach ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant qu'on a des éléments dans notre Collection, on va pouvoir construire un "itérateur".
//                  Iterator<String> it = c.iterator();
// Cet Iterator possède deux méthodes :
//      --> hasNext() : boolean, si il revient true, c'est qu'il reste des éléments dans ma Collection à visiter.
//      --> next() : retourne l'élement suivant que l'on peut visiter.
// Attention, une erreur est jetée lorsqu'on utilise next(), alors que hasNext() est false.
//                  while(it.hasNext()) {System.out.println(it.next());}
// Nous avons aussi un autre pattern qui permet d'itérer sur une Collection sans passer par le pattern itérator : forEach.
// for(String s : c){System.out.println(s);} --> à noter que forEach est en fait un for() avec une syntaxe particulière.
// Donc nous avons un élément d'itération qui utilise un iterator, Iterator, et un élément d'itération qui n'en utilise pas : forEach.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Retirer des éléments d'une Collection pendant une itération ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On a une troisième méthode sur iterator autre que next() et hasNext() : remove().
// Imaginons qu'on veut retirer de cette collection, tous les caractères qui font plus de 5 caractères :
//                  Iterator<String> it = c.iterator();
//                      while(it.hasNext()){
//                          String s = it.next();
//                          if(s.length() > 5){
//                              it.remove();
//                          }
//                      }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation de l'interface Iterator ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons une dernière chose sur ces itérators, considérons que nous avons :
// al = new ArrayList<String>();
// ll = new LinkedList<String>();
// On a vu que la méthode itérator intervient sur Collection donc :
// Si on fait al.iterator() et ll.iterator(), les deux résultats seront Iterator<String>.
// Pourtant est-ce que ces deux objets sont les mêmes ?
// Non car ils appartiennent à deux classes différentes, mais ils ont le même type : Iterator<String>.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Interdire les doublons dans une Collection avec un Set ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'interface est implémentée par une première sous interface qui est Set qui peut être mise en place par la classe HashSet :
//                  Set<String> set = new HashSet<><>;
// On ne précise pas qu'il s'agit de String dans le constructeur <> ou l'implémenteur <> car Java va automatiquement le faire vu qu'on le précise avant.
// On est pas obligé de mettre le type, par contre on est obligé de mettre les <>, qu'on appelle en Java l'opérateur "Diamant".
// Cette interface n'ajoute pas de nouvelles méthodes à Collection, mais elle en change le comportement.
// En effet, elle interdit à Collection d'avoir des doublons, on à la garantie que tous les éléments sont uniques.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment un Set détecte-t-il les doublons dans ses éléments ? //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons qu'on ait le Set suivant : Set<String> set = new HashSet<><>;.
//      set.add("one"); --> returns true
//      set.add("two"); --> returns true
//      set.add("one"); --> returns false (car c'est un doublon)
// Donc le Set refuse d'ajouter une valeur qu'il à déjà dans son set.
// Si on utilise la methode .add de Collection, cela retourne un boolean aussi, mais l'ajout n'échoue jamais contrairement à Set.
// Comment HashSet() sait que la chaîne de caractères existe déjà dans le Set ?
// HashSet est une API du JDK et elle exploite la manière dont le JDK fonctionne.
// HashSet pour comparer des Strings utilise equals / hashCode (si deux objets sont égaux avec equals, ils ont le même hashcode).
// HashSet va calculer le hashCode des différents objets du Set et va les comparer entre eux.
// Si HashSet trouve deux objets qui ont le même hashCode, il va utiliser equals pour vérifier si ils sont bien égaux.
// Cette optimisation permet d'aller plus vite que d'utiliser equals() qui est plus lent que hashCode().
// Car deux éléments qui ont le même hashCode ne sont pas forcément égaux, mais le sont si ils sont égaux aux yeux de equals().
// Mais cela repose sur le fait qu'on ait bien surchargé hashCode(), et bien surchargé equals().
// La surcharge de ces deux méthodes est donc quelque chose qu'il faut faire systématiquement.
// Si on oublie de les surcharger, HashSet ne fonctionnera plus.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ordonner les éléments d'une Collection dans une List //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième extension de Collection : l'interface List.
// List<String> list = new ArrayList<><>; (ici aussi on ne renseigne pas le type dans l'opérateur diamant, le compilateur s'en charge).
// L'implémentation par défaut de l'interface List est la même que l'implémentation par défaut de l'interface Collection : ArrayList, ce qui peut être perturbant.
// Donc un ArrayList, c'est à la fois une Collection et une List.
// Dans une List, les éléments sont ordonnés alors qu'ils ne le sont pas dans une Collection ou dans un Set.
// Dans une List chaque élément à un index qui est entretenue par ArrayList et nous permet un accès aux éléments par leur numéro d'index.
// get(x) --> nous retourne la valeur de l'index x.
// remove(x) --> retire la valeur de l'index x, et prendra automatiquement la valeur de l'index x+1, l'ancienne valeur de l'index x+1 deviendra celle de x+2 etc.
// set(x, "five") --> la valeur actuelle de l'index x va être retirée et remplacée par "five".
// add(x, "six") --> la valeur de l'index x va être remplacée par "six", son ancienne valeur va être pourssée à l'index x+1, cette dernière à x+2 etc.
// Donc avec la méthode add(x, ""), on remplace la valeur de l'index x, on décalle toutes les autres valeurs, et on créé un index en bout de liste pour la dernière valeur poussée.
// sublist(beginIndix, endIndex) --> créé une sous liste en incluant la première borne et en excluant la dernière.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Itérer sur les éléments d'une List, utilisation d'un ListIterator /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On peut aussi récupérer l'iterator avec List.
// list.iterator() --> Iterator<> qui est la même interface que pour Collection ou pour Set.
// On a une autre méthode quie est listIterator().
// Elle retourne : listIterator<String> qui possède deux méthodes : hasPrevious() & previous().
// On peut également accéder à la valeur de l'index avec deux autres méthodes : nextIndex() & previousIndex().
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenir les éléments d'un Set triés avec SortedSet //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La dernière interface est une extension de Set et s'appelle : SortedSet.
// Son implémentation s'appelle TreeSet :
//                  SortedSet<String> set = new TreeSet<><>;
// Cela fonctionne comme un Set, donc on a pas de doublons, mais en plus les éléments sont triès par ordre croissant.
// Mais attention ils sont triès mais pas ordonnés.
// Ordonnés signifie associés à un index, le premier aura l'index 0, le second l'index 1 etc. et quand on itère, on le fait en fonction des index.
// Triés signifie qu'ils sont organisés par exemple pour les String en ordre alphabétique.
// Si on prends un ensemble {b, c, d, a}, dans une List en itérant on aura {b, c, d, a}, alors qu'avec un SortedSet on aura {a, b, c, d}.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment un SortedSet maintient ses éléments triés /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment tous les éléments sont triés ?
// Dans le cas de la classe String c'est assez simple car ceux-ci sont comparables.
// Le mécanisme utilisés est : comparable / comparator.
// Si on créé un SortedSet avec des éléments qui sont non comparables, dans ce cas, le SortedSet est créé avec un Comparator.
// Soit les éléments sont comparables : on fourni un Comparator, soit on n'en fournit pas.
// Soit les éléments sont non-comparables : on doit fournir un Comparator.
// Ca reste utile d'ajouter un Comparator même quand les éléments sont comparables.
// En effet, comme ça on peut trier les éléments dans un ordre qui n'est pas l'ordre par défaut des éléments comparables.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Etendre SortedSet avec NavigableSet ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// SortedSet (Java-2) est en fait associée à une autre interface qu'on appelle NavigableSet (Java-6).
// NavigableSet à la même implémentation que SortedSet --> TreeSet.
// NavigableSet est plus avantageux a utiliser que SortedSet étant donné qu'il possède d'autres méthodes :
//      ceiling() : le plus grand élément, plus petit qu'un élément donné qui se trouve dans l'ensemble.
//      floor().
//      higher() : le plus petit élément, plus grand qu'un élément donné qui se trouve dans l'ensemble.
//      lower().
// Ces méthodes nous permettent d'extraire des éléments particuliers à partir d'une borne.
//      tailSet() : retourne un sous-ensemble au dessous d'un élément donné.
//      headSet() : retourne un sous-ensemble au delà d'un élément donné.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récapitulatif sur l'API Collection ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On a une première interface qui s'appelle Collection.
// Celle-ci est étendue par l'interface Set, qui permet de ne pas avoir de doublons mais ne rajoute pas de méthode à cette API.
// Set est elle-même étendue par deux interfaces : SortedSet et NavigableSet, liées l'une à l'autre.
// Ces deux interfaces réjoutent le fait que les éléments soient triés.
// L'autre interface principale est l'interface List, qui est différente de l'interface Set car elle peut avoir des doublons.
// Par contre les éléments y sont ordonnés donc organisés par index.
// Au niveau des implémentation, on a ArrayList et LinkedList pour Collection et List.
// Set à pour implémentation HashSeet, et SortedSet et NavigableSet ont pour implémentation TreeSet.
// A partir d'une collection on peut récupérer un Iterator, lui même étendu sur List avec ListIterator.
// Attention, on manipule toujours un Iterator à partir de son interface.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer des listes avec des éléments dedans /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment créer des Collections préremplies (avec des objets dedans).
// On a deux solutions pour le faire :
// La première est d'utiliser une méthode factory qui est disponible sur la classe factory qui s'appelle Arrays, la méthode s'appele asList().
//                  List<String> strings = Arrays.asList("one", "two", "three");
// Cette liste à une caractéristique, c'est que dessus, les méthodes .add() et .remove() sont non-actives.
// En revanche, les méthodes de type .replace() est active.
// On ne peut pas y ajouter ou supprimer des éléments, mais on peut en remplacer, c'est une liste immutable.
// A partir de Java 9 on a aussi  :
// List.of("one", "two", "three") : retourne une liste.
// Set.of("one", "two", "three") : retourne un set (si on met un doublon dans le jeu d'entrée, une erreur sera jetée et set refusera de créer le set).
// Leur caractéristiques a eux aussi est qu'ils sont immutables.
// On ne peut ni ajouter, ni retirer, ni modifier d'éléments existants.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer une liste à partir d'une autre liste ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous avons construit une liste de cette façon là :
//                  List<String> strings = List.of("one", "two", "three");
// Imaginons que nous voulons en faire une ArrayList, c'est possible car nous avons un constructeur qui prends une autre liste en paramètre.
//                  List<String> stringsCopy = new ArrayList<>(strings);
// Ainsi à présent notre liste est devenue mutable, on va pouvoir, ajouter, supprimer ou remplacer des éléments de cette liste.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Map ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction aux tables de hachage ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La seconde valeur foncamentale de l'API Collection est la notion de table de hashage
// C'est une table à deux colonnes, avec des clefs et des valeurs :
// Clef / Valeur
// 75 / Paris
// 50 / Manche
// 59 / Nord
// 33 / Gironde
// 83 / Var
// Cela ressembele un peu à la strucuture d'une base de donnée
// Dans celle-ci on a des clefs primaires associées à un ensemble de valeur de colonne correspondant à une ligne de la table dans laquelle je me trouve
// Quelles sont les opérations principales d'une table de hachage :
// Ajouter
// Retirer
// Remplacer
// Cardinal
// Effacer
// Itérer
// Tester (si une clef ou une valeur est présente de ma table de hashage)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'une table de hachage ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comme toutes les structures de l'API Collection, la table de hashage est modéllisée par une interface :
// Map<Integer, String> map = new HashMap<><>;
// Map prends deux paramètres, d'abord le type de la clef, puis celui des valeurs qui y sont associées
// Tout comme dans les structures vues précédemment, il n'est pas nécessaire d'indiquer le type après l'avoir nommé dans le diamant
// En effet, Java va le déduire tout seul au vu de ce qui a été déclaré précédemment

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lire une valeur à partir d'une clé avec la méthode get ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La première méthode que l'on va voir est la méthode .get() :
// map.get(33); --> returns "Gironde"
// Si la clef est absente de la table de hashage cela va me retourner null
// Pourtant c'est ennuyant car la valeur null peut aussi être stockée en tant que valeur
// Ainsi si on reçoit une valeur nulle en utilisant la méthode .get(), on ne peut pas savoir si c'est la valeur associée à la clef souhaitée,
// Ou si la clef est absente de la table de hashage
// On peut éviter ça en faisant un :
// map.getOrDefault(15, ""); --> on y passe en premier paramètre une clef qui n'est pas dans la table de hashage
// En second paramètre on passe une chaîne de caractères vides (valeur par défault) donc pas une valeur null
// Donc si on utilise une méthode sur null, il va retourner nullpointerexception alors que sur  une chaîne de caractères vide cela fonctionnerait
// --> Si l'index indiqué n'existe pas, il retourne la chaîne de caractères vide
// --> Si l'index indiqué existe, il retourne la clef associée
// --> Si l'index indiqué existe et que la valeur associée est null, il retourne null

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ajouter une paire clé valeur avec la méthode put //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour ajouter une paire clef valeur, on utilise la méthode .put() :
// map.put(72, "Sarthe");
// Si on fait : map.put(59, "NORD"); a: lors que cette valeur et index existent déjà mais que la valeur est en minuscule, que se passe t'il ?
// Dans ce cas là, le put va écraser la valeur déjà existante, ce qui n'est pas nécessairement ce qu'on veut
// map.putIfAbsent(59, "NORD");
// --> un premier test est fait pour savoir si la clef est présente dans la table de hashage ou pas
// Si elle est absente elle l'ajoute, si la valeur existante est nulle, la valeur est ajoutée aussi, si elle existe, elle ne l'ajoute pas
// map.replace(59, "NORD");
// --> Java va ajouter cette valeur à la clef souhaitée uniquement si la clef existe déjà dans la table de hashage
// map.replace(59, "Nord", "NORD");
// Si "Nord" est bien la valeur associée à l'index 59 de la table de hashage, cette valeur est remplacée par "NORD"

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Retirer une paire clé valeur avec la méthode remove ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La méthode .remove() vient en deux versions :
// map.remove(50);
// --> retire la paire clef valeur correspondante de la table de hashage
// map.remove(59, "NORD");
// --> retire la paire clef valeur correspondante aux deux paramètres présentés dans la méthode
// Ici, "NORD" est en majuscule, donc remove ne va pas trouver cette valeur associée à 59 dans la table donc elle ne removera rien

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tester la présence d'une clé ou d'une valeur avec contains ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment peut-on tester qu'une clef ou une valeur particulière se trouve bien dans une table de hashage
// La méthode .get() fonctionne mais donne un résultat ambigu
// map.containsKey(75);
// --> boolean
// map.containsValue("Sarthe");
// --> bbolean

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fusion, cardinal et effacement d'une table de hachage /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// map.putAll(otherMap);
// Cette méthode ajoute l'intégralité des clefs et valeurs associées de "otherMap", à la table de hashage map
// map.size();
// --> retourne le nombre de paire clefs-valeurs présentent dans la table de hashage map
// map.clear();
// --> efface l'intégralité du contenu de la table de hashage map

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Itérer sur une table de hachage ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment itérer sur une table de hashage ?
// Une table de hashage est déjà un genre de Collection de paire clef-valeurs
// On a pas de méthode Iterator sur map, car on a différentes manières de faire des itérations
// Concernant les clefs, celles-ci ne peuvent pas avoir de doublons
// Donc l'ensemble des clefs d'une table de hashage équivaut à un Set<Integer>
// map.keySet();
// --> Cette méthode va nous permettre de récupérer ce Set<Integer>
// Dans l'ensemble des valeurs d'une table de hashage, par contre on peut avoir des valeurs null, ainsi que des doublons
// Donc cet ensemble ne peut plus être un Set, mais une Collection<String> classique
// map.values();
// --> Cette méthode va nous permettre de récupérer cette Collection<String>
// Maintenant si on regarde l'ensemble des valeurs ainsi que des clefs, donc l'intégralité de la structure de la table de hashage
// Mais cette fois-ci on va obtenir un Set, car on a pas de doublons dans les paires clef-valeurs, car les clefs sont uniques
// Par contre cela va être un peu particulier car nous aurons un Set d'objets pour donner à l'integer clef un string particulier
// Set<Map.Entry<Integer, String>>
// map.entrySet();
// --> l'interface Map.Entry est un objet très simple car il encapsule seulement une clef et une valeur
// On va avoir plusieurs méthodes sur cette interface :
// getKey();
// --> Retourne un integer
// getValue();
// --> retourne une chaîne de caractère dans le cas présent
// setValue();
// --> cette méthode va prendre une nouvelle valeur en paramètre, et de modifier cette valeur dans la table de hashage
// On a donc une méthode pour modifier la valeur d'une clef, mais on ne peut pas modifier la clef d'une paire clef valeur
// On a une subtilité sur le Set et la Collection, c'est que ce sont des "VUES" sur la table de hashage
// Donc le Set n'est pas une copie des valeurs, mais une vue sur les index de la table de hashage
// Cette vue sera mise à jour automatiquement, si jamais la table de hashage est modifiée
// On y a droit uniquement à des méthodes de type "remove", dans ce cas là la paire clef-valeur sera retirée de la table de hashage
// Il en va de même avec la Collection des valeurs
// Donc ces vues sont mutables, on peut y retirer des clefs, des valeurs, ou des paires clefs valeurs
// Une fois qu'on à ce Set et cette Collection, on peut itérer dessus
// Donc itérer une table de hashage doit se faire via une des trois méthodes : map.keySet(), map.values() ou map.entreySet()

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenir des paires clés valeurs triées avec SortedMap ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On a une extension de map dans le JDK qui s'appelle SortedMap ainsi qu'une NavigableMap
// Ces deux extensions sont implémentées par la même classe d'implémentation qui s'appelle TreeMap
// Celle-ci est construite sur un algorythme particulier qui s'appelle le Red Black Tree
// C'est un arbre binaire assez sophistiqué qui permet de garantir que même après avoir ajouté des paires clefs-valeurs, il reste équilibré
// Ceci n'est pas forcément le cas des arbres binaires de base
// La sémantique particulière de SortedMap est que : les clefs sont triées de la même façon que dans SortedSet
// Si on ajoute une liste d'integer à SortedMap, elles seront triées par ordre croissant
// En effet, par défaut, la classe integer, implémente l'interface comparable et par défaut c'est cet ordre là qui sera utilisée
// La sémantique va être la même que pour SortedSet, c'est à dire que si la clef est comparable, on a pas besoin de passer de comparator à la construction de ma SortedMap
// Si les clefs sont non-comparables, on a besoin de passer un comparator pour les comparer
// Si les clefs sont non-comparables et qu'on a pas de comparator, mon SortedMap va sortir en erreur, on ne pourra pas ajouter de paire clef-valeur dedans
// Si les clefs sont comparables, on peut aussi passer un comparator :
// Auquel cas c'est la comparaison du comparator qui sera prioritaire sur le caractère comparable des clefs
// Donc si on veut trier ces clefs par ordre décroissant, on peut créer un SortedMap, et y passer un comparator qui va trier les integer dans l'ordre décroissant
// Au même titre que SortedSet, on a un certain nombre de méthodes particulières pour SortedMap :
// firstKey() --> retourne la première clef
// lastKey() --> retourne la dernière clef
// subMap(fromKey, toKey) --> va nous permettre d'extraire une sous-map de la map dans laquelle on se trouve en incluant l'index fromKey, et en excluant la valeur toKey
// Il y a aussi d'autres méthodes qui ont été introduites dans NavigableMap lors de Java 6

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation des buckets dans l'implémentation de HashMap //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment les choses fonctionnent-elles en interne dans une table de hashage, avec la notion de Bucket
// En fait à l'intérieur de la classe HashMap on à un tableau avec un certain nombre de cases égales à une puissance de 2 (commence à 16)
// Les 2^n cases sont autant de buckets, donc ces cases sont des buckets
// Imaginons qu'on veut ranger une paire clef-valeur dans cette table de hashage
// Dans un premier temps, l'implémentation de HashMap va calculer un code de hashage pour cette clef donc un hashCode
// Ce hashCode est différent de la classe Object classique de Java
// HashMap à sa propre façon de calculer sa table de hashage pour les clefs qu'on lui demande de stocker
// A partir de ce hashCode qui est un entier (qui peut être très grand, éventuellement même négatif), on va déterminer un index
// Cet index va représenter une case particulière de ce tableau
// Ainsi deux clefs différentes vont générer deux hashCode différents mais à leur tour, ceux-cis peuvent générer le même index
// On va donc ici pouvoir avoir des collisions
// Dans le bucket de ce tableau on a une structure qui va se créer et qui est interne à la table de hashage
// Celle-ci va finir par contenir la paire clef-valeur qu'on veut enregistrer et qu'on va appeler entry
// Cet objet n'est pas directement l'entrée, l'entrée est encapsulée dans un objet, et c'est cet objet qui est référencé à partir du tableau
// Si on ajoute une seconde paire clef-valeur, normalement on aura un différent index car la partie hashCode-index est optimisée pour éviter les collisions
// A partir d'un certain nombre de paires clefs-valeurs référencées dans cette table de hashage, ce tableau va être copié dans un tableau plus grand
// Ce nombre est égal à 11 ou 12, donc avant qu'il soit saturé, justement pour éviter les collisions d'index
// Si jamais deux clefs différentes génèrent le même index, l'objet qui encapsule la première entrée va se comporter comme une liste chaînée
// Créant un deuxième objet qui va encapsuler une deuxième entrée, donc lorsque le même index est utilisé, une petite liste chaînée sera créée à cet index
// On a une optimisation dans la classe HashMap, qui fait qu'à partir d'un certain nombre d'éléments dans la liste chaînée, celle-ci deviendra un arbre binaire
// De cette manière on pourra retrouver les entrées très rapidement
// Maintenant comment est-ce que ça se passe lorsqu'on est en lecture ? Imaginons dans une table avec des millions d'entrées
// Il suffit de calculer l'index à partir de la clef pour trouver l'objet se situant dans le bucket et lire la valeur définie dans cet objet
// On dit que cet Algorythme est en O(1) (en O de 1), et HashSet est aussi basé sur une table de hashage dans laquelle on ne regarde que les valeurs

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer des tables de hachage pré-remplies //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Map<Integer, String> map = ...
// On peut appeler un constructeur de HashMap qui prends map en paramètre et qui créé une nouvelle map
// Map<...> copyOfMap = new HashMap<><map>;
// C'était notre unique solution jusqu'en Java 8
// A partir de Java 9 on a des méthodes factory directement sur Map, un peu comme on a vu sur Set et List
// Map<Integer, String> map = Map.of(75, "Paris",33, "Gironde", 50, "Mannche");
// Cette méthode factory prends en paramètre en alternance, une clef, une valeur et ainsi de suite
// Cette méthode fonctionne bien jusqu'a une dizaine de paire clef-valeur, si on en a plus, cette méthode ne pourra plus fonctionner
// Mais la méthode suivante permet d'ajouter le nombre d'entrées qu'on veut :
// Map.ofEntries(e1, e2, e3, ...);
// Maintenant pour construire ces entrées, on peut faire comme ceci :
// Map.Entry<...> e1 = Map.entry(59, "Nord");
// --> Cette méthode Map.entry() nous retourne un objet de type Map.entry avec de valeurs de type correspondantes
// Exactement comme pour les autres méthodes factory ded List et de Set, la table de hashage retournée n'est pas exactement une HashMap
// C'est une table de hashage immutable, on ne peut pas y ajouter ou retirer de paire clef-valeur, ni modifier de clef ou de valeur d'une paire clef-valeur
// Aussi, pour la méthode "of" ou la méthode "entry", si on rentre deux paires clef-valeur qui ont la même clef, la deuxième viendrait écraser la première
// A ce moment-là on aurait une erreur, on ne peut pas spécifier de table de hashage corrompue à l'aide de ces méthodes

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récapitulatif sur les tables de hachage de l'API Collection ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voici la structure globale des tables de hashage dans l'API Collection :
// Map --> SortedMap --> NavigableMap
// Les implémentations sont HashmMap pour Map, et TreeMap (avec l'algorythme Red Black Tree), pour SoredMap et NavigableMap
// Si on veut itérer :
// keySet() --> Set pour itérer sur les clefs
// values() --> Collection pour itérer sur les valeurs
// entrySet() --> Set de Map.Entry (objet encapsulant une paire clef-valeur)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Autres élements de l'API Collection ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Classes obsolètes de l'API Collection /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il y a plusieurs classes de l'API Collection dont on a pas encore parlé
// Vector & Stack, Hashtable & Dictionnary
// Ces classses sont obsolètes, il ne faut donc plus les utiliser
// Elles sont toujours présentent dans le JDK car elles étaient présentent avant l'ajout de l'API Collection (donc présentent dans la version Java 1)
// La première version du JDK est sortie en 1995-1996
// L'API Collection à été ajoutée en Java 2, donc en 1998

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Classes Arrays et Collections /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deux dernières classes peuvent être mentionnées :
// --> Arrays : classe factory, ne fait pas partie de l'API Collection à proprement parler
// Elle possède tout un tas de méthodes qui sont très pertinente dans le cas de traitement de données en mémoire
// Nottament sur des tableaux (Arrays.asList() par exemple)
// --> Collections : classe factory, donc qui ne comporte que des méthodes statiques
// Ces méthodes rendent un certain nombre de services dans le contexte du traitement de données à partir de collections dans la mémoire de la JVM
// Ces deux classes doivent être vues et lues dans la documentation

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java Arrays ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// This class contains various methods for manipulating arrays (such as sorting and searching). This class also contains a static factory that allows arrays to be viewed as lists.
// The methods in this class all throw a NullPointerException, if the specified array reference is null, except where noted.
// The documentation for the methods contained in this class includes briefs description of the implementations.
// Such descriptions should be regarded as implementation notes, rather than parts of the specification.
// Implementors should feel free to substitute other algorithms, so long as the specification itself is adhered to.
// (For example, the algorithm used by sort(Object[]) does not have to be a MergeSort, but it does have to be stable.).
// This class is a member of the Java Collections Framework.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : Lambda expressions et interfaces fonctionnelles ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction aux Lambda Expressions ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définition des Lambda Expressions /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les Lambdas expressions sont un ajout de Java 8 en 2014, surement l'un des deux ou trois ajouts les plus importants depuis sa création
// Son impact se répercute sur l'ensemble des API, en particulier sur le traitement des données en mémoire
// L'API Collection subit une réecriture majeure du fait de l'introduction des Lambdas expressions
// On a donc des fonctionnalités supplémentaires pour aller chercher les données et les traiter
// L'API Stream, également introduite dans Java 8 est entièrement construite autour de l'utilisation des Lambdas Expressions
// Donc en plus du pattern Iterator, nous avons tous les pattern de l'API Stream pour intéroger les données en stockage

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Notion d'Interface Fonctionnelle //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La notion de Lambda expression est basé sur une nouvelle notion qui est l'interface fonctionnelle
// C'est une interface qui ne fonctionne qu'une seule méthode : donc pour l'implémenter on a besoin d'implémenter une seule méthode
// Une Lambda Expression --> Implémentation d'une interface fonctionnelle
//    public interface Consumer<T> {
//         public void accept(T t);
//    }
// Le type de l'objet T va être n'importe quel objet ou classe (String, Integer ...)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une première lambda implémentation de Consumer ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment va t'on écrire l'implémentation de cette interface consumer ? C'est là que se trouve l'originalité des Lambdas Expressions
//     Consumer<String> cons = (String s) -> {
//         System.out.println(s);
//     }
// Vu que la méthode accept() retourne void, on a pas besoin de return dans notre déclaration
// Donc une Lambda expression est une méthode simplifiée pour la méthode que l'on implémente
// On peut aussi écrire vu que l'expression entre {} ne fait qu'une seule ligne
//     cons = s -> System.out.println(s);
// La syntaxe des Lambdas Expressions est donc cette écriture simplifiée
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Continuons avec Consumer et Predicate /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Consumer et la méthode forEach() d'une liste //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il s'avère que dans les collections il y a une méthode dont on a pas encore parlé : forEach()
// List<String> strings = ....
// strings.forEach("objet de type Consumer");
// forEach() prends pour paramètre un objet de type Consumer
// Vu qu'on est sur une List de String, il est naturel que ce soit un Consumer de String aussi
// strings.forEach(s -> System.out.println(s));
// Ici, on a passé en paramètre de cet appel de méthode une implémentation de cette interface Consumer en utilisant une Lambda Expression
// Comment la méthode forEach() fonctionne t'elle ?
// En interne, elle va itérer elle-même sur tous les éléments de la liste
// Puis elle va passer ces éléments en paramètres de la Lambda Expression que l'on vient de passer
// Donc si on a trois valeurs de liste one, two & three
// s va prendre la valeur one, puis affichée sur la console, puis la même chose pour two puis pour three
// Ceci est donc une première interface fonctionnelle

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Interface Fonctionnelle : Predicate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième interface fonctionnelle, l'interface Predicate, celle-ci aussi est paramétrée par un type "T" particulier
// Elle a une unique méthode abstraite qui s'appelle "test", qui prends le type en paramètre et qui va retourner un boolean
// On va donc pouvoir créer des prédicats de strings, integer...
// public interface Predicate<t> {
//     public boolean test(T t);
// }
// Supposons que l'on veut créer un prédicat de string qui retourne true si le string qu'on lui passe en paramètre est non-null :
// --> Predicate<String> p1 = s -> s != null;
// Second exemple : retourne vrai si s fait mois de 10 caractères :
// --> Predicate<String> p2 = s -> s.length() < 10;

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser ensemble Consumer et Predicate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons d'abord voir un petit détail qui n'est pas évident au premier abord :
// Consumer<String> C = s -> System.out.println(s);
// Predicate<String> p = s -> startsWith("B");
// N'oublions pas que la méthode Consumer est définie par une méthode accept(), et que même si on ne la voit pas elle est bien là. On peut donc écrire :
// c.accept("Bonjour");
// En faisant ça, "Bonjour" sera affichée sur la console
// boolean b1 = p.test("Bonjour");
// En faisant ça, ça nous retourne true
// boolean b2 = p.test("le monde");
// La ça va retourner false
// Donc même quand nous utilisons des Lambdas Expressions pour implémenter des interfaces fonctionnelles,
// Nous pouvons toujours sur les variables créées appeler les méthodes définies sur ces interfaces fonctionnelles

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lambda à deux paramètres : BiConsumer /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant nous allons voir une nouvelle interface qui s'appele BiConsumer et qui prends, elle, deux paramètres :
// public interface BiConsumer<T, U> {
//     public void accept(Tt, Uu);
// }
// Comment peut-on implémenter BiConsumer avec une Lambda Expression :
// BiConsumer<String, Integer> b = (s, i) -> System.out.println(s + "-" + i);
// Donc on peut définir des interfaces fonctionnelles qui prennent plusieurs paramètres, la syntaxe change légèrement (parenthèses)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lambda à deux paramètres : BiPredicate ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On a aussi une interface BiPredicate :
// public interface BiPredicate<T, U> {
//     public boolean test(Tt, Uu);
// }
// Prenons par exemple un BiPredicate de String et de String pour voir si le second String est contenu dans le premier :
// BiPredicate<String, String> bp1 = (s1, s2) -> s1.contains(s2);
// Comment peut-on utiliser ce BiPredicate bp1 ?
// --> boolean b1 = bp1.test("Bonjour", "on"); : true
// --> boolean b2 = bp1.test("Bonjour", "le monde"); : false

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Application partielle : Transformer un BiPredicate en Predicate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons qu'on ait un BiPredicate comme le précédent :
// BiPredicate<String, String> bp = (s1, s2) -> s1.contains(s2);
// Ce BiPredicate bp, on peut le transformer en Predicate :
// Supposons qu'on veuille créer un Predicate qui teste si une chaîne contient le mot clef "ERROR"
// s1.contains("ERROR"); équivalent à bp.test(s1, "ERROR");
// Predicate<String> p = s -> bp.test(s, "ERROR");
// C'est une transformation d'un BiPredicate en Predicate, en fixant la valeur d'un des deux paramètres du BiPredicate
// C'est ce qu'on appelle faire de l'application partielle

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lambda : L'Interface Function /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Présentation de l'interface Function //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Troisième type d'interface fonctionnelle, l'interface Function, qui définit une méthode abstraite qui s'appelle apply() :
//      public interface Function<T, R> {
//          public R apply(Tt);
//      }
// La méthode apply() prends un objet de type T en paramètre et retourne un objet de type R
// Comment peut-on créer une fonction ? Toujours de la même façon :
// Function<String, Integer> length = s -> s.length();
// Exemple d'utilisation de cette fonction :
// int l = length.apply("Bonjour"); --> l = 7.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation de la BiFunction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une BiFunction est simplement une Function qui prends deux éléments en paramètres de type T et U et qui continue de retourner un objet de type R
//     public interface BiFunction<T, U, R> {
//         public R apply(Tt, Uu);
//     }
// Par exemple, trouver la position d'une chaîne de caractère dans une autre chaîne de caractère :
// BiFunction<String, String, Integer> indexOf = (s1, s2) -> s1.indexOf(s2);
// Comment va t'on pouvoir utiliser cette BiFunction :
// int index = indexOf.apply("Bonjour", "on"); --> returns 1

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transformer une BiFunction en Function ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Peut-on transformer la BiFunction précédente en une Function ? Avec une des deux chaînes de caractères fixe :
// Function<String, Integer> indexOfInBonjour = s -> indexOf.apply("Bonjour", s);
// Ce faisant, on a fait une application partielle d'indexOf (BiFunction précédente) sur son premier paramètre

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Opérateurs Unaires avec UnaryOperator /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On a une extension de Function qui s'appele UnaryOperator :
//      public interface Function<T, R> {
//          public R apply(Tt);
//      }
//     public interface UnaryOperator<T> {
//         extends Function<T, T>
//     }
// Donc un UnaryOperator est une extension au sens de l'héritage de l'interface Function (bien que ce soit aussi une interface)
// Cela particularise les Functions qui prennent des objets d'un certain type en paramètre et retourne des objets du même type
// Comment peut-on implémenter un UnaryOperator :
// UnaryOperator<String> upperCase = s -> s.toUpperCase();
// Donc ici on retourne bien un objet du même type que le paramètre
// UnaryOperator<Integer> inc = o -> i + 1;
// Comment peut-on utiliser ces UnaryOperators :
// L'interface UnaryOperator en elle-même n'ajoute pas de méthodes à l'interface Function, donc c'est toujours la méthode apply() que l'on va utiliser
// String s = upperCase.apply("Bonjour"); --> BONJOUR
// int i = inc.apply(10); --> 11

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Opérateurs Binaires avec BinaryOperator ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Function est donc étendu par UnaryOperator, et BiFunction, elle, est étendue par BinaryOperator
//     public interface BiFunction<T, U, R> {
//         public R apply(Tt, Uu);
//     }
//     public interface BinaryOperator<T> {
//         extends BiFunction<T, T, T>;
//     }
// Un BinaryOperator est vraiment un opérateur binaire classique au sens où on l'entends, par exemple :
// BinaryOperator<String> concat = (s1, s2) -> s1 + s2;
// String s = concat.apply("Bonjour", " le monde"); --> Bonjour le monde
// Un second exemple avec des entiers :
// BinaryOperator<Integer> add = (i1, i2) -> i1 + i2;
// int i = add.apply(10, 20); --> 30

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Interface Supplier et Récapitulatif des interfaces fonctionnelles /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Interface Supplier ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quatrième type d'interface fonctionnelle, l'interface Supplier, qui construit la méthode get(), ne prenant pas de paramètres :
//     public interface Supplier<T> {
//         public T get();
//     }
// Qu'est ce qu'un Supplier ? Un constructeur vide, qui ne prends pas de paramètres et qui permet de construire un objet est une forme de Supplier
// Comment peut-on écrire un Supplier :
// Supplier<String> bonjour = () -> "Bonjour";
// String s = bonjour.get();
// Supplier<Double> pi = () -> 3.14;
// int i = pi.get();
// Lorsqu'on met () en entrée de la Lambda Expression, cela signifie que celle-ci ne prends pas de paramètres en entrée

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan des interfaces fonctionnelles ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Consumer<T> --> accept(Tt) : le Consumer prends un objet et ne retourne rien
// Supplier<T> --> T get() : le Supplier ne prends rien et retourne un objet
// Predicate<T> --> boolean test(Tt) : le Predicate prends un objet et retourne un boolean
// Function<T, R> --> R apply(Tt) : la Function prends un objet d'un certain type et retourne un objet éventuellement d'un autre type
// Runnable --> void run() : le Runnable ne prends rien et ne retourne rien
// Ces quatre interfaces primordiales sont rangées dans le package : java.util.function, disponible à partir de Java 8
// C'est donc à partir de ces quatre interfaces fonctionnelles qu'on va construire la plupart des Lambdas Expressions qu'on va avoir dans nos applications
// En regardant le package en question, on se rends compte qu'il y a beaucoup plus d'interfaces (entre 40 et 45)
// En fait c'est parce qu'on à toutes les interfaces "Bi", ainsi que les Unary et Binary Operator
// Et on a aussi plein d'interface qui sont spécialisées à un type par exemple des "int Consumer", qui consomme des types int primitifs plutôt que des types integer
// Ces interfaces, il faut connaître leurs catégories, leurs méthodes, et savoir ce que chacune d'entre elles fait
// Il est bien de les connaîtres dans les deux sens, par exemple si on a besoin d'une Lambda qui prends un objet et ne retourne rien
// On doit savoir que l'on a besoin d'une interface Consumer et que sa méthode s'appele accept()
// Enfin la cinquième méthode "Runnable" elle existe depuis Java 1
// Les Lambdas n'ont été introduites qu'à partir de Java 8, mais il y a pas mal d'interfaces qui étaient présentent depuis longtemps
// Celles-ci sont devenues des interfaces fonctionnelles implémentables avec des Lambdas à partir de Java 8, et Runnable en fait partie
// Runnable est utilisée en programmation concurrente, elle modélise une tache en programmation concurrente, donc en programmation multi-thread
// C'est pour ça qu'elle à cette unique méthode void run() qui ne prends rien et ne retourne rien

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Composition des Lamda Expressions /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémenter Comparator avec les lambda ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir l'implémentation d'Expressions Lambdas dans un exemple qui n'a rien a voir avec ce que nous avons vu dans java.util.function
// Cet exemple est l'interface Comparator, présente depuis le tout début de Java, et qui n'a qu'une seule méthode abstraite compare()
//     public interface Comparator<T> {
//         public int compare(T t1,T t2);
//     }
// Prenons un exemple avec un Comparator de chaîne de caractères :
// Comparator<String> c1 = (String s1, String s2) -> s1.compareTo(s2);
// Le résultat est un int qui est < 0 si s1 < s2, il est = 0 si s1 = s2 et il est > 0 si s1 > s2
// Etant donné qu'on a qu'une seule ligne dans cette Lambda Expression, on a pas besoin de mettre d'accolades, ni de préciser de "return"
// s1.compareTo(s2) est bien un entier, donc le compilateur va associer cet entier à l'entier déclaré dans l'interface, et il n'y aura pas d'erreur
// Danc cet exemple-ci, le Comparator est celui qui compare les deux chaînes de caractères en les classant par ordre alphabétique
// On peut prendre un autre exemple :
// Comparator<String> c2 = (s1, s2) -> s2.compareTo(s1);
// Ce Comparator-ci va nous permettre de trier les éléments dans l'ordre inverse alphabétique
// Comparator<String> c3 = (s1, s2) -> Integer.compare(s1.length(), s2.length());
// Cette méthode compare(), propre aux integer va nous retourner un entier qui obéit exactement à la même sémantique que compareTo()

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Composition ou Chaînage des lambda expressions ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir maintenant un point très important et même fondamental de la programmation avec les Lambdas Expressions
// Il s'agit de la composition des Lambdas Expressions, nous parlerons parfois de combinaisons ou de chaînages
// Cela va nous servir à construire de nouvelles instances d'interfaces fonctionnelles sans écrire de Lambdas Expressions explicitement
// Nous allons donc combiner des Lambdas Expressions entre elles pour créer ces nouvelles instances
// Nous allons voir plusieurs exemples et le premier exemple est celui de l'interface Consumer
// Nous n'allons pas travailler avec la vraie interface Consumer du JDK, mais plutôt avec cette interface Consumer, une copie simplifiée de cette interface dans Eclipse :
// A partir de celle-ci nous allons pouvoir recréer la véritable interface Consumer disponible dans java.util.function
// Nous allons commencer par écrire une première implémentation de cette interface Consumer :
/*
    package org.vitu;
    import org.vitu.function.Consumer;

    public class PlayWithConsumer {

        public static void main(String[] args) {

            Consumer<String> c1 = s -> System.out.println("c1 = " + s);
            Consumer<String> c2 = s -> System.out.println("c2 = " + s);

            Consumer<String> c3 = s -> {
                c1.accept(s);
                c2.accept(s);
            };

            c3.accept("Bonjour");

        }

    }
*/
// Lorsqu'on lance ce projet, cela retourne :
// --> c1 = Bonjour
// --> c2 = Bonjour
// Mais ce n'est pas tout à fait comme ça que l'on souhaite l'écrire, on voudrais plutôt :
// --> c3 = c1.andThen(c2);
// Evidemment cette méthode ne se compile pas, il va donc falloir la créer :
// Clairement cette méthode andThen est définie sur l'interface Consumer
// Quand on veux ajouter une méthode à une interface ou à une class, il faut se poser trois questions :
// - Est-ce qu'il s'agit d'une méthode d'instance, ou est-ce qu'il s'agit d'une méthode classique ?
// La façon dont on appelle cette méthode andThen sur une instance de Consumer en fait clairement une méthode d'instance
// Si c'était une méthode classique on l'appellerait directement sur l'interface à partir du nom de l'interface
// - Qu'est-ce que cette méthode prends en paramètres ?
// C'est assez clair de la façon dont on l'a écrite, elle prends un Consumer en paramètre, donc une instance de l'interface Consumer
// - Qu'est-ce que cette méthode retourne ?
// andThen et affecté dans un objet de type Consumer, donc ce que doit retourner cette méthode andThen est également une instance de Consumer
// Maintenant nous pouvons la constuire dans le'interface Consumer :
// --> Consumer<T> andThen(Consumer<T> other);
// Evidemment, cette méthode andThen, si on en fait une méthode abstraite, l'interface Consumer ne sera plus une interface Fonctionnelle
// En effet, une interface fonctionnelle ne peut avoir qu'une seule méthode abstraite
// Donc cette méthode andThen est nécessairement une méthode concrête
// On peut ajouter des méthodes concrêtes à une interface fonctionnelle à condition d'en faire des méthodes par défaut
// Pour ça on utilise le mot clef "default" en début de déclaration
// Ce mot clef "default" fait d'une méthode concrête une méthode par défaut
// On a donc trois type de méthode sur les interfaces fonctionnelles :
// - Les méthodes abstraites
// - Les méthodes statiques
// - Les méthodes concrêtes, méthodes par défaut
// La possibilité de mettre des méthodes statiques et des méthodes concrêtes dans des interfaces fonctionnelles est apparu dans Java 8
// Jusqu'à Java 7 on ne peut mettre que des méthodes abstraites sur des interfaces fonctionnelles
// Pour l'instant cette méthode ne compile pas car on a déclarer qu'elle doit retourner un Consumer
// Si on met "return null", cela fonctionne
// Il faut maintentant que l'on ajoute un corps de méthode à andThen :
// Ce corps de méthode doit prendre un objet de type T, qui est l'objet que l'on doit consommer avec le Consumer que l'on est en train de construire
// Ce paramètre T doit être consommer d'abord avec le Consumer c1, puis avec le Consumer c2
// Le consommer veut donc dire executer sa méthode accept en lui passant le paramêtre T
/*
    package org.vitu.function;

    public interface Consumer<T> {

        void accept(T t);

        default Consumer<T> andThen(Consumer<T> other) {
            return (T t) -> {
                this.accept(t);
                other.accept(t);
            };
        }

    }
*/
// Le mot clef "other" nous sert à utiliser c2 qui est le paramêtre, et "this" prends c1
// Maintenant on peut retourner dans notre PlayWithConsumer class :
/*
    package org.vitu;
    import org.vitu.function.Consumer;

    public class PlayWithConsumer {

        public static void main(String[] args) {

            Consumer<String> c1 = s -> System.out.println("c1 = " + s);
            Consumer<String> c2 = s -> System.out.println("c2 = " + s);

            //Consumer<String> c3 = s -> {
            //	c1.accept(s);
            //	c2.accept(s);
            //};

            Consumer<String> c3 = c1.andThen(c2);

            c3.accept("Bonjour");

        }

    }
*/
// Maintenant, cela retourne bien :
// --> c1 = Bonjour
// --> c2 = Bonjour

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Protection de la composition //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous n'avons pas tout à fait terminé notre travail en fait
// Si on passe null à la méthode andThen, on obtien une "null pointer exception" ligne 11 de notre interface
// Effectivement, "other" attends un paramètre et si on lui passe null, il nous jette cette null pointer exception
// C'est assez ennuyant car notre méthode ne va pouvoir faire que jeter des erreurs
// Ce qui est ennuyant c'est que cette méthode peut-être construite sans aucune erreur nulle part...
// Il faut donc se protéger contre la création de Consumer corrompus
/*
	default Consumer<T> andThen(Consumer<T> other) {
		Objects.requireNonNull(other);
		return (T t) -> {
			this.accept(t);
			other.accept(t);
		};
	}
*/
// En utilisant la méthode Objects.requireNonNull sur other, on se protège
// Maintenant si on relance le code avec la mméthode andThen qui prends null,
// L'erreur jetée nous précise que cela vient de la ligne ou on passe null et non de la méthode andThen
// --> Consumer<String> c3 = c1.andThen(null);
// En conclusion :
// - On peut combiner ou chaîner des Lambdas Expressions en utilisant des méthodes par défaut
// Ainsi qu'en créant des interfaces par défaut sur des interfaces fonctionnelles implémentées par nos Lambdas Expressions
// - Il est absolument indispensable de se protéger contre la création de Lambdas Expressions corrompues

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Composition de Predicat ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On créé une interface Predicate dans le package function
// On créé une classe dans laquelle on a 3 prédicats, l'un qui regarde si la chaine est nulle, le second si la chaine est vide
// Le dernier est une combinaison des deux premières et nous dit si la chaine est non nulle et non vide
// --> Predicate<String> p3 = p1.and(p2);
// On va se poser les trois mêmes questions :
// - On l'appelle sur une instance et pas sur l'interface, donc c'est une instance
// - Elle prends en paramètre un prédicat
// - On affecte le retour de cette méthode dans une variable de type prédicat, donc elle retourne un prédicat
/*
    package org.vitu.function;

    public interface Predicate<T> {

        boolean test(T t);

        default Predicate<T> and(Predicate<T> other) {
            return (T t) -> this.test(t) && other.test(t);
        }
    }
*/
// Et notre classe :
/*
    package org.vitu;

    import org.vitu.function.Predicate;

    public class PlayWithPredicate {

        public static void main(String[] args) {

            Predicate<String> p1 = s -> s!= null;
            Predicate<String> p2 = s -> !s.isEmpty();

            Predicate<String> p3 = p1.and(p2);

            System.out.println("p3 est false pour une chaine nulle : " + p3.test(null));
            System.out.println("p3 est false opur une chaine vide : " + p3.test(""));
            System.out.println("p3 est true pour une chaine non nulle et non vide : " + p3.test("Bonjour"));

        }

    }
*/
// Le code se compile bien, pourtant on se retrouve exactement face au même problème qu'avec l'interface Consumer :
// C'est à dire que si le paramètre "other" est null, on ne pourra rien faire d'autre qu'avoir une nullPointerException
// On ajoute donc dans la méthode "and" : Objects.requireNonNull(other);
// On peut même aller un peu plus loin avec cette interface prédicat :
// Supposons que p2 soit vrai non pas quand la chaine est non vide, mais quand la chaine est vide
// On aimerait faire une opération de négation sur ces prédicats : Predicate<String> notP2 = p2.negate();
// On peut donc créer cette méthode de la même façon que la méthode and :
/*
	default Predicate<T> negate() {
		return (T t) -> !this.test(t);
	}
*/
// Maintenant on peut créer un prédicat p4 :
/*
    package org.vitu;

    import org.vitu.function.Predicate;

    public class PlayWithPredicate {

        public static void main(String[] args) {

            Predicate<String> p1 = s -> s!= null;
            Predicate<String> p2 = s -> !s.isEmpty();

            Predicate<String> notP2 = p2.negate();

            Predicate<String> p3 = p1.and(p2);

            Predicate<String> p4 = p1.and(notP2);

            System.out.println("p3 est false pour une chaine nulle : " + p3.test(null));
            System.out.println("p3 est false opur une chaine vide : " + p3.test(""));
            System.out.println("p3 est true pour une chaine non nulle et non vide : " + p3.test("Bonjour"));
            System.out.println("p4 est true pour une chaine non nulle et vide : " + p4.test("Bonjour"));
        }

    }
*/

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comparateur de User avec fonction d'extraction ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernier exemple, celui du Comparator
// On a créé l'interface Comparator, et une classe User très simple, un bean classique
// Bean avec deux variables déclarées en privé, puis deux Constructor, un vide et un qui prends la valeur des champs don on retire le super()
// On y ajoute des getter and setter, ainsi qu'une méthode override toString()
/*
    package org.vitu.model;

    public class User {

        private String name;
        private int age;

        public User() {
        }

        public User(String name, int age) {
            super();
            this.name = name;
            this.age = age;
        }

        public String getName() {
            return name;
        }

        public void setName(String name) {
            this.name = name;
        }

        public int getAge() {
            return age;
        }

        public void setAge(int age) {
            this.age = age;
        }

        @Override
        public String toString() {
            return "User [name=" + name + ", age=" + age + "]";
        }

    }
*/
// Maintenant dans notre code on créé notre comparaison :
/*
    package org.vitu;

    import org.vitu.function.Comparator;
    import org.vitu.model.User;

    public class PlayWithComparator {

        public static void main(String[] args) {

            User kylian = new User("Kylian", 20);
            User ngolo = new User("NGolo", 28);
            User blaise = new User("Blaise", 32);

            Comparator<User> cmp = (u1, u2) -> {
                String name1 = u1.getName();
                String name2 = u2.getName();
                return name1.compareTo(name2);
            };

            System.out.println("Kylian < NGolo : " + (cmp.compare(kylian, ngolo) < 0));
            System.out.println("Blaise < NGolo : " + (cmp.compare(blaise, ngolo) < 0));
            System.out.println("Blaise < Kylian : " + (cmp.compare(blaise, kylian) < 0));

        }

    }
*/
// Ici on retourne la comparaison du nom des deux utilisateurs
// Pour la classe String, on peut utiliser la méthode compareTo()
// Le code fonctionne bien, mais on peut utiliser une function à la place :
/*
    Comparator<User> cmp = (u1, u2) -> {
        String name1 = getName.apply(u1);
        String name2 = getName.apply(u2);
        return name1.compareTo(name2);
    };
*/
// Une fois arrivé là on peut se dire que la construction de ce Comparator de User, de quoi dépends t-il ?
// Il y a une astuce, on sélectionne le bloc de code et on demande à Eclipse de l'extraire dans une méthode :
// Ctrl+Shift+1 : il nomme la méthode extrated, et cette méthode prends en paramètre uniquement la function getName()
// La construction de se Comparator ne dépends que de la function que je viens d'écrire
// Maintenant on peut couper cette méthode extracted et la coller dans notre interface fonctionnelle
// On peut le faire car c'est une méthode static, une méthode factory de l'interface Comparator
// Méthode factory veut dire qu'elle est capable de construire des instances de l'interface Comparator
// Ctrl + Shift + 1 : Inline local variables sur name1 et sur name2 pour avoir tout sur une ligne
// Vu qu'on à plus qu'une ligne on peut à présent retirer les {} et le return dans la Lambda Expression
// De la même façon que précédemment, on se rends compte que si notre keyExtractor est null
// On va donc retourner une Lambda qui ne pourra rien faire d'autre que nous retourner une nullPointerException
// On peut aller encore un peu plus loin : le fait que ce soit un User que cette fonction prends en paramètre, n'est pas utilisé dans le code qui est ici
// Ca pourrait être en fait, n'importe quel type d'objet, ce Comparator est un Comparator de T
// Cette fonction tout ce qu'on veut c'est qu'elle prenne des objets de type T et qu'elle retourne des chaines de caractères
/*
    package org.vitu.function;

    import java.util.Objects;
    import java.util.function.Function;

    //import org.vitu.model.User;

    @FunctionalInterface
    public interface Comparator<T> {

        int compare(T t1,T t2);

    //	static Comparator<User> comparing(Function<User, String> keyExtractor) {
    //		Objects.requireNonNull(keyExtractor);
    //		return (u1, u2) -> keyExtractor.apply(u1).compareTo(keyExtractor.apply(u2));
    //	}

        static <T> Comparator<T> comparing(Function<T, String> keyExtractor) {
            Objects.requireNonNull(keyExtractor);
            return (u1, u2) -> keyExtractor.apply(u1).compareTo(keyExtractor.apply(u2));
        }
    }
*/

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comparateur de User avec fonction d'extraction ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Allons un peu plus loin et créons une fonction qui va prendre un User et retourner son age
// --> 	Function<User, Integer> getAge = user -> user.getAge();
// Et nous allons renommer l'ancien Comparator cmpName car nous allons créer un nouveau Comparator cmpAge
// --> Comparator<User> cmpAge = Comparator.comparing(getAge);
// Là nous avons un problème de compilation car notre méthode factory "comparing" prends T (donc ça peut être un User), mais retourne un String
// Or getAge retourne un Integer, d'où l'erreur de compilation
// Cela dit en regardant les choses d'un peu plus près, on se rends compte que le Comparator n'a pas vraiment besoin que le keyExtractor retourne un String
// La seule chose que l'on utilise sur l'objet retourné par le keyExtractor, c'est le fait que cet objet possède une méthode compareTo
// Or la méthode compareTo() est définie sur une interface qu'on appelle "Comparable"
// Cette interface Comparable ne définit qu'une méthode abstraite, c'est donc une interface fonctionnelle qui s'appelle compareTo()
// Donc dans la déclaration de mon Comparator, on a pas besoin de déclarer un String, mais seulement un objet comparable
// On va donc remplacer String par un objet de type U, et déclarer au début après T, U qui extends Comparable
// Or, Comparable est une interface qui est elle-même paramétrée par un objet de type T
// Maintenant keyExtractor retourne bien un objet qui possède une méthode compareTo(), donc on a le droit d'appeler la méthode compareTo() sur cet objet
/*
	static <T, U extends Comparable<U>> Comparator<T> comparing(Function<T, U> keyExtractor) {
		Objects.requireNonNull(keyExtractor);
		return (u1, u2) -> keyExtractor.apply(u1).compareTo(keyExtractor.apply(u2));
	}
*/
// Aussi notre code appelant va également pouvoir se compiler car String en tant que type étends le type comparable de String
// Et que la classe Integer en tant que type, étends également le type Comaparable
// Si une classe implémente une interface, on dit que le type représenté par cette classe étends le type représenté par cette interface
// Si on a créé ce deuxième Comparator c'est pour pouvoir créer un troisième Comparator qui combine les deux précédents
// --> Comparator<User> cmp = cmpName.thenComparing(cmpAge);
// - On l'appelle sur un Comparator qui existe donc c'est une méthode d'instance et non static
// - On prends un Comparator en paramètre
// - On retourne un Comparator
// Donc on peut commencer à l'écrire comme les précédents, on return null et ça compule, puis on ajoute les deux paramètres entre parenthèses puis -> 0 et ça compile encore
// Donc on peut à présent mettre des {} et réfléchir à ce qu'on va mettre dedans
// On compare d'abord avec this pour le name, puis on compare other avec age au cas où les noms sont les mêmes
// Il faut toutefois aussi se protéger dans notre nouvelle méthode
/*
	default Comparator<T> thenComparing(Comparator<T> other) {
		Objects.requireNonNull(other);
		return (T t1,T t2) -> {
			int compare = this.compare(t1, t2);
			if (compare == 0) {
				return other.compare(t1, t2);
			} else {
				return compare;
			}
		};
	}
*/
// Cela dit, le code ci-dessus n'est pas encore totalement satisfaisant
// Les deux Comparator que l'on combine dépendes directement de la function d'extraction qu'on a utilisée
// La fonction qui permet d'extraire le nom de l'utilisateur et celle qui permet d'extraire son age
// Donc il faudrait passer directement à l'API ces fonctions d'extractions qui sont les véritables informations qui nous permettent de construire le comparateur combiné
// Et que l'API se débrouille toute seule pour construire les comparateurs intermédiaires et pour les combiner directement
// On va commencer par inliner cmpName et ensuite passer getAge en paramètre de then Comparing
// Ainsi nous n'aurons plus besoin du Comparator cmpAge
// Nous avons donc ce que nous souhaitons réellement, un Comparator qui compare d'abord deux utilisateurs en fonction de leur nom, puis en fonction de leur age
// Pourtant nous avons à présent une erreur de compilation, caar la méthode thenCompring() qu'on à écrite ne prend spas une fonction en paramètre, mais un Comparator
// On a donc besoin d'une autre méthode thenComparing(), qui va prendre une fonction en paramètre
/*
	default <U extends Comparable<U>> Comparator<T> thenComparing(Function<T, U> keyExtractor) {
		return null;
	}
*/
// On a ajouté U en déclaration de la méthode car celle-ci n'était pas définie lorsqu'on l'appelait dans thenComparing()
// Maintenant comment est-ce qu'on peut implémenter cette méthode ?
// On créée une autre méthode que l'on va directement créer comme une méthode par défaut, et qui porte le même nom que la méthode thenComparing() déjà existante
// Elle ne va pas prendre pour paramètre un Comparator mais une function qui prends un objet de type T (ici un User)
// Cette fonction va retourner un objet de type U, qui doit lui aussi être un objet comparable, puisqu'on va appeler une méthode compareTo() dessus
// Cette fonction, on va aussi l'appeler keyExtractor()
// Le paramètre U n'est pas défini au niveau du comparator mais on peu le définir au niveau de la méthode
// Exatement comme on avait fait pour la méthode factory, on va dire qu'il étends Comparable<U>, car cette fonction doit nous retourner des objets comparables
// Donc maintenant on créé Comparator de T que l'on appelle "other", à partir de la méthode factory qu'on a "comparing", passant keyExtractor en paramètre
// Ceci nous créé le Comparator "other"
// Et enfin, nous pouvons retourner this.thenComparing(other), en appellant l'autre méthode par défaut que l'on vient de programmer
/*
	default <U extends Comparable<U>> Comparator<T> thenComparing(Function<T, U> keyExtractor) {
		Comparator<T> other = comparing(keyExtractor);
		return this.thenComparing(other);
	}
*/
// Dans cette méthode thenComparing(), on pourrait écrire la Lambda Expression explicitement
// Mais en fait on est pas obligé de le faire car on a déjà une méthode factory qui nous permet de créer un comparateur a partir d'une fonction d'extraction
// Ainsi qu'une méthode thenComparing() qui nous permet de combiner deux comparateurs existants
// Donc on va s'appuyer sur ce code pour créer cette méthode
// On ajoute un User qui à le même nom que Blaise mais qui est plus jeune pour tester la méthode
// --> Voila comment on peut s'appuyer sur des méthodes statiques et des méthodes par défaut pour construire des comparateurs de façon simple
// - Le premier objectif est de déporter tout le code technique et complexe dans l'API, de le masquer dans les interfaces fonctionnelles
// Ainsi on peut avoir un code applicatif le plus simple possible qui va pouvoir utiliser le code de cet API qui est plus complexe
// - Le second objectif est d'avoir un code beaucoup plus robuste car toute la gestion des erreurs est reportée vers l'API
// Ainsi on a moins de bug dans le code applicatif, et si les API ont été bien faites, on a normalement aucun bug côté API aussi

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Conclusion Composition ou Chaînage des lambda expressions /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour conclure, nous pouvons aller regarder la vraie interface Consumer de java.util.function
// Elle a bien une méthode accept, mais elle a bien aussi une méthode andThen qui permet de chainer des Consumer
// Celle-ci ressemble tout à fait à la méthode que l'on à écrite
// Dans l'interface Predicate on a bien la méthode test, ainsi qu'une méthode and() et une méthode negate()
// On a aussi pour Predicate une méthode or() et une méthode isEqual(), cette dernière va nous permettre de comparer un prédicat à une référence qui elle, est fixée
// La vraie interface Comparator renferme tout une collection de méthodes par défaut et de méthodes factory
// L'interface function à bien la méthode apply, et on a aussi andThen() qui permet de faire du chainage de fonctions
// Elle a aussi une méthode factory qui permet de construire la fonction identity()
// --> Les méthodes static et les méthodes par défaut sont une possibilité technique qui a été introduite en Java 8
// C'est aujourd'hui massivement utilisé, à la fois pour construire des API, et au premier rang desquels bien sûr, les API du JDK
// C'est également utilisé pour construire les applications
//      --> Le mot clef default --> permet de définir une méthode concrète
//      --> La méthode andThen --> retourne une lambda expression
//      --> Aucun méthode --> est une méthode statiques
//      --> La seconde méthode --> est une méthode d'instance
//      --> Objects.requireNonNull(other) --> permet  de jeter une exception plus proprement
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définition avancée des lambda Expressions /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définition complète d'une interface fonctionnelle /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous revenons quelques instants sur cette notion d'interface fonctionnelle
// Nous avons vu qu'à partir de Java 8, une Lambda Expression est l'implémentation d'une interface fonctionnelle
// Ce ne sont pas des classes, ce sont nécessairement l'implémentation d'interfaces, et ces interfaces sont fonctionnelles
// Qu'est-ce qu'une interface fonctionnelle :
// - C'est une interface
// - Elle n'a qu'une unique méthode abstraite
// Dans certain cas nous pouvons aussi avoir une méthode par défault et une méthode statique comme par exemple or() et equals() respectivement pour Predicate
// Ces méthodes ne sont pas abstraites donc on peut en avoir autant qu'on veut
// - Les méthodes de la classe "Object" ne comptent pas (par exemple la méthode .requireNonNull())
// Pourquoi aurait-on envie de mettre une méthode de la classe Object dans une interface fonctionnelle ? Ou dans une interface tout court d'ailleurs ?
// En fait, cette méthode, définie dans l'interface ne va rien imposer pour l'implementation, étant donné que tout est "Object" dans Java, sauf les Lambdas
// Donc tous les objets que l'on va construire vont avoir ces méthodes de la classe Object, mécaniquement
// La vraie raison est que quelque fois nous avons besoin de préciser la sémantique de ces méthodes
// Par exemple dans l'interface Collection, nous avons la définition de la méthode equals(), ça ne sert à rien car la méthode equals() est de base dans toutes les implémentations de Collection
// Effectivement, Collection ne peut pas être implémentée avec une Lambda Expression
// Cette méthode equals() s'y trouve à cause de la documentation qui y est atachée, en effet celle-ci précise ce que cela veux dire que deux Collections soient égales
// - L'anotation @FunctionalInterface, qui se situe sur toutes les interfaces fonctionnelles de java.util.fonction, cette annotation est optionnelle
// Si on met cette option sur une interface, et que dans cette interface nous avons plusieurs méthodes abstraites, cette interface ne sera pas fonctionnelle et nous aurons une erreur de compilation
// C'est donc une sécurité qui permet de voir dès la compilation si une interface est fonctionnelle ou non
// Cette annotation est optionnelle pour des raisons de compatibilité ascendante : si on a du vieux code antérieur à Java 8, on a pas besoin de le recompiler
// En effet, les interfaces qui n'ont qu'une seule méthode abstraite dans ce vieux code deviennent fonctionnelles mécaniquement en Java 8 et peuvent être implémentées avec des Lambdas sans modifications
// Si cette annotation avait été rendue obligatoire, il aurait fallu que l'on reprenne notre vieux code que l'on y ajoute cette annotation partout et que l'on recompile ce code pour pouvoir implémenter mes vieilles annotations avec des Lambdas Expressions
// Avec cette option nous pouvons donc demander confirmation au compilateur du caractère fonctionnel de l'interface qui est annotée

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les lambda expressions sont-elles des objets ? ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// On a vu qu'en Java, toutes les structures que l'on pouvait créer, les méthodes sont nécessairement enregistrées dans des classes
// On y accède soit au niveau du nom de la classe pour les éléments statiques soit à l'aide d'une instance pour les éléments non-statiques
// Mais dès l'instant qu'on veut créer une méthode, donc éxecuter du code, on est obligé de le mettre dans une classe et donc d'y accéder au travers d'un objet
// Quand on écrit le code suivant : User user = new User();
// Et le code suivant : Predicate<String> p = s -> s.isEmpty();
// --> Nous avons une différence fondamentale entre ces deux lignes, c'est qu'on utilise le mot clef "new" dans la première déclaration et non dans la seconde
// Dans la première ligne nous demandons a la machine Java de nous créer un objet de type User alors que dans la seconde ligne nous ne faisons pas cette demande
// Donc la machine Java est libre de nous créer un objet ou de ne pas nous créer un objet, elle est donc libre de faire ce qu'elle veut de l'éxecution de ce code
// Combien de cas dans Java, peut-on créer un objet sans déclarer de "new" :
// - La déclaration de la Lambda Expression en est une
// - String s = "Bonjour"; --> Ce faisant la machine Java va nous créer un objet de type String qui va prendre la valeur "Bonjour"
// Si toutefois un peu plus loin dans notre code, nous avons un String s2 qui est également égal à "Bonjour", là la machine Java va pouvoir mettre en place une optimisation
// La machine Java sait que la chaîne de caractères "Bonjour" est essentiellement immutable, donc s2 va pointer vers le même objet que s
// Elle a le droit de faire ça car nous ne lui demandons pas explicitement de créer un nouvel objet
// - int[] tab = {1, 2, 3}; --> c'est une création de tableau est c'est parfaitement légal, et on n'utilise pas "new"
// --> Ce sont les trois seuls cas qui existent dans Java, dans lequel on peut créer des structures, des éléments, sans le mot clef "new", donc sans demander la création explicite d'un objet
// Comment est-ce que ça se passe pour les Lambdas Expressions ?
// Pour les Lambdas Expressions nous avons une instruction de ByteCode particulière qui s'appelle 'INVOKE DYNAMIC', qui a été introduite en Java 7 pour les langages dynamiques
// Cette instruction a par la suite été récupérée dans Java 8 pour implémenter les Lambdas Expressions
// Cette instruction de ByteCode va passer la main à un morceau de code, qui est bien sûr connu à la compilation, mais qui par nature va pouvoir change d'une version Java à une autre
// Donc une Lambda Expression est toujours compilée de la même manière, avec une INVOKE DYNAMIC
// Mais ce dernier peut lui même passer la main à un morceau de code qui pourra changer dans le futur
// Aujourd'hui ce morceau de code, il se trouve que c'est une méthode statique, qui est privée, et créée par le compilateur, et qui se trouve dans la classe où on a créé notre Lambda Expression
// Mais il se peut très bien que dans les versions futures de Java, ce soit autre chose, car INVOKE DYNAMIC donne cette possibilité de changer ce qui est appelé
// --> Donc en fait une Lambda n'est pas vraiment un objet : invoquer une Lambda est en fait invoquer une méthode statique qui se trouve dans la classe ou la Lambda a été créée
// --> Il n'y a donc pas de véritable objet derrière
// --> Une Lambda Expression est donc un "Objet qui n'a pas d'identité"
// Mais donc une question se pose : si ce n'est pas un objet, est-ce qu'on a une méthode equals() ? une méthode hashCode() ? Une méthode toString() ?
// La réponse est oui. On peut faire p.toString(), le compilateur va accepter ça et la JVM va executer ce code
// Mais si on fait ça, nous allons perdre les possibilités d'optimisation que la JVM peut mettre en place
// Et ce, du fait qu'une Lambda Expression est juste l'invocation d'une méthode statique, au premier rang desquelles se trouve l'inlining du code
// Si jamais on commence a appeler toString(), hashCode()... on aura des résultats (qui n'ont aucun intérêt d'ailleurs) qui vont probablement être faux
// En effet, appeler equals() pour comparer des Lambdas Expressions n'a absolument aucun sens, tout comme hashCode()
// Et surtout, la JVM ne pourra pas mettre en place toutes les optimisations qu'elle peut mettre en place dans le cadre des Lambdas Expressions
// --> Donc une Lambda Expression est-elle un objet ? La réponse est ni-oui ni-non, quelque chose entre les deux
// --> La réponse est un peu oui car on peut appeler les méthodes toString(), hahsCode() ou equals()
// --> La réponse est aussi non car en fait il ne faut pas le faire, car si on le fait, les Lambdas Expressions seront beaucoup moins rapides en terme d'éxecution

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Syntaxe des Method Reference //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour écrire des Lambdas Expressions en Java nous pouvons aussi utiliser la syntaxe des Methods References
// C'est une méthode différente pour écrire les Lambdas Expressions que celle qu'on à utilisée jusqu'à maintenant avec la ->
// Avant on faisait : Consumer<String> c = s -> System.out.println(s)
// Ici on voit que la méthode println(), invoquée sur l'obket System.out prends en paramètre une chaîne de caractères s qui est précédemment déclarée
// --> System.out::println est l'équivalence avec l'écriture classique
// Dans un IDE, pour Eclipse par exemple, on peut modifier l'écriture en ouvrant le menu contextuel avec ctrl + 1
// Dans ce menu Eclipse va nous proposer de convertir la Lambda Expression avec une Method Reference
// Quel est l'intérêt d'écrire une Method Reference plutôt qu'une Lambda Expression ?
// --> Le premier intérêt est la lisibilité du code, plus facile a lire et donc à corriger
// --> Le second intérêt est la performance qui sera légèrement meilleure :
// Une Lambda Expression va invoquer une métode statique alors qu'une Method Reference ne fait pas cette invoquation
// On a en tout quatre type de Method Reference :
// - Bound Instance : veut dire qu'on invoque une méthode sur une instance donc sur un objet
// --> s -> System.out.println(s); --> System.out::println
// Ca y ressemble mais ce n'est pas une méthode statique, c'est une méthode d'instance sur un objet
// - Static : d -> Math.sqrt(d); --> Math::sqrt
// La nous avons un Unary Operator, qui prends un double, et retourne un double
// Cette fois-ci, ce qu'on met avant les :: est un nom de type, qui peut être une classe, une interface, une classe abstraite, et après nous avons un nom de méthode
// - Unbound Instance : (s1, s2) -> s1.indexOf(s2); --> String::indexOf
// La nous avons une bi-fonction qui prends deux chaînes de caractères et qui nous retourne un entier
// Ici on remarque que la méthode de cette fonction est invoquée sur le premier élément s1 et prends en paramètre s2
// Donc si nous avions 5 paramètres à cette Lambda Expression, la méthode indexOf() sera appliquée sur le premier paramètre, et les 4 autres paramètres seront passés en paramètres de cette méthode
// Cette Method Reference à une apparence d'appel statique, mais ce n'en est pas un, la méthode indexOf() est une méthode d'instance
// - Constructor : name -> new User(name); --> User::new
// Ici nous avons une fonction qui prends un String, et qui nous retourne une instance de ce String
// Comment peut-on savoir que User::new correspond bien à name retourne new User ?
// Nous pourrions très bien également écrire un supplier qui ne prends pas de paramètres : () -> new User();
// Nous pourrions aussi écrire une bifonction : (name, age) -> new User(name, age);
// Mais en fait, toutes ces trois Lambdas Expressions sont mapées sur la même Method Reference
// User::new va désigner ces trois Lambdas Expressions
// Comment peut-on les distinguer ? On peut les distinguer grâce au type de la Method Reference
// Ce qui est donc important dans ces 4 Method Reference, c'est d'en connaître le type
// Si on ne connaît pas le type d'une Method Reference, on ne peut pas la redéployer sous forme d'une Lambda Expressions
// La bonne nouvelle, c'est qu'une Method Reference, comme toute variable en Java, on en connaît systématiquement son type :
// Ca peut être un champs, une constante, un paramètre de méthode, une variable locale à l'intérieur d'une méthode
// On connaît toujours le type de ce qu'on manipule en Java à la compilation
// Donc si on veut comprendre exactement ce que fait une Method Reference, on a besoin de connaître son type
// Et c'est à partir de son type que l'on peut remonter à la Lambda Expression que l'on avait à l'origine

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les lambda Expressions et l'Api Collection ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Traiter les éléments d'une liste //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'arrivée des Lambdas Expressions en Java a eu un impact très important sur l'ensemble des API du JDK
// En particulier avec les API qui s'occupent du traitement des données en mémoire
// Jusqu'a Java 8 on avait que l'API Collection qui s'occupait du traitement des données en mémoire, et a partir de Java 8 on a l'API Stream qu'on verra plus tard
// L'API Collection a été très modifiée par l'arrivée des Lambdas
// Et notamment on a un certain nombre de méthodes qui prennent des Lambdas Expressions en paramètre et qui ont été ajoutées aux différentes interfaces de Collection
// On trouve ces nouvelles méthodes dans les deux hiérarchies de l'API Collection, la hiérarchie Map et la hiérarchie Collection
// Par exemple : List<String> strings = ... ; (one, two, three, four, five)
// La première méthode est définie sur l'interface Iterable (la super interface de Collection)
// Iterable<String> va prendre la méthode forEach(Consumer<String> c);
// Un consumer de String car c'est pour Iterable<String> qui est la super interface de List<String>
// Comment on fait pour appeler strings.forEach() ? Il faut lui passer un Consumer en paramètre
// --> strings.forEach(s -> System.out.println(s));
// Ce forEach va donc appliquer le Consumer à chacun des éléments de la Collection
// Si on est dans une List, ça sera les éléments dans l'ordre, et si on est dans un Set ou une Collection, ce sera les éléments dans n'importe quel ordre
// Si on est dans un sortedSet, ce sera les éléments dans l'ordre de leur tri
// Cela nous évite de passer par une boucle for qui va traiter tous les éléments d'une Collection un par un, ce que l'on appele une itération externe
// Ainsi, à l'intérieur du forEach, on a une itération sur la Collection

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Retirer des éléments d'une Collection /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La seconde méthode est définie sur Collection, dans notre exemple Collection<String>, c'est la méthode removeIf()
// removeIf(Predicate<String> p); --> s est retiré de la Collection si p.test(s) est true (prédicat retourne un boolean)
// Ce prédicat va donc être appliqué à tous les éléments de la Collection sur laquelle on applique removeIf()
// Si le prédicat retourne true, l'élément est retiré
// Attention : cela suppose que la List sur laquelle on applique cette méthode soit une liste qui supporte le remove soit une liste mutable
// La liste qui est retournée par erase.asList() ne supporte pas le remove (mais le replace)
// Si on construit notre liste avec List.of, ça nous retourne une liste immutable qui ne supporte pas le remove non plus
// Exavtement comme le forEach() le removeIf() va itérer en interne sur la Collection
// C'est donc un moyen pour remplacer une itération externe avec une boucle for ou un while par une itération interne

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transformer les éléments d'une List ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La troisième méthode ajoutée sur List, donc pour suivre notre exemple sur List<String> : replaceAll()
// Cette méthode va faire comme les deux précédentes et effectuer une itération interne sur la Collection
// Il va donc appliquer une transformation sur tous les éléments de cette liste
// Cette transformation est contrainte, car étant donné qu'il va prendre un élément d'une liste et le remplacer par un autre élément dans la même liste
// Cet autre élément sera nécessairement du même type, la Lambda Expression associée pourrait être une function
// Mais la Lambda Expression qui prends un élément d'un type et retourne un élément du même type est en fait un Unary Operator
// --> replaceAll(UnaryOperator<String> op);
// Attention : replaceAll() ne fait pas de remove, il fait juste un remplacement, donc replaceAll() va fonctionner sur les listes qui supportent le remplacement
// Par exemple, erase.asList() retourne une liste qui supporte le remplacement
// En revanche, List.of est toujours une liste immutable donc on ne peut pas faire de remplacement dessus

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Trier les éléments d'une List /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernière méthode ajoutée à l'API Collection, du moins sur la partie Collection de l'API Collection : c'est la méthode sort()
// --> sort(Comparator<String> c);
// Cette méthode va trier les éléments d'une liste en fonction du comparator qui est passé en paramètre
// Elle n'a pas été définie sur Collection parce que dans une Collection ou dans un Set, on a pas de notion de tri des éléments
// Donc ça n'a pas de sens de vouloir trier les éléments d'une Collection ou d'un Set, ça n'a de sens que pour une List ou un sortedSet (mais ce dernier trie déjà les éléménts)
// Donc voila pour les 4 méthodes qui ont été ajoutées à la structure de Collection dans l'API Collection à l'occasion de la sortie de Java 8
// Ainsi que dans l'introduction des Lambdas Expressions

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Exemple de traitement d'une liste de String ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si on prends par exemple notre liste : List<String> strings = ...; (one, two, three, four, five)
// Pour commencer on va retirer les éléments qui commencent par la lettre f :
// strings.removeIf(s -> s.startWith("f")); --> avec un predicate
// On aura pour résultat : (one, two, three)
// Supposons que l'on veuille mettre les éléments de notre liste en majuscule :
// strings.replaceAll(s -> s.toUpperCase()); --> avec un UnaryOperator
// On aura pour résultat : (ONE, TWO, THREE)
// Supposons maintenant que l'on veuille trier dans l'ordre inverse de l'ordre alphabétique nos éléments :
// strings.sort(Comparator.naturalOrder().reversed()); --> avec un Comparator
// Ici on utilise deux méthodes factory de l'interface Comparator
// Supposons enfin que l'on veut afficher notre résultat :
// strings.forEach(s -> System.out.println(s)); --> avec un Consumer

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Traitement sur Table de hachage avec Map //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent les méthodes ajoutées sur l'interface Map en Java 8 et qui prennent des Lambdas Expressions
// Pour cela nous allons prendre une table de hashage avec des integer et des strings correspondants : Map<Integer, String> map
// Clef | Valeur
//   75 | Paris
//   59 | Nord
//   50 | Manche
//   33 | Gironde
//   83 | Var
// La première méthode que l'on va voir est une méthode forEach(), elle ressemble un peu a la méthode forEach() définie sur itérable (disponible sur toutes les Collections)
// Sauf que forEach() sur les Collections prennait chaque élément un par un, le forEach() de Map, va prendre chaque paire clef/valeur sous la forme : (key, value)
// La sémantique va rester la même :
// forEach((key, value) -> System.out.println(key + " - " + value);
// La méthode qui prends deux éléments et ne retourne rien est un BiConsumer
// Encore une fois cela va nous permettre en l'occurrence d'afficher le contenu d'une table de hashage sur la console
// Surtout cela va nous permettre de transformer une itération qui devrait se trouver dans notre code (for ou while) en une itération interne

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transformation d'éléments d'une Map ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La méthode suivante que l'on va voir est la méthode replaceAll(), cette méthode permet de faire ce que l'on appelle du remapping
// --> replaceAll(BiFunction<Integer, String> bf);
// Par exemple :
// replaceAll((codePostal, departement) -> departement.toUpperCase());
// replaceAll((codePostal, departement) -> codePostal + " -> " + departement);
// Il y a un certain nombre de choses auxquelles il faut faire gaffe lorsqu'on manipule replaceAll
// Dans une table de hashage, une clef peut être nulle, et la valeur d'une clef peut être nulle aussi
// Si on veut se protéger contre une clef nulle ou une valeur nulle, il vaut mieux utiliser une autre méthode que la méthode replaceAll
// Par exemple une des méthodes de type "Compute"

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Modifier les valeurs d'une Map par clé avec Map.compute() /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Seconde méthode de remapping : la méthode compute
// Cette méthode prends deux paramètres, un integer pour une clef, et une fonction de remapping, donc une BiFunction
// --> compute(Integer, BiFunction<Integer, String, String> bf);
// La méthode replaceAll() agit sur l'intégralité des paires clefs-valeurs d'une table de hashage, donc on a une itération a l'intérieur de replaceAll()
// La méthode compute() prends un Integer en premier paramètre, donc elle ne peut pas agir sur une autre clef que celle spécifiée en paramètre
// - La première opération réalisée par compute est de faire clef.get(clef) pour vérifier qu'il y a bien une valeur associée à cette clef
// Le résultat peut être null dans deux cas, d'abord si la clef ne se trouve pas dans la table de hashage, ou si elle s'y trouve mais que sa valeur est null
// - En second, elle va appeler le remapping avec les deux valeurs (la clef et sa valeur associée), donc elle peut très bien appeler une ou plusieurs valeurs null
// Si la nouvelle valeur est nulle, alors la clef est retirée de la table de hashage !
// --> Donc la méthode compute ne peut pas associer une valeur null à une clef existante dans la table de hashage
// Si la nouvelle valeur calculée est non-null, alors la paire clef-valeur est ajoutée à la table de hashage
// Donc la particularité de la méthode compute() est qu'elle ne suppose pas que la clef passée en paramètre se trouve ou ne se trouve pas dans la table de hashage
// Elle va donc fonctionner dans les deux cas

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Modifier les valeurs d'une Map par clé avec Map.computeIfPresent() ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Seconde méthode de la famille de méthode compute() : la méthode computeIfPresent()
// --> computeIfPresent(Integer clef, BiFunction<Integer, String, String> bf);
// - La subtilité est que cette méthode agit si la clef est dans la table et associée à une valeur non-null
// Si la valeur associée à la clef demandée dans cette méthode est null, alors la clef est considérée comme absente
// - Si la clef est bien présente et associée à une valeur non-null, alors, la fonction de remapping est appelée
// Si la fonction de remapping retourne une valeur null, alors la clef est retirée de la table de hashage
// Donc la sémantique est la suivante : on agit, si la clef est dans la table et a une valeur non-null
// Et on fait le remapping uniquement si la nouvelle valeur générée est non-null
// Si cette dernière est null, alors la clef associée est retirée de la table de hashage

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Modifier les valeurs d'une Map par clé avec Map.computeIfAbsent() /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernière méthode de cette famille de trois méthodes issues de la méthode compute définie sur Map : la méthode computeIfAbsent()
// Imaginons un liste de Strings(one, two, three, four, five, six, seven)
// Nous allons construire une table de hashage composée d'entier et de liste de chaines de caractères : Map<Integer, List<String>> map
// Les clefs vont être associées à la longueur des chaines de caractères :
// 3 --> {one, two, six}
// 4 --> {four, five}
// 5 --> {three, seven}
// Ce type de table de hashage est un travail fait pour la méthode que nous présentons ici
// Elle fonctionne en faisant un mapping que si la clef qui est appelée ne se trouve pas dans la table de hashage
// computeIfAbsent(Integer clef, Function<Integer, List<String>> f);
// map.computeIfAbsent(3, key -> new ArrayList<>());
// La fonction que l'on passe est bien une fonction d'entier et de liste de chaine de caractères
// Elle prends un entier en paramètre et retourne une liste de chaine de caractères
// Elle va être invoquée que si 3 n'est pas encore une clef dans la table de hashage
// La méthode computeIfAbsent() va nous retourner la valeur qu'elle vient de traiter dans la table de hashage
// Si jamais la méthode a éxecuté cette fonction, elle va nous retourner une liste vide
// Si jamais elle n'a pas éxecuté la fonction parce que 3 était déjà dans la table de hashage, elle va nous retourner la liste associée à 3
// Il ne nous reste plus qu'à chainer cet appel avec un .add
// computeIfAbsent(Integer clef, Function<Integer, List<String>> f).add("one");
// Il faut donc après le mettre dans une boucle for() pour la boucler dans tous les éléments de la liste

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Agréger des valeurs dans un container non mutable /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La méthode computeIfAbsent() fonctionne très bien lorsqu'on veut agréger plusieurs valeurs entre elles
// Et ce dans une même structure qui constitue les nouvelles valeurs de la table de hashage qu'on est en train de créer
// Mais elle se fonde sur un élément qui est que cette valeur de la table de hashage est un élément mutable, qui est donc modifiable
// Nous allons essayer de faire le même exemple que précédemment mais avec un élément non-mutable, ce qui va rendre impuissante computeIfAbsent()
// Nous allons prendre le même exemple que précédemment, mais plutôt que de créer des listes de strings en fonction de leur longueur
// Nous allons créer des listes de concaténation de chaines de caractères
// Au lieu de 3 -> "one", "two", "six" nous aurons 3 -> "one, two, six"
// Nous ne pouvons effectivement pas utiliser computeIfAbsent(), parce que nous ne pouvons rien ajouter dans une chaîne de caractères
// Une chaine de caractères dans Java est immutable, nous ne pouvons rien y ajouter dedans
// Nous allons utiliser la méthode suivante :
// merge(Integer length, String value, Bifunction<String, String, String> bf);
// --> map.merge(4, "five", (old value, addedValue) -> oldValue + ", " + addedValue);
// Evidemment cette BiFonction ne sera appelée que si cette clef existe déjà dans la table de hashage
// Elle ne sera pas appelée pour une nouvelle paire clef-valeur que l'on ajoute dans la table de hashage
// Donc les deux méthodes computeIfAbsent() et merge() nous permettent en fait de faire des tables de hashage
// Dans lesquelles les valeurs sont le résultat de l'agrégation de valeurs existantes
// Agrégation dans un conteneur mutable de type List ou table de hashage, pour computeIfAbsent()
// Agrégation dans un conteneur non-mutable de type chaine de caractères pour la méthode merge()

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récapitulatif des méthodes sur Map en Java 8 //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récapitulons les méthodes ajoutées sur Map, construites sur l'utilisation des Lambdas Expressions, ajoutées à l'occasion de la sortie de Java 8
// - forEach(BiConsumer);
// Ici le BiConsumer est construit sur les paires clef-valeur de la table de hashage
// - replaceAll(BiFunction);
// Cette BiFunction prends en paramètres une clef et une valeur, et retourne la valeur qui va être associée a la clef dans cette table de hashage
// Ces deux premières fonctions fonctionnent sur l'ensemble des paires clef-valeur d'une table de hashage
// Elles contiennent donc en interne une itération sur ces paires clef-valeur
// - compute(key, BiFunction);
// - computeIfPresent(key, BiFunction);
// Ces deux méthodes prennent une clef et une BiFunction de remapping en paramètres
// Cette BiFunction de remapping prends elle-même une clef et une valeur en paramètre et retourne la nouvelle valeur associée à cette clef
// Ces deux méthodes sont appelées sur une clef particullières de la table de hashage à la différence de forEach() et replaceAll()
// - computeIfAbsent(key, Function);
// - merge(key, value, BiFunction);
// computeIfAbsent() est utilisée si la clef en paramètre ne se trouve pas dans la table de hashage
// Si elle ne s'y trouve pas, alors la function est appelée, et cette function est censée générer une valeur qui va être associée à la clef en paramètre
// merge() a aussi un double fonctionnement, soit la clef ne se trouve pas dans la table de hashage, auquel cas merge() va agir comme un put() et associe la valeur à cette clef
// Soit la clef se trouve déjà dans la table de hashage, auquel cas la BiFunction va être appelée avec la valeur existante, la valeur que l'on veut placer
// Et cette BiFunction est censé générer une nouvelle valeur qui va être associée à cette clef
// Ces deux dernières méthodes sont utilisées pour agréger différentes valeurs a des clefs
// computeIfAbsent() va travailler avec des valeurs non-mutables, typiquement des List et des tables de hashage
// merge() fonctionne avec des valeurs immutables comme vu dans l'exemple du sous-sous-chapitre précédent
//      --> Penser à traiter dans la BiFunction le cas où la valeur est null

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : API Stream, Collectors, Optionals //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à l'API Stream ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu jusqu'à présent que dans les applications Java, les données sont stockées dans des instances de Collection
// Instances de Collection au sens large, car cela peut être des List, des Set, des Collections, des SortedSet ou des tables de hashage
// Nous avons aussi vu que l'API Collection, pour accéder aux éléments qu'elle contient, elle expose le pattern iterator
// Le problème est que l'API Collection ne propose que ce pattern pour accéder aux objets qu'elle contient
// A partir de Java 8, nous avons une deuxième API qui arrive, l'API Stream
// Celle-ci offre de nouvelles méthodes d'accès aux objets stockés en mémoire, principalement dans des Collections, mais pas seulement
// Elle va permettre de traiter ces objets de manière très sophistiquée, en tout cas mieux qu'avec le pattern iterator
// A côté de l'API Stream, nous avons aussi l'API Collector, ces deux API sont connectées l'une à l'autre

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les patterns Map, Filter et Reduce ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le pattern Map, Filter et Reduce //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'API Stream est construite sur un pattern de traitement de données fondamental : Map / Filter / Reduce
// Pour comprendre comment ce pattern fonctionne, nous allons prendre un exemple en supposant qu'on à une List d'utilisateurs List<User>
// On voudrais connaître la moyenne d'âge de mes utilisateurs qui ont plus de 20 ans
// users --> ages --> ages > 20 --> moyenne
// Première étape, on transforme notre list d'utilisateurs en liste d'âges --> c'est ce qu'on appelle un Mapping avec Map
// Seconde étape, on retire les âges qui sont inférieur à 20 --> c'est une filtre avec Filter
// Dernière étape, on agrège les informations --> c'est une étape de réduction avec Reduce

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapping avec Map //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le mapping prends un ensemble d'objets d'un certain type et retourne un ensemble d'objet d'un autre type
// --> Donc ça change le type des objets traités mais en revanche, conserve le nombre de ces objets
// Il y a une contrainte propre à Java, c'est que si on fait un mapping sur des éléments ordonnés, comme une List, le mapping va conserver l'ordre des éléments

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Filtrer avec Filter ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'étape de filtrage est fondamentalement différente de l'étape de mapping
// --> En effet, elle va retourner des éléments du même type que ceux qu'elle a filté
// --> Le filtrage ne conserve pas le nombre d'objets (cela peut même vider une liste selon le critère de filtre choisit)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Réduction avec Reduce /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'étape de réduction est très complexe, nous la verrons en détail plus tard
// --> Pour le moment on va considérer qu'une réduction est un peu comme une agrégation SQL
// Cela peut être une somme, un min, un max, une valeur moyenne...

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Modéliser avec Map, Filter et Reduce //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment peut-on modéliser ces différentes opérations ?
// Nous pouvons les modéliser avec des Lambdas Expressions :
// --> Pour le mapping, nous avons la Function<T, R>
// --> Pour le filtrage, nous avons le Predicate<T>
// --> Pour la réduction, nous avons la BiFunction (approximation, car pas toujours efficace)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire un Map/Filter/Reduce ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment peut-on implémenter Map/Filter/Reduce, d'abord en utilisant iterator
// List<User> users = ...
// int count = 0;
// for(User user : users){
//    if(user.getAge() > 20) {
//        count++;
//        sum += user.getAge;
//    }
// }
// int avg = sum / count;
// Attention : si il n'y a aucun utilisateur au dessus de 20 ans, count sera égal à 0 et va poser un problème Mathématique !
// Ceci est donc la manière classique d'utiliser un iterator dans Map/Filter/Reduce
// La première idée à laquelle nous pouvons réfléchir est que finalement getAge() est un filtrage et for est un mapping
// Nous pourrions donc utiliser des Lambdas Expressions à la place !
//  ages = users.map(u -> u.getAge());
//  agesFiltered = ages.filter(a -> a> 20);
//  moyenne = agesFiltered.averaged();
// Ce pattern est plus simple, plus lisible et plus performante

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Identifier les problèmes de l'implémentation de map / filter / reduce sur l'API Collection ////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// En regardant les choses d'un petit peu plus prêt, supposons que notre List<User> contienne plus de 10 000 000 de Users
// Dans la boucle for classique, en utilisant iterator, on va appliquer la boucle à chaque utilisateur un par un
// Donc cette méthode consomme trois entiers au niveau de la mémoire : count, sum & avg
// Il ne stocke absolument aucune donnée intermédiaire
// Dans la méthode avec les Lambdas Expressions cela se comporte différemment
// Vu que map() n'altère pas le nombre d'éléments dans la List, nous allons nous retrouver avec 10 000 000 d'utilisateurs après le mapping
// Et donc à ce moment-là on multiplie la consommation de mémoire de notre pattern par 2
// Avec filter(), les 10 000 000 vont générer une seconde copie d'une List, nous payons donc le coût d'une deuxième duplication dans cette List
// A la fin, notre résultat est simplement un entier, mais donc avec deux listes intermédiaires que l'on va mettre au garbage collector
// Cette façon est donc catastrophique de faire les choses
// Il ne faut pas designer comme ça l'implémentation de Map/Filter/Reduce dans l'API Collection
// Le problème est que la méthode map() ne peut pas créer de duplication de l'ensemble qu'elle traite :
// C'est le problème fondamental de cette façon d'écrire les choses
// C'est embétant car c'est un façon très séduisante d'écrire les choses, en effet c'est très lisible
// Elle permet des optimisations que la boucle for ne permet pas : notamment le calcul parallèle.
// C'est donc exactement pour ça que l'API Stream a été créée, pour proposer une implémentation du Map/Filter/Reduce qui soit lisible
// Ayant aussi des degrés d'optimisation, et qui ne créée pas de duplication dess ensemles de données qui sont traitées

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Commençons avec Stream ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémenter map/filter/reduce sur un Stream ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment allons nous faire pour utiliser cet API Stream
// Dans collection, nous avons une méthode stream(), qui va nous retourner un stream de Users
// Sur cette méthode stream, nous avons une méthode map(), la même qu'on à imaginé dans le chapitre précédent mais qui ne pouvais pas fonctionner
// --> .map(u -> u.getAge()); cette méthode nous retourne un stream, sur lequel nous allons pouvoir appliquer une méthode filter()
// --> .filter(age -> age > 20); nous passons un Predicate à la méthode filter
// --> .reduce(...); nous verrons plus tard, car elle prends des paramètres qui permettent d'implémenter différents types de réduction
// Ce qui est important la dedans : Users.stream() nous retourne un Stream<User>
// Donc Stream est une interface du JDK dont une instance nous est retournée par cet appel à stream
// La méthode map nous retourne un Stream d'âges, donc si ce sont des âges ce sera un Stram<Integer>
// Le type de Stream est différent (précédemment User) donc c'est un nouvel objet qui nous est retourné : map() ne retourne pas le même objet
// Filter, lui ne change pas le type des objets qu'on traite, donc c'est toujours un Stream<Integer> qu'il nous retourne, mais c'est un nouveau Stream également
// Reduce nous retourne un integer puisqu'on lui demande une moyenne
// Nous avons donc un méthode map() et une méthode filter() qui nous retournent à chaque fois de nouveaux objets de type Stream<>
// Cela a une conséquence : un Stream est un objet qui est VIDE, au sens ou il ne porte pas les données qu'il va traiter
// C'est pour cela que nous pouvons créer un nouveau Stream<> à chaque étape, car celui-ci est quasiment gratuit à créer puisqu'il est vide

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Opérations intermédiaires et opérations terminales sur un Stream //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// List<User> users = ...
//     users.stream()                   --> créé un stream vide
//         .map(u -> u.getAge());       --> retourne un nouveau stream vide
//         .filter(age -> age > 20);    --> retourne un nouveau stream vide
// Ces deux dernières méthodes ne réalisent aucun traitement, elles déclarent juste des opérations
// Donc à quel moment allons nous réaliser notre traitement ?
// --> celui-ci sera réalisé lorsque nous allons appeler une méthode reduce(...) avec les bons paramètres sur cet objet Stream
// Cette méthode reduce(), elle ne retourne pas un Stream<> (qui est vide) mais nous retourne une valeur
// C'est donc le fait d'avoir une méthode reduce() qui va déclencher l'intégralité des traitement sur notre List<User> users
// C'est un peu comme la boucle for() d'auparavant, qui fait l'intégralité des traitements map(), filter() et reduce() en une seule passe sur les données
// Donc la boucle for() n'itère qu'une seule fois sur les données
// Nous avons donc deux types de méthode sur stream() :
// - map() & filter() sont des opérations intermédiaires, car elles retournent un autre Stream<>
// - reduc() est une méthode terminale, elle retourne donc autre chose qu'un Stream<>, y compris "void"

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Modéliser une réduction avec une BiFunction associative ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous revenons à présent sur l'étape de reduce(), supposons que nous avons un ensemble d'entiers mis dans un tableau :
// --> | 2 | 3 | 1 | 4 | 2 | 2 | 5 | 6 |
// Nous voulons calculer la somme de ces entiers en utilisant une opération de réduction :
// Nous avons besoin juste besoin d'une BiFunction, qui pourrait être un Binary Operator : BiFunction<i1, i2> -> i1 + i2
// Nous allons procéder de façon itérative, que l'on peut dans ce cas-ci appeler un "folding"
// --> 2 + 3 = 5; 5 + 1 = 6; 6 + 4 = 10; 10 + 2 = 12; 12 + 2 = 14; 14 + 5 = 19; 19 + 6 = 25;
// Donc nous prenons les éléments dans l'ordre dans lequel ils arrivent
// Cette Opération de réduction, ou ici Lambda de réduction, ne doit pas dépendre de l'ordre par lequel nous l'éxecutons sur les éléments
// Car si nous avons un stream() construit sur un Set<>, nous ne pouvons pas prévoir l'ordre dans lequel les éléments vont être consommés par ce Stream<>
// Il faut donc que notre Lambda soit indépendante de l'ordre par lequel les éléments vont être consommés
// Donc il faut que : (2 + 3) + 1 = (3 + 1) + 2 --> Cette propriété s'appele l'ASSOCIATIVITE
// Dans l'API Stream, les Lambdas que nous utilisons pour faire nos réductions doivent être associatives
// Si elles ne le sont pas, il ne va rien se passer, le code va compiler quand même, il va s'éxecuter quand même sans erreurs
// --> mais il va surtout nous générer un résultat qui sera faux !
// Donc les Lambdas de réduction doivent être associatives, et c'est au développeurs qui les écrivent de s'assurer qu'elles le sont

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Associativité des lambda //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons quelles Lambdas Expressions sont associatives :
// - (i1, i2) -> i1 + i2        --> l'addition est bien associative
//            -> Max(i1, i2)    --> le maximum est bien associatif
//            -> Max(i1, i2)    --> le minimum est bien associatif
// - (i1, i2) -> i1² + i2²      --> la sommme des carrés n'est pas associative
// - (i1, i2) -> (i1 + i2)/2    --> la moyenne n'est pas associative
// De manière générale, nous ne pouvons pas écrire de Lambda de réduction qui permette de calculer la valeur moyenne avec cet algorythme là
// Il n'y a pas de filet de sécurité, il faut tester à chaque fois l'associativité des Lambdas de Réduction !

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Construction des Streams //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Premier Pattern de construction ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons donc vu un premier aperçu de ce que l'on peut faire avec des stream()
// Nous avons aussi vu les propriétés de ces Stream<> ainsi que les problèmes pouvant être rencontrés lors de l'étape de réduction
// Comment construire des Stream avec le JDK ?
// - à partir d'une collection : nous avons une méthode stream() sur l'API Collection
// - nous avons une méthode factory qui va nous permettre de construire un stream vide : Stream.empty()
// - nous avons une seconde méthode factory : Stream.of("one", "two", "three")
// Ici nous avons passé trois Strings à of(), qui va nous retourner un stream de Strings connectés sur l'ensemble de ces trois Strings
// Nous ne pouvons pas vraiment dire que ce Stream<> contient ces éléments, puisque dans un Stream<> il n'y a pas d'éléments
// - Arrays.stream(tableau) : nous retourne un Stream<> ouvert sur un tableau
// Nous pourrions éventuellement passer le tableau dans la méthode of(), mais cela pourrait avoir des effets secondaires pervers

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Traiter des nombres avec IntStream, LongStream et DoubleStream ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons deux méthodes factory sur la classe Random qui permettent de construire des stream(), et ceux-ci sont intéressants
// Jusqu'à présent nous avons manipulé des Stream<T> d'objets, dans lesquels T peut prendre n'importe quelle valeur de classe, d'interface ou de classe abstraite
// Nous avons aussi des Stream<> de nombres, donc de type primitifs, car ces derniers ne sont pas des objets
// Si nous utilisons des Stream<Integer>, chacun des Integer sera enveloppé dans un objet, ce qui rendra l'efficacité et la performance moindre
// --> IntStream ints = Random.ints() : ints retourne un objet de type IntStream
// --> LongStream longs = Random.longs()
// --> DoubleStream double = Random.doubles() ?
// Comment pouvons nous passer d'un stream de nombre à un stream d'objets et réciproquement ?
// Sur les trois objets ci dessus, nous avons une méthode qui s'appelle mapToObj
// Cette méthode va prendre une fonction qui va transformer ces nombres en des objets
// Pour passer d'un Stream d'objet à un Stream de nombre :
// mapToInt mapToLong mapToDouble
// Ces trois méthodes prennent des fonctions particulières qui prennent les objets du Stream<> et vont retourner un entier, un long ou un double respectivement
// Les trois Streams de nombres ont un deuxième intérêt : ils ont des méthodes de récuction particulières qui n'ont de sens que pour les Stream<> de nombre
// Par exemple une méthode Sum et une méthode Average

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Générer des Streams ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons une méthode sur IntStream pour générer des Stream<> de nombre qui est particulièrement utile : IntStream.range()
// C'est une méthode statique, donc une méthode factory
// Nous lui passons deux integer en paramètres, et elle va nous générer un Stream<Integer>
// IntStream.range(0, 9); va nous générer un Stream<Integer> allant de 0 à 9 (première borne incluse et dernière borne exclue)
// Si on fait un forEach(System.println()), nous aurons une liste d'objets allant de 0 à 9
// Cela peut nous être très utile pour générer par exemple des listes d'objets tous identiques
// Si nous voulons générer une liste avec 10 fois la chaîne de caractères "Bonjour" dedans :
// IntStream.range(O, 10)
//          .mapToObj(
//             index -> "Bonjour") --> on utilise l'index car chacun des nombres est un index
//          .collect(Collectors.toList());
// --> cela nous retourne une List<String> qui contiens 10 fois "Bonjour"
// La méthode .rangeClosed(0, 10) inclus la dernière borne

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découper une chaîne de caractères à l'aide de Pattern.splitAsStream() /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir deux pattern d'ouverture de Stream<> directement sur des chaînes de caractères
// Nous pouvons découper la chaîne de caractères "Bonjour le monde", en un tableau de chaînes de caractères en utilisant la méthode suivante :
// --> String[] tab = s.split(" "); cela nous retourne un tableau contenant "Bonjour", "le", "monde"
// " " est une chaîne de caractères, mais c'est aussi une expression régulière RegEx
// Donc la méthode split() fait des choses assez sophistiquées :
// Elle analyse une chaîne de caractères en tant qu'expression régulière, et elle l'utilise pour découper une autre chaîne de caractères
// Donc si nous voulons créer un Stream<> à partir de ce tableau :
// --> Stream<String> stream = Arrays.stream(tab);
// Donc ici nous utilisons une API qui essentiellement fait pleins d'efforts pour traiter les données au fur et à mesure qu'elle les consomme
// Et a droit nous avons une API qui va commencer par découper par découper la chaîne de caractères, ce qui est éventuellement coûteux
// Construire un tableau puis le passer à Arrays.stream
// Nous avons en fait un pattern qui est beaucoup plus efficace pour faire ce genre de choses qui travaille avec un objet du JDK qui s'appelle "Pattern"
// Pattern pattern = Pattern.compile(" ");
// Stream<String> str = patter.splitAsStream(s);
// Quelle est la différence entre ces deux méthodes :
// splitAsStream() va découper la chaîne de caractères au fur et à mesure que le Stream va en consommer les éléments
// Si le Stream<> a besoin du premier élément, splitAsStream() va déterminer le premier élément
// Si le Stream<> n'a besoin que du premier élément, ça c'est la méthode de réduction qui va le dire, splitAsStream() ne vas pas découper le reste de la chaîne
// Alors que dans le premier cas, avant de construire le Stream<> on à déjà créé le tableau, donc on a déjà découpé l'ensemble de la chaîne

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Obtenir un Stream de lettres d'un String //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième méthode de Stream<> sur la classe Strings, la méthode s.chars()
// String s = "Bonjour le monde";
// IntStream str = s.chars() --> retourne un stream des lettres de la chaîne de caractères
// Il retourne donc un Stream d'entiers qui contiennent les codes ASCII de ces lettres
// Souvent dans les applications, nous avons besoin de convertir ce IntStream en Stream<String>
// Pour ça nous avons deux pattern, un dispo entre Java 8 et 10, et l'autre dispo en Java 11
// Java 11 :
// Stream<String> <-- str.mapToObj(
//     lettre -> Character.toString(letter)
//     )
// Java 8 - 10 :
// On va commencer par convertir notre Stream de codes ASCII en un Stream de caractères (donc de type char)
// Stream<String> <-- str.mapToObj(lettre -> (char)lettre)
//                       .map(s -> Character.toString(c))
// Cette seconde méthode va essentiellement nous retourner le même stream de chaînes de caractères que la première méthode
// ATTENTION : Ces deux méthodes sont différentes, elles ne prennent pas le même paramètre
// Dans la première, Character.toString() prends un entier en paramètre, le code ASCII du caractère souhaité
// La seconde prends un Char en paramètre

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Connecter un stream aux lignes d'un fichier ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir un dernier type de Stream particulier : un Stream que l'on peut ouvrir dans des fichiers texte
// Nous utilisons une classe factory qui s'appelle "Files", que nous utiliserons avec une méthode factory qui s'appele "lines"
// --> Files.lines(path, paramètre qui va fixer le type d'encodage du fichier que nous sommes en train d'ouvrir(UTF-8, ASCII...))
// Le paramètre path, est un objet de type path, est l'instance d'une interface qui s'appele "Path"
// Pour le construire, nous avons une méthode factory qui s'appelle "Paths" :
// --> Path path = Paths.get("temp/file.txt");
// Stream<String> s = Files.lines(path, ...);
// Ainsi nous avons toute l'API Stream pour traiter les lignes de mon fichier .txt
// Donc nous pouvons aussi utiliser des données stockées sur le disque et pas forcément les données en mémoire
// Cela nous permet de mettre en valeur deux choses :
// - Un Stream se connecte à une source (données en mémoire, une Collection, un tableau, du contenu textuel dans un fichier)
// - Cette source est "non-bornée" : quand on connecte notre Stream sur une source, nous ne savons pas exactement combien d'éléments cette source va générer

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Streams infinis ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir deux méthodes factory définies sur l'interface Stream supplémentaires pour générer des Stream<>
// --> Stream.generate(Supplier<T> sup)
// Stream.generate(() -> "Bonjour");
// Ceci va être généré à l'infini, donc si jamais on a le malheur d'appeler sur ce Stream, la méthode count(), nous allons générer un code qui ne rendra jamais la main
// Il faut donc appeler une méthode court-circuit, ou une méthode skip(), ou une méthode limit()
// --> Stream.iterate(T seed, UnaryOperator<T> op);
// Stream.iterate("", s -> s + " + ");
//       .count(); sera donc aussi un code qui se génère à l'infini
// Nous pouvons appeler une méthode : .takeWhile(s -> s.length() < 10)
//                                    .count
// Ces deux méthodes sont très utiles pour générer des séries d'objet, que nous allons ensuite pouvoir utiliser dans nos traitements

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définition complète de Stream /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définition complète d'un Stream ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons faire à présent un petit récapitulatif de ce que nous avons vu sur les Stream<>
// - Un Stream se connecte à une source, et qu'il va consommer les éléments de cette source
// --> Nous avons vu différents types de sources : des Collections, des tableaux (arrays), des chaînes de caractère
// Ou encore des sources de nombres aléatoires et des lignes dans un fichier
// - Un Stream ne contient pas de données, c'est un objet vide, il ne va pas porter les données de la source
// En effet il va les consommer et les passer à autre chose qui se trouve derrière lui
// --> Ainsi c'est un objet "gratuit" a construire
// --> Nous avons donc des méthodes intermédiaires sur ce Stream, qui retournent un autre Stream
// --> Nous avons des méthodes terminales, qui vont retourner autre chose que des Stream, y compris "void"
// --> Nous ne pouvons effectuer qu'UN APPEL de méthode intermédiaire ou terminal sur un Stream
// Ces 4 indications sont des conséquences du fait qu'un Stream ne contient pas de données
// - Un Stream ne connaît pas à priori le nombre d'éléments qu'il va traiter
// - Un Stream ne DOIT PAS modifier la source de ses données

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Méthodes de traitement sur un Stream //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avec map(), filter(), distinct(), sorted() ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent en détail les différentes opérations intermédiaires disponible sur l'API Stream
// Nous en avons déjà vues deux :
// - map(Function<T, R> t) --> retourne un Stream<R>
//      --> map() fonctionne pour les nombres primitifs avec une Function<> aussi : mapToInt(), mapToLong(), mapToDouble() retournant des IntStream, LongStream & DoubleStream
// - filter(Predicate<T> p) --> retourne un Stream<T>, cette méthode ne change pas le type du Stream<> sur lequel il opère
//      --> Cette méthode fonctionne aussi bien sur les Stream<> d'objets que sur les Stream primitifs
// - distinct() : Cette méthode retourne un Stream<> du même type que le Stream<> sur lequel il est appelé
//      --> Cette méthode va simplement retirer les doublons du Stream<> sur lequel elle opère
// - sorted() : Cette méthode existe en deux versions et va ordonner les éléments du Stream<> en entrée et va les trier dans un ordre propre à ces éléments
//      --> Si on l'appelle dans la première version, c'est à dire, sans paramètre, elle va trier les éléments du Stream<> si ceux-ci sont comparables en utilisant compareTo()
//      --> La deuxième version prends un Comparator en paramètre sorted(Comparator<T> cmp) et va trier les éléments en fonction de ce Comparator
//      Et ce indépendament du fait que les éléments du Stream<> soient comparables ou non
// Donc nous pouvons voir qu'un Stream<> partage certaines propriétés des Collections
// --> Il peut avoir des objets qui sont ordonnés, par exemple si on ouvre un Stream<> sur une List<>
// --> Il peut également avoir des objets triés, quelque soit la source du Stream<>, si on appelle sorted() dessus, le Stream<> descendant sera un Stream<> d'objets triés

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avec limit() et skip() ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons d'autres méthodes intermédiaires, nous avons deux méthodes également très utiles :
// - limit(l) : qui prends en paramètre un Long --> cette méthode va nous permettre de limiter le nombre d'objets que l'on va prendre dans un Stream<>
// - skip(l) : qui prends également un long en paramètre --> cette méthode va nous permettre de sauter les objets du début d'un Stream<>
// Voyons comment ces méthodes fonctionnent sur un exemple :
// --> Stream.of("one", "two", "three", "one");
// Nous allons mettre ce Stream<> dans une variable : stream
// stream.limit(2L);
// stream.forEach(s -> System.out.println(s)); --> retourne : one two
// stream.skip(2L);
// stream.forEach(s -> System.out.println(s)); --> retourne : three one
// stream.limit(3L); --> one two three
// stream.skip(2L); --> three
// stream.forEach(s -> System.out.println(s)); --> retourne : three
// A chaque opération intermédiaire, un nouveau Stream<> est créé
// Si jamais on avait fait skip(4L) après un limit(3L), c'est un code qui n'aurait jamais rendu la main car le skip() va attendre d'avoir le bon nombre d'éléments et celui-ci n'arrivera jamais

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avec dropWhile() et takeWhile() ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ajoutons deux méthodes à cette API Stream, qui ne sont disponible qu'à partir de Java 9 et non Java 8 :
// - takeWhile(Predicate<T> t); : takeWhile() va transmettre les éléments qu'il consomme au Stream<> descendant, tant que le Predicate est vrai
//      Si nous utilisons l'exemple précédent :
//      stream.takeWhile(s -> s.length == 3);
//      stream.forEach(System.out.println(s)); --> cela retourne : one two
//      --> Le Predicate cesse d'être vrai à "three", donc, takeWhile() stop la boucle à ce moment-là
// - dropWhile(Predicate<T> t); : dropWhile() va fonctionner à peu près de la même façon, c'est une porte qui s'ouvre, et une fois qu'elle est ouverte elle reste ouverte
//      stream.dropWhile(s -> s.startWith("o"));
//      stream.forEach(System.out.println(s)); --> cela retourne : two three one

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La méthode FlatMap() //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il nous reste encore l'opération intermédiaire FlatMap à voir, cette opération est un petit peu particulière, mais il est très important de bien la comprendre
// Si nous prenons par exemple trois lignes de texte :
// un jardin
// des fleurs
// un raton laveur
// Et nous allons supposer que nous avons un Stream<Strings> qui s'appelle lines et qui contient ces trois lignes de texte
// --> En fait, l'opération flatMap, permet de découper les éléments d'un Stream en un Stream et de tout mettre à plat
// Function<String, Stream<String>> f = line -> Pattern.compile(" ").splitAsStream(line);
// Pattern.compile(" ") est une manière de découper la chaîne de caractères à l'aide d'un RegEx, ici sur l'espace
// Donc cette ligne est transformée en un Stream<String> dans laquelle chaque String est un mot
// Si on prends : lines.map(f) : lines est un Stream<String> et map(f) est un Stream<Stream<String>>
// La fonction flatMap() va agir de la manière suivante : lines.flatMap(f) : lines est toujours un Stream<String>, et flatMap(f) devient un Stream<String> aussi
// Donc flatMap() met à plat tous les sous-Stream<> du Stream<> sur lequelle elle agit dans un seul Stream<>
// Si on fait un forEach() dessus, on aura tous les mots de chaque ligne
// Donc contrairement a map() et filter(), flatMap() change le type des éléments et change aussi leur quantité

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Collector et Sortie d'un Stream ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Opérations Terminales /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Revoyons à présent les opérations termminales possibles sur l'API Stream, en reprenant comme exemple : Stream.of("one", "two", "three", "four");
// - Nous avons déjà vu forEach(Consumer<T> c); : Le Consumer de cette méthode retourne Void, et donc la méthode retourne Void aussi.
// C'est une opération terminale car elle ne retourne pas de Stream<>, les opérations intermédiaires retournent un Stream<> alors que les opérations terminales non.
// Le fait d'appeler forEach() va déclencher tous les traitements sur le Stream et la consommation des éléments de la source
// - count(); : Cette méthode retourne un Long, qui est le nombre d'éléments qui vont être consommés par ce Stream<>, donc le nombre d'éléments que la source est susceptible de fournir.
// Certaines sources continennent une infinité d'éléments, auquel cas la méthode count() ainsi que la méthode forEach() ne rendra jamais la main.
// - allMatch(Predicate<T> p) : La méthode allMatch() est vraie si le prédicat passé en paramètre est vraie pour tous les éléments du Stream<>.
// - nonMatch(Predicate<T> p) : La méthode nonMatch() est vraie si le prédicat passé en paramètre est faux pour tous les éléments du Stream<>.
// Ces deux méthodes sont des méthodes court-circuit, car elles peuvent rendre la main, avant d'avoir vu tous les éléments du Stream<>.
// --> Nous avons donc deux grandes familles d'opérations terminales :
// --> Une famille d'opérations terminales qui ont besoin de voir tous les éléments du Stream<> pour rendre la main.
// --> Une famille d'opérations terminales qui n'ont pas besoin de voir tous les éléments du Stream<> pour rendre la main.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Collector : Construire des List, des Set et des tableaux à la sortie d'un Stream //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons également des opérations terminales qui permettent de construire des Collections (List<>, Set<> ou SortedSet<>) ou des tableaux, en reprenant le même exemple que précédemment :
// Stream.of("one", "two", "three", "four");
// stream.filter(s -> length() = 3);
// Nous pouvons passer une méthode collect() dans laquelle nous allons passer un objet de type Collector que nous verrons par la suite.
// stream.collect(Collectors.toList()); : Nous passons ici la classe factory Collectors, qui possède plusieurs méthodes factory, ici nous utilisons toList().
// Ceci nous retourne un objet de type Collector qui est capable de collecter les éléments du Stream<> et de les mettre dans une List<>.
// --> List<String>
// Nous avons aussi : Collectors.toSet();
// C'est donc les méthodes les plus simple pour construire des Collections en utilisant des objets Collectors et la méthode collect().
// Nous pouvons aussi construire un tableau, bien que ce soit beaucoup moins utile et beaucoup moins utilisé :

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Élément neutre d'une réduction ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il nous reste encore quelques opérations terminales à voir, mais avant ça nous allons revenir sur la réduction et la réduction associative.
// Auparavant nous avons mis 0 en premier paramètre : reduce(0, (i1, i2) -> i1 + i2);
// Supposons que nous avons deux tableaux A & B à réduire :
// A : 3, 2, 1, 4, 1, 5.
// B : 2, 2, 4, 3, 1, 6.
// Notre opérateur de réduction sera R tel que R(A) & R(B).
// Nous voulons réduire ces deux tableaux pour qu'ils forment un tableau C égal à la réunion des tableaux A & B : C = AUB.
// Etant donné que mon opération de réduction est associative (addition), nous pouvons dire que :
// R(C) = R(AUB) = R[R(A), R(B)]
// Ici nous disons seulement que la somme de l'union équivaut à la somme des sommes, toutefois, cela nous amène à un cas particulier : la Réduction de l'ensemble vide.
// Un Stream<> peut être vide, et même si la source de notre Stream<> produit des objets, si nous avons une opération de filtrage dans mon traitement du Stream<> par exemple.
// Nous pouvons très bien arriver en entrée de notre traitement de réduction sans aucun élément.
// Si A = vide --> C = B --> R(C) = R(B) = R[R(0), R(B)]
// Cette dernière affirmation est vraie seulement si la réduction de l'ensemble vide est l'élément neutre de R.
// La réduction de l'ensemble vide doit être l'élément neutre de l'opération de réduction.
// Donc le 0 que nous mettons en premier paramètre, est la valeur par défaut qui va être retournée si la méthode reduce est appelée sur un Stream<> vide.
// Donc ce 0 doit être l'élément neutre de l'opération de réduction, pour une addition, l'élément neutre est bien le 0.
// Cette partie est très importante car dans l'implémentaition de la méthode reduce(), la méthode utilise le fait que cet élément est l'élément neutre de l'opération de réduction.
// La méthode l'utilise comme premier élément pour amorcer la suite de la réduction sur tous les éléménts restants.
// Que se passe t-il à présent si nous effectuons une opération de réduction qui n'admet pas d'élement neutre : min, max & average.
// Dans ce cas là, la réduction va nous dire, que nous sommes en train de réduire un Stream<> qui est vide, nous ne pouvons pas produire de résultat, et donc voila ce que je donne.
// Cette opération de réduction va nous retourner un objet de type OPTIONAL : cet objet est juste un wrapper sur un résultat, qui peut être vide, et sur lequel nous pouvons tester si contient un élément.
// Si l'opération de réduction à pu nous retourner un résultat, elle va nous retourner un résultat OPTIONAL non vide.
// Si en revanche l'opération de réduction à réduit l'ensemble vide, elle va nous retourner un résultat OPTIONAL vide.
// En regardant de plus prêt la méthode reduce(), nous avons une seconde méthode reduce(), qui va prendre un opérateur en paramètre : reduce(operateur);
// Cette seconde méthode reduce() ne prends pas de premier paramètre qui permet de porter l'élément neutre.
// Cette seconde méthode reduce() nous retourne un OPTIONAL plutôt que de retourner directement le résultat.
// Les méthodes min, max, average et reduce(operateur) sont des opérations terminales qui retournent des instances OPTIONAL pour signaler qu'il se peut qu'elles ne puissent pas retourner de résultat.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Sortie des méthodes terminals avec Optional ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les opérations terminales qui retournent un optional sont min(Comparator<T> cmp) et max(Comparator<T> cmp) et reduce((i1, i2) -> i1 + i2) dans la version qui ne prends pas d'élément neutre en paramètre.
// Nous avons aussi deux autres méthodes qui retournent un optional :
// findFirst() : cette méthode retourne le premier élément du Stream<> qu'elle trouve.
// findAny() : cette méthode est différente de findFirst() car elle tiens du fait que certains Stream<> sont ordonnés et pas d'autres.
// Sur les Stream<> de nombres, nous avons également des méthodes min(), max() et average() qui vont retourner des optionals.
// Enfin, nous avons aussi pour mémoire une méthode sum() sur les Stream<> de nombres, mais celle-ci ne retourne pas un optional, mais un élément du type de nombre dont le Stream<> est issu.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Collectors et types de Collection /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons donc vu que l'API Stream possède une méthode collect() et que cette méthode, prends un Collector en paramètre.
// Stream<String> strings = Stream.of("one", "two", "three", "four", "five", "six", "seven");
// Nous allons donc commencer à collecter ces chaînes de caractères en utilisant des Collector particuliers.
// --> strings.collect(Collectors.toList()); : Ici nous utilisons la méthode factory toList() issue de la classe factory Collectors.
// --> strings.collect(Collectors.toSet()); : Ici nous utilisons la méthode factory toSet() issue de la classe factory Collectors.
// Déjà nous pouvons voir que collect() nous retourne soit un objet de type List<String> soit de type Set<String>, donc deux objets de type différents.
// Donc le type retourné par la méthode collect() dépends du Collectors que nous passons en paramètres.
// Nous avons aussi un autre Collectors qui est également très pratique :
// --> strings.collect(Collectors.joining()); : Cette méthode va concatener les éléments et va nous retourner un seul objet de type string.
// Nous pouvons même passer des paramètres à cette méthode joining() : .joining(","); ou encore .joining(",", "(", ")") --> .joining("séparateur", "préfixe", "suffixe").
// La méthode joining() va aussi nous gérer de nombreux cas particuliers tout seul comme si le Stream<> est vide ou s'il ne contient qu'un seul élément.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Collectors et tables de hachage ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// En gardant le même exemple que précédemment, nous allons voir un Collectors qui est très important : groupingBy(), il permet de construire des tables de hashage.
// Ces tables de hashage sont très importantes car, comme nous allons le voir bientôt, nous pouvons par la suite en faire des histogrammes.
// --> stream.collect(Collectors.groupingBy(s -> s.length())); : nous pouvons aussi l'écrire sous forme de Method Reference : stream.collect(Collectors.groupingBy(String::length));
// 3 --> one, two, six
// 5 --> three, seven
// 4 --> four, five
// Donc groupingBy(), regroupe les éléments d'un Stream<> en fonction d'une clef qui est le résultat de la fonction qui lui est passée en paramètre.
// A ces clefs il va associer des listes qui sont composées de l'ensemble des éléments du Stream<> dont le résultat de la fonction sont associés à cette clef.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// DownStream Collector //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Post-traiter les valeurs d'un table à l'aide d'un downstream collector et de groupingBy() /////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ce n'est pas tout ce que peut faire groupingBy(), effectivement cette méthode peut nous faire des List<>, mais nous pouvons aussi passer un second Collectors en paramètre à groupingBy().
// --> stream.collect(groupingBy(String::length, ...)); : à cet emplacement nous pouvons passer un "downstream Collector".
// En fait, avant de créer des List<>, groupingBy() créé des Stream<>, auxquel il va appliquer le downstream Collector.
// Donc nous avons la possibilité de passer en deuxième paramètre du groupingBy(), une espèce de post-traitement.
// Celui-ci va être utilisé pour traiter les valeurs associées aux clefs, avant que la table de hashage ne soit finalement construite.
// Si on regarde le groupingBy() auquel nous ne passons qu'un seul paramètre, celui-ci est cablé sur le groupingBy() qui prends un downstream collector, ce dernier étant tout simplement Collectors.toList().
// Si dans ce downstream collector, nous passons Collectors.toSet() : stream.collect(groupingBy(String::length, Collectors.toSet())); --> Nous mettrons des valeurs dans des Set<> plutôt que dans des List<>.
// Si nous lui passons : stream.collect(groupingBy(String::length, Collectors.joining(","))); --> plutôt que de construire des List<> ou des Set<>, toutes les valeurs seront concaténées.
// Dans le premier cas nous aurons une map() d'entiers et de List<String>.
// Dans le second cas nous aurons une map() d'entiers et de Set<String>.
// Dans le dernier cas nous aurons une map() d'entiers et de chaînes de caractères.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Compter des éléments et extraire un max ou min à l'aide d'un downstream collector /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons déjà vu toList(), toSet() & joining() qui sont des Collectors qui peuvent être appelés directement dans la méthode collect() ou en tant que downstream collector d'un groupingBy().
// Nous avons d'autres Collectors qui sont très intéressants, pas nécessairement dans la méthode collect(), mais en tant que downstream collector.
// --> counting() : qui va retourner le nombre d'éléments d'un Stream<>.
// Nous pouvons faire stream.collect(Collectors.counting()); (retourne le nombre d'éléments du Stream dans un Long) mais cela va faire doublon car nous avons déjà la méthode .count().
// En revanche, sur une table de hashage, en tant que downstream collector, il va nous permettre de compter le nombre d'éléments associés à un index de la table de hashage.
// Dans notre exemple si on fait : stream.collect(groupingBy(String::length, Collectors.counting())); cela nous retournera une map() d'integer et de long.
// --> maxBy(Comparator)
// --> minBy(Comparator)
// Ces downstream collectors sont très utiles lorsque nous voulons faire des post-traitements sur les valeurs d'une table de hashage.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Trouver la longueur de chaîne la plus fréquente dans un Stream de String //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Stream<String> strings = Stream.of("one", "two", "three", "four", "five", "sic", "seven");
// Quelle est la longueur de chaîne de caractères la plus fréquente dans ce Stream<> ?
//      Map<Integer, Long> map = stream.collect(Collectors.groupingBy(
//          String::length,
//          Collectors.counting()
//      ));
// Maintenant nous voulons extraire la paire clef-valeur pour laquelle la valeur est la plus grande.
// Pour ça nous avons un pattern particulier sur les tables de hashage qui travaille avec des Stream<>, mais malheureusement, pour Map<> nous n'avons pas de méthode stream().
// Ce que nous savons c'est que le résultat de cette table de hashage est une "entry", une paire clef-valeur, or sur les tables de hashage nous avons trois méthodes :
// keySet() qui nous retourne le Set<> des clefs de la table, values() qui nous retourne la collection des valeurs & entrySet(), qui nous retourne le Set<> des paires clefs-valeurs de la table de hashage.
// Or il se trouve que pour Set<> nous avons une méthode stream().
//      map.entrySet().stream() --> nous retourne le Stream<> des paires clef-valeur de cette table de hashage.
// Sur ce Stream<> nous cherchons a avoir la plus grande paire clef-valeur au sens de la comparaison des valeurs, qui sont des Long donc des éléments comparables donc :
// --> map.entrySet().maxBy(Comparator.comparing(e -> e.getValue()))
// Il faut se rappeler qu'un max est une opération de réduction qui n'admet pas d'élément neutre, et les opérations qui n'admettent pas d'élément neutre retournent des optionals.
// Cet optional pose problème si le Stream<> sur lequel nous travaillons est vide, or ce n'est pas le cas ici.
// Sur cet optional nous pouvons donc appeler la méthode get(), qui provient de la classe optional :
// --> map.entrySet().maxBy(Comparator.comparing(e -> e.getValue())).get();
// Si nous voulions le max des clefs, nous aurions pu utiliser e.getKey() à la place de e.getValue().
// Ici nous créons donc un comparator de l'objet mapEntry, mais il se trouve que sur l'interface mapEntry elle-même, nous avons des méthodes factory pour créer des comparator de mapEntry.
// Donc nous aurions aussi pu écrire la même chose de la manière suivante :
// --> map.entrySet().maxBy(Map.Entry.comparingByValue()).get();
// Ce comparingByValue() nous retourne un comparator qui nous permet de comparer des mapEntry en fonction de leurs valeurs.
// Nous avons aussi une autre méthode factory qui se nomme comparingByKey() qui fait le même travail mais en comparant les mapEntry en fonction de leurs clefs.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Trouver les longueurs de chaîne les plus fréquentes par inversion de Map //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Stream<String> strings = Stream.of("one", "two", "three", "four", "five", "sic", "seven", "eight");
// Si nous appliquons le même code que précédemment, nous cherchons le max de nos paires clefs-valeurs, mais il va nous sortir une seule valeur alors qu'à présent il y a deux max.
// Il va nous falloir retourner toutes les valeurs maximales, et ce sous forme d'une collection, donc typiquement, une List<>.
// Vu que cela doit nous retourner une List<>, nous pouvons nous dire que c'est un travail pour groupingBy(), sauf que le groupingBy() va devoir être fait de manière intelligente et sophistiquée.
// Le début du pattern va être le même que précédemment, nous commençons par construire notre table de hashage :
// --> map = strings.stream(groupinBy(String::lenght, Collectors, counting()));
// Pour traiter cette Map<>, il faut que nous prenions le Set<> de paires clef-valeur, et d'en faire un Stream<> :
// --> map.entrySet().stream(); --> Ce sont des Entry<Integer, Long>.
// Maintenant nous voulons en faire un Set<Long, Integer>, et les regrouper par les Long.
// --> map.entrySet().stream().collect(groupingBy(e -> e.getValue()));
// Ici, si nous ne passons pas de paramètres, nous alllons nous retrouver avec une List d'éléments du Stream sur lesquels nous sommes.
// Donc non pas une liste d'entiers, mais une liste d'entrées d'entiers et de longs.
// Donc nous allons passser un second downstream collector, dont le travail va être de prendre les entiers, et d'extraire la clef de ces entrées.
// Ainsi, de prendre un objet d'un certain type, et de retourner un objet d'un autre type : c'est donc un travail de mapping, nous sommes en train de mapper des entrées dans leurs clefs.
// --> map.entrySet().stream().collect(groupingBy(e -> e.getValue()), Collectors.mapping(e -> e.getKey()));
// Sauf que le Collectors.mapping() est un peu spécial car il prends lui-même un downstream collector pour ranger ce qui a été collecté dans une structure de collection :
// --> map = map.entrySet().stream().collect(groupingBy(e -> e.getValue()), Collectors.mapping(e -> e.getKey(), toList()));
// Nous avons ainsi 3 Collectors, le groupingBy(), qui prends lui même le mapping() en downstream collector, qui prends lui-même toList() comme downstream collector.
// Ici le type de Map qui nous est retourné est le suivant : Map<Long, List<Integer>>
// Les clefs sont les valeurs des entrées que nous avons dans le stream, donc ce sont des Long.
// Les valeurs sont le mapping de ces entrées dans leurs clefs, donc des entiers qui ont été collectées dans des List<>.
// 3 - one, two, six --> 3
// 4 - four, five --> 2
// 5 - three, seven, eight --> 3
// Ceci devient à présent :
// 3 - {3, 5}
// 2 - {4}
// A partir de cette table de hashage, nous pouvons refaire un entrySet.stream(), et un maxBy(), cette fois-ci en extrayant le max sur les clefs, et non plus sur les valeurs.
// Cela nous retournera la List<> des longueurs de chaînes que nous attendons lorsque nous ferons le get() sur l'optional qui nous sera retourné.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Compter le nombre d'éléments identiques dans un Stream avec groupingBy() //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir un exemple d'application de cette API Collector qui consiste à compter le nombre d'éléments identiques que nous pouvons avoir dans un Stream<>.
// Stream<Integer> numbers = Stream.of(1, 2, 2, 1, 3, 2, 1, 1, 3, 3, 1, 4);
// Nous voulons donc savoir dans ce Stream<> combien nous avons de 1, combien nous avons de 2, de 3 et de 4.
// Ainsi nous pourrons savoir à la fin, quel est l'élément le plus représenté, ou le moins représenté à l'intérieur de ce Stream<>.
// C'est un travail parfait pour l'API Collector, et notamment pour le collector groupingBy().
// 1 -> 5
// 2 -> 3
// 3 -> 3
// 4 -> 1
// Donc nous voulons en fait construire un table de hashage, dont les clefs sont les valeurs du Stream<> et les valeurs sont le nombre de fois que ces valeurs apparaîssent dans le Stream<>.
// Les clefs de cette table de hashage sont les valeurs du Stream<>, donc lorsque nous écrirons : stream.collect(Collectors.groupingBy()), nous aurons une subtilité.
// Nous devrons nous rappeler que la première fonction que nous mettrons en paramètres est une fonction qui prends un élément du Stream<> et qui retourne une clef particulière du Stream<>.
// Nous n'avons pas de transformation entre l'élément du Stream<> et la clef de la table de hashage.
// Donc le premier paramètre sera la fonction identité :
// --> stream.collect(Collectors.groupingBy(Function.identity()));
// Si nous en restons là, quelle table de hashage, la fonction va t'elle nous construire ?
// 1 -> {1, 1, 1, 1, 1}
// 2 -> {2, 2, 2}
// 3 -> {3, 3, 3}
// 4 -> {4}
// Cette table de hashage est assez curieuse car nous avons des clefs associées à des listes de valeurs qui sont identiques aux clefs.
// Il nous faut donc à présent associer 1, au nombre de fois qu'il est représenté, donc compter le nombre d'éléments de chaque List<>.
// Or, nous pouvons passer un deuxième paramètre au collector groupingBy(), que l'on appelle un downStream collector :
// --> stream.collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));
// Donc counting() va faire le travail en comptant les éléments qui sont dans cette liste qui et en fait un Stream<>.
// Cela va bien nous retourner une Map<Integer, Long> (Integer sont le type d'objets retournés par la fonction identity(), et Long, le type d'objet retourné par le downStream collector counting()).
// Si à présent nous voulons déterminer quel élément revient le plus souvent dans ce Stream<> :
// --> map.entrySet().stream().max(Map.Entry.comparingByValue());
// Il faut toutefois que nous nous souvenons d'une dernière chose, c'est que les opérations max() sur stream, retournent un optional, donc nous pouvons appeler get() directement dessus :
// --> map.entrySet().stream().max(Map.Entry.comparingByValue()).get(); --> retourne la paire clef-valeur {1, 5}.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Plus loin avec l'API Collector ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation de toMap() ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu qu'il était possible avec l'API Collector de construire des tables de hashage, avec un premier collectors qui s'appelle groupingBy().
// Ce dernier prends au moins un paramètre qui est une fonction qui va transformer les éléments du Stream<> en une clef, qui va servir de clef à une table de hashage.
// Nous avons vu que groupingBy() regroupait les éléments du Stream<> dans des List<> associées à ces clefs, automatiquement
// Enfin, que nous pouvions mettre un post-traitement sur ces List<> avec un downstream collector.
// Nous avons un deuxième collector qui nous permet de construire des tables de hashage qui s'appelle toMap(), qui prends deux fonctions en paramètres :
// --> Une première fonction qui s'appelle le keyMapper : celle-ci prends les éléments du Stream<> et qui les transforme en clef, exactement comme le groupingBy().
// --> Une seconde fonction qui s'appelle le valueMapper : celle-ci prends les éléments du Stream<> et cette fois-ci les transforme en valeurs.
// Le Collectors.toMap() a une particularité, c'est que nous ne pouvons pas avoir de doublons de clefs dans les clefs.
// Donc, si deux éléménets du Stream<> génèrent au travers du keyMapper, la même valeur de clef, le Collectors.toMap() va jeter une erreur.
// Collectors.groupingBy() est, lui prévu pour ça, il a prévu que deux éléments du Stream<> peuvent générer la même clef.
// Si c'est le cas, ces deux éléments vont être mis dans une List<> associés à cette clef.
// Mais comment peut nous servir toMap() ?
// Si jamais le Stream<> d'éléments sont des objets qui sortent d'une base de données, ces derniers ont tous une clef primaire.
// Imaginons que nous voulons les mettre dans un cache, ou mettre un sous-objet de ces objets dans un cache.
// Pour ceci le Collectors.toMap() est parfait car nous aurons la garantie de ne pas avoir de doublons de nos objets dans notre Stream<>.
// Si jamais nous avons besoin de gérer le fait d'avoir des doublons, nous pouvons passer un troisième paramètre à Collectors.toMap() :
// --> mergeFunction : celle-ci est une fonction de fusion, est fonctionne en tant que Binary Operator (qui prends deux éléments d'un certain type et qui retourne un élément du même type).
// Ce binary operator va être appliqué à l'objet qui a déjà préalablement était associé à la clef, au nouvel objet que nous souhaitons associer à la clef, et va produire un troisième objet.
// Ce binary operator fonctionne de la même manière que la fonction merge() dans Map<>, permettant elle aussi de fusionner deux valeurs.
// Nous n'avons pas de version de toMap() qui prends un downstream collector, donc une fois que les valeurs sont créées, nous ne pouvons pas faire de post-traitement dessus.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A l'intérieur du Collector ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent dans le détail comment fonctionne un Collectors.
// Jusqu'à présent nous avons utilisé des Collectors qui était déjà tout prêts grâce à la classe factory Collectors.
// Un objet de type Collectors est en fait construit sur 4 objets :
// --> Le premier est un objet qui va nous permettre de construire un container mutable dans lequel nous allons accumuler les éléments du Stream<>.
// --> Le second élément est en fait un "Accumulator", qui va nous permettre d'ajouter un élément du Stream<> au container mutable.
// --> Le troisième élément que nous n'avons pas encore utilisé et qui s'appelle le "Combiner". Celui-ci permet de fusioner deux container mutables.
// --> Le quatrième élément est le "Finisher". Cet élément va prendre le container mutable et le transformer en quelque chose d'autre.
// Nous allons voir un exemple de Finisher car c'est un élément dont nous n'avons pas toujours besoin. Il y a plein d'exemples dans lesquels le Finisher n'effectue aucune actions.
// Comment pouvons nous modéliser ces 4 expressions : En fait nous pouvons les modéliser avec des Lambdas Expressions.
// --> La première étape est quelque chose qui ne prends rien et retourne un container : () -> container.
// Donc c'est un Supplier.
// --> La deuxième étape prends quelque chose qu'elle ajoute au container, donc ne retourne rien : (container, element) -> {}.
// Donc c'est un BiConsumer.
// --> La troisième étape prends deux container et retourner un seul container : (container1, container2) -> container.
// Donc c'est une BiFunction un peu spéciale car le type des deux éléments d'entrée est le même que celui de sortie. Donc en fait c'est un Binary Operator
// --> La quatrième étape prends un container et en retourne un autre qui peut être le même ou peut être différent selon les cas.
// Donc cette partie là est modélisée par une fonction.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Construction des Collector toList(), toSet() et groupingBy() à l'aide de cette modélisation ///////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A quoi correspondent les 4 étapes de composition d'un Collector par exemple dans le Collectors.toList() ?
// --> () -> new ArrayList<>();
// --> (list, e) -> list.add(e);
// --> (list1, list2) -> {
//          list1.addAll(list2);
//          return list1;
//      }
// --> identity(); (car nous n'avons pas à transformer la liste finale).
// Si nous regardons le Collectors.toSet(), cela peut-être intéressant de le comparer à Collectors.toList() :
// --> () --> new HashSet();
// --> (set, e) -> set.add(e);
// --> (set1, set2) -> {
//             set1.addAll(set2);
//             return set1;
//      }
// --> identity();
// Donc la seule différence est le supplier qui nous permet de construire le type de container mutable créé à l'origine.
// Regardons à présent le Collectors.groupingBy() :
// --> () -> new HahSet();
// Seulement l'étape accumulator va être un peu plus complexe.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Construction du Collector joining() à l'aide de cette modélisation ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le Collector joining() est très intéressant car il va essayer de concatener les éléments du Stream<> sur lequel nous travaillons en une chaîne de caractères.
// Pourtant le supplier est sensé construire un élément mutable, or il se trouve que la chaîne de caractères n'est pas du tout un container mutable.
// Donc pour joining(), le supplier ne peut pas être seulement "new String". Donc nous allons utiliser une classe proche de String, la classe StringBuilder :
// --> () -> new StringBuilder();
// Or, là nous sommes en train de construire un container mutable qui n'est pas le container que nous voulons retourner à la fin (String et non StringBuilder).
// --> (StringBuilder, e) -> StringBuilder.append(e);
// --> (StringBuilder1, StringBuilder2) -> StringBuilder1.append(StringBuilder2);
// Il ne nous reste que le finisher à construire. Jusqu'à présent c'était toujours la fonction identity() :
// --> (StringBuilder) -> StringBuilder.toString().
// Si nous regardons la classe factory Collectors, nous pouvons voir qu'il y a dedans un Collector qui s'appelle "collectionAndThen()".
// Ce dernier prends un premier collector en paramètre, et une fonction en deuxième paramètre qui est en fait un nouveau finisher.
// Celui-ci peut surcharger le finisher du collector qui est passé en paramètre de collectingAndThen().
// Donc, ce finisher, nous pouvons aussi le particulariser avec la classe factory Collectors.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le type Optional //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Construire un Optional ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu lorsque nous avons étudié la réduction que certaines réductions posaient problème.
// La réduction consiste en appliquer une opération de réduction sur les éléments d'un Stream<>, et si cette opération de réduction n'admet pas d'élément neutre, nous ne savons pas réduire l'ensemble vide.
// Donc lorsque le Stream<> que nous cherchons à réduire ne comporte plus d'éléments.
// C'est donc un vrai problème que nous avons traité d'une manière particulière : les opérations de réduction qui n'admettent pas d'élément neutre retournent systématiquement un objet OPTIONAL.
// Si le Stream<> n'est pas vide, la réduction se passe bien et l'optional va contenir le résultat de cette réduction.
// En revanche, si le Stream<> est vide, l'optional est vide aussi, et nous avons des méthodes sur Optional pour tester si cet optional est bien vide.
// Toutefois nous n'avons pas vu comment fonctionne cet objet optional particulièrement, cet objet est très intéressant et c'est ce que nous allons voir à présent :
// --> Sa première propriété est que c'est un objet 'wrapper' qui peut être vide.
// Ceci est à la différence des wrappers de type primitif, pour envelopper les types primitifs (integer, long...), ceux-ci ont nécéssairement une valeur et ne peuvent pas être vide.
// --> Sa seconde propriété est qu'il ne peut pas contenir la valeur 'null'.
// En fait, la classe optional est finale, donc nous ne pouvons pas l'étendre, et ses constructeurs sont privés.
// Pour la construire nous avons trois méthodes factory :
// - Optional.empty(); qui nous permet de construire un optional vide.
// - Optional.of(...); qui prends une valeur --> si nous appelons cette méthode avec un paramètre 'null', une nullPointerException est lancée.
// - Optional.ofNullable(...); qui prends également une valeur --> si nous appelons cette méthode avec un paramètre 'null', mais cela ne va pas nous retourner un optional wrappé sur la valeur null.
// En effet optional ne peut pas contenir null. Cela va nous retourner un optional qui va être vide.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Accéder au contenu d'un Optional //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment vas t-on pouvoir aller chercher le résultat qui est dans un optional ? Pour cela nous avons plusieurs méthodes :
// --> isEmpty() : retourne true ou false dépendamment que nous ayons une valeur ou non dans l'optional.
// --> isPresent() : retourne l'inverse d'isEmpty().
// --> get() : retourne le résultat que nous avons dans cet optional.
// Si nous sommes absolument certains d'avoir réduit un Stream qui n'est pas vide, nous pouvons appeler get() directement de façon assez sécurisée, et get() nous retournera l'objet qui est wrappé.
// --> orElse(T t) : cette méthode nous permet de cumuler les deux, elle prends un objet de type T en paramètre sur Optional<T>.
// Cette méthode nous retourne l'argument que nous lui avons passé en paramètre si jamais l'optional est vide.
// Ecrire les choses de cette manière nous cache quelque chose de dangereux. En effet, l'objet t est éventuellement coûteux à construire.
// Si cet objet est coûteux à construire, au moment ou nous appelons orElse(), nous allons le construire puisque tous les paramètres d'une méthode doivent être résolus à l'appel de cette méthode.
// Et si cela se trouve, cet objet que nous avons construit ne vas pas nous servir, puisque si nous avions déjà un objet dans l'optional, c'est ce dernier qui sera retourné et non t.
// Pour résoudre ce problème nous avons donc une dernière méthode :
// --> orElseGet(Supplier<T>) : c'est donc le supplier qui va être capable de construire cet objet t. Effectivement un Supplier<> est un objet quasiment gratuit à construire.
// En effet, c'est une lambda expression, et tant que nous n'invoquons pas la méthode get() en l'occurence de ce Supplier<>, elle ne sera pas executée.
// Donc la méthode orElseGet() est préférable si jamais l'objet t de la méthode orElse() est coûteux à construire.
// Il nous reste une dernière méthode à voir :
// --> orElseThrow() : cette méthode nous jette une erreur si jamais l'optional est vide.
// Enfin, à partir de Java 10, nous avons une version différente qui est ajoutée :
// --> orElseThrow(Supplier<> sup) : celle-ci prends un Supplier d'exception, qui va nous permettre de construire l'exception qui va être jetée par cette expression orElseThrow() particulière.
// Nous avons donc en conclusion des méthodes qui nous permettent d'aller chercher la valeur qui se trouve dans l'optional de façon explicite.
// Avec des méthodes qui permettent de tester si effectivement nous avons quelque chose dans l'optional ou pas.
// Et enfin nous avons des méthodes qui nous permettent de contrôler les exceptions qui vont être générées par la méthode get() si jamais nous l'invoquons alors que l'optional est vide.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Traiter le contenu d'un Optional //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons aussi une deuxième famille de méthodes sur Optional<T> qui vont ouvrir de nouvelles possibilités.
// --> ifPresent(Consumer<T>) : si nous appelons cette méthode et que nous n'avons pas d'objets dans notre optional, il ne se passe rien, le consumer n'est pas appelé.
// En revanche si on a bien quelque chose dans notre optional, alors le consumer va être appelé.
// Donc par exemple, si nous voulons juste imprimer le contenu de notre optional, plutôt que de faire opt.isPresent() et opt.get(), nous pouvons faire : opt.ifPresent(System.out::println);
// Ainsi, le test pour savoir si l'optional est vide ou pas va être fait à l'intérieur de la méthode ifPresent().
// --> map(Function<T, R> f) : que se passe t'il si nous faisons opt.map(f) ? En fait il peut se passer deux choses :
// Soit nous avons un objet dans notre optional, auquel cas cela va nous retourner un Optional<R>, cet optional contenant la transformation de l'objet qui se trouvait dans l'optional par la fonction f.
// Soit notre optional est vide, auquel cas, il va nous retourner un autre optional vide.
// --> filter(Predicate<T> p) : que se passe t'il si nous faisons opt.filter(p) ? Il se passe a peu près la même chose qu'avec la méthode map() :
// Soit nous avons un optional vide, auquel cas cela nous retourne un autre optional vide.
// Soit nous avons un optional qui n'est pas vide, auquel cas le prédicat va être appelé sur l'objet wrappé.
// Enfin, si le prédicat est vrai, cela nous retourne un Optional<T>, soit il est faux, et il retourne un optional vide.
// --> flatMap(Function<T, Optional<R>> f) : cette dernière méthode va faire la même chose que les méthodes map() et filter().
// Si l'optional est vide, cela retourne un optional vide. Si non, cela va appliquer cette fonction contenue et va retourner non pas un optional d'optional de R mais un optional de R.
// Nous pouvons constater que ces méthodes ressemblent beaucoup aux méthodes de Stream<> :
// - ifPresent() --> forEach() : qui prends également un prédicat.
// - map() --> map().
// - filter() --> filter().
// - flatMap() --> flatMap().
// En fait, ces méthodes nous permettent de regarder un optional, comme étant un Sream<> qui aurait deux caractéristiques :
// --> Il peut consommer 0 ou 1 élément : il est vide ou ne l'est pas.
// --> Il peut être réutilisable, alors qu'un objet Stream<> ne peut être utilisé qu'une seule fois, alors que l'optional pourra l'être autant que nécessaire.
// Par ailleurs, sur optional, nous avons une méthode stream() qui va nous permettre de construire un Stream<> à partir de cet optional.
// Il pourra alors contenir l'objet wrappé par l'optional ou un Stream<> vide.
// En conclusion nous avons deux familles de méthodes pour traiter un optional :
// --> Soit une famille de méthodes qui va nous permettre de tester, d'opérer ou de récupérer sur un contenu.
// Ceci avec des méthodes get(), ou des méthodes qui vont nous permettre de contrôler les erreurs qui vont être jetées.
// --> Soit nous regardons notre optional comme un Stream<> en l'intégrant directement à notre traitement de données, et pour ce faire nous pouvons même le convertir en un Stream<> avec la méthode stream().

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan de l'API Stream /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur l'API Stream /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// --> Nous avons vu que l'API Stream tout d'abord, sa raison d'être est qu'elle intêgre le pattern map() / filter() / reduce().
// --> Nous avons deux types de Stream<> : les streams d'objets Stream<T>, et les Stream<> de nombres, IntStream<>, LongStream<> & DoubleStream<>.
// --> Nous avons vu qu'un Stream<> se connecte à une source de données, et le corolaire de ce fait est qu'un Stream<> est vide, il ne porte pas les données qu'il traite.
// Ce dernier point à deux conséquences :
//      --> Un Stream<> ne peut être utilisé qu'une seule fois.
//      --> La première conséquence est que nous avons deux types de méthodes sur un Stream<> :
//              - Les méthodes intermédiaires : ce sont des méthodes qui retournent un Stream<> : map() qui prends une fonction, filter() qui prends un prédicat, sorted(), distinct().
//              - Les méthodes terminales : ce sont des méthodes qui retournent autre chose qu'un Stream<> : count() qui prends un Long.
//                  et forEach() qui prends un consumer et l'applique à tous les éléments du Stream<>, allMatch() & nonMatch(), qui prennent tous deux un prédicat en paramètre.
//                  Les méthodes count() et forEach() s'appliquent sur l'ensemble du Stream<> alors que allMatch() et nonMatch() sont des méthodes court-circuit.
//                  Nous avons aussi vu sur les méthodes terminales les méthodes max(), min(), et average() (ce dernier seulement sur les Stream<> de nombres).
//                  Mais celles-ci ont des problèmes pour traiter les Stream<> vides --> d'où la notion d'optional.
// D'une façon générale, quand nous ne savons pas réduire un Stream<> vide, parce que l'opération de réduction n'admet pas d'élément neutre, la méthode retourne systématiquement un optional.
// Nous avons vu quelques éléments sur la manière d'utiliser optional :
// --> Une première famille de pattern isPresent/get.
// --> Une seconde famille de pattern nous permettant de regarder un optional comme s'il était un Stream<> avec une méthode map(), filter(), ifPresent() et même une méthode flatMap().
// Cette notion d'optional est même parfois utilisée dans certaines versions de la méthode reduce().
// --> La dernière opération terminale que nous avons vu est la méthode collect() qui prends en paramètre un objet de type Collectors.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : API Stream, Collectors et Optionals par la pratique ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mise en pratique //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Coding sur l'Api Stream n°1 1/2 //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// package org.vitu.stream;
//
// import java.io.IOException;
// import java.nio.file.Files;
// import java.nio.file.Path;
// import java.util.Arrays;
// import java.util.List;
// import java.util.Optional;
// import java.util.regex.Pattern;
// import java.util.stream.Stream;
//
// public class FirstContactWithStreams {
//
// 	public static void main(String... args) throws IOException {
//
// 		// Stream sur une liste
// 		List<String> strings = List.of("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten");
// 		System.out.println("Stream sur une liste");
// 		strings.stream().forEach(System.out::println);
//
// 		// Stream sur un tableau
// 		String[] arrayOfStrings = {"one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten"};
// 		// arrayOfStrings.stream(); --> ne fonctionne pas, car la methode stream() ne s'applique pas sur ce type d'objets.
// 		System.out.println("\nStream sur un tableau");
// 		Arrays.stream(arrayOfStrings).forEach(System.out::println);
//
// 		// Stream a partir d'elements
// 		System.out.println("\nStream sur des élémnets");
// 		// \n pour faire un retour chariot
// 		Stream.of("one", "two", "three", "four").forEach(System.out::println);
//
// 		// Stream sur les lignes d'un fichier (repertoire files cree a la racine du projet et non dans le repertoire source)
// 		// Path path = Path.of("c:/tmp/debug.log"); est une maniere d'importer en chemin absolu
// 		String fileName = "files/lines.txt";
// 		Path path = Path.of(fileName);
// 		// Nous testons si le chemin existe
// 		boolean exists = Files.exists(path);
// 		System.out.println("\nLe fichier " + fileName + " existe : " + exists);
// 		Stream<String> lines = Files.lines(path); // Classe factory Files (privee), erreur de compilation a l'ecriture, resolue en ajoutant "throws IOException lors de la déclaration main
// 		System.out.println("\nStream sur les lignes d'un fichier");
// 		lines.forEach(System.out::println);
//
// 		// Stream sur un pattern
// 		String line = "one two three four";
// 		// Pattern 1
// 		String[] split = line.split(" ");
// 		System.out.println("\nStream sur une ligne découpée par split");
// 		Arrays.stream(split).forEach(System.out::println);
// 		// Pattern 2
// 		Pattern pattern = Pattern.compile(" "); // permet de creer un pattern d'expression reguliere
// 		// String[] split2 = pattern.split(line); equivalent a la meme chose que precedemment
// 		System.out.println("\nStream sur une ligne découpée par un pattern");
// 		pattern.splitAsStream(line).forEach(System.out::println);
// 		// La difference est que dans le premier cas, Pattern 1, un tableau est cree en decoupant la chaine de caracteres, qui seront donc stockees en memoire
// 		// Le Pattern 2 lui, va traiter les elements un par un, et donc ne pas les stocker en memoire
//
// 		// Maintenant nous allons utiliser le tableau pour recuperer le premier string de longueur 3
// 		// Cette methode va nous retourner un optional, donc pour le voir, au lieu d'utiliser get(), nous utilisons la methode orElseThrow()
// 		String s1 = Arrays.stream(split).filter(s -> s.length() == 3).findFirst().orElseThrow();
// 		System.out.println("\nPremière chaîne de longueur 3 : " + s1);
//
//
// 		// A present nous utilisons le pattern pour retourner le premier string de longueur 3
// 		// Le code est un peu plus long, mais au lieu de tout decouper avant de filtrer les elements, il va d'abord faire le premier element puis le tester et ainsi de suite
// 		String s2 = Pattern.compile(" ").splitAsStream(line).filter(s -> s.length() == 3).findFirst().orElseThrow();
// 		System.out.println("\nPremière chaîne de longueur 3 : " + s2);
// 		// Mais dans ce cas là pourquoi retourne t'on un optional ?
// 		// Parce que findFirst(), si il est utilisé sur un Stream<> vide, nous ne saurons pas quoi retourner
//
// 		// Stream<> vide --> Que se passe t'il si nous demandons le premier élément sur un Stream<> qui est vide ? Ca n'a pas de sens, donc cela nous retourne un optional
// 		Stream<String> emptyStream = Stream.empty();
// 		Optional<String> first = emptyStream.findFirst();
// 		boolean empty = first.isEmpty();
// 		System.out.println("\nStream vide find first = " + empty);
// 		// L'Optional est donc le choix qui a ete fait pour toutes les operations dont l'issue est incertaine, donc si elles retournent des Stream<> vides ou non
// 		// Ici c'est evident mais parfois on ne sait pas si le Stream<> retourne sera vide, par exemple
// 		Stream<String> emptyStream2 = strings.stream().filter(s -> s.length() > 50);
// 		Optional<String> first2 = emptyStream2.findFirst();
// 		boolean empty2 = first2.isEmpty();
// 		System.out.println("\nStream vide find first2 = " + empty2);
// 	}
// }
//
//
// package org.vitu.stream;
//
// import java.util.Optional;
//
// public class PlayWithOptional {
//
// 	public static void main(String[] args) {
// 		// Quelle est la difference entre int10 et integer10 ?
// 		// int10 est un type primitif sur lequel nous n'avons pas de methodes
// 		// integer10 n'est pas un type primitif, Integer est une classe "wrapper", car c'est une classe qui enveloppe une valeur, ici 10, et qui permet de rajouter des methodes sur cette valeur
// 		// Donc l'objet de la classe Integer est d'avoir acces a des methodes
// 		Integer integer10 = Integer.valueOf(10);
// 		int int10 = 10;
//
//
// 		// Un optional est une classe wrapper, et ici elle enveloppe la valeur "one"
// 		// La difference avec la classe Integer, est qu'avec optional, nous pouvons ne pas avoir de valeur enveloppee alors qu'Integer doit systematiquement envelopper une valeur
// 		Optional<String> opt = Optional.of("one");
// 		Optional<String> emptyOpt = Optional.empty();
//
// 		boolean empty = opt.isEmpty();
// 		System.out.println("Optional vide : " + empty);
// 		System.out.println("Optional vide : " + emptyOpt.isEmpty());
//
// 		String string = opt.get();
// 		System.out.println("Contenu de opt = " + string);
//
// 		// String string2 = emptyOpt.get(); Ceci va jeter une erreur car il ne peut pas nous retourner l'ensemble vide, il faut donc utiliser orElseThrow()
// 		// Ci-après jette quand même une erreur mais nous permet de nous rappeler de prendre en consideration que l'optional peut etre vide
// 		// String string2 = emptyOpt.orElseThrow();
// 		// System.out.println("Contenu de emptyOpt : " + string2);
//
// 		// A savoir, la classe optional ne peut pas contenir "null" !
// 		// En effet, le code ci-dessous va jeter une nullPointerException, alors que le code precedent c'est une autre erreur
// 		// Optional<String> nullOpt = Optional.of(null);
// 		// System.out.println("Contenu de nullOpt = " + nullOpt);
//
// 		// Enfin, nous pouvons tester avec la methode ofNullable() si un optional est null, si il est null, il retourne un optional vide
// 		// Donc si nous sommes dans du code et nous ne savons pas si l'objet que nous passons en parametre est null ou pas, nous pouvons appeler ofNullable()
// 		Optional<String> nullOpt = Optional.ofNullable(null);
// 		boolean empty2 = nullOpt.isEmpty();
// 		System.out.println("nullOpt is empty = " + empty2);
// 	}
// }
//
//
// package org.vitu.stream;
//
// import java.io.IOException;
// import java.nio.file.Files;
// import java.nio.file.Path;
// import java.util.Comparator;
// import java.util.List;
// import java.util.function.Function;
// import java.util.regex.Pattern;
// import java.util.stream.Collectors;
// import java.util.stream.Stream;
//
// public class PlayWithMapFilterReduce {
//
// 	public static void main(String[] args) throws IOException {
//
// 		List<String> strings = List.of("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten");
//
// 		// Jusqu'a present nous avons vu l'operation de mapping et l'operation de filtrage
// 		// --> Le mapping ne change pas le nombre d'elements traites, mais on change le type des elements
// 		int maxLength =
// 		strings.stream() // Stream<String>
// 			.map(s -> s.length()) // Stream<Integer>
// 			.max(Comparator.naturalOrder()) // L'operation max retourne un optional
// 			.orElseThrow(); // Puisque c'est un optional, get(), ne fonctionnera pas
//
// 		System.out.println("Longueur max = " + maxLength); // Retourne 5
//
// 		// Maintenant que se passe t'il si on reprends le code qui permet de lire le fichier (en reprenant du code de la class FirstContactWithStream
// 		String fileName = "files/lines.txt";
// 		Path path = Path.of(fileName);
//
// 		// Maintenant si on cherche un max entier :
// 		int maxLengthLine =
// 		Files.lines(path)
// 			.mapToInt(String::length) // En passant mapToInt() cela nous retournera une IntStream() au lieu de map(), ca nous evite de passer un comparateur dans max()
// 			.max() // Car nous savons comment comparer des entiers de facon naturelle
// 			.orElseThrow();
// 		System.out.println("Longueur max = " + maxLengthLine); // Nous donne la longueur de la ligne la plus longue (20) et non pas la ligne la plus longue
//
// 		// Et si nous cherchons un max de chaine de caracteres :
// 		String maxLineByLength =
// 		Files.lines(path)
// 			.max(Comparator.comparing(line -> line.length()))
// 			.orElseThrow(); // le max de string retourne un optional donc nous devons utiliser orElseThrow()
// 		System.out.println("Ligne de longueur maximale = " + maxLineByLength); // retourne "five six seven eight"
//
// 		// Pour le moment nous avons 4 lignes, donc 4 elements dans notre Stream<>
// 		long count = Files.lines(path).count();
// 		System.out.println("Count = " + count);
//
// 		// Mais nous voudrions avoir 12 elements dans notre Stream<>, nous pouvons utiliser la technique pattern
// 		System.out.println("\nStream sur une ligne découpée par un pattern");
//
// 		Pattern pattern = Pattern.compile("[ ,:!]");
//
// 		Function<String, Stream<String>> toWords =
// 			l -> pattern.splitAsStream(l);
//
// 		String line = "one two three four";
// 		Stream<String> stream = toWords.apply(line);
// // 			Pattern.compile(" ")
// // 				.splitAsStream(line);
// 		stream.forEach(System.out::println);
//
// 		// Ici nous avons mis le pattern de split dans une fonction, et l'appliquons sur la ligne que nous voulons
// 		Stream<Stream<String>> streamOfStream =
// 		Files.lines(path) // Retourne un Stream<String>
// 			.map(toWords); // Stream<Stream<String>>
//
// 		long count2 = streamOfStream.count();
// 		System.out.println("Count = " + count2); // Nous obtenons toujours 4, car la methode map() ne modifie jamais le nombre d'elements du Stream<> sur lequel elle opere
//
// 		Files.lines(path)
// 			.map(toWords)
// 			.forEach(System.out::println);
// 		// Retourne :
// 		// java.util.stream.ReferencePipeline$Head@66d33a
// 		// java.util.stream.ReferencePipeline$Head@7cf10a6f
// 		// java.util.stream.ReferencePipeline$Head@7e0babb1
// 		// java.util.stream.ReferencePipeline$Head@6debcae2 --> donc les 4 elements retournes sont bien des Stream car c'est l'interface Stream qui nous est retournee
//
// 		// Maintenant plutot que d'avoir un Stream<> qui contient 4 Stream<> qui contiennent des elements, nous voulons un seul Stream<> avec tous les elements des Stream<Stream<>> remis a plat
// 		long countwords = Files.lines(path) // Retourne un Stream<String>
// 			.flatMap(toWords) // Retourne aussi un Stream<String>
// 			.count();
// 		System.out.println("Count words : " + countwords);
// 		// Ainsi flatMap() prends une fonction et cette fonction doit retourner un Stream<>, et elle prends les Stream<> créés par cette fonction et les met a plat dans un Stream<> unique
// 		// Donc map() ne change pas le nombre d'elements du Stream<>, mais flatMap() si.
//
// 		// Travaillons a présent avec une liste contenant tous les mots du fichier
// 		List<String> words =
// 		Files.lines(path)
// 			.flatMap(toWords)
// 			.collect(Collectors.toList());
// 		System.out.println("\nMots du fichier texte :");
// 		words.forEach(System.out::println); // Ici nous utilisons la methode forEach() de List<>
//
//
// 		String word = "eleven";
// 		Stream<Character> letters = word.chars().mapToObj(letter -> (char)letter);
// 		// Ici nous pourrions très bien dire que letters est une fonction, qui prends un string, et retourne un Stream<Character>
// 		Function<String, Stream<Character>> toLetters = w -> w.chars().mapToObj(letter -> (char)letter);
//
// 		System.out.println("\nLettres :");
// 		letters.forEach(System.out::println);
//
// 		System.out.println("\nLettres en utilisant la méthode chars :");
// 		toLetters.apply("twelve").forEach(System.out::println);
//
// 		// Nous pouvons donc faire un flatMap sur cette exemple aussi, pour avoir un seul Stream<Character>
// 		System.out.println("\nLettres du fichier :");
// 		Files.lines(path) // Stream<String> : lignes du fichier
// 			.flatMap(toWords) // Stream<String> : mots du fichier
// 			.flatMap(toLetters) // Stream<Character> : lettres du fichier
// 			.distinct() // Pour enlever les doublons
// 			.sorted() // Pour les trier par ordre alphabétique
// 			.forEach(System.out::print); // Pour toutes les imprimer sur la meme ligne et non une ligne par lettre pour "println"
//
// 		// Maintenant nous ajoutons des caracteres speciaux au fichier lines.txt
// 		// Pour ne pas avoir ces caracteres speciaux dans nos Stream<> il nous suffit d'ajouter ces caracteres speciaux au pattern initial (uniquement les espaces)
// 		// --> Pattern pattern = Pattern.compile("[ ,:!]");
// 		// Si a présent on ajoute "émile" au fichier .txt : Nous sommes sense avoir une erreur, car Java est sensé utiliser des fichiers UTF-8
// 		// On peut modifier l'encryptage du fichier en faisant clic droit > propriétés sur le fichier dans le package explorer
// 	}
// }
//
//
// package org.vitu.stream;
//
// import java.io.IOException;
// import java.nio.charset.StandardCharsets;
// import java.nio.file.Files;
// import java.nio.file.Path;
// import java.util.stream.Stream;
//
// public class PlayWithCharset {
//
// 	public static void main(String[] args) throws IOException {
//
// 		// Stockage de l'input dans une variable
// 		Path path = Path.of("files/lines-non-utf8.txt");
// 		// Creation d'un Stream<> encodant dans un Charset en particulier
// 		Stream<String> lines = Files.lines(path, StandardCharsets.ISO_8859_1);
// 		System.out.println("Count = " + lines.count());
// 	}
// }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Coding sur l'Api Stream n°1 2/2 //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// package org.vitu.stream;
//
// import java.io.IOException;
// import java.nio.file.Files;
// import java.nio.file.Path;
// import java.util.Collection;
// import java.util.Comparator;
// import java.util.List;
// import java.util.Map;
// import java.util.Map.Entry;
// import java.util.Set;
// import java.util.function.Consumer;
// import java.util.function.Function;
// import java.util.function.Predicate;
// import java.util.stream.Collectors;
// import java.util.stream.Stream;
//
// import org.vitu.stream.model.Commune;
// import org.vitu.stream.model.Departement;
//
// public class PlayWithDepartements {
//
// 	public static void main(String[] args) throws IOException {
//
// 		// Appel a la methode
// 		String path = "files/departements.txt";
// 		List<Departement> departements = readDepartements(path);
//
// 		departements.forEach(System.out::println);
//
// 		List<Commune> communes = readCommunes("files/communes.txt");
// 		System.out.println("# Communes = " + communes.size());
//
// 		// Maintenant pour distribuer les communes par departement, nous allons utiliser l'API Collectors dans une table de hashage
//
// 		// D'abord nous allons creer la function qui nous retournera le departement en fonction de la commnune
// 		Function<Commune, String> toCodeDepartement =
// 			commune ->
// 				commune.getCodePostal().startsWith("97") ?
// 					commune.getCodePostal().substring(0, 3) :
// 					commune.getCodePostal().substring(0, 2);
// 		// Maintenant pour tester que notre fonction fonctionne bien
// 		// communes.stream()
// 		// 	.map(toCodeDepartement)
// 		// 	.distinct()
// 		// 	.forEach(System.out::println);
//
// 		// Pour regrouper les sous-stream en list<>, nous pouvons passer un downstream collector au collector groupingBy()
// 		Map<String, List<Commune>> communeByCodeDepartementList =
// 			communes.stream()
// 				.collect(Collectors.groupingBy(toCodeDepartement, Collectors.toList()));
//
// 		Map<String, Set<Commune>> communeByCodeDepartementSet =
// 				communes.stream()
// 					.collect(Collectors.groupingBy(toCodeDepartement, Collectors.toSet()));
//
// 		System.out.println("# of map = " + communeByCodeDepartementList.size());
// 		System.out.println("# of map = " + communeByCodeDepartementSet.size());
//
// 		Map<String, Long> numberOfCommunesByCodeDepartement =
// 			communes.stream()
// 				.collect(
// 						Collectors.groupingBy(
// 								toCodeDepartement,
// 								Collectors.counting())
// 						);
// 		System.out.println("# communes " + numberOfCommunesByCodeDepartement);
//
// 		communeByCodeDepartementList.get("93")
// 			.forEach(System.out::println);
//
// 		communeByCodeDepartementSet.get("78")
// 		.forEach(System.out::println);
//
// 		long count = communeByCodeDepartementList.get("93").stream()
// 				// .count();
// 				.collect(Collectors.counting()); // Nous pouvons aussi compter aeec un collector
// 		System.out.println("# communes dans le 93 : " + count);
//
// 		// Nombre total de communes
// 		// Departement departement = departements.get(0);
// 		Consumer<Departement> addCommunesToDepartement =
// 				d -> communes.stream()
// 					.filter(c -> c.getCodePostal().startsWith(d.getCodePostal()))
// 					.forEach(d::addCommune);
// 		departements.forEach(addCommunesToDepartement);
// 		departements.forEach(d -> System.out.println(d.getNom() + " possède " + d.getCommunes().size() + " communes."));
//
// 		// Flatmap
// 		Function<Departement, Stream<Commune>> flatMapper = d -> d.getCommunes().stream();
//
// 		long countCommunes = departements.stream().flatMap(flatMapper).count();
// 		System.out.println("# communes = " + countCommunes);
//
// 		// Le departement qui a le plus de communes
// 		// communes {78=4, 974=23, 93=4}
// 		Map.Entry<String, Long> maxEntry = numberOfCommunesByCodeDepartement.entrySet().stream()
// 				// .max(Comparator.comparing(entry -> entry.getValue()))
// 				.max(Map.Entry.comparingByValue())						// Equivalent a la ligne precedente
// 				.orElseThrow();											// Car le max() nous retourne un optional
// 		String maxCodeDepartement = maxEntry.getKey();
// 		Long maxCountOfCommunes = maxEntry.getValue();
// 		System.out.println(maxCodeDepartement + " -> " + maxCountOfCommunes);
//
// 		Set<String> keySet = numberOfCommunesByCodeDepartement.keySet();
// 		Collection<Long> values = numberOfCommunesByCodeDepartement.values();
// 		Set<Entry<String, Long>> entrySet = numberOfCommunesByCodeDepartement.entrySet();
// 	}
//
// 	private static List<Commune> readCommunes(String path) throws IOException {
// 		Path pathToCommunes = Path.of(path);
//
// 		Predicate<String> isComment = line -> line.startsWith("#");
//
// 		Function<String, String> toNom = l -> l.substring(0,l.indexOf(" ("));
//
// 		Function<String, String> toCodePostal = l -> l.substring(l.indexOf(" (") + 2, l.length() - 1);
//
// 		Function<String, Commune> toCommune = l -> new Commune(toNom.apply(l), toCodePostal.apply(l));
//
// 		List<Commune> communes =
// 			Files.lines(pathToCommunes)
// 				.filter(isComment.negate())
// 				.map(toCommune)
// 				.collect(Collectors.toList());
// 		return communes;
// 	}
//
// 	private static List<Departement> readDepartements(String path) throws IOException {
// 		// Nous creons un path menant a la source de donnees
// 		Path pathToDepartements = Path.of(path);
// 		// Nous creons un predicat qui teste si une ligne est une ligne de commentaire
// 		Predicate<String> isComment = line -> line.startsWith("#");
// 		// Nous creons une fonction (qui peut servir en parametre de map()) qui transforme un string en un autre string pour recuperer le code postal d'une ligne
// 		Function<String, String> toCodePostal = l -> l.substring(0, l.indexOf(" - "));
// 		// Nous creons une fonction (qui peut servir en parametre de map()) qui transforme un string en un autre string pour recuperer le nom d'une ligne
// 		Function<String, String> toNom = l -> l.substring(l.indexOf(" - ") + 3);
// 		// Nous creons une derniere fonction qui combine les deux et que nous pourrons passer en parametre de map()
// 		Function<String, Departement> toDepartement = l -> new Departement(toCodePostal.apply(l), toNom.apply(l));
// 		// Nous creons la liste de departement en passant par des stream
// 		return Files.lines(pathToDepartements)		// Retourne toutes les lignes du fichier
// 				.filter(isComment.negate())			// Retourne toutes les lignes sauf les lignes de commentaires
// 				.map(toDepartement)					// Retourne des departements et nom des string
// 				.collect(Collectors.toList());		// Retourne une List<Departement>
// 	}
//
// 	// int indexOfSeparator = line.indexOf(" - ");
// 	// String codePostal = line.substring(0, indexOfSeparator);
// 	// String nom = line.substring(indexOfSeparator + 3);
// 	// String codePostal = toCodePostal.apply(line);
// 	// String nom = toNom.apply(line);
// 	// String line = "93 - Seine Saint-Denis";
//
// 	// Departement departement = toDepartement.apply(line);
//
// 	// System.out.println("departement = " + departement);
// 	// System.out.println("code postal = " + codePostal);
// 	// System.out.println("nom = " + nom);
//
// 	// String line = "La Plaine-des-Palmistes (97406)";
//
// 	// String nom = line.substring(0, line.indexOf(" ("));
// 	// String codePostal = line.substring(line.indexOf(" (" ) + 2,  line.length() - 1);
// 	// System.out.println("nom = " + nom);
// 	// System.out.println("code postal = " + codePostal);
// }
//
// package org.vitu.stream;
//
// import java.util.List;
// import java.util.Map;
// import java.util.Map.Entry;
// import java.util.function.Function;
// import java.util.stream.Collectors;
//
// public class CountingStreamElement {
//
// 	public static void main(String [] args) {
//
// 		// Quel element apparait le plus souvent dans cette liste
// 		List<String> strings =
// 				List.of("one", "five", "one", "two", "six", "seven", "eight", "two", "three", "four",
// 						"five", "one", "eight", "nine", "ten", "two", "three", "four", "six", "seven",
// 						"eight", "two", "three", "four", "five", "one", "eight", "nine", "ten", "two",
// 						"one", "eight", "nine", "ten", "eight", "nine", "ten", "nine", "ten", "two");
//
// 		Function<String, String> classifier = word -> word;
// 		// Map<String, Long> map =
// 		// Map<String, List<String>> map =
// 		Map<String, Long> map =
// 			strings.stream()
// 				.collect(Collectors.groupingBy(classifier, Collectors.counting()));
// 		System.out.println("Map = ");
// 		map.forEach((key, value) -> System.out.println(key + " -> " + value));
//
// 		Map.Entry<String, Long> maxEntry =  map.entrySet().stream().max(Map.Entry.comparingByValue()).orElseThrow();
//
// 		System.out.println("\nMax entry by value = ");
// 		System.out.println(maxEntry.getKey() + " -> " + maxEntry.getValue());
// 		// Ceci fonctionne tant que nous n'avons pas d'ex equo en max, que se passe t-il si nous avons deux max()
// 		// Nous allons renverser la table de hashage en mettant le nombre d'occurences en clef et une liste de string associes
// 		// 4 -> [one, two]
// 		// Plutôt que chaque string (sans doublon) en clef et leurs nombre d'occurences en valeurs
// 		// one -> 4
// 		// two -> 4
// 		// Map<Long, List<Map.Entry<String, Long>>> map2 =
// 		Map<Long, List<String>> map2 = map.entrySet().stream()						// Map.Entry<String, Long>
// 			.collect(Collectors.groupingBy(entry -> entry.getValue(),
// 					Collectors.mapping(entry -> entry.getKey(), Collectors.toList())));
//
// 		Map.Entry<Long, List<String>> maxEntry2 = map2.entrySet().stream().max(Map.Entry.comparingByKey()).orElseThrow();
//
// 		System.out.println("\nMax entry by key = ");
// 		System.out.println(maxEntry2.getKey() + " -> " + maxEntry2.getValue());
// 		// Retourne 6 -> [two=6, eight=6], ce qui n'est pas très beau, donc nous allons passer un downstream collector
// 	}
// }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Troisième Partie : L'accès aux fichiers dans Java /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : Exceptions /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définition des Exceptions /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'est ce qu'une erreur dans une application Java /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent comment nous pouvons gérer les erreurs dans les applications en Java.
// Nous devons tout d'abord distinguer plusieurs types d'erreurs :
// --> les bugs : sont la première catégorie d'erreurs.
// Par exemple, lors de la lecture d'un tableau de 10 éléments, nous souhaitons ajouter un onzième élément, or cela est impossible car un tableau ne peut pas être redimmensionné une fois établi.
// Cela peut aussi être l'invocation d'une méthode au travers d'un pointeur qui est null.
// Ces deux exemples sont des choses que nous devons corriger dans notre application si jamais ils sont rencontrés.
// --> Runtime / JVM : imaginons que nous avons une application qui fonctionne mais qui demande beaucoup de mémoire, voire de plus en plus, et finalement plus que ce que la JVM peut lui fournir.
// La JVM fonctionne dans un système d'exploitation, celui-ci gère une certaine quantité de mémoire, la mémpoire physique en général.
// Il ne peut donc pas fournirà la JVM plus de mémoire qu'il ne l'est autorisé.
// --> Erreurs auxquelles nous pouvons nous attendre : erreurs que nous pouvons anticiper.
// Par exemple, nous avons une application qui fait appel à un système de fichier, qui va lire et écrire des fichiers.
// L'application est bien écrite, il n'y a pas de bug, ni de problèmes de mémoire.
// Par contre nous avons besoin d'avoir accès à la partition sur le disque sur lequel ces fichiers existent.
// Manque de chance, quelqu'un à l'extérieur de mon application modifie cette partition, et modifie les droits d'accès en lecture et en écriture sur cette partition.
// A ce moment-là l'application va rencontrer des erreurs de fonctionnement, du fait que l'environnement extérieur à changé, et que celui-ci ne nous permet plus de garantir un fonctionnement nominal.
// Ce sont des erreurs que nous pouvons anticiper dans une application, et que nous devons étudier pour avoir une application robuste.
// --> Ces trois types d'erreurs sont gérées différement par le langage Java avec des catégories d'exception pour chacune de ces erreurs.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Class Throwable, message d'erreur et pile d'appel /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir que ces trois catégories d'erreur sont modélisées par autant de classes, et en fait une erreur est un objet, une instance d'une classe.
// En Java, tout est objet, y compris les erreurs que nous allons pouvoir manipuler.
// --> Parmi les classes qui modélisent les erreurs, nous en avons une qui est fondamentale, la classe 'Throwable', attention, ce n'est pas une interface, mais bien une classe.
// Cette classe a un statut particulier dans le JDK : toutes les classes qui "extends" la classe Throwable vont modéliser des erreurs et vont être gérées de manière particulière par la JVM.
// Dans cette classe, nous avons trois propriétés fondamentales :
// - Le message d'erreur : Quand une erreur est générée, une extension de Throwable va être générée.
// Et dans cet objet, nous pouvons enregistrer un String qui va porter le message d'erreur qui va nous permettre d'expliquer ce qu'il s'est passé, et quel était le contexte de génération de cette erreur.
// Remarque : Si nous travaillons sur une application internationalisée, supportant plusieurs langues, nous pouvons internationaliser les messages d'erreur.
// Ainsi, une même erreur peut avoir un message dans différentes langues, langues supportées par l'application.
// --> getMessage() : retournant une chaîne de caractères qui est le message d'erreur.
// - La stack trace : En Français, une 'pile d'appel', c'est toute la liste des méthodes, l'enchaînement d'appel de méthodes ainsi que leurs numéros de lignes, celle qui a généré l'erreur.
// --> printStackTrace() : permet d'afficher cette stack trace sur la console.
// Nous pouvons également passer des paramètres à cette méthode pour imprimer cette pile d'appel ailleurs que sur la console, notamment sur un fichier, ou l'envoyer sur le réseau par exemple.
// La stack trace est vraiment une information fondamentale lorsque nous voulons faire du debug.
// En effet, elle nous donne des informations très précises sur le contexte dans lequel était notre application lorsque l'erreur a été générée.
// - La root cause : Si jamais une erreur est générée du fait d'une autre erreur en amont, à ce moment-là cette deuxième erreur peut posséder un pointeur, vers la première erreur qui a été générée.
// Cette dernière méthode est optionelle, le message d'erreur et la stack trace sont toujours générées, contrairement à la root cause.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Première extension de Throwable: Error ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La première classe que Throwable étends est la classe Error.
// Cette classe modélise les erreurs qui en général ont lieu au niveau de la JVM, au niveau du runtime Java.
// --> OutOfMemoryError : celle-ci sera jetée lorsque la JVM n'aura plus de mémoire.
// --> StackOverflowError : par exemple lorsqu'une méthode s'appele elle-même, il y a saturation.
// Ces erreurs-là peuvent signaler des bug dans notre application (souvent le cas pour StackOverflowError), mais pas forcément.
// Effectivement, OutOfMemoryError ne vient pas forcément d'un bug de notre application, cela peut aussi être un problème dans la configuration de notre JVM.
// --> Ces erreurs n'ont pas besoin d'être gérées explicitement.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième extension de Throwable : Exception ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La seconde classe étendue par Throwable que nous allons voir est la classe Exception. Celle-ci est elle-même étendue par une autre classe que nous allons voir par la suite.
// Quelles sont les extensions directes de la classe Exception ?
// --> IOException : jetée lorsque nous avons un problème d'entrée / sortie (Input/Output) : accès réseau ou disque.
// --> FileNotFoundException : Cette exception concerne une erreur à l'accès disque et étends l'IOException.
// --> Nous avons aussi "SQLException" : nous pouvons envoyer des commandes SQL au travers d'un module Java qui s'appelle JDBC.
// Ces commandes SQL vont être envoyées et analysées par la base de donnée. Or Java n'a pas les moyens pour vérifier si le SQL est correct.
// Donc si jamais la SQL n'est pas correcte, une erreur va être lancée dans la base de donnée, et renvoyée à l'application qui va nous lancer la SQLException.
// --> Ces exceptions ont besoin d'être gérées explicitement.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Troisième extension de Throwable : RuntimeException ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour la dernière catégorie, Exception est elle-même étendue par la classe "RuntimeException".
// --> NullPointerException.
// --> ArrayIndexOutOfBoundsException : lorsque nous essayons de lire au delà de la limite d'un tableau.
// --> ArithmeticException : par exemple lors d'une division par 0 sur un entier ou un long.
// Ces trois exceptions sont des bugs.
// --> Ces erreurs n'ont pas besoin d'être gérées explicitement.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Exceptions checked et unchecked ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Donc voila pour les trois catégories d'erreur.
// --> Les errors, qui sont une extension directe de Throwable. Ils signalent généralement des problèmes liés au RunTime, mais aussi parfois des bugs comme pour StackOverflowError.
// --> La seconde extension de Throwable, c'est Exception qui possède les extensions directes IOException, FileNotFoundException et SQLException, ce sont des erreurs que nous pouvons anticiper.
// Le JDK, le langage Java va nous obliger à les gérer explicitement --> ce sont les 'Checked Exception'.
// --> Enfin nous avons les Runtime Exceptions, qui étendent la classe Exception, qui étends elle-meme Throwable.
// Celles-ci sont appelées 'Unchecked Exception' car elles n'ont pas besoin d'être gérées explicitement.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gestion des Exceptions ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérer une exception localement ou en la transmettant //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous venons de voir que nous avons deux catégories d'Exceptions : les 'Unchecked Exception' et 'Checked Exception'.
// Nous n'avons pas besoin de gérer les Unchecked Exceptions.
// Les Checked Exceptions, elles doivent être gérées --> Il nous faut donc écrire du code qui prévoit le cas où une Checked Exception est effectivement générée par une application.
// Par exemple, nous essayons de lire un fichier, il va falloir, et c'est le JDK qui nous oblige ça, il va falloir écrire du code qui gère la situation dans laquelle le fichier n'est pas lisible.
// La Gestion d'une Exception, c'est écrire du code spécifique pour cette exception. Ceci peut-être fait selon deux approches :
// --> Attraper l'exception et la traiter localement : Par exemple, nous avons besoin de nous adresser à une base de données, pour une raison ou une autre, celle-ci n'est pas disponible.
// Nous envoyons une requête et nous recevons une erreur, localement nous aurons du code qui va nous dire que la base de données n'est pas disponible, donc nous n'allons pas pouvoir faire notre traitement.
// --> Transmettre l'exception au code qui nous appelle : Avec le même exemple, nous recevons une erreur et nous la transmettons a la méthode qui l'appelle.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transmettre une exception au code appelant avec un throws /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Premier cas, nous jouons à la patate chaude en transmettant l'exception créée à la méthode appellée.
// Imaginons que nous avons le code suivant :
// public String readFromFile(...)
//      {
//          String line = readLine();
//          return line;
//      }
// La méthode readLine() effectue un accès au disque, celui-ci peut échouer, et l'exception qui va être générée (IOException ou FileNotFoundException) doit être gérée explicitement.
// Pour faire le premier cas, nous devons modifier la signature de notre méthode en utilisant le mot clef 'throws':
// --> Public String readFromFile(...) throws FileNotFoundException {...}
// Nous devons donc juste ajouter le nom de la classe après 'throws', ce n'est pas forcément une checked exception, cela peut aussi être une unchecked exception, même si ce n'est pas forcément utile.
// Cela nous indique que l'exécution de la méthode est susceptible de générer une exception de la classe qui est désignée.
// Donc, la méthode qui appelle readFromFile() devra à son tour, soit gérer localement l'exception, soit la transmettre à sa méthode mére.
// Lorsque nous sommes dans une méthode de bas niveau, il est très difficile de prendre une décision sur ce que nous pouvons faire avec une exception.
// Généralement nous allons la transmettre, jusqu'à nous retrouver dans un code de niveau suffisant qui va pouvoir donner un sens métier à cette exception.
// A ce moment-là nous pourrons soit signaler l'exception à l'utilisateur, soit retomber sur un comportement par défaut.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Attraper une exception avec un try / catch ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La seconde possibilité est de traiter l'exception localement et donc d'écrire du code qui va commencer par attraper l'exception.
// Pour ce faire dans un premier temps, nous allons exécuter le code concerné dans un bloc try{} :
// public String readFromFile(...)
//      try {
//          String line = readLine();
//          return line;
//      } catch (FileNotFoundException e) {e.getMessage()};
// Ensuite nous utilisons le mot clef catch() : qui signifie que nous allons attraper les exceptions qui sont susceptibles d'être généré oar le code dans le bloc try{}.
// catch() prends en paramètre le nom de la classe de l'exception susceptible d'être généré et le range dans un paramètre que nous appelons e comme exception.
// Dans le bloc suivant, nous écrivons ce qui doit être fait avec l'exception générée.
// Ce pattern fondamental est appelé le pattern try / catch.
// L'exécution de ce code se déroule de la manière suivante :
// --> En premier lieu, le JDK teste la méthode readLine(), si celle-ci se déroule bien, dans ce cas, la méthode return est exécutée, l'intérieur du catch ne sera pas exécuté.
// --> Si une exception survient lors de la méthode readLine(), la méthode return n'est pas exécutée, car la variable line ne s'est pas créée vu que readLine() n'a pas pu s'exécuter.
// --> A ce moment-là, le bloc catch est exécuté, et nous passons au return final, qui sera une valeur par défaut.
// A noter que si nous avons une NullPointerException avec ce code, elle sera jetée car elle n'a pas été citée dans le bloc catch.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Attraper plusieurs exceptions avec plusieurs blocs catch //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Que se passe t'il si nous avons un bloc try{} qui peut générer plusieurs exceptions ?
// try {
//     String line = readLine();
//     int number = Integer.parseInt(line);
// }
// Nous avons plusieurs stratégies que nous pouvons appliquer :
// --> Nous décidons d'attraper toutes les exceptions que ce code est susceptible de générer :
// catch (Exception e) {...}
// Ici, toutes les exceptions qui sont des instances de la classe entre parenthèses, ici Exceptions, seront concernées par le bloc de code du catch.
// C'est rarement une bonne idée de mettre Exception ou même Throwable, car un bug pourrais se cacher derrière une autre exception.
// --> La seconde approche consiste à faire un bloc catch par exception :
// catch (FileNotFoundException e) {...} catch (NumberFormatException e) {...}
// Ici, si nous avons une NullPointerException, elle ne lancera pas l'un de ces deux blocs catch.
// Tout ceci est vrai jusqu'à Java 6, à partir de Java 7, nous avons une autre méthode que nous allons voir à présent.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer et jeter une exception applicative à partir d'une exception du JDK //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Revenons à présent sur le pattern de multi-catch :
// try {
//     String line = readLine();
//     int number = Integer.parseInt(line);
// } catch (IOException | NumberFormatException e) {
// A.E. ae = new ApplicationException();
// throw ae;
// };
// Nous utilisons le pipe pour créer un 'ou'.
// Maintenant nous voulons convertir l'exception e en une Exception Applicative. C'est très utile pour créer des exceptions liées a la partie métier de l'application.
// Ci-dessus nous avons créer une nouvelle exception d'application, et l'avons jetée en utilisant 'throw' et non 'throws', cette dernière étant la signature que l'on ajoute à une méthode.
// Or nous avons vu que dans la classe Throwable, nous avions plusieurs propriétés : le message et la stacktrace.
// Lorsqu'on créée la new ApplicationException(), la stack trace se fait sur cette ligne là, or la véritable exception est le 'e' du bloc catch.
// Sauf que dans l'exemple ci-dessus, nous ne saurons pas si c'est un IOExceptio ou une NumberFormatException, et donc nous ne saurons pas de quelle ligne du bloc try{} l'exception a été jetée.
// Pour contourner ce problème il nous faut passer l'exception e en paramètre de la nouvelle ApplicationException(e).
// Donc, la troisième propriété de la classe Throwable est qu'elle définit la root cause.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ajouter un bloc finally à un try / catch //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le pattern try / catch tel que nous l'avons vu n'est pas tout à fait complet. Nous pouvons y rajouter une dernière clause après try / catch, qui est la cause 'finally'.
// Nous avons donc trois éléments :
// --> try {} : dans lequel nous essayons d'exécuter le code.
// --> catch (Exception e) {} : dans lequel nous attrapons les exceptions, nous pouvons aussi avoir un multi-catch, et même plusieurs blocs catch.
// --> finally {} : dans lequel nous garantissont que le code contenu dans le bloc finally sera exécuté après les blocs try et catch. Celui-ci est optionnel.
// Ce dernier bloc nous permet donc d'exécuter du code qui doit être exécuté malgré une éventuelle exception. Par exemple, une partie du bloc try peut se retrouver dans le finally.
// A noter que si l'exécution du bloc try est réussie, le bloc catch n'est par conséquent pas exécuté, toutefois, le bloc finally sera dans tous les cas de figure exécuté.
// L'utilisation de ce bloc finally peut être très utile lors d'utilisation de fichiers, car nous devons toujours les fermer, et ce bloc pourra les fermer qu'une erreur soit jetée ou non.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ne jamais mettre de return dans un bloc catch ou un finally ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrivons un petit quizz :
//     String quizz(){
//         try{
//             return "try";
//         } catch (Exception e) {
//             return "catch";
//         } finally {
//             return "finally";
//         }
//     }
// Qu'est-ce que cette méthode va nous retourner ?
// Nous exécutons le return "try" sans encombre donc le bloc catch ne sera pas exécuté, toutefois le bloc finally le sera donc nous aurons aussi return "finally" avant de quitter la méthode.
// De même si nous avons une exception jetée dans le try, le return "catch" sera exécuté, mais aussi le return "finally", car celui-ci est garanti d'être exécuté avant de quitter la méthode.
// Donc quel return va gagner ? Le try ou le finally ? Le catch ou le finally ?
// IL NE FAUT JAMAIS ECRIRE DE RETURN DANS UN CATCH OU UN FINALLY !

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Conclusion sur la gestion des erreurs en Java /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons deux catégories d'erreurs : CHECKED / UNCHECKED.
// --> CHECKED : qui étends la classe Exception.
// --> UNCHECKED : qui étends les classes Error et RuntimeException qui étends elle-même Exception.
// Toutes ces classes étendes une classe fondamentale qui est Throwable, et qui contient trois propriétés fondamentales :
// --> Un message d'erreur : que nous pouvons récupérer avec le getter 'getMessage()' et qui peut être internationalisé.
// --> Une stack trace : nous avons une API particulière pour manipuler cette stack trace et pour la visiter, introduite dans une version plus récente de Java.
// --> Une root cause : quand elle existe, car une exception peut être elle-même sa propre root cause.
// Ces propriétés sont donc disponibles sur toutes les classes d'exceptions que nous pouvons imaginer.
// Pour les checked exception, nous sommes obligé de les gérer, et nous avons deux pattern disponibles pour ce faire :
// --> Le try / catch / (finally) : avec la clause finally qui est optionnelle.
// --> Déclarer que l'exception est jetée par la méthode dans laquelle nous nous situons (patate chaude).
// A l'intérieur du catch, nous pouvons décider de ce que nous faisons de l'exception, nous pouvons décider de l'enregistrer dans de la journalisation, accompagnée de sa pile d'appel (stack trace).
// Généralement dans un bloc catch, nous n'utilisons pas de System.out.println() sauf en exercice ou en test, car les applications fonctionnent le plus souvent sans console.
// Les deux Exceptions suivantes sont elles aussi notables :
// --> public class IllegalStateException extends RuntimeException : Thrown to indicate that a method has been passed an illegal or inappropriate argument.
// --> public class IllegalArgumentException extends RuntimeException : Signals that a method has been invoked at an illegal or inappropriate time.
// In other words, the Java environment or Java application is not in an appropriate state for the requested operation.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : API Java I/O ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à l'API Java I/O /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Parlons à présent d'une API extrèmement importante du JDK, l'API Java I/O : Input / Output.
// Cette API s'intéresse à l'intégralité des mécanismes qui permettent à une application Java qui vit dans une machine Java d'aller échanger des données à l'extérieur, d'en recevoir ou d'en envoyer.
// Qu'est-ce que nous pouvons considérer comme l'extérieur ? Il s'agit de deux choses majoritairement et d'une troisième chose mineure :
// --> Les disques de stockage de masse : au travers de l'API Java I/O, nous allons pouvoir lire et écrire des fichiers sur le disque.
// --> Le réseau : qui contient deux types de ressources extrèmement importantes auxquelles nous pouvons accéder :
//      - Le web, au travers du protocole HTTP.
//      - Les bases de données.
// A savoir qu'il existe des bases de données en mémoire qui peuvent fonctionner à l'intérieur de la JVM dans laquelle fonctionne notre application, bien que ce soit rare.
// Les échanges avec les bases se font indépendemment du fait qu'elles soient SQL (relationnelles), ou NOSQL (type Mongo).
// --> L'accès à la mémoire dite 'Off Heap' : Lorsque nous créons des objets dans une JVM, ils sont créés dans une zone de mémoire qui s'appelle 'heap'.
// Cette mémoire est celle qui est gérée de façon directe par la JVM. Elle est gérée au sens où nous pouvons demander de la mémoire dedans.
// Lorsqu'elle n'est plus utilisée, elle sera récupérée par le 'garbage collector'. Donc la mémoire 'heap' est gérée par le 'garbage collector'.
// Il existe une autre zone de mémoire, externe à la mémoire dite 'heap', que nous appelons la mémoire 'off heap'.
// C'est donc au travers, non pas directement de Java I/O, mais au travers d'extensions de Java I/O que nous pouvons accéder à cette mémoire 'off heap'.
// Cette mémoire 'off heap' est vraiment importante car elle permet d'étendre les capacités de mémoire d'une application Java par plusieurs ordres de grandeur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java IO, NIO et NIO 2 /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent l'organisation générale, ainsi qu'avec une perspective historique :
// --> 1995 : Java 1 : Java I/O.
// --> 2002 : Java 4 : Java NIO (Java New Input Output), c'est dans cette nouvelle version que se trouve les échanges avec la mémoire 'off heap'.
// --> 2011 : Java 7 : Java NIO2 : qui amène des nouvelles classes, performances et concepts.
// --> De futures travaux sont réalisés sur la mémoire 'off heap' et sortiront avec de versions futures de Java.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java I/O : Accès disques //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Chemins sur un disque avec File et Path ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Un des points fondamentaux de Java qu'il faut bien comprendre est celui de la 'portabilité'.
// Cela signifie qu'une application doit fonctionner de la même façon dans une JVM, indépendamment de l'OS sur lequel nous nous situons.
// Toutefois, si il y a bien quelque chose de spécifique aux OS, c'est la manière d'accéder au disque, par conséquent la manière dont nous écrivons les chemins vers le disque.
// Il y a donc un gros effort de l'API Java I/O pour essayer d'abstraire le fait que nous nous adressons à un disque Windows, Linux ou MacOS.
// Cet effort d'abstraction commence déjà sur la façon dont nous allons accéder aux fichiers sur le disque.
// Pour modéliser les chemins sur les disques, nous avons deux éléments :
// --> File : qui est une classe, présente depuis Java 1.
// --> Path : qui est une interface, nous permettant de faire des choses que Path ne nous permet pas de faire. Qui dit interface, dit classe d'implémentation. Path est arrivé avec Java 7, donc NIO2.
// Ces deux éléments permettent de modaliser des chemins vers le 'File System'.
// Quel est l'intérêt d'avoir fait une interface plutôt qu'une classe ? Cela nous permet d'avoir une classe d'implémentation qui est propre à chaque système d'exploitation.
// En général, ces file systems exposent les mêmes fonctionnalités, nous pouvons toujours écrire le chemin vers un fichier, vérifier si celui-ci existe, si il peut être lu, écrit, créé...
// Si ce chemin représente un fichier au sens classique ou plutôt un répertoire, ou si le fichier est un fichier exécutable.
// Ces fonctionnalités qui existent dans tous les OS, vont se trouver dans la classe 'File'.
// Par contre, il y a parfois des attributs plus spécifiques qui ne sont pas modélisés par 'File', par exemple les attributs de sécurité.
// Chacune des implémentations spécifiques de 'Path' vont pouvoir exposer dans ces applications les attributs de sécurité qui sont spécifiques à chaque File System.
// D'où l'intérêt d'avoir une interface avec plusieurs implémentations propres à chaque File System, plutôt qu'une classe générique qui va représenter un dénominateur commun entre tous les File System.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer des instances de File et Path ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment pouvons nous créer une instance de File :
// --> File f = new File("files/debug.log");
// --> File f = new File("c:/tmp/debug.log");
// Le paramètre qui est une chaîne de caractères représente le chemin du fichier, celui-ci peut être absolu ou relatif, ici il est sur la première ligne relatif, puis sur la seconde, absolu.
// L'API Java I/O peut changer un '/' en un '\' (ces derniers étant spécifiques à Windows). Si nous voulons utiliser les '\', nous devons les 'escaper', c'est à dire :
// --> File f = new File("c:\\tmp\\debug.log");
// Comment pouvons nous créer une instance de Path ? C'est différent, puisque c'est une interface et non une classe, nous ne pouvons pas faire 'new Path' :
// --> Path p = Path.of("files/debug.log"); --> Disponible à partir de Java 11.
// La méthode of() est une méthode factory, donc c'est une méthode statique définie directement sur l'interface Path.
// --> Path p = Paths.of("file\\debug.log"); --> Disponible à partir de Java 7.
// Dans ce cas là nous utilisons la classe factory 'Paths', qui possède exactement la même méthode of(), à laquelle nous pouvons passer notre chemin relatif ou absolu, avec '/' ou '\'.
// Nous pouvons aussi créer un Path à partir d'un URI, mais nous verrons cela plus tard.
// Il y a une chose qu'il faut absolument comprendre lorsque nous créons une instance de Path, ou que nous créons une instance de File.
// --> Ce sont des objets qui modélisent un chemin sur le File System. Cela ne créée en aucun cas un fichier sur le File System.
// Ce ne sont que grossièrement des wrappers sur une chaîne de caractères avec quelques informations supplémentaires.
// Il n'y a aucun accès disque qui est fait en utilisant new File() ou Path.of().
// Ces objets sont donc seulement des objets en mémoire, il n'y a aucun accès sur le disque, il n'y a aucune vérification de l'existance de ces fichiers ou chemin, ni de création de fichiers.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Analyse du chemin modélisé par un File ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Que pouvons nous faire sur ce chemin dans un premier temps ?
// File f = new File("files/debug.log");
// --> getName() : retourne le nom du fichier en retirant la partie 'chemin' du nom du fichier -> debug.log.
// --> getParent() : retourne le répertoire parent du fichier -> files.
// --> getPath() : retourne le chemin du fichier -> files/debug.log.
// Ces trois appels de méthodes manipulent juste des chaînes de caractères, il n'y a aucune vérification sur le disque qui est faite, aucun accès au disque.
// --> getCanonicalPath() : va essayer de déterminer le chemin absolu vers le fichier, retourne la même chose si le chemin est déjà absolu, et retourne le chemin absolu si celui fourni est relatif.
// Cette méthode amène à deux remarques importantes :
// - La notion de répertoire courant : le chemin relatif est relatif au répertoire courant de notre application, si nous utilisons Eclipse, ce sera le répertoire du projet.
// - Il faut un accès au File System : Il faut donc faire une requète au File System. Que se passe t'il si la requète échoue ? Une Exception sera générée.
// Cette méthode est donc susceptible de jeter une IOException, il faudra donc la gérer, soit avec Throws, soit avec try / catch / finally.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Manipuler un fichier avec une instance de File ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous venons de voir une première catégorie de méthodes qui nous permet d'analyser le chemin modélisé par l'objet File.
// Nous avons une deuxième catégorie de méthodes, qui nous permet de tester si ce fichier existe, et éventuellement, ce que nous pouvons faire avec ce dernier.
// --> isFile() / isDirectory() : retournent des booleans si le fichier est un fichier ou un répertoire, et sera susceptible de jeter des Exceptions, puisqu'elle effectue une requête au File System.
// --> canRead() / canWrite() / canExecute() : retournent des booleans si le fichier peut être lu, écrit ou exécuté respectivement. Sera aussi susceptible de jeter des Exceptions.
// --> exists() : retourne un boolean si le fichier existe. Sera aussi susceptible de jeter des exceptions.
// --> createNewFile() / mkDir() / mkdirs() : créé un fichier, un répertoire ou des répertoires (dans le même url : newDir1/newDir2/newDir3...) respectivement à condition qu'il(s) n'existe(nt) pas déjà.
// --> delete() / renameTo() : tente de supprimer le fichier, puis tente de le renommer avec la chaîne de caractères passée en paramètre respectivement.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Accéder aux I/O ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisation de l'API /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment cette API Java I/O est-elle organisée ?
// Nous allons d'abord voir l'organisation générale avant de s'intéresser à chacune des parties.
// Les flux ont été divisés en deux catégories :
// - Les flux textes.
// - Les flux binaires.
// Il y a une seconde division qui sont les flux en lecture et les flux en écriture. Ces 4 catégories sont modélisées par 4 classes :
//                      Texte       |       Binaire
// Lecture :            Reader      |       InputStream
// Ecriture :           Writer      |       OutputStream
// --> Ces 4 classes sont des classes abstraites, donc pour les instancier, il va falloir les étendres. Et de ce fait, le JDK va nous fournir des extensions de ces classes.
// --> Ces 4 classes ne définissent pas le médium de sortie. Donc nous définissons comment nous lisons ou comment nous écrivons, mais nous ne définissont pas vers quoi nous écrivons ou nous lisons.
// Ce médium de sortie va typiquement être :
// -> Un Fichier.
// -> Un Socket.
// -> Un Buffer (de mémoire).
// Nous allons donc avoir non pas 4 classes mais 4 x 3 classes environ car 12 possibilités, ce qui conplexifie le code mais permet d'être précis.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lecture avec Reader ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lecture de caractères avec Reader /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'avons nous dans la classe Reader ? Déjà nous savons qu'elle est abstraite, nous ne pouvons pas l'instancier directement, donc nous devons utiliser une extension concrête de cette classe :
// --> abstract Reader
// - read() : permet de lire un seul caractère à partir d'un médium de sortie (si la classe Reader est abstraite cela signifie qu'elle n'a pas de médium de sortie définie).
// - read(char[]) : permet de lire un tableau de caractère. La méthode read() est une méthode read(char[]) qui va lire un tableau de 1 caractère).
// - skip() : permet de sauter un certain nombre de caractères (précisé en paramètre).
// - close() : dès l'instant qu'on demande l'ouverture d'une ressource, il faut impérativement que l'on demande sa fermeture de façon à ne pas se retrouver à saturer le système.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pattern de lecture de fichier avec un Reader //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créons à présent une instance de Reader :
// --> File file = new File("...")
// --> Reader reader = new FileReader(file);
// Ici nous utilisons la méthode FileReader() pour lire à partir d'un fichier.
// Comment pouvons nous utiliser ce Reader pour lire le contenu du fichier ?
// Tout d'abord nous pouvons remarquer que le type de ma variable est Reader et non FileReader (qui est une extension de Reader).
// Le pattern canonique que nous pouvons utiliser est d'utiliser un tableau :
// char[] chars = new char[1024];
// --> reader.read(chars);
// Le tableau que nous utilisons est donc un 'buffer'. Passer ce tableau en paramètre de la méthode read() va déclencher la lecture du fichier.
// Et la mécanique interne du FileReader() va prendre le contenu du fichier et va commencer à remplir le tableau chars[] avec ce contenu.
// A noter qu'il n'est pas certain que le tableau soit rempli entièrement, nous n'avons aucune garantie que le tableau soit rempli entièrement. Cette méthode retourne un integer 'n' :
// int n = reader.read(chars);
// Donc n peut être inférieur à 1024. Donc n est le nombre caractères qui ont été copiés du fichier vers le contenu du tableau.
// Nous savons que le fichier à été entièrement lu lorsque n prends la valeur '-1'.
// Donc il va falloir que nous itérons sur la méthode read() autant de fois que nécessaire jusqu'à ce que la valeur de n soit de -1.
// --> while(n > -1) (ou while n <> -1) {
//          sb.append(chars, 0, n);
//          n = reader.read(chars);
//      }
// Nous devons à présent trouver où stocker les données du tableau avant qu'il soit écrasé par les données de l'itération suivante !
// Nous avons plusieurs façon de le faire, mais par exemple nous pouvons utiliser un StringBuilder, qui est une classe qui enveloppe un tableau de caractères.
// Ce StringBuilder peut élargir son tableau au fur et à mesure que les données arrivent, un peu comme ArrayList<>.
// StringBuilder sb = new StringBuilder();
// Les paramètres sont chars pour la source de données à append à sb, 0 est la première case de notre tableau chars que nous voulons copier, et n est le nombre d'éléments à prendre dans ce tableau.
// Attention à bien utiliser n et non 1024, car le tableau n'est pas tout le temps rempli, puisque c'est un buffer.
// Ensuite nous pouvons récupérer nos données :
// String fileContent = sb.toString();
// Un StringBuilder peut donc être "un peu" vu comme une chaîne de caractères mutable, même si nous n'avons pas tout à fait les mêmes méthodes sur String et sur StringBuilder.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fermeture d'un Reader, gestion des exceptions /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons oublié précédemment un point important : nous n'avons pas fermé le Reader : reader.close();
// Ainsi, nous nous assurons que la ressource système a bien été fermée. Si nous ne le faisons pas nous avons un bug, celui-ci peut être très dérangeant sur une grosse application.
// Il est donc très important de fermer les ressources système que nous ouvrons, si nous ne le faisons pas, nous créons un bug de 'file leaking'.
// Il nous manque maintenant le dernier point, la gestion des exceptions.
// File file = new File("..."); --> ne jette pas d'exception car il ne s'agit que d'un wrapper sur un chemin, donc une chaîne de caractères.
// En revanche, la demande de création d'un FileReader, jette une exception.
// De plus, fermer un FileReader : reader.close(); jette aussi une exception.
// Il faut donc mettre tout le code dans un try / catch / finally :
// Voici la première façon de faire :
//         try {
//             File file = new File("...");
//             Reader reader = new FileReader(file);
//             ... reader.read(chars); ...
//             reader.close();
//         } catch (IOException e) {
//             ...
//         }
// Toutefois, cette technique est buggée, de manière assez subtile, mais nous pouvons le déceler en se souvenant de quelle manière fonctionnent les blocs try / catch / finally.
// Si l'exception est lancée avant la méthode close(), celle-ci ne sera pas exécutée, ce sera le code du bloc catch qui sera lancée.
// Il nous faut donc un mécanisme qui effectuera la méthode close() quelle que soit la manière dont le bloc try sera exécuté, nous pouvons donc ajouter un bloc finally.
//         try {
//             File file = new File("...");
//             Reader reader = new FileReader(file);
//             ... reader.read(chars); ...
//             reader.close();
//         } catch (IOException e) {
//             ...
//         } finally {
//             reader.close();
//         }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fermeture d'un Reader dans le bloc finally ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Examinons ce que nous pouvons faire avec cette dernière version :
//         Reader reader = null;
//         try {
//             File file = new File("...");
//             Reader reader = new FileReader(file);
//             ... reader.read(chars); ...
//         } catch (IOException e) {
//             ...
//         } finally {
//             reader.close();
//         }
// Cela signifie que reader doit être connu dans le bloc finally, donc nous ne pouvons pas le déclarer dans le bloc try.
// Le problème est que la méthode close() jette aussi une exception de type IOException, donc il nous faut ajouter un bloc try / catch dans la méthode finally :
//         Reader reader = null;
//         try {
//             File file = new File("...");
//             Reader reader = new FileReader(file);
//             ... reader.read(chars); ...
//         } catch (IOException e) {
//             ...
//         } finally {
//             try {
//                 if (reader != null) {reader.close();}
//             } catch (IOException) {
//                 ...
//             }
//         }
// Que se passe t'il si le close() jette une exception ? Nous ne pouvons pas faire grand chose à part mettre une stratégie en place pour retenter plusieurs fois le close, ou autre.
// Ce n'est pas l'idéal... Mais nous n'avons pas tout à fait terminé. En effet, la construction du FileReader dans le bloc try peu elle aussi jeter un IOException.
// Si c'est le cas, FileReader jette une exception, reader reste null, et nous ne pourrons pas le fermer dans finally.
// Nous pouvons donc aussi avoir une NullPointerException donc il faut ajouter une clause if pour tester le reader.
// Donc c'est assez technique, et plutôt complexe, il va donc pouvoir y avoir des bugs et des file leaking.
// C'est le pattern que nous utilisons jusqu'à Java 6 inclus. A partir de Java 7 nous avons un autre pattern try-with-ressource.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fermeture d'un Reader avec un-try-with-resources //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// En quoi consiste le pattern 'try-with-ressources' ?
// File file = new File("..."); --> Nous pouvons toujours créer notre file car cela n'est pas susceptible de lancer d'exceptions.
// A partir de Java 7, nous pouvons ajouter un argument au try :
// try (Reader reader = new FileReader(...)){
//     reader.read(chars);
// } catch (IOException e){
//     ...
// }
// Donc à l'intérieur de notre bloc try, nous ouvrons des ressources et le try-with-ressources voit que ces ressources ont été ouvertes.
// Ainsi, nous pouvons mettre notre bloc catch habituel, et nous n'avons plus besoin de mettre un bloc finally.
// Donc, quand nous sortons de ce try / catch, toutes les ressources qui ont été ouvertes dans le try vont automatiquement être fermées.
// Ainsi, tout le code utilisé avant Java 7 est compris et compilé dans ce try-with-ressources, ce qui rends le code plus lisible.
// Note : Nous pouvons mettre en paramètre du try, toutes les ressources qui permettent l'implémentation d'une interface particulière qui s'appelle 'AutoCloseable'.
// Cette interface ne définit qu'une seule méthode qui s'appelle 'close()', et c'est cette méthode qui va être appelée automatiquement lorsque l'exécution du programme va quitter le try ou le catch.
// Cela signifie que si nous voulons créer des ressources propres à notre application, nous pouvons le faire en l'utilisant dans le try-with-ressources.
// Toutefois, nous pouvons le faire à condition d'implémenter cette interface, et par conséquent de fournir une méthode close().

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer un BufferedReader ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent une seconce extension de la classe Reader : 'BufferedReader', elle prends en paramètre une instance de Reader et fonctionne comme un buffer.
// Nous avons déjà vu l'extension FileReader, mais qui pose quelques soucis car il ne lit que caractère par caractère.
// Reader reader = new FileReader(...);
// BufferedReader br = new BufferedReader(reader);
// Quel est l'intérêt de faire ça ? Cela nous permet de rajouter des méthodes à reader, c'est d'ailleurs souvent pour cela que nous étendons des classes.
// Mais cela permet aussi de modifier le comportement de certaines méthodes existantes.
// Le fait d'avoir une classe qui étends une autre classe, et qui en plus est un wrapper sur cette classe est un pattern qui porte un nom : le pattern 'DECORATOR'.
// Donc BufferedReader est une décoration de la classe abstraite Reader. Donc BufferedReader étends Reader, et le wrappe en même temps, donc a besoin d'une instance de Reader pour fonctionner.
// BufferedReader possède deux méthodes qui sont particulièrement intéressantes :
// --> br.readLine(); : Retourne une chaîne de caractères qui est en fait une ligne du fichier texte, il lit donc toute une ligne jusqu'à avoir le caractère de fin de ligne.
// --> br.lines(); : Retourne un Stream<String> qui consomme, une par une, toutes les lignes du fichier texte.
// BufferedReader est elle-même étendue par une autre classe qui s'appelle 'LineNumberReader', et qui suit le même pattern Decorator.
// LineNumberReader nr = new LineNumberReader(br); : A savoir que nous pourrions très bien lui passer simplement reader comme paramètre aussi.
// --> nr.getLineNumber(); : Retourne le numéro de ligne que nous sommes en train de lire, et ce à partir du numéro de ligne à laquelle nous avons commencer le buffer, ou à celui que nous avons setté.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fermeture avec deux ressources à fermer ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment fonctionne le try-with-ressources quand nous avons deux ressources à fermer ?
// File file = new File(...);
// try (Reader reader = new Reader(File);
//     BufferedReader = new BufferedReader(reader);) {
//         ...
//     } catch (IOException e){
//         ...
//     }
// Ainsi, le try-with-ressources va fermer, d'abord le BufferedReader, puis le Reader.
// A savoir qu'ici, la vraie ressource à fermer est le Reader, car celui-ci est sur une ressource externe.
// Toutefois, puisque le BufferedReader contient lui-même le Reader, c'est une bonne pratique de le fermer aussi.
// Il faut donc les passer tous les deux en paramètres du bloc try, avec un point-virgule après chaque.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur la classe Reader ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons un peu ce que nous avons vu sur la classe Reader.
// Tout d'abord, c'est une classe abstraite qui permet de lire des tableaux de caractères à partir de flux d'entrée, ou des caractères un par un.
// C'est une méthode abstraite et par conséquent elle doit être étendue pour pouvoir être utilisée.
// --> FileReader() : qui permet d'ouvrir des flux en lecture sur des fichiers.
// --> StringReader() : qui permet d'ouvrir des flux en lecture sur des chaînes de caractères, donc des objets qui se trouvent en mémoire.
// --> CharArrayReader() : qui permet d'ouvrir des flux de caractères sur des tableaux de caractères, donc également des données en mémoire.
// --> BufferedReader() : qui est un décorateur, et que nous pouvons donc construire sur n'importe laquelle des trois classes ci-dessus.
// Le bufferedReader est lui même étendu par une autre classe :
// --> LineNumberReader() qui contient un compteur interne qui compte les lignes depuis le début de la lecture (et pas forcément le début du fichier).

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture avec Writer //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire du texte avec Writer ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent la classe Writer, le pendant de la classe Reader. La dernière permet de lire des flux textuels, tandis que la première permet d'écrire des flux textuels.
// La structure de la hiérarchie de Writer est exactement la même que celle de Reader, c'est donc une classe abstraite.
// Elle définit des opérations de base, écriture d'un caractère et/ou d'un tableau de caractères, en supplément, Writer permet d'écrire des chaînes de caractères, donc des instances de String.
// Nous allons aussi trouver des extensions de Writer qui vont permettre d'écrire sur des fichiers, dans des chaînes de caractères, ou dans des tableaux de caractères.
// Nous avons également une décoration avec le 'BufferedWriter'.
// Commençons par voir les méthodes fondamentales de Writer :
// --> write(int) : permet d'écrire un caractère, prends un integer en paramètre pour un certain nombre de raisons, mais elle ne regarde que les 16 premiers bits de cet integer pour en faire un caractère.
// --> write(char[]) : permet d'écrire un tableau de caractères dans le flux de sortie. Une autre version prends un offset et une longueur en paramètre pour définir la portion du tableau à écrire.
// --> write(String) : permet d'écrire une chaîne de caractères.
// Ces trois méthodes retournent void, elles sont juste censées fonctionner. Nous n'aurons donc pas besoin d'écrire la même boucle que pour Reader.
// --> append(...) : Si nous souhaitons écrire en début de fichier ou en fin de fichier si par exemple ce dernier existe déjà, nous avons un certain nombre de méthodes append() qui sont définies.
// --> close() : qui nous permet de fermer le flux venant de la ressource système.
// --> flush() : cette méthode garantie que ce que nous avons écris dans le Writer, mais qui n'a pas été transmis sur le disque, sera bien transmis sur le disque.
// Cette dernière méthode n'existe pas sur la classe Reader. Elle garantie que les appels systèmes ont bien été faits.
// Ceci pour demander à ce que l'intégralité du contenu écrit au travers du Writer a bien été transmis au système d'exploitation.
// Charge après au système d'exploitation de transmettre ce contenu vers le disque si il s'agit d'un FileWriter.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser un Writer dans un try-with-ressources, appel à flush /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment construis t'on un Writer :
// Un BufferedWriter est un Writer bufferisé, donc les performances peuvent-être sensiblement meilleures en l'utilisant.
// La méthode newLine() permet de passer à la ligne suivante, comme son nom l'indique.
// try (
//     Writer writer = new FileWriter(...);
//     BufferedWriter = new BufferedWriter(writer);
// ) {
//     br.write("Hello World!\n");
//     br.newLine();
// } catch (IOException e) {
//     ...
// }
// Ainsi, le try-with-ressources va fermer le Writer et le BufferedWriter, et ce, dans le bon ordre. Toutefois, qu'en est-il des méthodes flush() ?
// Il faut toujours se soucier de : quelle méthode flush() est appelée sur quel objet ? Car nous pouvons avoir des pièges.
// Lorsqu'on appelle la méthode close(), (ici c'est fait automatiquement via le try-with-ressources), nous avons un appel à flush(), qui est effectué avant.
// Donc dans le code ci-dessus, la méthode flush(), puis la méthode close() est appelée automatiquement via le try-with-ressources.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire du texte formaté avec PrintWriter //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons une classe extrèmement intéressante dans la hiérarchie des Writer qui est la classe 'PrintWriter'.
// Cette classe a trois catégories de méthodes :
// --> print(...); : Imprime les éléments dans des fichiers textes, donc sous forme textuelle, elle fait la conversion vers le format texte automatiquement et peut prendre tout types de paramètres.
// --> println(...); : Prends le même type de paramètres et fait la même chose en ajoutant un saut de ligne à la fin.
// --> printf(...); : Pour formater le texte et utilise les mêmes paramètres que le C.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur la classe Writer et ses extensions //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons a peu près la même hiérarchie que sur Reader :
// Writer :
// --> FileWriter.
// --> StringWriter.
// --> CharArrayWriter.
// --> BufferedWriter.
// --> PrintWriter : Utilisée dans l'API Servlet (pour écrire en HTML par exemple).
// Quand nous demandons un Writer pour écrire du texte, typiquement au format HTML, vers le navigateur du client, c'est en fait une instance de PrintWriter que nous récupérons.
// Cette instance nous permet notamment de faire des printf, c'est à dire des impressions avec formqtage, utilisant le même genre de syntaxe que celle utilisée en C.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Files et flux bufferisés //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Remarque sur les BufferedReader et les BufferedWriter :
// A partir de Java 7, nous avons un pattern supplémentaire qui nous permet de créer ces bufffer à partir d'une classe factory, donc statique qui s'appelle 'Files' :
// --> Files.newBufferedWriter(path);
// --> Files.newBufferedReader(path, charSet); : le second argument est optionnel, un charSet est un objet qui modélise un jeu de caractères.
// Quand nous manipulons des fichiers texte, nous nous heurtons très rapidement au fait que nous avons plusieurs façons d'encoder des caractères dans des fichiers.
// Le standart normal, que tout le monde devrait utiliser est l'UTF-8, qui est une manière d'encoder les caractères fonctionnant avec 16 bits.
// Toutefois certains caractères exotiques sont encodés par combinaisons de 16 bits, nous faisant aller au delà des 16 bits.
// Nous avons également beaucoup de caractères qui sont encodés en ISO-8659_1 ou ASCII. A savoir que l'UTF-8 et le ISO sont directements supportés par le JDK.
// Nous avons la classe StandardCharSets.UTF-8 ou .ISO... que nous pouvons passer à la place de charSet en paramètre du newBufferedReader.
// Si nous ouvrons des fichiers en UTF-8 nous n'avons pas besoin de préciser de charSet car par défaut ils sont en UTF-8.
// Nous avons également un deuxième type de paramètre que nous pouvons passer à ces méthodes : StandardOptions.
// Cette méthode permet d'ouvrir un fichier seulement si il existe, ou de l'ouvrir au début, ou de l'écrire à la fin, selon la documentation.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur la hiérarchie Writer et Reader //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récapitulons ce que nous avons vu sur les Writer, et les Reader, deux classes abstraites :
//              Reader  |   Writer
//          FileReader  |   FileWriter
//        StringReader  |   StringWriter
//     CharArrayReader  |   CharArrayWriter
//      BufferedReader  |   BufferedWriter      --> Extensions et wrapper : DECORATOR
//                      |   PrintWriter

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : API Java I/O par la pratique ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mise en pratique //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Coding sur l'Api Java IO n°1 /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// --> Première partie sur les exceptions :
// package org.vitu.exceptions;
//
// public class MyAppException extends Exception { // RunTimeException { --> Ceci est une UncheckedException, pour laquelle nous n'avons pas besoin de gérer l'exception
//
// 	// Puisque MyAppException étends Exception, cela en fait une 'checked Exception'
//
// 	// Nous gardons le constructeur vide car c'est important de le faire pour les exceptions
// 	public MyAppException() {
// 	}
//
// 	public MyAppException(String message) {
// 		// Tout code avant le constructeur (ici) ne fonctionnera pas
// 		super(message);
// 	}
// 	// Si nous n'avons pas message, nous aurons deux constructeurs, un vide, et un autre qui prends un message en paramètre
// 	// Utiliser super() nous permet d'appeler le constructeur de la classe que nous étendons qui prends une chaîne de caractères en paramètres
// 	// En faisant ctrl + clic gauche sur le mot clef super(), cela nous renvoies vers la méthode qui est appelée par super(), ici, Exception
// 	// Il y a deux règles pour le super(), nous ne pouvons pas en avoir deux par constructeur, et nous ne pouvons rien écrire avant le super
// }
//
// package org.vitu.exceptions;
//
// public class PlayWithExceptions {
//
// 	public static void main(String... args) { 	// throws MyAppException {
// 		// Si nous gardons 'main throws MyAppException, cela veut dire que nous ne faisons rien pour la gérer puisque main est la méthode mère
// 		// Nous ne pouvons pas renvoyer l'exception à une méthode mère à la méthode main, vu que c'est elle-même la méthode mère
//
//
// 		String information = "No information";
//
// 		try {
//
// 			information = getInformation(true);
// 			information += " bien reçue";
//
// 		} catch (MyAppException e) {
//
// 			// Nous imprimons le message
// 			System.err.println("Exception = " + e.getMessage());
// 			// Nous récupérons la StackTrace
// 			// ATTENTION : la StackTrace est générée uniquement si nous avons fait 'throw new MyAppException' !
// 			e.printStackTrace();
// 			// Tout ceci nous est imposé car MyAppException étends Exception qui est une CheckedException
//
// 			// La stacktrace nous imprime ceci :
// 			// org.vitu.exceptions.MyAppException: Message d'erreur
// 			// --> D'abord, cela nous donne la classe de l'Exception qui a été jetée avec le message d'erreur (préparé dans sa classe)
//
// 			// at org.vitu.exceptions.PlayWithExceptions.getInformation(PlayWithExceptions.java:37)
// 			// --> Nous donne la classe et la méthode dans laquelle l'Exception a été jetée, plus un lien avec la ligne où l'Exception a été générée
//
// 			// at org.vitu.exceptions.PlayWithExceptions.main(PlayWithExceptions.java:14)
// 			// --> Nous dis d'où nous venions lorsque l'Exception a été jetée
//
// 			// --> Nous avons donc l'intégralité de l'ensemble de l'enchaînement des méthodes
// 		}
// 		// En utilisant System.err au lieu de System.out, cela imprime en erreur donc en rouge
// 		System.err.println("Information = " + information);
//
// 	}
//
// 	public static String getInformation(boolean error) throws MyAppException {
// 		// Ajouter 'throws MyAppException nous indique que cette variable là peut jeter une MyAppException
// 		// Dès que nous faisons ça, le JDK nous impose de gérer 'getInformation' car MyAppException est une CheckedException
// 		// Eclipse nous propose, soit d'ajouter une clause 'throws' (patate chaude), soit de mettre la déclaration dans un bloc try / catch
// 		// Nous avons un dernier warning sur 'information' nous indiquant qu'il faut initialiser la variable, donc nous le faisons.
// 		if (error) {
// 			// Si nous passons getInformation(true),
// 			// MyAppException myAppException = new MyAppException("Message d'erreur");
// 			// throw myAppException;
// 			// En faisant de cette manière là, la StackTrace nous emmène à la ligne de la création de l'Exception et non la ligne où elle a été jetée !
// 			// Il vaux mieux donc toujours utiliser le code suivant pour obtenir la ligne où l'Exception a été jetée dans la StackTrace :
// 			throw new MyAppException("Message d'erreur");
// 		} else {
// 			// En appellant getInformation(false), la méthode retourne "Une information"
// 			return "Une information";
// 		}
// 	}
//
// }
//
// package org.vitu.exceptions;
//
// public class PlayWithMoreExceptions {
//
// 	public static void main(String[] args) {
//
// 		// Pour bypasser des méthodes statiques pour toutes les 3 suivantes, nous pouvons créer une instance de PlayWithMoreExceptions :
// 		PlayWithMoreExceptions play = new PlayWithMoreExceptions();
//
// 		String message = "No information";
// 		String information = play.start(message);// play.start(null); --> va générer une NPE, NullPointerException
//
// 		System.out.println("Information = " + information);
//
// 	}
//
// 	public String start(String message) {
// 		// int i = 10/0; // --> Exception in thread "main" java.lang.ArithmeticException: / by zero
// 		return init(message);
// 	}
//
// 	public String init(String message) {
// 		// int[] tab = new int[5];
// 		// int i = tab[10]; // --> Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: Index 10 out of bounds for length 5
// 		return getInformation(message);
// 	}
//
// 	public String getInformation(String message) {
// 		int length = message.length();
// 		return "Une information capitale";
// 	}
// }
//
// --> Deuxième partie sur les Exceptions :
// package org.vitu.exceptions;
//
// import org.vitu.exceptions.model.Commune;
//
// public class PlayWithNullPointerException {
//
// 	public static void main(String[] args) {
//
// 		Commune commune = new Commune();
//
// 		int length = commune.getMaire().getAdresse().getRue().length();
// 		// --> New feature of Java 14 : NPE are more detailled for debug
// 		// Exception in thread "main" java.lang.NullPointerException:
// 		// Cannot invoke "org.vitu.exceptions.model.Maire.getAdresse()" because the return value of "org.vitu.exceptions.model.Commune.getMaire()" is null
// 		// at org.vitu.exceptions.PlayWithNullPointerException.main(PlayWithNullPointerException.java:11)
// 		System.out.println("Length = " + length);
// 	}
// }
//
// package org.vitu.exceptions.model;
//
// public class Commune {
//
// 	private Maire maire;
//
// 	public Maire getMaire() {
// 		return maire;
// 	}
//
// 	public void setMaire(Maire maire) {
// 		this.maire = maire;
// 	}
// }
// package org.vitu.exceptions.model;
//
// public class Maire {
//
// 	public Adresse getAdresse() {
// 		return adresse;
// 	}
//
// 	public void setAdresse(Adresse adresse) {
// 		this.adresse = adresse;
// 	}
//
// 	private Adresse adresse;
// }
//
// package org.vitu.exceptions.model;
//
// public class Adresse {
//
// 	private String rue;
//
// 	public String getRue() {
// 		return rue;
// 	}
//
// 	public void setRue(String rue) {
// 		this.rue = rue;
// 	}
// }
//
// package org.vitu.files;
//
// import java.io.File;
// import java.io.IOException;
// import java.nio.file.Path;
//
// public class FunWithFiles {
//
// 	public static void main(String[] args) throws IOException {
//
// 		// I- Partie création
// 		// Les objets 'File' et 'Path' datent de Java 1
// 		File file = new File("files/debug.log");
// 		// Il existe donc une méthode toString() sur File car nous pouvons le print sans jeter d'exception même si il n'existe pas.
// 		System.out.println("File = " + file);
// 		// --> File = files\debug.log : Toutefois nous pouvons voir que le / est devenu un \ automatiquement grâce au RunTime Java.
// 		Path path = Path.of("files/debug.log");
// 		System.out.println("Path = " + path);
// 		// Nous pouvons effectuer les deux mêmes constats sur Path que ceux fait précédemment sur File.
// 		// Il n'y a donc aucun accès disque en créant une instance de File ou de Path, ce sont des wrapper sur des chaînes de caractères qui est censé représenter un chemin sur un disque.
// 		// Nous pouvons aussi écrire un Path ou un File en chemin absolu plutôt que relatif comme les deux exemples précédents.
// 		File mdp = new File("C:/Users/Emile/Desktop/Paperasse/mdp.txt");
//
// 		// II- Partie requête sur le FS (File System)
// 		// Il existe de nombreuses méthodes pour tester et faire d'autres actions sur les chemins :
// 		System.out.println("debug.log existe ? --> " + file.exists());
// 		System.out.println("mdp existe ? --> " + mdp.exists());
// 		System.out.println("mdp est un répertoire ? --> " + mdp.isDirectory());
// 		System.out.println("mdp est il lisible ? --> " + mdp.canRead());
// 		System.out.println("mdp est il exécutable ? --> " + mdp.canExecute());
// 		// A savoir qu'à ce moment-là, il y a bien des requêtes sur le File System qui sont effectuées.
//
// 		// III- Interroger le file
// 		System.out.println("Name de mdp : " + mdp.getName()); 						// --> Retourne le nom du fichier ou du dossier
// 		System.out.println("Parent de mdp : " + mdp.getParent()); 					// --> Retourne le chemin du répertoire parent
// 		System.out.println("Path de mdp : " + mdp.getPath());						// --> Retoutne la chaîne de caractères sur laquelle le Path a été construit
// 		System.out.println("Canonical Path de mdp : " + mdp.getCanonicalPath());	// --> Ne retourne pas la même chose que getPath(), jette une IOException
//
// 		File canonical = new File("files./././../debug.log");
// 		System.out.println("Name de canonical : " + canonical.getName());
// 		System.out.println("Parent de canonical : " + canonical.getParent());
// 		System.out.println("Path de canonical : " + canonical.getPath());
// 		System.out.println("Canonical de canonical : " + canonical.getCanonicalPath()); // Il essaye de résoudre le chemin donné avec les informations qu'il à
//
// 		// Répertoire courant
// 		File currentDirectory = new File(".");
// 		System.out.println("Répertoire courant = " + currentDirectory);
// 		System.out.println("Répertoire courant = " + currentDirectory.getCanonicalPath());
// 	}
// }
//
// --> Partie sur le try / catch / finally et le try-with-ressources
// package org.vitu.files;
//
// import java.io.File;
// import java.io.FileWriter;
// import java.io.IOException;
// import java.io.Writer;
//
// public class EvenMoreFunWithFiles {
//
// 	public static void main(String[] args) {
//
// 		// Le fichier suivant n'existe pas encore
// 		File file = new File("files/data.txt");
//
// 		// Nous créons un nouveau fichier avec un bloc try / catch, car il y a une éventualité de lancement d'une IOException
// 		// try {
// 			// Création du fichier
// 			// file.createNewFile();
// 			// System.out.println("Le fichier a bien été créé !");
// 			// Ecriture de contenu dans le fichier
// 			// Writer writer = new FileWriter(file);
// 			// writer.write("Bonjour le monde!\n"); 				// L'écriture se fait dans les buffer internes, et transmis au FileSystem
// 			// writer.write("Une deuxième ligne");
// 			// writer.flush();									// L'ordre est transmis au FileSystem pour l'écrire, donc le fichier sera modifié
// 			// writer.close();									// Pour éviter des bugs de file leaking, très important, close() appelle flush() également
// 			// !!! : Génère un file leaking si une des lignes précédentes lance une erreur car le fichier ne sera pas flushé et closé !!!
//  		// } catch (IOException e) {
// 			// System.out.println(e.getMessage());
// 			// e.printStackTrace();
// 		// }
// 		// Pourtant, le fichier n'est pas visible dans l'arborescence, il faut rafraichir le package explorer avec clic droit refresh et aussi F5
//
// 		// La bonne pratique
// 		try (Writer writer = new FileWriter(file)) {
// 			file.createNewFile();
// 			System.out.println("Le fichier a bien été créé !");
// 			writer.write("Bonjour le monde!\n");
//
// 			getInformation(true);
//
// 			writer.write("Une deuxième ligne");
// 			// writer.close(); --> Puisque writer est en paramètre du try-with-ressources, il sera automatiquement closé, donc flushé en sortant du bloc try / catch
//  		} catch (IOException e) {
// 			System.out.println(e.getMessage());
// 			e.printStackTrace();
// 		} finally {
// 			System.out.println("Le finally est bien éxecuté");
// 		}
// 		System.out.println("Nous continuons le code après le bloc try / catch");
// 	}
// 	// Permet de lancer une exception au sein du bloc try
// 	public static String getInformation(boolean error) throws IOException {
// 		if (error) {
// 			throw new IOException("Erreur générée");
// 		} else {
// 			return "Une information";
// 		}
// 	}
// }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Coding sur l'Api Java IO n°2 /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// --> Writers
// package org.vitu.files;
// public class QuizzWithFinally {
//
// 	public static void main(String[] args) {
//
// 		QuizzWithFinally quizzWithFinally = new QuizzWithFinally();
//
// 		String message = quizzWithFinally.quizz(true);
// 		System.out.println("Message = " + message);
//
// 	}
//
// 	public String quizz(boolean error) {
//
// 		try {
// 			if (error) {
// 				throw new IllegalStateException("Je jette l'exception");
// 			}
// 			return "Try";
// 		} catch (Exception e) {
// 			// Il est très déconseillé de mettre les Exceptions en global comme ici, il vaut mieux préciser de quelle classe d'Exception il s'agit
// 			System.out.println("Je suis dans le catch");
// 		} finally {
// 			System.out.println("Je suis dans le finally");
// 		}
//
// 		return "avec une erreur";
// 		// Donc le bloc finally s'exécute avant le return du bloc try lorsqu'il n'y a pas d'erreur
// 		// Lorsqu'on à une erreur, le catch s'exécute, puis le finally, puis le return de la classe quizz
// 	}
// }
//
// package org.vitu.files;
// import java.io.BufferedWriter;
// import java.io.File;
// import java.io.FileWriter;
// import java.io.IOException;
// import java.io.StringWriter;
// import java.io.Writer;
//
// public class SomeMoreTextFiesAwesomeness {
//
// 	public static void main(String[] args) {
//
// 		File file = new File("files/data.txt");
//
// 		StringWriter writerBackup = null;
//
// 		try (StringWriter writer = new StringWriter();) {
// 			// Nous avons aussi la méthode CharArrayWriter() qui à aussi une méthode toString() mais qui ne jette pas d'erreur
// 			write(writer, "Message 1");
// 			writerBackup = writer;
//
// 		} catch (IOException e) {
// 			System.out.println(e.getMessage());
// 			e.getStackTrace();
// 		} finally {
//
// 		}
//
// 		System.out.println("Writer :");
// 		System.out.println(writerBackup.toString());
//
//
// 		// try (Writer writer = new FileWriter(file);BufferedWriter bw = new BufferedWriter(writer);) {
// 			// Nous avons vu qu'il existe une classe qui étends Writer qui se nomme BufferedWriter
// 			// Nous pouvons passer aussi un integer en second paramètre pour donner une taille au buffer
// 			// BufferedWriter fait partie du Pattern Decorator
//
// 			// bw.write("Bonjour le monde!");
// 			// bw.newLine(); // Cette méthode n'existe pas sur la classe Writer, encore un avantage d'utiliser BufferedWriter
// 			// bw.write("Seconde ligne");
// 			// bw.newLine();
// 			// bw.write("Troisième ligne");
// 			// Comme writer est en paramètre du bloc try, la méthode close(), et par conséquent la méthode flush() est automatiquement exécutée
// 			// writer.flush();
// 			// Par contre, la méthode flush() n'est pas exécutée pour bw
// 			// Sinon nous pouvons déplacer la déclaration du BufferedWriter dans les paramètres du bloc try
// 			// bw.flush();
// 		// } catch (IOException e) {
// 			// Toutes les exceptions donné en paramètre ET toutes leurs extensions seront attrappées par le bloc catch
// 			// Ici par exemple, FileNotFoundException, qui étends IOException sera aussi catchée par le bloc catch
// 			// System.out.println(e.getMessage());
// 			// e.printStackTrace();
// 		// }
// 		System.out.println("Code exécuté!");
// 		// En executant ce code, il s'avère que rien ne s'écrit dans le fichier, il nous manque les flush()
// 	}
//
// 	public static void write(Writer writer, String message) {
// 		try (BufferedWriter bw = new BufferedWriter(writer);) {
// 			bw.write("Début du message");
// 			bw.newLine();
// 			bw.write(message);
// 			bw.newLine();
// 			bw.write("Stop");
// 		} catch (IOException e) {
// 			// Toutes les exceptions donné en paramètre ET toutes leurs extensions seront attrappées par le bloc catch
// 			// Ici par exemple, FileNotFoundException, qui étends IOException sera aussi catchée par le bloc catch
// 			System.out.println(e.getMessage());
// 			e.printStackTrace();
// 		}
// 	}
// 	// Ici nous appelons la méthode write avec un writer et un String en paramètres
// 	// Le BufferedWriter est flushé et closé après avoir effectué le bloc try
// 	// Le writer est ensuite flushé et closé aussi
// }
//
// package org.vitu.files;
// import java.io.BufferedWriter;
// import java.io.CharArrayWriter;
// import java.io.PrintWriter;
// public class PlayWithPrintWriter {
//
// 	public static void main(String[] args) {
//
// 		CharArrayWriter writer = new CharArrayWriter();
// 		// Cette classe stocke les données en mémoire, et par conséquent ne jette pas d'exception (peut-être vu en lisant la description de la classe)
// 		// BufferedWriter bw = new BufferedWriter(writer);
// 		// Ici nous décorons Writer
// 		PrintWriter printWriter = new PrintWriter(writer);
// 		// La classe PrintWriter permet d'utiliser les println et printf qui viennent du C
// 		// Cette décoration ne jette pas d'exceptions non plus
// 		// Aussi nous décorons une décoration de Writer, nous avons donc deux niveaux de décoration
//
// 		int number = 12;
// 		// Ici, number est imprimé en tant qu'integer
// 		printWriter.println("number = " + number);
// 		// Ici, number est imprimé en tant que chaîne de caractères
// 		printWriter.println(number);
//
// 		boolean b = true;
// 		printWriter.println(b);
// 		// Nous pouvons aussi imprimer avec format
// 		printWriter.printf("Number = %d\n", 42);
// 		// La documentation se situe ici : https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Formatter.html#syntax
// 		// Nous pouvons aussi la trouver en survolant la méthode printf et en cliquant sur le lien 'Format String Syntax'
//
// 		// Nous ne sommes pas dans un bloc try-with-ressources, donc il faut guarantir l'envoi des données depuis le FS
// 		printWriter.flush();
// 		writer.flush();
//
// 		System.out.println("Résultat = ");
// 		// Nous imprimons notre CharArrayWriter (données en mémoire)
// 		System.out.println(writer.toString());
// 	}
// }
//
// --> Readers
// package org.vitu.files;
// import java.io.FileReader;
// import java.io.IOException;
// import java.io.Reader;
//
// public class PlayWithReader {
//
// 	public static void main(String[] args) {
//
// 		// PATTERN DE BASE POUR LIRE LE CONTENU D'UN FICHIER AVEC UN READER
//
// 		// D'abord nous créons l'endroit où stocker les caractères lus dans quelque chose :
// 		StringBuilder sb = new StringBuilder();
//
// 		try (Reader reader = new FileReader("files/sonnet.txt");) {
// 			// FileReader peut jeter deux exceptions : IOException & FileNotFoundException
// 			// Or FileNotFoundException étends IOException
// 		// } catch (FileNotFoundException e) {
// 		// 	System.out.println("J'attrape la FNFE");
// 		// 	e.printStackTrace();
// 			// Donc il est inutile d'avoir les deux
//
// 			// Vu que le fichier est très petit, nous pouvons donner un petit buffer à notre tableau de caractères
// 			char[] chars = new char[128];
//
// 			// La méthode read(chars) nous retourne un entier du nombre de caractères qu'elle à lu
// 			int number = reader.read(chars);
// 			// Retourne 16, mais si nous passons [1_000_000], n'en retourne que 555
// 			// Donc ce n'est pas parce que le tableau de caractères est grand qu'il est nécessairement rempli
// 			// System.out.println("J'ai lu " + number + " caractères. ");
// 			// Pour savoir quand le fichier à été entièrement lu, la méthode read() retourne '-1'
// 			// Il faut donc le passer dans une boucle :
// 			System.out.println(number + " lus.");
//
// 			while (number != -1) {
// 				// Maintenant il faut append les caractères au StringBuilder
// 				// Sans oublier d'ajouter les deux derniers paramètres pour qu'il sache de où à où les caractères doivent être lus
// 				sb.append(chars, 0, number);
// 				number = reader.read(chars);
//
// 				System.out.println(number + " lus.");
// 				// Retourne :
// 				// 128 lus.
// 				// 128 lus.
// 				// 128 lus.
// 				// 128 lus.
// 				// 96 lus.
// 				// -1 lus.
// 			}
// 		} catch (IOException e) {
// 			// System.out.println(e.getMessage());
// 			System.out.println("J'attrape l'IOE");
// 			e.printStackTrace();
// 		}
// 		System.out.println("Contenu du fichier :");
// 		System.out.println(sb.toString());
//  }
// }
// --> Reader part two
// package org.vitu.files;
// import java.io.BufferedReader;
// import java.io.FileReader;
// import java.io.IOException;
// import java.io.Reader;
// import java.util.stream.Collectors;
//
// public class PlayWithBufferedReader {
//
// 	public static void main(String[] args) {
//
// 		// PATTERN AVEC UN BUFFEREDREADER POUR LIRE LE CONTENU D'UN FICHIER
//
// 		// Cette métode est beaucoup plus concise
//
// 		String sonnet = null;
//
// 		try (Reader reader = new FileReader("files/sonnet.txt");
// 			BufferedReader br = new BufferedReader(reader);) {
// 			// Ici nous décorons notre Reader avec un BufferedReader
// 			// L'avantage c'est que nous avons deux méthodes supplémentaires avec cette décoration : readLine() et lines() (qui retourne un Stream<> de Strings)
// 			// Nous pouvons ainsi le concaténer dans un seul string à l'aide du Collector joining() avec le '\n' pour les séparer
// 			sonnet = br.lines().collect(Collectors.joining("\n"));
// 		} catch (IOException e) {
// 			System.out.println("J'attrape l'IOE");
// 			e.printStackTrace();
// 		}
// 		System.out.println("Contenu du fichier :");
// 		System.out.println(sonnet);
// 	}
// }
// numbers.txt :
// 23
// 25
// # Ceci est un commentaire
// 45
// 12
// # Ceci est un autre commentaire
// 314
// bonjour
// 128
// 56
// package org.vitu.files;
// import java.io.BufferedReader;
// import java.io.FileReader;
// import java.io.IOException;
// import java.io.Reader;
// import java.util.ArrayList;
// import java.util.List;
//
// public class ReadNumbersFromFile {
//
// 	public static void main(String[] args) {
//
// 		List<Integer> ints = new ArrayList<>();
//
// 		try (Reader reader = new FileReader("files/numbers.txt");
// 			BufferedReader br = new BufferedReader(reader);) {
//
// 			String line = br.readLine();
//
// 			while (line != null) {
//
// 				try {
// 					int number = Integer.parseInt(line);
// 					ints.add(number);
// 				} catch (NumberFormatxception e) {
// 					e.printStackTrace();
// 					System.out.println(line + " is not a number.");
// 				}
//
// 				System.out.println("line = " + line);
// 				line = br.readLine();
// 			}
//
// 		} catch (IOException e) {
// 			e.printStackTrace();
// 		// } catch (NumberFormatException e) {
// 		// 	e.printStackTrace();
// 		}
// 		// Le code s'arrête et n'affiche pas ints ci-après quand on ne catch pas la NFE
// 		System.out.println("ints = " + ints);
// 		// Tous les nombres apparaissant après le string entré par erreur dans le fichier
// 		// Il faut donc nest le try / catch pour la méthode parseInt, à l'intérieur de la boucle du try-with-ressources
// 	}
// }
//
// package org.vitu.files;
// import java.io.BufferedReader;
// import java.io.FileReader;
// import java.io.IOException;
// import java.io.Reader;
// import java.util.ArrayList;
// import java.util.List;
//
// public class ReadNumbersFromFileV2 {
//
// 	public static void main(String[] args) {
//
// 		List<Integer> ints = new ArrayList<>();
//
// 		try (Reader reader = new FileReader("files/numbers.txt");
// 			BufferedReader br = new BufferedReader(reader);) {
//
// 			String line = br.readLine();
//
// 			while (line != null) {
//
// 				int number = Integer.parseInt(line);
// 				ints.add(number);
//
// 				System.out.println("line = " + line);
// 				line = br.readLine();
// 			}
// 		// Pour éviter d'avoir deux blocs catch, ou de mettre la classe mère (ici Exception), nous pouvons faire un MultiCatch en utilisant un 'ou' '|'
// 		} catch (IOException | NumberFormatException e) {
// 			e.printStackTrace();
// 		}
//
// 		System.out.println("ints = " + ints);
// 	}
// }
//
// package org.vitu.files;
// import java.io.BufferedReader;
// import java.io.FileReader;
// import java.io.IOException;
// import java.io.Reader;
// import java.util.ArrayList;
// import java.util.List;
// import java.util.function.Function;
// import java.util.stream.Collectors;
// import java.util.stream.Stream;
//
// public class ReadNumbersFromFileV3 {
//
// 	public static void main(String[] args) {
//
// 		Function<String, Stream<Integer>> lineToInt =
// 				line -> {
// 					try {
// 						return Stream.of(Integer.parseInt(line));
// 					} catch (NumberFormatException e) {
// 						// System.out.println(line + " is not a number. ");
// 					}
// 					return Stream.empty();
// 				};
// 		// En faisant ainsi, nous retournons soit un Stream<> contenant un entier, soit un Stream<> vide
// 		// Ainsi notre fonction gère les erreurs en interne
//
// 		List<Integer> ints = new ArrayList<>();
//
// 		try (Reader reader = new FileReader("files/numbers.txt");
// 			BufferedReader br = new BufferedReader(reader);) {
// 				ints = br.lines()
// 						.filter(line -> !line.startsWith("#"))		// En ajoutant le filter nous pouvons retirer les commentaires si ils commencent tous par '#'
// 						.flatMap(lineToInt)							// flatMap() nous sert à transformer un Stream<Stream<>> en un seul Stream<>
// 						.collect(Collectors.toList());				// La méthode collect() en passant le Collector toList() nous transforme notre Stream<> en List<>
// 		} catch (IOException e) {
// 			e.printStackTrace();
// 		}
// 		System.out.println("ints = " + ints);
// 	}
// 	// Nous pourrions aussi remplacer Stream.of() par un optional en disant que le résultat du parseInt() sera mis dans un optional
// 	// Et si jamais on ne peut pas repartir on retourne un optional vide avant de finir par un flatMap() sur les optionals
// }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Coding sur l'Api Java IO n°3 /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Création d'un premier decorator 'PersonOutputStream':
//      - Dans un premier temps, nous créons un nouveau projet Java dans Eclipse 'PlayWithDecoration'.
//      - Puis nous créons un model bean 'Person', ayant les champs 'name', 'city' et 'age'.
//      - Enfin, nous créons une nouvelle classe 'PersonOutputStream'.
//          --> Nous voulons que cette classe 'décore' la classe 'OutputStream', plutôt que 'FileOutputStream', ce qui est une mauvaise idée.
//      - Ensuite, nous pouvons créer un champs privé de type 'OutputStream', puis générons un constructeur (en retirant le 'super()').
//          --> Nous avons à présent 'presque' décoré la classe 'PersonOutputStream'.
//      - Maintenant, cette classe doit exposer une méthode 'writeFields(List<Person>)'.
//  - Nous allons construire une fonction permettant de transformer un objet de type 'Person' en tableau de Byte.
//      - Pour ce faire, il nous faut retourner ses champs sous forme de tableau de Byte, deux champs sont des String, et un champs est un int.
//          --> Pour utiliser une ressource dans un try-with-resources, celle-ci doit implémenter 'AutoCloseable'.
//  - Mainenant, nous allons créer le second décorator 'PersonInputStream', pour ce faire, nous allons utiliser le même raisonnement :
//      - Nous voulons que 'PersonInputStream' soit une décoration de 'OutputStream'.
//          Donc dans un premier temps, nous allons créer un champs privé 'InputStream', puis le constructeur de la classe utilisant ce dernier champs.
//              --> Nous avons à présent un premier élément de notre décoration.
//      - Maintenant, nous devons créer notre méthode 'readFields()', retournant une List<Person>.
//          Une fois le squelette de notre méthode créé, nous allons créer une 'Function' prenant un tableau de 'byte' et retourne un objet 'Person', comme nous l'avons fait pour 'PersonOutputStream'.
//          Maintenant, nous pouvons écrire la function, de sortes à ce qu'elle retourne deux String et un int (name, city & age).
//          Dans la fonction, nous avons besoin d'un 'ByteArrayInputStream', et nous avons besoin de le décorer avec un 'DataInputStream'.
//          Nous avons besoin à présent d'un objet pouvant lire des chaînes de caractères, le DataInputStream, car celui-ci possède les méthodes nécessaires pour lire des String et des int.
//          Ensuite nous pouvons créer un try-with-resources prenant notre ByteArrayInputStream et notre DataInputStream en paramètres.
//              --> Nous construisons, puis retournons notre objet Person à l'aide de la méthode 'Stream.of()'.
//      - Maintenant, nous pouvons travailler sur la méthode 'readFields()', nous devons récupérer les octets à l'intérieur de notre InputStream.
//          Pour ce faire, nous allons créer un objet de type 'BufferedInputStream', et utiliser sa méthode 'readAllBytes()'.
//              --> Cette méthode jettant une IOException, nous pouvons l'encapsuler dans un nouveau try-with-resources.
//          Enfin, nous pouvons ainsi créer un nouveau 'ByteArrayInputStream' à partir de l'objet retourné par la méthode précédente.
//      - Nous allons modifier notre fonction, de sortes à ce qu'elle ne prennent pas un 'byte[]' en entrée, mais un 'ByteArrayInputStream'.
//          Par la suite, nous extrayons la fonction dans une méthode externe, le restant de la fonction pouvant être transcrit en une Method Reference.
//          Par contre, nous devons aussi attraper une EOFException, et ce, avant d'attraper l'IOException, car la première étends la dernière.
//      - Maintentant, nous allons utiliser le pattern de la 'Poisened Pill', consistant à mettre un marqueur dans un flux, qui permet de stopper le flux lorsque ce marqueur est rencontré.
//          Lorsque nous allons arriver au EOF, nous allons retourner un objet de type Person, qui est static, privé et final, de sortes à avoir cette Person lorsqu'on attrape la EOFException.
//          De cette manière, notre méthode 'readFields()' va construire une List<Person> en utilisant les méthodes 'generate()', 'flatMap()' et 'collect()'.
//          Ainsi que la méthode 'takeWhile()' prenant en paramètre notre objet de type Person 'EOF' permettant de stopper le stream lorsque la fin du fichier est rencontrée et éviter l'EOFException.
//          Enfin, nous devons implémenter 'AutoCloseable' sur notre classe, et remplir la méthode héritée 'close()'.
//          Cette dernière méthode va simplement faire de la délégation 'this.inputStream.close()', et jettera une IOException plutôt qu'une plus générale 'Exception'.
//  - A présent, nous pouvons créer une nouvelle classe, avec une méthode main 'ReadPeople', pour lancer notre PersonInputStream.
//      - Dans un bloc try-with-resources, prenant en paramètres un FileInputStream (prenant le fichier .bin en paramètre), et un PersonInputStream, prenant le FileInputStream en paramètre.
//          A l'intérieur, nous pouvons construire notre List<Person> en appelant notre méthode 'readFields()', puis avec une boucle forEach(), les imprimer sur la console.
//      - Enfin, il nous manque à surcharger la méthode 'equals()' et la méthode 'hashCode()' dans notre classe 'Person', car la méthode 'equals()' est appelée pour égaler notre Person 'EOF'.
//  --> Nous générons un Stream<Person> à partir d'un ByteArrayInputStream, nous ouvrons ensuite les streams sans les modifier, lors de la méthode 'flatMap()', c'est la fonction identité.
//          Ceci nous ouvre les streams, et nous élimine les streams vides. Les streams vides sont les streams qui surviennent si l'IOException a été jetée.
//          Cette méthode à un troisième cas, avec un marqueur pour l'EOF, nous indiquant que le Stream est terminé.
//              --> Donc, lorsque la fin du fichier est arrivée, nous retournons une Person particulière, 'EOF', qui est la pillule empoisonnée, donc une instance qui ne peux pas exister.
//          Ainsi, nous mettons cette poisonned pill dans un stream, puis dans notre méthode 'readFields()', nous testons si cette personne existe avec 'takeWhile()'.
// --> Ce système de pillule empoisonnée est très utilisé par les personnes gérant des files d'attente dans les réseaux par exemple.
// -----------
//                  package org.vitu.files.model;
//                  import java.io.Serializable;
//                  import java.util.Objects;
//                  public class Person implements Serializable {
//                      private String name;
//                      private String city;
//                      private int age;
//                      public Person() {
// 	                    }
//                      public Person(String name, String city, int age) {
// 	                        this.name = name;
// 	                        this.city = city;
// 	                        this.age = age;
//                      }
//                      public String getName() {
//                          return name;
//                      }
//                      public void setName(String name) {
//                          this.name = name;
//                      }
//                      public String getCity() {
//                          return city;
//                      }
//                      public void setCity(String city) {
//                          this.city = city;
//                      }
//                      public int getAge() {
//                          return age;
//                      }
//                      public void setAge(int age) {
//                          this.age = age;
//                      }
//                      @Override
//                      public int hashCode() {
// 	                        return Objects.hash(age, city, name);
//                      }
//                      @Override
//                      public boolean equals(Object obj) {
// 	                        if (this == obj)
// 	                            return true;
// 	                        if (obj == null)
// 	                            return false;
// 	                        if (getClass() != obj.getClass())
// 	                            return false;
// 	                        Person other = (Person) obj;
// 	                            return age == other.age && Objects.equals(city, other.city) && Objects.equals(name, other.name);
//                      }
//                      @Override
//                      public String toString() {
// 	                        return "Person [name=" + name + ", city=" + city + ", age=" + age + "]";
//                      }
//                  }
// -----------
//                  package org.vitu.files;
//                  import java.io.ByteArrayOutputStream;
//                  import java.io.DataOutputStream;
//                  import java.io.IOException;
//                  import java.io.OutputStream;
//                  import java.util.List;
//                  import org.vitu.files.model.Person;
//                  public class PersonOutputStream implements AutoCloseable {
//                      private OutputStream outputStream;
//                      public PersonOutputStream(OutputStream outputStream) {
// 	                        this.outputStream = outputStream;
//                      }
//                      public void writeFields(List<Person> people) {
// 	                        people.stream()
// 		                        .map(this::personToBytes)
// 		                        .forEach(this::writeBytes);
//                      }
//                      private byte[] personToBytes(Person person) {
// 	                        byte[] bytes = null;
// 	                        try (ByteArrayOutputStream bos = new ByteArrayOutputStream();
// 		                         DataOutputStream dos = new DataOutputStream(bos);) {
// 	                            // Ecrire deux String.
// 	                            dos.writeUTF(person.getName());
// 	                            dos.writeUTF(person.getCity());
// 	                            dos.flush();
// 	                            // Ecrire un int.
// 	                            dos.write(person.getAge());
// 	                            dos.flush();
// 	                            bos.flush();
// 	                            // Nous récupérons le tableau de bytes final.
// 	                            bytes = bos.toByteArray();
// 	                        } catch (IOException e) {
// 	                            e.printStackTrace();
// 	                        }
// 	                        return bytes;
//                      }
//                      private void writeBytes(byte[] bytes) {
// 	                        try {
// 	                            this.outputStream.write(bytes);
// 	                        } catch (IOException e) {
// 	                            e.printStackTrace();
// 	                        }
//                      }
//                      @Override
//                      public void close() throws IOException {
// 	                        this.outputStream.close();
//                      }
//                  }
// -----------
//                  package org.vitu.files;
//                  import java.io.BufferedInputStream;
//                  import java.io.ByteArrayInputStream;
//                  import java.io.DataInputStream;
//                  import java.io.EOFException;
//                  import java.io.IOException;
//                  import java.io.InputStream;
//                  import java.util.ArrayList;
//                  import java.util.List;
//                  import java.util.function.Function;
//                  import java.util.stream.Collectors;
//                  import java.util.stream.Stream;
//                  import org.vitu.files.model.Person;
//                  public class PersonInputStream implements AutoCloseable {
//                      private static final Person EOF = new Person("EOF", null, 0);
//                      private InputStream inputStream;
//                      Function<ByteArrayInputStream, Stream<Person>> bytesToPerson = this::bytesToPerson;
//                      public PersonInputStream(InputStream inputStream) {
// 	                        this.inputStream = inputStream;
//                      }
//                      public List<Person> readFields() {
// 	                        try (BufferedInputStream is = new BufferedInputStream(inputStream);) {
// 	                            byte[] bytes = is.readAllBytes();
// 	                            ByteArrayInputStream bis = new ByteArrayInputStream(bytes);
// 	                            List<Person> people = Stream.generate(() -> bytesToPerson(bis))
// 		                                .flatMap(stream -> stream)
// 		                                .takeWhile(person -> isEndOfStream(person))
// 		                                .collect(Collectors.toList());
// 	                            return people;
// 	                        } catch (IOException e) {
// 	                            e.printStackTrace();
// 	                        }
// 	                        return new ArrayList<>();
//                      }
//                      private boolean isEndOfStream(Person person) {
// 	                        return !person.equals(EOF);
//                      }
//                      private Stream<Person> bytesToPerson(ByteArrayInputStream bis) {
// 	                        try (DataInputStream dis = new DataInputStream(bis);) {
// 	                            String name = dis.readUTF();
// 	                            String city = dis.readUTF();
// 	                            int age = dis.readInt();
// 	                            return Stream.of(new Person(name, city, age));
// 	                        } catch (EOFException e) {
// 	                            return Stream.of(EOF);
// 	                        } catch (IOException e) {
// 	                            e.printStackTrace();
// 	                        }
// 	                        return Stream.empty();
//                      }
//                      @Override
//                      public void close() throws IOException {
// 	                        this.inputStream.close();
//                      }
//                  }
// -----------
//                  import java.io.FileOutputStream;
//                  import java.io.IOException;
//                  import java.util.List;
//                  import org.vitu.files.PersonOutputStream;
//                  import org.vitu.files.model.Person;
//                  public class WritePeople {
//                      public static void main(String[] args) {
// 	                        Person p1 = new Person("Paul", "Manchester", 32);
// 	                        Person p2 = new Person("NGolo", "Chelsea", 29);
// 	                        Person p3 = new Person("Kylian", "Paris", 19);
// 	                        Person p4 = new Person("Hugo", "Tottenham", 28);
// 	                        Person p5 = new Person("Zinedine", "Chelsea", 29);
// 	                        List<Person> people = List.of(p1, p2, p3, p4, p5);
// 	                        try (FileOutputStream fos = new FileOutputStream("files/people.bin");
// 		                         PersonOutputStream pos = new PersonOutputStream(fos);) {
// 	                            pos.writeFields(people);
// 	                        } catch (IOException e) {
// 	                            e.printStackTrace();
// 	                        }
// 	                        System.out.println("Done");
//                      }
//                  }
// -----------
//                  import java.io.FileInputStream;
//                  import java.io.IOException;
//                  import java.util.List;
//                  import org.vitu.files.PersonInputStream;
//                  import org.vitu.files.model.Person;
//                  public class ReadPeople {
//                      public static void main(String[] args) {
// 	                        try (FileInputStream fis = new FileInputStream("files/people.bin");
// 		                         PersonInputStream pis = new PersonInputStream(fis);) {
// 	                            List<Person> people = pis.readFields();
// 	                            people.forEach(System.out::println);
// 	                        } catch (IOException e) {
// 	                            e.printStackTrace();
// 	                        }
// 	                        System.out.println("Done!");
//                      }
//                  }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Coding sur l'Api Java IO n°4 /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons commencer par créer un nouveau projet 'PlayWithZipOutputStream', puis une classe 'PlayWithZip' dans 'org.vitu.zip' dans le dossier 'src'.
//  - Pour commencer, quelle est la différence entre un fichier .zip et un fichier .gzip ?
//      --> Dans un fichier .zip, nous pouvons avoir une structure de répertoire, donc pleins de fichiers, organisés dans des répertoires et des sous-repértoires.
//      --> Dans un fichier .gzip, nous ne pouvons avoir qu'un seul fichier, pas de répertoires.
//  - Comment est-ce que ça fonctionne ? Nous avons une classe 'ZipOutputStream', qui se construit sur un 'OutputStream', lui même construit sur un 'FileOutputStream'.
//      Il suffit ensuite de l'entourer d'un try-with-resources, et d'attrapper soit la 'FileNotFoundException', soit la classe 'IOException' dont elle hérite.
//          - Nous écrivons au travers d'un 'GZipOutputStream' de la même manière que nous écririons au travers de n'importe quel 'OutputStream', en effectuant des 'Write' par exemple.
//              Nous pouvons aussi décorer notre 'GZipOutputStream' avec un 'Data' ou avec un 'ObjectOutputStream'.
//              Puis nous effectuons des 'Write' dessus, et cela est envoyé dans un flux 'GZippé' automatiquement pour nous, ce qui est simple puisqu'il n'y a qu'un seul fichier dans un 'GZip'.
//          - Pour un fichier 'Zip', c'est un peu plus compliqué, car à l'intérieur de notre try-with-resources, nous allons devoir gérer des 'ZipEntry', prenant un chemin de fichier en paramètre.
//                  --> Ainsi, nous pouvons appeler la méthode 'putNextEntry()' sur notre objet de type 'ZipOutputStream' en lui passant notre objet de type 'ZipEntry' en paramètre.
//          - Nous pouvons ainsi récupérer un chemin contenant plusieurs fichiers et répertoires, et l'ajouter dans notre code en tant que 'Path' avec la méthode 'Path.of("chemin")'.
//              Ensuite, nous pouvons utiliser la méthode 'walk()' sur l'objet 'Files' de l'API 'Java NIO', pour récupérer un Stream<Path>.
//                  --> Si nous imprimons chacun des Path sur la console en effectuant un 'stream.forEach(System.out::println)', nous constatons que tous les répertoires et tous les fichiers sont listés.
//              Enfin, nous pouvons filtrer, puis mapper ce stream afin d'avoir une List de paths.
//          - De cette manière, nous pouvons utiliser notre ZipOutputStream pour itérer chaque élément de la liste dans notre bloc try-with-resources pour ajouter une nouvelle ZipEntry à chaque fois.
//          - Toutefois, nous devons ajouter un "/" à la fin de chacun des paths de répertoire pour que notre ZipOutputStream sâche qu'il s'agit d'un répertoire et non d'un fichier.
//              Donc nous allons d'abord récupérer le chemin absolu, puis si c'est un répertoire, nous allons y ajouter un "/".
//      --> A présent nous avons un fichier zip qui s'est créé, contenant les répertoires et les fichiers ! Toutefois, ces fichiers sont vides, il va falloir les écrire.
//  - Nous devons donc ajouter du contenu dans ces fichiers lorsqu'ils sont sous forme d'un ZipEntry, avant d'employer la méthode 'putNextEntry()' sur notre objet ZipOutputStream.
//      Pour ce faire, si nous utilisons un DataOutputStream avec la méthode 'writeUTF()', cela ne vas pas fonctionner car les caractères de séparations seront mal codés dans nos fichiers.
//      Nous allons plutôt utiliser un OutputStreamWriter, que nous plaçons dans les resources à fermer du try-with-resources.
//      Ainsi, nous pouvons créer un autre bloc try-with-resources avec un BufferedReader dans notre condition ou le path est un fichier.
//      Avec une boucle while, nous pouvons lire le fichier et écrirer la ligne dans le fichier de destination tant qu'il existe une ligne.
//          --> Enfin, nous devons utiliser aussi un BufferedWriter qui va décorer notre OutputStreamWriter pour écrire les nouvelles lignes dans notre fichier.
//      Pour finir, il nous faut flusher nos deux Writers dans le bon ordre.
// -----------
//                  package org.vitu.zip;
//                  import java.io.BufferedReader;
//                  import java.io.BufferedWriter;
//                  import java.io.FileOutputStream;
//                  import java.io.IOException;
//                  import java.io.OutputStream;
//                  import java.io.OutputStreamWriter;
//                  import java.nio.file.Files;
//                  import java.nio.file.Path;
//                  import java.util.List;
//                  import java.util.stream.Collectors;
//                  import java.util.stream.Stream;
//                  import java.util.zip.ZipEntry;
//                  import java.util.zip.ZipOutputStream;
//                  public class PlayWithZip {
//                      public static void main(String[] args) throws IOException {
// 	                        String dirName = "C:/Users/Emile/Desktop/JAVA/java-projects/emile-workspace/PlayWithServiceLoader/src";
// 	                        Path dir = Path.of(dirName);
// 	                        Stream<Path> stream = Files.walk(dir);
// 	                        List<Path> paths = stream.filter(path -> path.toString().length() > dirName.length() + 1)
// 		                            .map(path -> path.toString().substring(dirName.length() + 1))
// 	    	                        .map(Path::of)
// 	    	                        .collect(Collectors.toList());
// 	                        try (OutputStream os = new FileOutputStream("files/archive.zip");
// 		                            ZipOutputStream zos = new ZipOutputStream(os);
// 		                            OutputStreamWriter osw = new OutputStreamWriter(zos);
// 		                            BufferedWriter bw = new BufferedWriter(osw);) {
// 	                            for (Path path : paths) {
// 		                            Path absolutePath = Path.of(dirName, path.toString());
// 		                            if (Files.isDirectory(absolutePath)) {
// 		                                String zipEntryName = path.toString() + "/";
// 		                                ZipEntry zipEntry = new ZipEntry(zipEntryName);
// 		                                zos.putNextEntry(zipEntry);
// 		                            } else {
// 		                                ZipEntry zipEntry = new ZipEntry(path.toString());
// 		                                zos.putNextEntry(zipEntry);
// 		                                try (BufferedReader reader = Files.newBufferedReader(absolutePath);) {
// 			                                String line = reader.readLine();	
// 			                                while (line != null) {
// 			                                    osw.write(line);
// 			                                    bw.newLine();
// 			                                    bw.flush();
// 			                                    osw.flush();
// 			                                    line = reader.readLine();
// 			                                }
// 		                                } catch (IOException e) {
// 			                                e.printStackTrace();
// 		                                }
// 		                            }
// 	                            }
// 	                        } catch (IOException e) {
// 	                            e.printStackTrace();
// 	                        }
// 	                        System.out.println("Done!");
//                      }
//                  }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quatrième Partie : Les API Avancées ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : Api Reflection /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Présentation de l'API Reflection //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Parlons à présent de l'API Reflection, à quoi sert-elle et pourquoi a t'elle été introduite en Java ?
// Cette API est au coeur d'un certain nombre de choses, en particulier des applications Java EE, Spring, ou encore le mapping objets relationnels.
// Lorsque nous écrivons le code suivant, nous savons que nous avons un objet 'user' qui est de type User, donc une instance de la classe User.
// Comme nous connaissons la classe User, et que dans celle-ci nous avons une méthode getName() qui est déclarée, nous savons que nous pouvons appeler : user.getName().
// Parallèlement, nous savons que getName() nous retourne une chaîne de caractères qui est en fait le nom de l'utilisateur.
// Nous avons donc une partie technique : nous savons que la méthode getName() existe.
// Et une partie applicative : nous savons qu'elle nous retourne une chaîne de caractères qui est en fait le nom de l'user ciblé.
// --> L'API Reflection va nous permettre de traiter des objets 'o' sans que nous sachions à quelle classe ces objets appartiennent.
// Cet objet peut appartenir à n'importe quelle classe, mais nous pouvons l'interroger pour découvrir à quelle classe il appartient.
// La classe en elle-même, nous allons pouvoir l'introspecter, ce pourquoi nous appelons parfois cette API Introspection, pour connaître :
// - Ses champs.
// - Ses méthodes.
// - ...
// --> Ainsi nous pourrons connaître par la suite la valeur de ces champs et de ses méthodes pour pouvoir les invoquer sur l'objet d'origine.
// L'introspection nous permet donc de manipuler des objets, ainsi de lire leurs champs et invoquer leurs méthodes, et éventuellement même en construire d'autres.
// Ceci, sans connaître à la compilation, donc au moment ou nous écrivons notre code, la classe à laquelle appartient cet objet.
// --> C'est donc quelque chose de très puissant, très fondamental car cela a de nombreuses applications, et c'est assez technique à mettre en place.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Où est utilisé l'API Reflection ? /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quelles sont les applications de l'API Reflection ? --> Elles sont en fait inombrables.
// --> Java EE
//      - CDI : objet qui fait de l'injection de dépendances.
//      - JPA : qui fait du mapping d'objets relationnels, capacité à écrire automatiquement des objets en base de données.
//      - JSF : Java Server Faces, qui permet de construire des interfaces graphiques dans le navigateur.
//      - JAX_RS : Qui permet de construire des services REST.
//      - JAX_WS : Qui permet de construire des services Web.
// --> Spring
//      - REST, WS (WebServices).
//      -
// --> ... : tout un tas d'autres framework qui utilisent massivement l'API Reflection.
// C'est donc une API qui est très technique, mais qui est à la base d'inombrables frameworks.
// Elle est à la base du fonctionnement de l'écrasante majorité des applications à l'heure actuelle écrites en Java en entreprise.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Manipulation des Classes avec l'API Reflection ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Class, instances de Class /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le point d'entrée que nous allons utiliser pour expliquer l'API Reflection est une classe qui s'appelle 'Class'.
// Cette classe 'Class' modélise les classes que nous utilisons dans une application Java.
// Nous savons déjà qu'en Java, tout est objet, rien ne peut vivre à l'extérieur d'un objet dans une application Java.
// Ainsi, même les classes, sont modélisées par des objets dans Java.
// User user = ...
// --> Class c = user.getClass(); : donc l'objet 'c' modélise la classe à laquelle appartient 'user'.
// --> Class c2 = String.class; : c2 va nous permettre de modéliser la classe des chaînes de caractères. ATTENTION : 'class' est un mot-clef du langage.
// Il faut noter aussi que l'objet Class 'c' que nous récupérons avec user.getClass() est toujours le même, quel que soit l'instance de user que nous utilisons.
// Donc l'objet Class est unique, quelle que soit la façon dont nous le récupérons.
// Il est intéressant de regarder le contenu de cette classe Class :
// public class Class {
//     private Class(...) {...}
// }
// Nous pouvons déjà remarquer que le constructeur est privé. Qu'est ce que ceci a pour conséquences ?
// --> Cela veut dire que de l'extérieur de la classe Class, nous ne pouvons pas appeler ce constructeur qui est privé.
// --> Nous ne pouvons donc l'appeler que depuis l'intérieur de la classe Class.
// --> Nous pouvons l'appeler de l'intérieur de la classe Class, avant que la première instance de cette classe Class ne soit construite.
// Donc la seule façon de pouvoir l'appeler est d'avoir une méthode statique, publique, qui nous retournera une instance de Class :
// public class Class {
//      private Class(...) {...}
//      public static Class ...
// }
// --> Class.(méthode statique)
// C'est de cette manière que cela fonctionne à l'intérieur de la machine virtuelle Java.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Instances de Class à partir du nom d'une classe ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le troisième pattern très important est la fameuse méthode statique. Celle-ci nous permet de récupérer une instance de Class, en l'occurence existante à partir d'un nombre.
// Cette méthode statique peut donc être invoquée au travers du nom de la classe, et elle prends une chaîne de caractères en paramètre, et elle retourne une instance de Class :
// --> Class c = Class.forName("..."); --> Quelle est cette chaîne de caractères ?
// Cette chaîne de caractères est en fait le nom complet de la classe.
// Par exemple la classe String à un nom 'String', puis elle a nom complet qui comporte le package dans laquelle cette classe se trouve : 'java.lang.String'.
// Ainsi, Class.forName("java.lang.String"); va nous retourner une instance de String.class.
// --> C'est fondamental car cela signifie qu'à partir du nom d'une classe dans une chaîne de caractères, nous pouvons récupérer une référence sur l'objet class.
// L'avantage est qu'à partir d'un fichier .xml qui contient des noms de classe, à partir d'un fichier .json, à partir d'un fichier .txt, nous pouvons récupérer des instances de la classe souhaitée.
// Si par exemple nous voulons récupérer les références sur la classe user, nous pouvons écrire le code suivant :
// Class userClass = Class.forName("org.vitu.model.User");
// --> Si cette classe se trouve bien sur ce chemin, nous allons récupérer un pointeur vers l'instance de cette classe.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'instances à partir d'un objet de type Class ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant que nous avons une instance de notre classe User : Class userClass = ...
// Nous allons maintenant pouvoir faire trois choses :
// - Créer des instances de cette classe, donc des instances de 'user'.
// - Aller chercher des informations sur le contenu de cette classe, typiquement, ses champs et ses méthodes.
// - Pouvoir aller lire et modifier les valeurs de ces champs, et pouvoir invoquer ces méthodes.
// Voyons dans un premier temps comment créer des instances de la classe user à partir de la classe qui modélise cet utilisateur :
// --> Object o = user.newInstance(); : la méthode newInstance() nous retourne un objet.
// --> User user = (User) o; : Ainsi, nous pouvons caster directement l'objet dans un utilisateur.
// Nous aurions pu aussi par ailleurs fusionner ces deux lignes en une seule.
// Avec cette méthode newInstance(), invoquée sur la classe qui représente user, nous pouvons donc créer des instances de user, ce qui est très pratique.
// Maintenant les choses ne se font pas magiquement, lorsque nous voulons créer un objet, il y a forcément un constructeur qui est invoqué.
// Quel va être le constructeur invoqué par newInstance() ? --> Il s'agit en fait du constructeur vide.
// Donc l'appel à newInstance() va faire appel à un constructeur vide de cette classe. Par contre, ou bien ce constructeur vide existe, ou bien il n'existe pas.
// Si jamais il n'existe pas, newInstance() va jeter une exception, d'ailleurs, newInstance() jette tout un tas d'exception qu'il va falloir attraper.
// Donc tout le code précédent s'écrit nécessairement dans des blocs try / catch.
// A quelle condition ce constructeur vide existe t'il ?
// - Soit nous n'avons pas de constructeur dans la classe, dans ce cas là, nous savons que le constructeur vide se trouve là par défaut.
// - Soit le constructeur vide est écrit excplicitement.
// D'où l'importance de toujours déclarer des constructeurs vides lorsque nous codons une nouvelle classe.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Manipulation des champs d'une classe //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récupérer des champs d'une classe /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Class userClass = ...
// Voyons maintenant dans un second temps comment nous pouvons récupérer le(s) champs d'une classe, pour ça nous avons trois pattern :
// --> Field f1 = userClass.getField("name"); : cet objet de type 'field' est un modèle du champs 'name' à l'intérieur de cette classe.
// Que le champs 'name' soit public, privé, protégé, ou package protected, nous allons pouvoir récupérer un objet de type field.
// Nous avons d'autres pattern pour récupérer des objets de type field :
// --> Field[] fields = userClass.getFields(); : ceci retourne un tableau de champs, celui-ci contient tous les champs PUBLIC de notre classe userClass, ainsi que ceux de sa 'SuperClasse'.
// Donc si userClass n'étends pas une autre classe, et si elle ne possède pas de champs public, ce qui est la bonne façon de faire, le tableau retourné sera vide.
// Nous avons enfin une dernière méthode :
// --> Field[] fields2 = userClass.getDeclaredFields(); : cette méthode nous retourne les champs de userClass, et uniquement ces champs (pas ceux de ses SuperClasses).
// Ces champs peuvent être public, private ou protected ou package protected, ces derniers sont les champs qui n'ont pas de modificateur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Analyse d'un champ avec l'objet Field /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Donc à présent nous avons un objet qui modélise une class : Class userClass = ...
// Sur cet objet, nous avons récupéré un champs field : Field field = ... : supposons qu'il s'agit du champs 'name'.
// Ce dernier objet est donc une référence qui modélise ce champs. Que pouvons-nous faire sur ce champs ? Et bien nous pouvons faire pas mal de choses :
// --> field.getName(); : retourne une chaîne de caractère qui est le nom de ce champs.
// --> field.getModifiers(); : retourne un objet un petit peu compliqué que nous pouvons analyser.
// Ce dernier objet va nous permettre de savoir si le champs est final ou pas, si il est privé, public, protected ou package protected, si il est static ou si c'est un champs d'instance
// --> get(Objetc o);
// --> set(Object o);
// Ces deux dernières méthodes sont probablement les plus importantes, mais aussi les plus délicates à manipuler.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lire le champ d'un objet avec Field ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Essayons à présent de visualiser un petit peu les choses :
// Nous avons notre objet userClass, qui est de type Class, son pointeur étant userClass.
// Dans l'objet de type Class, nous avons un certain nombre d'objets de type Field, dont l'objet field (name).
// Tout autour de cette objet de type class, nous avons tout un tas d'objets de type User, qui sont des instances d'utilisateurs : u1, u2, u3, u4, u5, u6 & u7.
// Nous voulons à présent, à l'aide de l'objet field, trouver le name de l'utilisateur u6.
// Chaque utilisateur possède son propre champs 'name' avec une valeur qui lui est propre.
// Il va donc falloir que nous passons cet objet u6 en paramètre de la méthode get() de l'objet field que nous avons récupéré :
// --> name6 = fielf.get(u6); : Cette méthode nous retourne le name de l'objet u6.
// Ce code là est équivalent à u6.name : qui nous retourne une chaîne de caractères qui va être le name de u6.
// Toutefois, si nous faisons u6.name à l'extérieur de user, nous n'aurons un résultat que si le champs name est un champs public.
// Si le champs name est private, et que nous ne faisons rien, la méthode filed.get(u6); invoquée à l'extérieur de la classe user va nous jeter une exception.
// Ceci car nous n'avons pas le droit de lire des champs privés de l'extérieur d'une classe.
// Si nous voulons que cette méthode fonctionne, nous allons devoir appeler une autre méthode avant la méthode get() qui est :
// --> field.setAccessible(true); : cette méthode prends en paramètre un boolean et retourne.
// Faire de cette manière ne rends pas le champs field qui était privé, public.
// Cela dit simplement à l'API Reflexion de ne pas vérifier les contraintes (privé, public, protected, package protected) quand elle va invoquer la méthode get().
// Cela permet donc de lever l'intégralité des contraintes de sécurité, et avec elles les contraintes de visibilité.
// Ainsi, avec ces deux lignes de code, nous pouvons, par réflection, aller lire les champs privés d'une classe, quand bien même nous ne sommes pas à l'intérieur de cette classe.
// La seule condition est de posséder le nom de ce champs, que nous pouvons récupérer en intérrogeant la classe Class.
// Field f1 = userClass.getField("name");
// field.setAccessible(true);
// name6 = fielf.get(u6);

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire le champ d'un objet avec Field /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// En plus de cette méthode get(), nous avons également une méthode set() :
// --> field.set(u6, "..."); : En passant en paramètre, l'objet qui possède le champs dont nous voulons fixer la valeur, ainsi que la chaîne de caractère que nous souhaitons modifier dans l'objet.
// Donc nous utilisons le champs field 'name', qui déjà modélise un champs particullier de cette classe pour fixer la valeur d'une instance particulière de cette classe à une valeur que nous donnons.
// L'équivalent de ce code serait : u6.name = "...";
// Nous avons aussi les mêmes contraintes et devons utiliser : field.setAccessible(true).
// Ainsi, à travers de cet objet field, nous pouvons lire, et écrire, donc modifier la valeur d'un champs au travers d'une classe, quelque soit la modification de ce champs.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Manipulation des méthodes d'une classe ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récupérer les méthodes d'une classe avec Method ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le second élément que nous pouvons trouver dans une classe et que nous pouvons récupérer grâce à l'API Reflexion, ce sont les méthodes.
// --> Method m = userClass.getMethod("nomDeLaMethode", ...); : Ainsi nous passons d'abord le nom de la métode en chaîne de caractères.
// Nous passons ensuite le type des paramètres que cette méthode prends, par exemple : String.Class. Ce ou ces derniers paramètres peuvent aussi être vides, selon la méthode recherchée.
// Si la méthode n'est pas trouvée, une exception sera jetée, donc encore une fois, nous devons encapsuler ce code dans un bloc try / catch.
// Nous avons aussi deux autres méthodes du même type :
// --> Method[] ms = userClass.getMethods(); : va retourner un tableau contenant l'ensemble des méthodes public de cette classe ET des classes superClass de cette classe.
// --> Method[] ms = userClass.getDeclaredMethods(); : retourne un tableau avec les méthodes déclarées dans userClass.
// Et ce, qu'elles soient public, private, protected ou package protected, méthodes statiques ou d'instance.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Method : accéder aux informations d'une méthode ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons maintenant que nous avons une instance de classe vers la classe user qui s'appelle userClass.
// Nous avons aussi une instance d'un objet Method, donc de type methode qui s'appelle nameGetter et que nous avons récupéré avec un des pattern que nous avons vu précédemment.
// Nous allons pouvoir faire le même genre de chose sur les objets de type Method que sur les objets de type Field :
// --> nameGetter.getName() : retourne le nom de la méthode sous forme de chaîne de caractères.
// --> nameGetter.getModifiers() :
// --> nameGetter.getReturnType() : retourne une classe, ici par exemple cela retournera la classe String. Cela peut aussi être void.classe, pour une méthode qui ne retourne rien, donc void.
// --> nameGetter.getParameters() : retourne un tableau de paramètres de type parameter : Parameter[] parameterTypes, chaque objet parameter portant le type et le nom du paramètre de cette méthode.
// --> nameGetter.getParameterCount() : retourne le nombre de paramètres qu'utilise cette méthode, cela peut aussi être 0.
// --> nameGetter.getParameterTypes(); : retourne un tableau de class : Class[] parameterTypes.
// A présent, comment pourrons nous faire pour invoquer cette méthode par Reflexion ?

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Method : invoquer une méthode sur un objet par Reflection /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// En fait nous nous retrouvons exactement dans la même contexte pour invoquer une méthode que pour positionner la valeur d'un champs, ou que pour lire la valeur d'un champs.
// Comment allons-nous pouvoir appeler la méthode nameGetter sur le user u3, sachant que cette méthode est connue à l'intérieur de l'instance de classe userClass.
// A savoir que nous n'avons qu'une seule instance de classe pour autant d'instances d'user que nous voulons. Nous allons utiliser la même approche que pour la lecture ou l'écriture d'un champs.
// Nous allons invoquer cette méthode nameGetter sur un objet, à l'aide d'une des méthodes de cet objet.
// --> Objet o = nameGetter.invoke(u3);
// Vu que nous savons que cet objet est une chaîne de carractères, nous allons pouvoir le caster :
// --> String s = (String) o;
// Pour le moment les choses sont simples car la méthode nameGetter ne prends pas de paramètres. Supposons à présent que la méthode que nous souhaitons appeler est nameSetter().
// --> nameSetter.invoke(u3, "nomDuUser"); : Cette méthode nameSetter ne va rien nous retourner, donc void, donc il n'est pas nécessaire de la mettre dans une variable.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Method : invoquer une méthode privée //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons aussi récupérer des méthodes qui sont privées. Toutefois, en éxecutant le code précédent pour une méthode privée, il jettera une exception.
// Si nous voulons pouvoir invoquer une méthode privée :
// nameGetter.setAccessible(true);
// Etant donné le code précédent dans ce sous-chapitre, tout peut jeter des exceptions donc doivent être compris dans des blocs try / catch.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Conclusion ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Retour sur les modificateurs des champs et des méthodes ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Petit retour sur les modificateurs donc nous avons parlé dans ce chapitre.
// --> int modifiers = field.getModifiers();
// --> int modifiers = method.getModifiers();
// Cet int joue le rôle de 'champs de bits', c'est à dire qu'il à une valeur vu que c'est un entier, mais ce qui à du sens dans cette valeur est la valeur de ces bits pris individuellement.
// C'est quelque chose qui est très utilisé en C.
// Donc pour savoir si le champs ou la méthode est finale, ou statique, ou privée, ou publique, ... Il va falloir que nous allions voir les bits dans cet entier, ce qui est assez fastidieux.
// En fait nous avons une classe Modifier qui ont toute une série de méthodes auxquelles nous pouvons passer cet entier 'modifier' et qui retournent des booleans :
// --> Modifier.isFinal(modifier);
// --> Modifier.isPrivate(modifier);
// --> Modifier.isPublic(modifier);
// --> Modifier.isStatic(modifier);
// --> Modifier.isSynchronized(modifier);

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur l'API Reflection ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'avons nous vu sur cette API Reflexion :
// --> Nous avons vu la classe qui s'appelle Class :
//      - Comment obtenir des instances de cette classe :
// Soit directement (User.class, String.class), soit à partir d'un objet sur lequel nous invoquons getClass(), soit avec forName() avec le nom de la classe en paramètre.
//      - Comment interroger le contenu de cette classe.
//      - Comment créer des objets instances de cette classe.
// --> Nous avons vu la classe Field :
//      - Comment obtenir des instances de champs.
//      - Comment utiliser ces instances pour lire et/ou écrire les champs d'un objet.
// --> Nous avons vu la classe Method :
//      - Comment obtenir des instances de méthodes.
//      - Comment invoquer cette méthode sur des objets. Avec la problématique du passage de paramètres et de la récupération du type de retour, des objets retournés par cette méthode.
// --> Nous pouvons aussi aller voir comment fonctionne la classe Constructor.
// public final class Constructor<T> : Constructor provides information about, and acces to, a single constructor for a class.
// Constructor permits widening conversions to occur when matching the actual parameters to newInstance() with the underlying's constructor's formal parameters.
// Constructor throws an IllegalArgumentException if a narrowing conversion would occur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// API Reflection par la pratique ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// LiveCoding : API Reflection par la pratique 1/2 ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quelle est l'utilité de l'API Reflection ? Elle est peu utilisée au sein d'une application, car très touchy, toutefois, elle est massivement utilisée par tous les frameworks.
// Il est toutefois important de comprendre comment l'API fonctionne, car cela nous permet de comprendre plus facilement comment tous ces framework fonctionnent.
// Que pouvons-nous faire avec l'API Reflection ?
//      --> L'API Reflection est une espèce de boite à outils, qui va nous permettre de récupérer des informations sur ces classes.
//              Une fois que nous aurons nos informations sur ces classes, nous allons pouvoir utiliser cette information pour manipuler le contenu des instances de cette classe.
//  - Nous allons créer un nouveau projet, avec une classe 'PlayWithReflection' possèdant une classe main, ainsi qu'une classe de type 'Person', avec un nom, une ville et un âge.
//      - Dans notre classe main, nous pouvons créer une instance de Person.
//      - La première chose que nous pouvons faire c'est utiliser la méthode 'getClass()' de la classe 'Object', cela nous retournera une instance de classe.
//          --> Qu'est-ce que cette instance de classe ? C'est une classe qui va permettre de modéliser le contenu de toutes les classes en Java, donc en l'occurence, celui de la classe Person.
//          Sur cet objet, nous pouvons par exemple faire 'getName()', ce qui nous retournera le nom entier de la classe : 'org.vitu.model.Person'.
//          Nous pouvons aussi récupérer la SuperClasse de cette classe dans un autre objet Class (ici ce sera 'java.lang.Object'), ou encore les interfaces qu'elle implémente dans un Class[].
//          Cela nous retourne 'Serializable', nous pouvons ajouter l'implémentation de l'interface Comparable à notre bean (chose qui se fait assez souvent).
//      - Nous pouvons aussi appeler les champs de cette classe avec les méthodes 'getFields()' et 'getDeclaredFields()' retournant chacun 'Field[]'.
//          - Quelle est la différence entre ces deux méthodes et les deux tableaux qu'elle retourne ?
//                  --> 'getFields()' retourne tous les champs public de cette classe et des classes qu'elle étends.
//                          Or, en principe, si nous suivons le principe d'encapsulation, tous les champs doivent être privés donc nous ne devrions pas avoir de Field retourné par cette méthode.
//                  --> 'getDeclaredFields()' nous retournera l'ensemble des champs de la classe, qu'ils soient public, protected, package-protected ou private.
//          - Que pouvons-nous faire de ces champs une fois que nous les avons recueillis ?
//              Nous pouvons récupérer les noms de ces Fields avec la classe 'getName()', nous pouvons aussi récupérer leur type avec la méthode 'getType()'.
//                  --> Ceci nous retournera quelque chose du type : nom : 'nom', type : 'java.lang.String'.
//          - Nous pouvons aussi appeler la méthode 'getModifiers()' sur ces objets de type 'Field', qui nous retournera un int contenant des bytes avec les informations.
//              Ces informations peuvent ensuite être utilisées comme paramètres des méthodes de la classe 'Modifiers'.
//      - De la même façon, nous pouvons récupérer les méthodes d'une classe avec la méthode 'getMethods()' sur l'objet de type 'Class'.
//              - En appelant la méthode 'getMethods()', cela nous retourner toutes les méthodes publiques de la classe et de sa super classe, avec les classes des types des paramètres pour chacune :
//                  --> Comme par exemple : 'public final void java.lang.Object.wait(long,int) throws java.lang.InterruptedException', provenant de la super classe 'Object'.
//                  --> Ou encore : 'public void org.vitu.reflect.model.Person.setCity(java.lang.String)', provenant de la classe 'Person'.
//                  --> Si nous surchargeons une méthode de la super classe dans la classe, celle-ci apparaîtra comme méthode de la classe et non de sa super classe d'où elle est originaire.
//              - Nous pouvons aussi appeler la méthode 'getDeclaredMethods()', qui nous retournera l'ensemble des méthodes publiques et privées de l'objet de type Class :
//                  --> Comme par exemple : 'public int org.vitu.reflect.model.Person.compareTo(java.lang.Object)'.
//                  --> Attention, cela ne retourne pas les méthodes de la super classe, contrairement à la méthode 'getMethods()'.
//                  --> Si nous extrayons le comparator de la méthode 'compareTo()' dans une métode privée 'buildComparator()', nous pourrons la voir listée avec les declared methods.
//      - Enfin, nous pouvons de la même manière récupérer les constructeurs de nos classes si elle existent avec la méthode 'getConstructors()'.
//              - En appelant la méthode 'getConstructors()', nous avons tous les constructeurs de l'objet de type Class ciblé, mais PAS ceux qu'elle peut hériter de sa super classe.
//                  --> 'public org.vitu.reflect.model.Person()' et 'public org.vitu.reflect.model.Person(java.lang.String,java.lang.String,int)'.
//              - La méthode 'getDeclaredConstructors()', elle, retourne tous les constructeurs, peu importe qu'ils soient publics ou non.
//  - Donc l'API Reflection nous permet de récupérer toutes les informations de nos objets.
//          --> Attention toutefois à ne pas confondre méthodes et constructeurs, car ceux-ci ne sont pas du tout gérés de la même manière.
//      - Derrière tout cela, nous pouvons effectuer des choses un peu plus précises, comme par exemple récupérer les champs par noms avec la méthode 'getField("nomDuChamps")'.
//          --> La différece est que lorsque nous allons chercher un champs en particulier, cela peut nous jeter des exceptions :
//                  - 'NoSuchFieldException' : si le champs demandé n'existe pas, elle étends Exception, donc c'est une checked Exception et nous devons la jeter ou la catcher.
//                  - 'SecurityException' : qui n'est pas une checked Exception car elle étends RuntimeException, donc nous ne sommes pas obligés de la jeter ou de la catcher.
//          Toutefois, comme les champs ne sont pas publics, une 'NoSuchFieldException' sera jetée, il nous faut passer par la méthode 'getDeclaredFields()'.
//              --> Name field : 'private java.lang.String org.vitu.reflect.model.Person.name'.
//      - Ces méthodes en incluant le nom fonctionne aussi avec la méthode 'getMethod()' et 'getDeclaredMethod()' qui vont toutes deux jeter une 'NoSuchMethodException'.
//              --> Method getName : 'public java.lang.String org.vitu.reflect.model.Person.getName()'.
//          Si nous effectuons la même chose pour une méthode de type set, comme 'setAge', une exception sera jetée car le compilateur s'attends à avoir un argument dans cette méthode.
//              --> Ceci car une méthode est caractérisée par son nom et par les paramètres qu'elle prends. Il faut donc appeler la méthode de cette manière : 'getDeclaredMethod("setAge", int.class)'.
//          Ainsi, si nous avons une seconde méthode qui s'appelle 'setAge()' mais qui prends un String en paramètre, nous pourrons aussi l'appeler.
//      - Ceci fonctionne aussi avec les constructeurs, la méthode 'getConstructor()', si elle ne prends pas de paramètres, retourne le constructeur vide, s'il existe et s'il est public.
//          Aussi, si nous n'avons pas de constructeurs, mais que nous l'appelons tout de même avec cette méthode, il va tout de même nous retourner le constructeur vide.
//              --> En effet, le compilateur en créé un automatiquement s'il n'y en a pas un de précisé dans la classe.
// -----------
//                  package org.vitu.reflect.model;
//                  import java.io.Serializable;
//                  import java.util.Comparator;
//                  import java.util.Objects;
//                  public class Person implements Serializable, Comparable {
//                      private static final long serialVersionUID = 1L;
//                      private String name;
//                      private String city;
//                      private int age;
//                      public Person() {
// 	                 name = null;
//                      }
//                      public Person(String name, String city, int age) {
// 	                 super();
//                  	this.name = name;
// 	                 this.city = city;
// 	                 this.age = age;
//                      }
//                      public String getName() {
//                          return name;
//                      }
//                      public void setName(String name) {
//                          this.name = name;
//                      }
//                      public String getCity() {
//                          return city;
//                      }
//                      public void setCity(String city) {
//                          this.city = city;
//                      }
//                      public int getAge() {
//                          return age;
//                      }
//                      public void setAge(int age) {
//                          this.age = age;
//                      }
//                      public void setAge(String age) {
//                          this.age = Integer.parseInt(age);
//                      }
//                      @Override
//                      public int hashCode() {
//                  	return Objects.hash(age, city, name);
//                      }
//                      @Override
//                      public boolean equals(Object obj) {
// 	                 if (this == obj)
// 	                     return true;
// 	                 if (obj == null)
// 	                     return false;
//                  	if (getClass() != obj.getClass())
// 	                     return false;
// 	                 Person other = (Person) obj;
// 	                 return age == other.age && Objects.equals(city, other.city) && Objects.equals(name, other.name);
//                      }
//                      @Override
//                      public String toString() {
// 	                        return "Person [name=" + name + ", city=" + city + ", age=" + age + "]";
//                      }
//                      @Override
//                      public int compareTo(Object other) {
//                  	Comparator<Person> comparator = buildComparator();
// 	                 return comparator.compare(this, (Person) other);
//                      }
//                      private Comparator<Person> buildComparator() {
// 	                 return Comparator
// 	                 	.comparing(Person::getName)
// 	                 	.thenComparing(Person::getAge);
//                      }
//                  }
// -----------
//                  package org.vitu.reflect;
//                  import java.lang.reflect.Constructor;
//                  import java.lang.reflect.Field;
//                  import java.lang.reflect.Method;
//                  import java.lang.reflect.Modifier;
//                  import java.util.Arrays;
//                  import org.vitu.reflect.model.Person;
//                  public class PlayWithReflection {
//                      public static void main(String... args) throws NoSuchFieldException, SecurityException, NoSuchMethodException {
// 	                    Person person = new Person("Didier", "Paris", 35);
// 	                    // Class
// 	                    Class personClass = person.getClass();
// 	                    String name = personClass.getName();
// 	                    System.out.println("Name : " + name);
// 	                    Class superClass = personClass.getSuperclass();
// 	                    System.out.println("Super Class : " + superClass);
// 	                    Class[] interfaces = personClass.getInterfaces();
//                      System.out.println("Interfaces :");
//                  	Arrays.stream(interfaces).forEach(System.out::println);
//                  	// FIelds
//                  	Field[] fields = personClass.getFields();
//                  	System.out.println("Fields :");
//                  	Arrays.stream(fields).forEach(System.out::println);
//                  	Field[] declaredFields = personClass.getDeclaredFields();
// 	                    System.out.println("Declared Fields :");
// 	                    Arrays.stream(declaredFields).forEach(System.out::println);
// 	                    for (Field declaredField : declaredFields) {
// 	                        System.out.println("   Field" + declaredField.getName());
// 	                        Class<?> fieldType = declaredField.getType();
// 	                        System.out.println("       type : " + fieldType);
// 	                        int modifiers = declaredField.getModifiers();
// 	                        System.out.println("       private : " + Modifier.isPrivate(modifiers));
// 	                        System.out.println("       static : " + Modifier.isStatic(modifiers));
// 	                        System.out.println("       final : " + Modifier.isFinal(modifiers));
// 	                        System.out.println("       private : " + Modifier.isPrivate(modifiers));
// 	                    }
// 	                    // Methods
// 	                    Method[] methods = personClass.getMethods();
//                     	System.out.println("Methods :");
// 	                    Arrays.stream(methods).forEach(System.out::println);
//                     	Method[] declaredMethods = personClass.getDeclaredMethods();
//                     	System.out.println("Declared methods :");
//                     	Arrays.stream(declaredMethods).forEach(System.out::println);
//                     	// Constructors
//                     	Constructor[] constructors = personClass.getConstructors();
// 	                    System.out.println("\nConstructors :");
// 	                    Arrays.stream(constructors).forEach(System.out::println);
//                     	Constructor[] declaredConstructors = personClass.getDeclaredConstructors();
//                     	System.out.println("\nDeclared constructors :");
//                     	Arrays.stream(declaredConstructors).forEach(System.out::println);
//                     	// Field by name
// 	                    Field nameDeclaredField = personClass.getDeclaredField("name");
//                     	System.out.println("\nName field : " + nameDeclaredField);
//                     	// Method by name
//                     	Method nameDeclaredMethod = personClass.getDeclaredMethod("getName");
//                     	System.out.println("\nMethod getName : " + nameDeclaredMethod);
//                     	Method ageDeclaredMethod = personClass.getDeclaredMethod("setAge", int.class);
// 	                    System.out.println("\nMethod setAge with int : " + ageDeclaredMethod);
//                     	Method ageDeclaredStringMethod = personClass.getDeclaredMethod("setAge", String.class);
// 	                    System.out.println("\nMethod setAge with String : " + ageDeclaredStringMethod);
//                     	// Constructors by name
//                     	Constructor emptyConstructor = personClass.getConstructor();
//                     	System.out.println("\nEmpty constructor" + emptyConstructor);
//                     	Constructor constructor = personClass.getConstructor();
//                     	System.out.println("\nEmpty constructor" + constructor);
//                      }
//                  }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// LiveCoding : API Reflection par la pratique 2/2 ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Dans un premier temps, nous allons manipuler le contenu des objets, et créer des instances d'objets à partir du nom de la classe.
//      Précédemment, nous avons vu quel type d'information nous pouvons récupérer à partir d'un objet de type 'Class'.
//      - Nous allons commencer par créer une nouvelle classe 'GettingClassReference'.
//          - Pour débuter, nous allons aller chercher une référence de classe, sans passer par une instance ou par son nom directement.
//              Nous avons vu deux méthodes pour le faire précédemment :
//                  --> Soit créer une instance de Person, puis appeler la méthode 'getClass()' sur cette instance.
//                  --> Soit appeler directement la classe avec 'Person.class'.
//              Il y a aussi une troisième méthode pour ce faire. Nous pouvons appeler la méthode 'forName()' sur l'objet 'Class' en lui passant le chemin complet de la classe :
//                  --> 'Class.forName("org.vitu.reflect.model.Person");'
//              Etant donné que nous essayons de récupérer une instance de 'Class', donc une instance d'Object, il jette une 'ClassNotFoundException', au cas où le chemin spécifié n'existe pas.
//                  --> Cette partie est la chose qui est probablement la plus utile, lorsque nous faisons de la réflexion.
//                  --> A partir d'un nom de classe (via un fichier de propriétés ou un fichier XML), nous pouvons récupérer une instance de cette classe.
//          - Dans la JVM, il y a un pattern qui est utilisé, le pattern 'Class Singleton'.
//              Attention à ne pas confondre avec le pattern 'Singleton' impliquant qu'il ne peut y avoir qu'une seule instance de la classe implémentant ce pattern dans la JVM.
//                  --> Le pattern 'Class Singleton', dit que si deux instances d'une classe donnée implémentant ce pattern correspondent au même objet physique, ces deux instances doivent être égales.
//              Si la classe Person l'implémentait, nous ne pourrions pas avoir deux instances de Person différentes qui seraient égales au sens de la méthode 'equals()'.
//                  --> Il se trouve que la classe 'Class' implémente ce pattern.
//              Comparons les trois instances entre elles-même avec la méthode 'equals()', puis avec '==' (chose qu'il ne faut jamais faire, on ne compare jamais des références de cette manière).
//                  --> Nous aurons pour résultat dans les deux cas une égalité.
//                  --> Dans le premier cas, nous comparions les classes elles-mêmes, et dans le second, nous comparions en fait les objets.
//                          --> Donc l'espace mémoire alloué a ces deux objets est le même.
//                          --> Donc le pointeur personClassV1 pointe vers la même zone mémoire, donc la même adresse que le pointeur personClassV2.
//              Donc, dans la mémoire de notre application, nous n'avons qu'une seule instance de la classe 'Class' qui représente la classe 'Person', et nous ne pouvons pas en avoir une deuxième.
//                  --> Quelque soit la manière dont nous récupérons un pointeur vers cette instance, ce pointeur sera toujours le même.
//      - Maintenant, nous allons créer une nouvelle classe 'InstantiatingClasses'.
//          - Premièrement, nous allons récupérer une instance de la classe Person, comme nous l'avons fait précédemment.
//              Maintenant, nous allons créer une instance de 'Person', grâce à cela. Pour cela nous avons deux patterns :
//                  --> Nous pouvons utiliser la méthode 'newInstance()' sur notre objet de type 'Class', si nous l'imprimons, cela nous donne : 'Person = Person [name=null, city=null, age=0]'.
//                          Tous les champs sont initialisés à 'null' ou '0' puisque nous ne lui avons pas fourni de paramètres.
//                          Ceci explique par le fait que la méthode 'newInstance()' appelle le constructeur vide de la classe.
//                          Si nous n'avons pas de constructeur dans la classe, le constructeur vide sera automatiquement créé par la JVM, comme nous l'avons vu précédemment.
//                          Si nous n'avons qu'un constructeur prenant des paramètres sans constructeur vide, le constructeur vide ne sera pas créé par la JVM et une InstanciationException sera jetée.
//                              --> Cette méthode est dépréciée depuis Java 9, pour des raisons de sécurité, donc nous ne devons plus utiliser cette méthode.
//                  --> La seconde méthode sera de passer par le constructeur vide, à l'aide de la méthode 'getConstructor()' auquel nous ne passons pas de types de paramètres, vue précédemment.
//                          Pour ce faire, nous apellons une autre méthode 'newInstance()' sur l'objet de type 'Constructor', retourné par la méthode 'getConstructor()' sur notre objet de type 'Class'.
//              Ces deux pattern, vont toutefois supposer que nous avons un constructeur vide, c'est donc pour cela que dans la définition des Java Bean, il est imposé d'avoir un constructeur vide.
//                  --> Ainsi, ces beans pourront être instancié juste avec une chaîne de caractères.
//          - Dans un second temps, maintenant que nous avons notre instance de classe, il va nous falloir peupler ses champs. Nous avons deux solutions pour le faire :
//                  --> Tout d'abord, nous pouvons passer par les champs, en récupérant un champs de notre objet de type 'Class', et en lui passant la méthode 'getDeclaredField("city")' par exemple.
//                          Par la suite, nous n'avons plus qu'à appeler la méthode 'set()' sur cet objet de type 'Field' retourné, en lui passant la chaîne de caractère souhaité.
//                          Toutefois, nous abons une 'IllegalAccessException' qui est jetée car le champs est 'private'. Si nous le passons à 'public', aucune exception n'est jetée.
//                          Pour le faire quand même, nous avons une 'porte dérobée', en passant la méthode 'setAccessible(true)' à notre objet de type 'Field', avant d'appeler la méthode 'set("...")'.
//                          --> Ceci nous permet de modifier la valeur d'un champs privé, de l'extérieur de la classe, en modifiant le 'Runtime Java'.
//                          --> Aussi, le champs "name" peut aussi être modifié, alors que nous l'avons déclaré comme 'private', mais aussi comme 'final'.
//                  --> Aussi, nous pouvons utiliser les méthodes 'set()' et 'get()' sur chacun des objets de type 'Field' de notre objet de type 'Class' pour jouer avec ses valeurs de champs.
//          - De plus, nous pouvons effectuer le même type d'opérations sur les méthodes de notre objet de type 'Class'.
//              Si nous créons une chaîne de caractères 'nameProperty' ayant pour valeur 'name'.
//              En Java, le champs d'un bean signifie qu'il a un getter, et un setter si le champs est modifiable, donc pas 'final'.
//              Nous pouvons récupérer la valeur d'un champs d'un objet de type 'Person', non pas à l'aide de champs, mais à l'aide de son getter.
//              Pour ce faire, il nous suffit de construire une chaîne de caractères 'getName', puis de l'insérer dans un objet de type 'Method' à l'aide de la méthode 'getDeclaredMethod(getName)'.
//              Enfin, nous pouvons appeler la méthode 'invoke()' sur cet objet de type Method, en lui passant l'objet de type 'Person' souhaité en paramètre.
//                  --> De cette manière, nous pouvons récupérer la valeur du champs de l'objet de type 'Person' en passant par une méthode de cet objet.
//  - Maintenant, nous allons créer un bean dans un fichier 'people.txt', et nous allons y mettre les types et valeurs de ses champs, ainsi que sa classe.
//      Comment allons-nous nous y prendre pour pouvoir lire ce fichier et en déduire un objet de type 'Person'.
//      - Nous commençons par créer une nouvelle classe 'ReadPaul', dans laquelle nous construisons un BufferedReader à l'aide du Path de notre fichier, pour le lire ligne par ligne.
//          Un 'BufferedReader' va retourner 'null' lorsqu'il atteints EOF, donc nous pouvons créer notre traitement à partir d'une boucle while, prenant pour condition que la ligne retourne null.
//      - Au vu du format du fichier .txt que nous avons en entrée, nous créons 4 HashMap pour y stocker les données lues au fûr et à mesure.
//          Par la suite, il nous faut traiter ligne par ligne pour ranger les données à mesure qu'elles arrivent.
//      - Dans un dernier temps, il nous faudra boucler sur chaque HashMap, puis traiter les données qu'elles contiennent.
//          Pour ce faire, nous pouvons utiliser comme technique celle de remplir les champs en appelant les méthodes setter, en construisant les setter, comme nous l'avons fait précédemment.
//      - Si nous rajoutons un autre champs 'retired' dans notre bean, et que nous complétons notre fichier d'entrée, nous pouvons adapter notre code de lecture en conséquences.
//          Dès l'instant que nous avons des types primitifs lorsque nous faisons de la réflection, nous devons les gérer spécifiquement à la main.
//      Voila comment nous pouvons, par réflection, générer automatiquement des beans, à partir d'information en lecture, qui sont uniquement constituées par des chaînes de caractères.
// -----------
//                  package org.vitu.reflect.model;
//                  import java.io.Serializable;
//                  import java.util.Comparator;
//                  import java.util.Objects;
//                  public class Person implements Serializable, Comparable {
//                      private static final long serialVersionUID = 1L;
//                      private String name;
//                      private String city;
//                      private int age;
//                      private boolean retired;
//                      public Person() {
// 	                        name = null;
//                      }
//                      public Person(String name, String city, int age, boolean retired) {
// 	                        this.name = name;
// 	                        this.city = city;
// 	                        this.age = age;
// 	                        this.retired = retired;
//                      }
//                      public boolean isRetired() {
//                          return retired;
//                      }
//                      public void setRetired(boolean retired) {
//                          this.retired = retired;
//                      }
//                      public String getName() {
//                          return name;
//                      }
//                      public void setName(String name) {
//                          this.name = name;
//                      }
//                      public String getCity() {
//                          return city;
//                      }
//                      public void setCity(String city) {
//                          this.city = city;
//                      }
//                      public int getAge() {
//                          return age;
//                      }
//                      public void setAge(int age) {
//                          this.age = age;
//                      }
//                      public void setAge(String age) {
//                          this.age = Integer.parseInt(age);
//                      }
//                      @Override
//                      public int hashCode() {
// 	                        return Objects.hash(age, city, name, retired);
//                      }
//                      @Override
//                      public boolean equals(Object obj) {
// 	                        if (this == obj) return true;
// 	                        if (obj == null) return false;
// 	                        if (getClass() != obj.getClass()) return false;
// 	                        Person other = (Person) obj;
//                          return age == other.age && Objects.equals(city, other.city) && Objects.equals(name, other.name) && retired == other.retired;
//                      }
//                      @Override
//                      public String toString() {
// 	                        return "Person [name=" + name + ", city=" + city + ", age=" + age + ", retired=" + retired + "]";
//                      }
//                      @Override
//                      public int compareTo(Object other) {
// 	                        Comparator<Person> comparator = buildComparator();
// 	                        return comparator.compare(this, (Person) other);
//                      }
//                      private Comparator<Person> buildComparator() {
// 	                        return Comparator
// 		                        .comparing(Person::getName)
// 		                        .thenComparing(Person::getAge);
//                      }
//                  }
// -----------
//                  package org.vitu.reflect;
//                  import java.lang.reflect.Constructor;
//                  import java.lang.reflect.Field;
//                  import java.lang.reflect.Method;
//                  import java.lang.reflect.Modifier;
//                  import java.util.Arrays;
//                  import org.vitu.reflect.model.Person;
//                  public class PlayWithReflection {
//                      public static void main(String... args) throws NoSuchFieldException, SecurityException, NoSuchMethodException {
// 	                        Person person = new Person("Didier", "Paris", 35, false);
// 	                        // Class
// 	                        Class personClass = person.getClass();
// 	                        String name = personClass.getName();
// 	                        System.out.println("Name : " + name);
// 	                        Class superClass = personClass.getSuperclass();
// 	                        System.out.println("Super Class : " + superClass);
// 	                        Class[] interfaces = personClass.getInterfaces();
// 	                        System.out.println("Interfaces :");
// 	                        Arrays.stream(interfaces).forEach(System.out::println);
// 	                        // FIelds
// 	                        Field[] fields = personClass.getFields();
// 	                        System.out.println("Fields :");
// 	                        Arrays.stream(fields).forEach(System.out::println);
// 	                        Field[] declaredFields = personClass.getDeclaredFields();
// 	                        System.out.println("Declared Fields :");
// 	                        Arrays.stream(declaredFields).forEach(System.out::println);
// 	                        for (Field declaredField : declaredFields) {
// 	                            System.out.println("   Field" + declaredField.getName());
// 	                            Class<?> fieldType = declaredField.getType();
// 	                            System.out.println("       type : " + fieldType);
// 	                            int modifiers = declaredField.getModifiers();
// 	                            System.out.println("       private : " + Modifier.isPrivate(modifiers));
// 	                            System.out.println("       static : " + Modifier.isStatic(modifiers));
// 	                            System.out.println("       final : " + Modifier.isFinal(modifiers));
// 	                            System.out.println("       private : " + Modifier.isPrivate(modifiers));
//                          }
// 	                        // Methods
// 	                        Method[] methods = personClass.getMethods();
// 	                        System.out.println("Methods :");
// 	                        Arrays.stream(methods).forEach(System.out::println);
// 	                        Method[] declaredMethods = personClass.getDeclaredMethods();
// 	                        System.out.println("Declared methods :");
//                      	Arrays.stream(declaredMethods).forEach(System.out::println);
// 	                        // Constructors
// 	                        Constructor[] constructors = personClass.getConstructors();
// 	                        System.out.println("\nConstructors :");
// 	                        Arrays.stream(constructors).forEach(System.out::println);
// 	                        Constructor[] declaredConstructors = personClass.getDeclaredConstructors();
// 	                        System.out.println("\nDeclared constructors :");
// 	                        Arrays.stream(declaredConstructors).forEach(System.out::println);
// 	                        // Field by name
// 	                        Field nameDeclaredField = personClass.getDeclaredField("name");
// 	                        System.out.println("\nName field : " + nameDeclaredField);
// 	                        // Method by name
// 	                        Method nameDeclaredMethod = personClass.getDeclaredMethod("getName");
// 	                        System.out.println("\nMethod getName : " + nameDeclaredMethod);
// 	                        Method ageDeclaredMethod = personClass.getDeclaredMethod("setAge", int.class);
// 	                        System.out.println("\nMethod setAge with int : " + ageDeclaredMethod);
// 	                        Method ageDeclaredStringMethod = personClass.getDeclaredMethod("setAge", String.class);
// 	                        System.out.println("\nMethod setAge with String : " + ageDeclaredStringMethod);
// 	                        // Constructors by name
// 	                        Constructor emptyConstructor = personClass.getConstructor();
// 	                        System.out.println("\nEmpty constructor" + emptyConstructor);
// 	                        Constructor constructor = personClass.getConstructor();
// 	                        System.out.println("\nEmpty constructor" + constructor);
//                      }
//                  }
// -----------
//                  package org.vitu.reflect;
//                  import java.lang.reflect.Field;
//                  import java.lang.reflect.InvocationTargetException;
//                  import java.lang.reflect.Method;
//                  import java.lang.reflect.Modifier;
//                  import org.vitu.reflect.model.Person;
//                  public class InstantiatingClasses {
//                      public static void main(String[] args)
// 	                    throws ClassNotFoundException,
// 	    	                    InstantiationException,
// 	    	                    IllegalAccessException,
// 	    	                    NoSuchMethodException,
// 	    	                    SecurityException,
// 	    	                    IllegalArgumentException,
// 	    	                    InvocationTargetException,
// 	    	                    NoSuchFieldException {
// 	                        String className = "org.vitu.reflect.model.Person";
// 	                        Class<?> personClass = Class.forName(className);
// 	                        System.out.println("\nClass : " + personClass);
// 	                        // Instantiation
// 	                        Person p1 = (Person) personClass.newInstance();
// 	                        System.out.println("Person = " + p1);
// 	                        Person p2 = (Person) personClass.getConstructor().newInstance();
// 	                        System.out.println("Person = " + p2);
// 	                        // Field
// 	                        Field cityField = personClass.getDeclaredField("city");
// 	                        System.out.println("    field city : " + cityField);
// 	                        cityField.setAccessible(true);
// 	                        int modifiers = cityField.getModifiers();
// 	                        boolean isPrivate = Modifier.isPrivate(modifiers);
// 	                        System.out.println("Field city is private ? " + isPrivate);
// 	                        cityField.set(p1, "Lyon");
// 	                        cityField.set(p2, "Paris");
// 	                        System.out.println("P1 = " + p1);
// 	                        System.out.println("P2 = " + p2);
// 	                        Field nameField = personClass.getDeclaredField("name");
// 	                        nameField.setAccessible(true);
// 	                        nameField.set(p1, "Olivier");
// 	                        nameField.set(p2, "Zinedine");
// 	                        System.out.println("P1 = " + p1);
// 	                        System.out.println("P2 = " + p2);
// 	                        Field ageField = personClass.getDeclaredField("age");
// 	                        ageField.setAccessible(true);
// 	                        ageField.set(p1, 28);
// 	                        ageField.set(p2, 54);
// 	                        System.out.println("P1 = " + p1);
// 	                        System.out.println("P2 = " + p2);
// 	                        Person p3 = new Person("Paul", "Manchester", 27, false);
// 	                        String name = (String) nameField.get(p3);
// 	                        String city = (String) cityField.get(p3);
// 	                        int age = (int) ageField.get(p3);
// 	                        System.out.println("Name : " + name);
// 	                        System.out.println("City : " + city);
// 	                        System.out.println("Age : " + age);
// 	                        // Method
// 	                        String nameProperty = "name";
// 	                        String getterName = buildGetterName(nameProperty);
// 	                        System.out.println("Getter name : " + getterName);
// 	                        Method getter = personClass.getDeclaredMethod(getterName);
// 	                        System.out.println("Get name de P1 : " + getter.invoke(p1));
// 	                        System.out.println("Get name de P2 : " + getter.invoke(p2));
// 	                        System.out.println("Get name de P3 : " + getter.invoke(p3));
// 	                        String setterName = buildSetterName("city");
// 	                        Method setter = personClass.getDeclaredMethod(setterName, String.class);
// 	                        setter.invoke(p1, "Nantes");
// 	                        setter.invoke(p2, "Lille");
// 	                        setter.invoke(p3, "Bordeaux");
// 	                        System.out.println("P1 : " + p1);
// 	                        System.out.println("P2 : " + p2);
// 	                        System.out.println("P3 : " + p3);
//                      }
//                      private static String buildGetterName(String nameProperty) {
// 	                        return "get" + nameProperty.substring(0, 1).toUpperCase() + nameProperty.substring(1);
//                      }
//                      private static String buildSetterName(String nameProperty) {
// 	                        return "set" + nameProperty.substring(0, 1).toUpperCase() + nameProperty.substring(1);
//                      }
//                  }
// -----------
//                  package org.vitu.reflect;
//                  import java.io.BufferedReader;
//                  import java.io.IOException;
//                  import java.lang.reflect.InvocationTargetException;
//                  import java.lang.reflect.Method;
//                  import java.nio.file.Files;
//                  import java.nio.file.Path;
//                  import java.util.ArrayList;
//                  import java.util.HashMap;
//                  import java.util.HashSet;
//                  import java.util.List;
//                  import java.util.Map;
//                  import java.util.Set;
//                  public class ReadPaul {
//                      public static void main(String[] args)
// 	                        throws InstantiationException,
// 	    	                    IllegalAccessException,
// 	    	                    IllegalArgumentException,
// 	    	                    InvocationTargetException,
// 	    	                    NoSuchMethodException,
// 	    	                    ClassNotFoundException {
// 	                        Path path = Path.of("files/people.txt");
// 	                        Map<String, String> beanTypes = new HashMap<>();
// 	                        Map<String, Set<String>> properties = new HashMap<>();
// 	                        Map<String, String> propertyTypes = new HashMap<>();
// 	                        Map<String, String> propertyValues = new HashMap<>();
// 	                        try (BufferedReader reader = Files.newBufferedReader(path);) {
// 	                            String line = reader.readLine();
// 	                            while (line != null) {
// 		                            if (line.startsWith("#")) {
// 		                                line = reader.readLine();
// 		                                continue;
// 		                            }
// 		                            String[] keyValuePairs = line.split("=");
// 		                            String key = keyValuePairs[0];
// 		                            String value = keyValuePairs[1];
// 		                            String[] keyElements = key.split("\\.");
// 		                            String bean = keyElements[0];
// 		                            if (keyElements[1].equals("class")) {
// 		                                String beanClass = value;
// 		                                beanTypes.put(bean, beanClass);
// 		                            } else {
// 		                                String property = keyElements[1];
// 		                                properties.computeIfAbsent(bean, k -> new HashSet<>()).add(property);
// 		                                if (keyElements.length == 3) {
// 			                                String propertyType = value;
// 			                                propertyTypes.put(bean + "." + property, propertyType);
// 		                                } else {
// 			                                String propertyValue = value;
// 			                                propertyValues.put(bean + "." + property, propertyValue);
// 		                                }
// 		                            }
// 		                            line = reader.readLine();
// 	                            }
// 	                        } catch (IOException e) {
// 	                            e.printStackTrace();
// 	                        }
// 	                        System.out.println("\nBean types :");
// 	                        beanTypes.forEach((key, value) -> System.out.println("    " + key + " -> " + value));
// 	                        System.out.println("\nProperties :");
// 	                        properties.forEach((key, value) -> System.out.println("    " + key + " -> " + value));
// 	                        System.out.println("\nProperty types :");
// 	                        propertyTypes.forEach((key, value) -> System.out.println("    " + key + " -> " + value));
//                      	System.out.println("\nProperty values :");
// 	                        propertyValues.forEach((key, value) -> System.out.println("    " + key + " -> " + value));
// 	                        List<Object> readObjects = new ArrayList<>();
// 	                        for (Map.Entry<String, String> typeForBean : beanTypes.entrySet()) {
// 	                            String bean = typeForBean.getKey();
// 	                            String beanType = typeForBean.getValue();
// 	                            Class<?> beanClass = Class.forName(beanType);
// 	                            Object o = beanClass.getConstructor().newInstance();
// 	                            for (String property : properties.get(bean)) {
// 		                            String type = propertyTypes.get(bean + "." + property);
// 		                            if (type.equals("int")) {
// 		                                Class<?> typeClass = int.class;
// 		                                String setterName = buildSetterName(property);
// 		                                Method setter = beanClass.getDeclaredMethod(setterName, typeClass);
// 		                                String valueAsString = propertyValues.get(bean + "." + property);
// 		                                int value = Integer.parseInt(valueAsString);
// 		                                setter.invoke(o, value);
// 		                            } else if (type.equals("boolean")) {
// 		                                Class<?> typeClass = boolean.class;
// 		                                String setterName = buildSetterName(property);
// 		                                Method setter = beanClass.getDeclaredMethod(setterName, typeClass);
// 		                                String valueAsString = propertyValues.get(bean + "." + property);
// 		                                boolean value = Boolean.parseBoolean(valueAsString);
// 		                                setter.invoke(o, value);
// 		                            } else {
// 		                                Class<?> typeClass = Class.forName(type);
// 		                                String setterName = buildSetterName(property);
// 		                                Method setter = beanClass.getDeclaredMethod(setterName, typeClass);
// 		                                String value = propertyValues.get(bean + "." + property);
//     		                            setter.invoke(o, value);
//     		                        }
// 	                            }
// 	                            readObjects.add(o);
// 	                        }
// 	                        System.out.println("\nRead objects :");
// 	                        readObjects.forEach(System.out::println);
//                      }
//                      private static String buildSetterName(String nameProperty) {
// 	                        return "set" + nameProperty.substring(0, 1).toUpperCase() + nameProperty.substring(1);
//                      }
//                  }
// -----------
// - Nous allons à présent voir un dernier mécanisme avec l'API Reflection, le mécanisme 'Service-Loader'.
//      - Dans un premier temps nous créons un nouveau projet 'PlayWithServiceLoader', ainsi qu'un package 'org.vitu.loader' contenant une interface 'MessageService' et une méthode 'getMessage()'.
//          Nous pouvons lui créer une implémentation 'GreetingsMessage' dans un package 'impl', implémentant la méthode de manière à ce qu'elle retourne une simple chaîne de caractères 'Greetings'.
//          Enfin, nous pouvons créer une méthode main dans une classe Main.
//          Il existe un mécanisme, existant depuis Java 6, et toujours utilisé par de nombreuses API et framework :
//              --> C'est la capacité de la machine Java à charger des classes automatiquement au démarrage.
//      - Pour le démontrer, nous allons créer un répertoire 'META-INF', qui, pour rappel est un répertoire standard que nous trouvons dans les applications Java.
//              --> Ce dernier permet de stocker les 'Metadonnées'.
//          Nous allons créer à l'intérieur de ce dossier, un autre dossier 'services'. Nous allons y créer un nouveau fichier se nommant comme l'interface 'org.vitu.loader.MessageService'.
//          A l'intérieur de ce fichier, nous allons écrire le nom complet de la classe d'implémentation 'org.vitu.loader.impl.GreetingsService'.
//          Nous pouvons ensuite créer une seconde implémentation de notre interface, la classe 'org.vitu.loader.impl.HelloService' retournant "Hello", et l'ajouter aussi dans notre fichier.
//      - Maintenant, dans notre méthode main, nous allons chercher un objet de type 'ServiceLoader', en le construisant à partir de notre interface à implémenter.
//          Cette objet implémentant l'interface 'Iterable', ce qui en fait donc une liste, et nous permet de l'itérer directement avec une boucle for.
//          Ainsi, nous pouvons lui demander d'itérer sur chaque implémentation de MessageService, et appeler leur implémentation de la méthode 'getMessage()' de leur interface commune.
//              --> L'objet de type 'ServiceLoader<MessageService>' va chercher le dossier 'META-INF/services', et considérer tous les noms des fichiers qui le composent comme des noms d'interfaces.
//              --> Ensuite, il va interpréter toutes les lignes de ce fichier comme étant les noms des classes implémentant l'interface dont le nom est le nom de ce fichier.
//                      --> Donc le ServiceLoader va instancier ces implémentations.
//          De cette manière, après, dans notre code, nous allons pouvoir demander au ServiceLoader de charger toutes les classes d'implémentation de l'interface l'intégrant.
//          Le ServiceLoader implémentant l'interface 'Iterable', qui est la super classe de toutes les Collections.
//      - Le ServiceLoader est utilisé par exemple par JDBC pour charger les drivers JDBC pour permettre aux applications Java de se connecter à des bases de données.
// -----------
//                  package org.vitu.loader;
//                  public interface MessageService {
//                      public String getMessage();
//                  }
// -----------
//                  package org.vitu.loader.impl;
//                  import org.vitu.loader.MessageService;
//                  public class HelloMessage implements MessageService{
//                      @Override
//                      public String getMessage() {
// 	                        return "Hello";
//                      }
//                  }
// -----------
//                  package org.vitu.loader.impl;
//                  import org.vitu.loader.MessageService;
//                  public class GreetingsMessage implements MessageService{
//                      @Override
//                      public String getMessage() {
// 	                        return "Greetings !";
//                      }
//                  }
// -----------
//                  org.vitu.loader.impl.GreetingsMessage
//                  org.vitu.loader.impl.HelloMessage
// -----------
//                  package org.vitu.loader;
//                  import java.util.ServiceLoader;
//                  public class Main {
//                      public static void main(String[] args) {
// 	                        ServiceLoader<MessageService> loader = ServiceLoader.load(MessageService.class);
// 	                        for (MessageService messageService : loader) {
// 	                            System.out.println(messageService.getMessage());
// 	                        }
//                      }
//                  }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cinquième Partie :  API Java pour XML, Programmation concurrente en Java //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : API pour XML ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à XML ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction : HTML, SGML et XML //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Parlons à présent des API Java pour XML. Tout d'abord nous allons devoir définir XMl, qu'est-ce que c'est et en quoi cela consiste de lire, créer et échanger des fichiers XML ?
// Dans les années 90, au début du web, trois langages apparaîssent : HTML, SGML & XML. Le premier est le plus utilisé, le troisième viendrait en second, et SGML est un peu plus confidentiel.
// Le HTML sert, au tout début du web, à décrire des pages qui vont être prises en compte par des navigateurs, puis affichées sur des écrans.
// --> Le HTML encode deux types d'informations :
//      - Des données.
//      - La mise en forme de ses données.
// C'est un peu ce qui lui est reproché, car en HTML nous avons un mélange de données brutes, et de la décoration qui va permettre d'afficher ces données dans un navigateur.
// Avec XML nous voulons différentier ces deux parties là, en ne se concentrant que sur les données, et en confiant la mise en forme de ces données à d'autres éléments, par exemple des fichiers CSS.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// XML, standard géré par le W3C /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Techniquement, nous pouvons dire que le XML est un langage de balises.
// Effectivement, 'ML', dans HTML, SGML et XML veut dire Markup Language, donc langage de balises.
// Ce sont ces balises qui vont donner un sens au contenu textuel d'un document XML.
// Nous pouvons aussi dire que c'est un standard, dont l'écriture est confiée à un organisme qui s'appelle le W3C : World Wide Web Consortium.
// Le W3C s'occuppe donc de : HTML, CSS, XML & XSL, ainsi que d'autres choses encore.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// XML, utilisé pour les échanges de données et la configuration /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A quoi le CML sert-il aujourd'hui ? Nous avons déjà vu qu'il sert à décrire des données, leurs valeurs, leurs nature etc.
// Ainsi, c'est un langage dont nous allons nous servir pour faire du transfert de données.
// Pendant très longtemps, environ entre le début des années 2000 et le milieu des années 2010, le XML est utilisé pour transférer des données entres :
// --> Services Web (WS).
// --> Services REST (RS).
// --> Configuration des applications.
// Il se trouve qu'aujourd'hui, le XML est remplacé dans ces deux domaines, et notamment dans les services REST, par un autre langage, qui est une forme de JavaScript : le JSON.
// Donc dans des services Web, ou REST, legacy, nous pouvons encore trouvé du XML, alors que dans ceux relativement récents, nous trouverons plutôt du JSON.
// Il reste un domaine, dans lequel le XML est toujours très utilisé, c'est le domaine de la configuration des applications.
// En effet, lorsque nous écrivons des applications Java EE ou Jakarta EE pour le futur, nous avons besoin d'indiquer un certain nombre de données de configuration pour l'application.
// Ces données se trouvent ainsi dans des fichiers de configuration, ceux-ci sont très majoritairement écrits en XML, bien que parfois remplacé marginalement par JSON, et majoritairement par YAML.
// Le YAML étant une version simplifiée de XML, et qui est assez dfférente, et qui est utilisé pour la configuration de certains systèmes.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Xerces, Xalan, DOM4J, JDOM ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il y a deux choses à comprendre en XML :
// --> C'est un standard, dont l'écriture est gérée par le W3C, et est complètement indépendante des autres langages informatiques (Java, C#, JavaScript...).
// --> C'est un langage qui va servir à transporter des données, et qui du fait de cette indépendance va permettre de transmettre ces données.
// Et ce, d'une application ou d'un serveur programmé dans un certain langage, vers une application ou un serveur programmé dans un tout autre langage.
// C'est donc la force de ce standard XML, que d'être ce que nous appelons 'agnostique', c'est à dire, non-dépendant des langages qui existent.
// En Java, nous avons besoin de code pour pouvoir lire, écrire, créer, analyser et requêter du XML. Nous parlons ainsi d'API XML pour Java.
// Les autres langages, ont leurs API pour XML, propre à leurs langages respectifs et qui ont leurs spécificités.
// En Java, la première API à laquelle nous pouvons penser est :
// --> Xerces / Xalan : qui est développée par la fondation Apache, et réadossée à une autre API qui s'appelle Xalan. Ces deux API sont accessibles directement dans le JDK.
// Donc, dès l'instant où nous travaillons avec un JDK, nous n'avons pas besoin d'importer des packages, ou des API tierces via Maven ou autre pour pouvoir utiliser Xerces ou Xalan.
// Ceci est vrai jusqu'au JDK V11. A partir de ce moment-là, Xerces et Xalan ne sont plus présents. Ces deux API ont été retirées du JDK.
// Xerces et Xalan ont l'avantage d'être parfaitement compatibles avec la norme W3C, et constituent même dans l'univers Java, une implémentation référence.
// L'inconvéniant est qu'elles sont assez anciennes en conception, du début des années 2000, et qu'elles sont donc assez lourdes à utiliser, assez pénibles et complexes, et peu intuitives.
// Nous avons d'autres API tierces que nous pouvons utiliser, qui sont particulièrement plus simples et plus performantes.
// Celle que nous allons utiliser dans nos exemples, est : DOM4J.
// C'est une API Java qui est libre de droit et open source, et qui est disponible sur : http://dom4j.github.io.
// Il existe d'autres API, dont nous pouvons citer JDOM.
// Dans la mesure ou XML est un standard bien établi, et qu'il ne bouge plus beaucoup depuis au moins une dizaine d'années, ces API n'ont pas non plus nécessairement évolué depuis un moment.
// DOM4J a été mise à jour en juillet 2018, pour apporter le support de Java 8, et le support de génériques qu'elle n'avait pas dans les versions précédentes.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Un premier document XML simple, éléments, sous-éléments, attributs ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrivons à présent un premier document XML :
// <user id="15">
//     <nom>Hugo</nom>
//     <age>29</age>
//     Texte libre
//     <!-- commentaires -->
// </user>
// --> Un document XML est composé de texte. Les balises, le contenu, tout est textuel dans un document XML. Ce qui signifie que l'encodage des caractères que nous allons utiliser va avoir son importance.
// --> Un document XML est composé de balises, et il ne possède qu'une seule et unique balise racine. Dans l'exemple précédent, nous ne pouvons pas avoir une autre paire de balises <user>.
// --> Un document XML peut être composé de sous-balises, dans l'exemple ci-dessus, les balise <nom> et <age>.
// --> L'ordre des sous-balises a son importance dans un document XML, dans l'exemple précédent, le document XML ne sera pas le même si nous inversons l'ordre des balises <nom> et <age>.
// --> Nous pouvons également avoir des commentaires dans un document XML.
// --> Nous pouvons également ajouter des attributs dans les balises, comme ici dans la balise <user id="15">, donc la balise user à pour attribut id, qui à une valeur la chaîne de caractères 15.
// Remarquons que 29 dans la balise <age> est bien une chaîne de caractères et non un entier, il faut donc le convertir par la suite.
// Remarquons aussi que nous pouvons avoir autant d'attributs que nous souhaitons dans une balise donnée. Ce tout comme nous pouvons avoir autant de sous-éléments que nous voulons dans un élement XML.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Structure d'un document XML, noeuds et branches ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Précisons à présent le vocabulaire que nous avons utilisé jusqu'à présent :
// Nous avons parlé de balises, qu'elles soient ouvrantes ou fermantes, mais généralement nous allons plutôt appeler ces paires de balises et ce qu'elles contiennent des 'éléments XML'.
// Nous avons aussi des attributs XML, qui vivent nécessairement à l'intérieur d'un élément XML.
// Les commentaires sont des parties textuelles mais qui ne portent aucune information, ils ne seront pas utilisés par les parseurs XML comme nous allons le voir par la suite.
// --> Les balises, les éléments, les attributs et les commentaires sont ce que nous appelons les noeuds d'un document XML. Cette terminologie définit tout ce que nous pouvons trouver dans un document XML.
// --> Les branches sont ce qui va mettre deux éléments d'un document XML en relation entre eux.
// Par exemple, il y a une branche entre <user> et <nom>, et elle indique que <nom> est fille de <user>.
// Ou encore, il y a une branche entre <nom> et <age>, et elle indique que <age> est frère de <nom>.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Texte de type CDATA et PCDATA /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// <user id="15">
//     <nom>Hugo</nom>
//     <age>29</age>
//     <devise>Droit <au> but</devise>
// </user>
// Ici, '<au>' va être interprétée comme une balise ouvrante, et n'ayant pas de balise fermante qui la suit, le document XML sera corrompu et donc illisible.
// Nous pouvons les insérer dans une paire de balises CDATA pour nous permettre d'éviter l'erreur précédente :
// <devise><![CDATA[ Droit <au> but]]></devise>
// Ainsi, ce qui se trouve à l'intérieur de la balise CDATA ser a lu mais non-analysé.
// En XML, nous différencions CDATA (Character Data) : données caractère brut non-analysées, donc non-parsées.
// Au contraire, les données PCDATA (Parsed Character Data) : sont les données caractères analysées, donc parsées.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définir un espace de noms dans un document XML ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernier point technique important à voir au niveau de la constitution d'un élément XML, c'est la capacité d'attacher un document XML à un espace de noms.
// A quoi peut bien servir un espace de nom ?
// Supposons que nous ayons deux systèmes, A et B, qui veulent tous les deux manipuler des objets de type user, encodés dans des documents XML qui vont s'appeler user des deux côtés.
// Ces deux systèmes A et B, d'une façon ou d'une autre, vont commencer à communiquer l'un avec l'autre et a s'échanger des user qui portent le même nom mais ne vont pas avoir les mêmes caractéristiques.
// C'est à dire qu'ils ne vont pas avoir les mêmes sous-éléments, les mêmes attributs, donc en un mot, seront différents. Comment pouvons nous nous y prendre ?
// Un analyseur XML va voir arriver deux documents qui se nomment user et qui vont avoir des caractéristiques différentes, aura besoin de les différencier, mais n'aura aucun élément pour le faire.
// L'élément que nous allons lui donner pour les différencuer est en fait d'attacher chaque document user à un espace de nom particulier, et va donner un nom à cet espace de nom.
// Ranger un document XML dans un espace de noms, c'est un peu comme ranger une classe dans un package, ou ranger un fichier dans un répertoire.
// Deux documents qui portent le même nom peuvent être différenciés dès l'instant où ils sont rangés dans deux répertoires différents.
// Donc le premier réflexe lorsque nous travaillons dans une application dans laquelle nous avons des documents XML à gérer, est de créer un espace de noms pour ranger ces documents XML.
// Ainsi nous ne serons pas embêtés à l'avenir avec des collisions de noms qui pourraient avoir lieu avec d'autres modules de la même application ou avec d'autres applications.
// Comment pouvons nous faire pour ranger notre élément XML user dans un espace de noms.
// --> Pour cela nous allons utiliser un attribut particulier qui s'appelle 'xmlns', qui signifie 'xml name space' :
// --> <user id="15" xmlns="http://t3.paris13.fr">.
// Il faut faire attention car l'espace de noms ressemble à un url, mais en fait il s'agit d'une URI.
// Le 'L' signifie 'Locator', alors que le 'I' signifie 'Identifier', donc il s'agit bien de deux objets différents.
// Donc, xmlns est un nom d'attribut standard qui est défini dans le standard xml du W3C, donc nous ne pouvons pas utiliser cet attribut pour autre chose que pour un espace de noms.
// Enfin, l'espace de noms ressemble à une url, mais il s'agit d'une uri.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Attacher un élément XML à un espace de noms ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une fois avoir créé notre espace de noms, il faut encore que nous attachons les éléments de notre document XML à cet espace de noms.
// Pour les attacher nous pouvons le faire de deux façons :
// - Soit nous utilisons les règles d'association par défaut.
// - Soit nous les attachons de manière explicite, ce qui est probablement le plus simple et le plus lisible. C'est ce que nous allons utiliser à présent.
//      <user id="15" xmlns="http://t3.paris13.fr">
//          <nom>Hugo</nom>
//          <age>29</age>
//          <devise>Droit <au> but</devise>
//      </user>
// Dès que nous avons déclaré notre espace de noms de cette façon, en fait nous ne pouvons utiliser que les règles d'associations par défaut.
// Si nous voulons attacher des éléments XML de manière explicite à cet espace de noms, il va falloir associer cet espace de nom à un préfixe, un préfixe XML.
//      <t3:user id="15" xmlns:t3="http://t3.paris13.fr">
//          <t3:nom>Hugo</t3:nom>
//          <age>29</age>
//          <devise>Droit <au> but</devise>
//      </t3:user>
// Ici nous avons attacher l'élement <nom> à l'espace de noms via le préfixe t3.
// Puisque l'espace de noms est défini dans l'élément user, il est visible par l'élément user, ainsi que tous les éléments fils de user.
// Nous aurions très bien pu mettre cet espace de noms dans la balise age, et ce dernier aurait été visible par la balise age, et tous ses éléments fils.
// Il est très fréquent de définir des espaces de noms locaux a des sous-éléments dans des documents XML de grande taille.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur la structure des documents XML //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous faisons le bilan de ce que nous avons vu sur les documents XML :
// - Nous avons parlé de la notion de document, différente de la notion de fichier, car les serveurs entre eux s'échangent des documents et non des fichiers.
// - Nous avons vu que les documents XML sont toujours composés de texte, et ce encodé en UTF-8, tous les autres encodages sont à bannir.
// - Un document XML est composé d'éléments, et ne contient qu'un unique élément racine.
// - Les éléments peuvent contenir des sous-éléments.
// - Les éléments peuvent contenir du contenu textuel PCDATA ou CDATA.
// - Les éléments peuvent avoir des attributs.
// - Les éléments peuvent être associés a des espaces de noms sous la forme d'url, associés à des préfixes qui nous servent à attacher ces éléments à ces espaces de noms.
// Remarque : nous pouvons aussi attacher des attributs à des espaces de noms même si nous n'en avons pas vu d'exemples.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// DOM4J /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'un document XML en mémoire avec DOM4J //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons créer des documents XML en mémoire, et écrire ce que nous avons écris en mémoire sur le disque, pour ça nous utilisons une API Java qui s'appelle DOM4J : fom4j.github.io.
// Le premier objet que nous devons créer est un objet de type document, il est créé avec une méthode factory 'createDocument()' sur un objet qui s'appelle DocumentHelper :
// Document doc = DocumentHelper.createDocument();
// Element root = doc.addElement("user").addAtribute("id", "15");
// Element user = root.addElement("nom").addText("Hugo");
// Element age = root.addElement("age").addText("29");
// Maintenant que nous avons ce document, comment pouvons nous faire pour l'écrire sur un fichier, ou pour l'envoyer à une autre machine sur le réseau ?

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un document XML dans un fichier avec DOM4J /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant que nous avons notre nouvel objet document, comment allons nous pouvoir l'écrire dans un fichier ?
// Dans l'API DOM4J, nous avons un objet particulier, qui s'appelle XMLWriter qui prends deux objets en paramètre, le premier de type output strean et le second de type output format :
// --> XMLWriter(out, outputFormat);
// Cet objet de type output stream, est relié à Java IO, donc nous pouvons maintenant faire :
//      Document doc = DocumentHelper.createDocument();
//      OutputStream out = new FileOutputStream(file);
//      OutputFormat outputFormat = OutputFormat.createPrettyPrint();
//      outputFormat/setEncoding("UTF-8");
//      XMLWriter w = new XMLWriter(out, outputFormat);
//      w.write(doc);
//      w.flush();
//      w.close();
// createPrettyPrint() est une méthode factory permettant de mettre les indentations sur le document XML pour en faciliter la lecture.
// Il existe une autre méthode permettant de tout imprimer sur une seule ligne, ce qui permet d'économiser des caractères lors de sa lecture par une autre machine.
// Il ne faut pas oublier de terminer par une méthode flush() puis une méthode close(), ou alors d'écrire ce code dans un bloc try-with-ressources.
// A noter que l'objet FileInputStream() a été ici ouvert sur un fichier, mais que nous aurions très bien pu l'ouvrir sur un socket en communication avec une autre machine.
// Donc en fait ce même pattern de code, permet d'écrire des fichiers XML, soit dans des fichiers, soit sur des sockets.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Modèle DOM et modèle SAX pour analyser le XML /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'approche que nous venons d'examiner consiste à créer un modèle objet en mémoire et à l'écrire dans un fichier, ou l'envoyer sur une socket.
// Nous pouvons aussi récupérer un document XML d'un fichier ou d'une socket, et recréer à partir de ce document XML un modèle objet en mémoire de façon à pouvoir analyser leur contenu.
// Document XML <--> Modèle objet <--> Mémoire.
// Cette approche est ce que nous appelons le DOM : Document Object Model.
// C'est une approche qui fonctionne bien tant que nous avons des documents XML qui ne sont "pas trop gros".
// Si nous recevons un document qui fait plusieurs Go voire plusieurs dizaines de Go, il va commencer a devenir très peu efficace en terme de CPU et en terme d'occupation de mémoire.
// Et cela de sortes à recréer un DOM complet en mémoire pour pouvoir l'analyser.
// Surtout que nous avons beaucoup de cas applicatif lorsque nous travaillons avec du XML, dans lesquels nous n'avons pas besoin de l'intégralité de l'information contenue dans le document reçu.
// Supposons que notre document XML contient la liste des salariés d'une entreprise, et que nous ne nous interressons qu'aux clients qui ont 20 ans aujourd'hui car nous voulons leur envoyer un e-mail.
// Dans ce cas là, nous allons nous interesser à un contenu du XML qui sera assez petit. Donc charger l'intégralité du contenu en mémoire va devenir très peu efficace par rapport à notre application.
// Donc le modèle DOM est adapté a certaines applications, mais très peu adapté à d'autres applications, car beaucoup trop coûteux en mémoire.
// Ainsi, à côté de cette approche DOM, nous avons une seconde approche, qui s'appelle l'approche SAX, et qui va précisémment traîter ce problème en particulier.
// Lorsque nous faisons du DOM, nous lisons l'intégralité du document XML, nous créons des éléments root, attributs... au fur et à mesure que nous lisons le document.
// La méthode readXML(), ne rends la main que lorsque l'intégralité du document et du graphe de ses objets sont créés.
// L'approche SAX consiste à dire que nous allons regarder notre document XML portion par portion.
// Un peu comme si nous avions une fenêtre d'observation qui nous permettait de scanner l'intégralité du document XML.
// Et à un moment donné, nous n'avons jamais plus que cette fenêtre qui est chargée en mémoire. Tout ce qui était avant à été oublié, et tout ce qui est après n'a pas encore été analysé.
// SAX va nous donner la possibilité d'agir en fonction de ce qui est lu, et au moment où l'analyseur SAX le lit.
// C'est à dire que nous allons pourvoir extraire de l'information de notre document XML avant qu'il soit totalement balayé, qu'il soit totalement analysé.
// Et si nous avons trouver l'information souhaitée avant qu'il soit totalement analysé, nous allons pouvoir interrompre cette analyse, avant la fin, ce qui sera beaucoup plus efficace.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// SAX ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fontionnement de SAX, premiers événements et callbacks ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Examinons sur un exemple la façon dont SAX fonctionne :
//      <t3:user id="15" xmlns="http://paris13.fr/">
//          <t3:nom>>Hugo</t3:nom>
//          <t3:age>29</t3:nom>
//      </t3:user>
// Lorsque nous prenons un espace de noms de ce type là, nous avons tout intérêt à prendre un espace de noms qui représente un site web dont nous possédons le nom de domaine.
// C'est une convention, et si nous la respectons, nous avons la garantie d'éviter des collisions entre différents espaces de noms.
// Dans un premier temps, il faut écrire du code pour créer un analyseur SAX. Celui-ci va analyser élément par élément, ou ci-dessus ligne par ligne.
// A savoir que ligne par ligne est plutôt réservé pour des fichiers, alors qu'il arrive souvent qu'un document XML soit sous forme de flux, et non de fichier.
// SAX va en fait générer ce que nous appelons des 'évènements'. Par exemple, lorsqu'il rencontre l'évènement racine, il va générer deux évènement : 'start document' ainsi que 'start element'.
// Ces deux éléments sont des évènements que nous allons pouvoir capter en donnant du code à SAX sous forme d'un callback.
// Lorsque l'évènement 'start document' sera jeté par SAX, sera émis par SAX, notre code sera sollicité sous la forme de l'appel d'une méthode particulière.
// Si nous ne sommes pas intéressé par un évènement particulier, nous n'avons pas besoin de le capter.
// Par contre, si nous guettons un évènement particulier, par exemple l'ouverture d'un élément dont le nom est 'nom', dans ce cas là nous pouvons le capter pour réagir sur l'élément qui nous intéresse.
// Avec cette captation, SAX va nous passer des arguments relatifs à l'évènement qui vient d'arriver.
// Nous avons d'autres évènements :
// --> start document
// --> start element
// --> end element
// --> end document
// Nous disons que SAX fonctionne sur un modèle d'évènement, à la différence de DOM qui fonctionne sur un modèle d'objet.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'un analyser SAX avec l'API Xerces //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quel code va t'on écrire pour écrire un analyseur SAX qui réagit sur les évènements du document XML suivant :
//      <t3:user id="15" xmlns:t3="http://paris13.fr/">
//          <t3:nom>>Hugo</t3:nom>
//          <t3:age>29</t3:nom>
//      </t3:user>
// Nous allons pour ça utiliser une API qui se nomme Xerces, et qui est intégrée au JDK jusqu'à la version 11.
// A partir de la version 11 du JDK, Xerces est retiré du JDK, et il faut donc l'importer dans des librairies séparées via Maven par exemple.
// Xerces fonctionne de la façon suivante : dans un premier temps, il nous faut configurer une 'fabrique' de SAX parser :
// SAXParserFactory sp = SAXParserFactory.newInstance();
//      sp.setNameSpaceAware(true); --> indique que le parser qui sera créé doit prendre en compte les espaces de noms définis dans les documents XML.
//      sp.setValidating(true); --> indique au parser SAX qui'il doit vérifier si le document XML analysé est bien valide,
//                              --> au sens du XML d'une part, et également au sens d'une grammaire que nous allons pouvoir passer pour spécifier la forme du document XML.
// SAXParser parser = sp.newSAXParser(); --> L'objet parser, est celui qui est capable d'analyser un document XML, et qui au fur et à mesure de son analyse, va générer les évènements dont nous parlions.
// Comment pouvons nous faire pour analyser ce document XML ?
// --> parser.parse(inputStream, handler); : Cette méthode parse nous retourne void.
// Tout ce code peut générer des exceptions donc il doit nécessairement imbriqué dans un bloc try / catch.
// L'objet 'handler est important car c'est celui que nous allons donner à notre SAXParser.
// Tout le code précédent définit uniquement la manière dont nous souhaitons analyser notre document XML, elle dépends aussi du document XML que nous souhaitons analyser à proprement parler.
// Toutefois, la façon dont nous souhaitons l'analyser et les informations que nous recherchons dedans vont être spécifiées au travers de l'objet 'handler' passé en paramètre de notre SAXParser.
// Cet objet 'handler', étends une interface abstraite, fournie par l'API et qui s'appelle 'defaultHandler'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'un premier handler simple SAX avec l'API Xerces ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ainsi nous avons donc un objet de type Default Handler dh, cette classe est fournie par, et est donc propre à l'API Xerces.
// Nous pouvons aussi faire du SAX avec DOM4J mais dans ce cas, les classes et leurs noms sont différents.
// Il s'agit d'une classe abstraite, donc pour pouvoir l'utiliser, il faut nécessairement l'étendre.
// C'est une classe abstraite un peu particulière car toutes les méthodes qui lui sont liées, sont elles, concrètes, nous pouvons ainsi l'écrire ainsi :
// --> DefaultHandler dh = new DefaultHandler(){};
// A ce moment-là nous créons une classe anonyme qui étends DefaultHandler, qui appelle le constructeur vide '()', et dont l'implémentation est en fait l'implémentation vide '{}'.
// Ainsi nous obtenons un objet 'dh' de type exact, cette classe anonyme, et qui étends DefaultHandler. Donc nous pouvons parfaitement déclarer son type comme étant 'DefaultHandler'.
// Cet objet dh va être passé à la méthode parser que nous venons de voir, et celui-ci ne va rien faire à part analyser le document XML sans en extraire aucune information.
// L'intérêt ici va être de surcharger DefaultHandler, de surcharger ces méthodes, de façon à injecter le comportement que nous souhaitons avoir.
// Par exemple, si nous souhaitions créer un message quand l'analyseur SAX va rencontrer le début du document, nous devrions surcharger la méthode :
// DefaultHandler dh = new DefaultHandler(){
//      public void startDocument() {
//          System.out.println("Début du document");
//      }
// };
// Cet objet dh, nous pouvons le passer en paramètre de la méthode parse de notre analyseur SAX, pour analyser le document XML.
// Ainsi, a chaque fois que le début du document XML sera rencontré, nous aurons le message "Début du document" qui s'affichera sur la console.
// Attention, qui appelle cette méthode ? --> C'est l'analyseur SAX lui-même. Cette méthode est un callback, que nous donnons à l'analyseur SAX.
// Et c'est celui-ci qui va appeler les méthodes de ce callback au fur et à mesure qu'il va rencontrer les éléments de notre document XML.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un handler qui détecte l'ouverture d'un élément XML ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous souhaitons écrire un handler qui affiche un message à chaque fois qu'un élément ouvrant est rencontré dans notre document XML.
// Dans ce cas il faut que nous surchargions une autre méthode :
//      DefaultHandler dh = new DefaultHandler(){
//          public void startElement(
//              String uri, String localName,
//              String qName, Attributes attr)
//      }
// Attention : pour que cette méthode soit appelée par l'analyseur SAX, il faut que celle-ci surcharge la méthode de DefaultHandler, donc qu'elle ait exactement la même signature (mêmes paramètres).
// Il y a une astuce dans Eclipse pour savoir si une méthode en surcharge une autre, dans la marge du code Eclipse, nous avons un petit triangle vert plein qui apparaît dans la marge.
// Si ce petit triangle vert plein n'apparaît pas dans l'éditeur de classe d'Eclipse, cela signifie que la méthode que nous avons créé ne surcharge pas la méthode de DefaultHandler.
// Une seconde façon de le voir, et qui va fonctionner dans tous les IDE, est d'ajouter une annotation : @Override, juste avant la déclaration de la méthode.
// Cette annotation est une indication qui est passée au compilateur en disant, notre intention et que cette méthode surcharge une méthode de la classe de base ou d'une des superclasses.
// Si ce n'est pas le cas, le compilateur va nous donner une erreur de compilation si de son point de vue il ne voit pas de surcharge.
// Maintenant, interessons nous aux différents arguments de la méthode startElement : uri, localName, qName & attr.
// --> A l'évidence, attr modélise les attributs de l'élément que nous sommes en train d'analyser, si il y en a, si il n'y en a pas, l'objet 'attributes' sera vide.
// Quelles sont ces trois chaînes de caractères, elles sont ce qui caractérise le nom d'un élément :
// --> D'abord nous avons le nom local de l'élément, ici "user", "nom", "age"... La partie locale signifie que nous nous regardons à l'intérieur de l'espace de noms.
// --> Ensuite nous avons l'URI, celui-ci est précisémment l'espace de noms d'un élément si il en a un, auquel le localName est attaché.
// Attention, il faut aussi que nous ayons configuré notre analyseur pour prendre en compte les espaces de noms.
// --> Enfin nous avons le qName, que nous appelons aussi le Fully Qualified Name, cette fois-ci ce sera le nom local, attaché a son espace de noms, donc par exemple "t3:nom".
// Cela peut aussi être à l'occasion "http://paris13.fr/":nom.
// Donc le qName est en fait en quelques sortes le nom complet d'un élément.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un handler qui compte les éléments d'un document XML ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Exerçons-nous a écrire un handler pour le document suivant à savoir que le second sous élément c, n'a pas de sous-élément ni de contenu textuel, donc nous pouvons l'écrire en balise autofermante.
//         <a>
//             <b>
//                 <c/>
//                 <c/>
//                 <c/>
//             </b>
//             <c/>
//         </a>
// Dans un premier temps, nous souhaiterions écrire un handler qui compte les éléments de ce document --> parser.parse(doc, handler); puis int count = handler.getCount() --> 6.
// Ceci à une conséquence directe, c'est à dire que sur notre handler, nous avons besoin d'une méthode getCount().
// Précédemment nous avons écris notre handler comme étant une classe anonyme, extension directe de la classe DefaultHandler. Nous avons toujours le droit de le faire.
// Mais si nous le faisons, cela signifie que nous ne pouvons pas rajouter de méthodes sur DefaultHandler, et à l'évidence, la méthode getCount() n'est pas disponible sur notre DefaultHandler.
// Donc dans ce cas là il va falloir que nous créions une vraie classe qui soit une extension de DefaultHandler, et qui expose la méthode getCount() :
// --> CountingHandler handler = new CountingHandler; : Cette classe devra donc être une extension de DefaultHandler.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture de la classe du handler qui compte les éléments //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quelle va être la forme de cette classe ?
//      parser.parse(doc, handler);
//      int count = handler.getCount();
//      CountingHandler handler = new CountingHandler(){};
//      public class CountingHandler extends DefaultHandler {
//          private int count;
//          public void startElement(...){
//              count++;
//          }
//          public int getCount(){
//              return count;
//          }
//      }
// Ici, graçe à l'approche SAX, même pour un fichier avec un million de lignes, notre code est simple, et son occupation en mémoire aurait été la même que celle-ci, c'est à dire extrèmement faible.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un handler qui compte des sous-éléments ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous voulons à présent créer un handler qui compte les éléments <c> qui sont eux-mêmes sous-éléments de <b> (en gardant l'exemple de document XML précédent).
// Il va donc falloir que nous détectons le moment où nous sommes dans l'élément <b>, donc le moment où nous rentrons dans l'élément <b>, puis où nous sortons de l'élément <b>.
// Ainsi, il nous faut un boolean, que nous pouvons appeler inB, qui ne soit vrai que lorsque nous sommes dans l'élément <b>.
// Nous allons donc devoir écrire le code dans la méthode startElement() :
// startElement(){
//     if(name.equals("<b>")){inB = true;}
//     if(name.equals("<c>")){count C++;}
// }
// endElement(){
//     if(name.equals("<b>")){inB = false;}
// }
// Remarque : ce code est simplifié car nous n'avons pas mis tous les paramètres de startElement(){} et de endElement(){}.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan de l'utilisation de SAX pour l'analyse de documents XML /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Donc si nous faisons un petit bilan de ce que nous avons vu :
// --> L'approche SAX s'appuye sur un : un modèle d'évènements.
// --> Il faut passer une classe qui encapsule des callbacks à l'objet qui va faire des analyses à proprement parler.
// --> Elle est adapté aux grands documents XML.
// --> Elle consomme peu de mémoire et peu de CPU.
// L'approche DOM quand à elle :
// --> Consiste à créer un modèle objet du document XML en mémoire.
// --> Elle est pratique est assez intuitive, notamment pour créer des documents XML.
// --> Toutefois elle est inadaptée aux grands documents XML, car l'usage de la mémoire et de la CPU sont fonction de la taille du document que nous avons besoin de traiter.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// XML Schema et DTD /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nécessité de contrats dans l'échange de documents XML : DTD et XML Schema /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Rapidement, lorsque nous avons des serveurs qui communiquent avec d'autres serveurs, et qu'ils s'échangent des documents XML, nous constatons que ces serveurs ont également besoin de 'contrats'.
// Un petit peu comme des contrats d'interface dans une application Java. Ils ont besoin de contrats pour échanger des documents XML qui sont valides.
// Ces contrats permettent :
// - De fixer la forme des documents XML.
// - De valider ou d'invalider des documents XML.
// - Faciliter les échanges entre systèmes.
// Ainsi, les serveurs peuvent communiquer, même si ils travaillent dans des langages différents : Java, C#, JavaScript, PHP...
// Dès l'instant où nous parlons de contrat, nous avons besoin de formaliser les contrats, et par conséquent d'un langage pour écrire ces contrats.
// Des langages nous en avons deux :
// - DTD : Document Type Definition, c'est le premier et le plus ancien, permet de fixer la forme que doit avoir un document XML.
// - XML Schema : est un second format, qui permet de s'occuper de la spécification des documents XML, ce dont le DTD ne peut pas faire.
// Ces deux langages sont des standards du W3C, donc entièrement spécifiés par le W3C.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'une première DTD : éléments et attributs ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment allons nous pouvoir spécifier la forme du document XML ci-dessous :
// <user id="15">
//      <!DOCTYPE user [
//          <!ELEMENT user (nom, age)>
//          <!ELEMENT nom (#CDATA)>
//          <!ELEMENT age (#PCDATA)>
//          <!ATTLIST user id #REQUIRED>
//      ]>
//     <nom>Hugo</nom>
//     <age>29</age>
// </user>
// Voici comment c'est fait. Toutefois, nous constatons que les balises DTD sont localement situées au sein du document XML.
// Nous souhaiterions spécifier ces balises DTD dans un fichier différent qui pourra être transmis aux serveurs.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Attacher un document XML à une DTD dans un fichier séparé /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons à présent que la DTD que nous avons écris précédemment est écrite dans un fichier txt, user.dtd.
// Maintenant nous voudrions attacher ce qui se trouve dans le document XML, à la DTD qui se trouve dans ce nouveau fichier.
// Nous avons deux façons de le faire, dépendemment de l'endroit où se situe le fichier .dtd :
// --> Nous pouvons aller le chercher localement sur notre système.
// --> Mettre le fichier en accès public sur internet.
// Les parsers XML savent faire les deux, mais les déclarations seront bien évidemment différentes.
// Elles commencent toutes les deux par la même chose :
// --> <!DOCTYPE user SYSTEM "_ // univ.paris13//DTD User//FR">
// --> <!DOCTYPE user PUBLIC "http://www.paris13.fr/dtd/user.dtd">
// Les parsers SAX vont eux devoir passer une validation du document XML et du format de la DTD si ils sont 'validants', comme nous l'avons vu précédemment.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// DTD : spécification d'un élément //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons en détail ce que nous pouvons mettre ou non dans un élément :
// <!ELEMENT
//           user                       --> déjà nous pouvons mettre le nom de l'élément : 'user'.
//                  (#PCDATA)>          --> du contenu parsé.
//                  (#CDATA)>           --> du contenu non-parsé.
//                  (nom, age)>         --> le nom de ses sous-éléments.
//                  EMPTY>              --> si cet élément ne peut avoir ni de contenu textuel, ni de sous-éléments, comme par exemple : <br/>, dans les pages HTML ou XHTML.
//                  (note+)>            --> indique que nous pouvons avoir des notes, avec un '+', cela signifie que nous pouvons avoir 0 ou 1 note.
//                  (note*)>            --> indique que nous pouvons avoir autant de notes que nous le souhaitons.
//                  (nom|name|age)*>    --> indique que nous pouvons avoir un sous-élément nom, ou age, ou name, et que nous pouvons en avoir plusieurs de chaque avec le caractère '*'.
// Tout ceci nous présente comment nous pouvons spécifier la forme d'un élément dans une DTD.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// DTD : spécification d'attributs et d'entités //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment pouvons nous spécifier un attribut :
// <!ATTLIST
//              user                        --> déjà nous devons noter le nom auquel cet attribut est attaché.
//                      id                  --> ensuite nous devons spécifier le nom de l'attribut.
//                          #REQUIRED>      --> indique que la présence de l'attribut est nécessaire pour que l'élément soit valide.
//                          #IMPLIED>       --> indique que la présence de l'attribut est optionnelle, il peut être présent ou non-présent.
//                          #FIXED "12">    --> indique que la présence de l'attribut est nécessaire et que la valeur de l'attribut est nécessairement celle qui doit être passée en paramètre.
// Nous pouvons également fixer des attributs en leur donnant des valeurs fournies dans une liste :
// <!ATTLIST user lang ("FR"|"EN"|"DE" ) "FR">      --> ici la valeur de l'attribut lang peut être soit FR, soit EN, soit DE, et sa valeur par défaut est FR.
// Enfin, nous avons un dernier élément qui est très utilisé, il s'agit de l'élément 'entity', celui-ci permet de spécifier des entités dans un document XML.
// C'est à dire des éléments textuels qui vont être substitués par des blocs de caractères ou des caractères.
// Ceux-ci peuvent être non standard en UTF-8, ce qui est plutôt rare. Ils peuvent aussi être fixés pour toute une application.
// <!ENTITY oelig "oe">
// <texte> &oelig; </text>
// Ou encore :
// <!ENTITY copyright "Creative Commons">
// <text> &copyright; </text>
// Ceci nous permet de créer des constantes dans notre document XML, ce qui est assez pratique.
// Il existe des tables d'entités standard pour le XHTML pour les caractères spéciaux.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Attacher un élément XML à un XML Schema ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La seconde façon de fixer une grammaire pour un fichier XML, est d'utiliser une autre technique qui s'appelle XML Schema.
// Historiquement, le XML Schema est arrivé après le DPD, qui apporte des avantages, mais aussi beaucoup de complexité, mais qui apporte aussi beaucoup plus de précisions.
// Par exemple nous pouvons dire qu'un certain attribut doit avoir une valeur d'integer, ou alors qu'un élément XML doit avoir un contenu textuel, et que ce dernier est un entier, une date.
// Cela peut aussi être une chaîne de caractères qui possède une forme particulière. Comment pouvons nous attacher un document XML à un XML Schema ? Nous allons voir un exemple
// Cet exemple est celui d'un document XML qui permet de spécifier une application web en Java EE :
// Nous allons maintenant dire que cet espace de noms est attaché à un XML Schema particulier, en ajoutant un autre attribut XML qui est en fait un standard du W3C.
// <web-app
//      version="3.1"
//      xmlns="http://xml.jscp.ord/xml/ns/javaee"
//      xmlns:xsi="http///www.w3.org/2001/XMLSchema-instance" xsi:schemalocation=""
//      xsi:schemalocation="http://xml.jscp.ord/xml/ns/javaee http://xmlns.jep.org/ns/javaee/web-app_3_1.xsd"
// >
// Ici il faut faire extrèmement attention, le premier élément de l'attribut xsi:schemalocation, est une URI qui représente le nom d'un espace de noms.
// Le second élément de cet attribut est par contre une URL, qui va permettre de télécharger le .xsd qui contient le XML Schema de ce document XML.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un XML Schema pour un document XML simple //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment allons-nous spécifier ce qu'est un XML Schema. Le XML Schema est un document XML, avec un élément racine, des sous-éléments, et avec des attributs.
// Donc, lire un XML Schema est un peu comme lire un document XML classique, ce qui n'est pas tout à fait le cas avec une DTD.
// Le prix à payer est que pour faire des choses simples, nous avons besoin de beaucoup plus de syntaxe, nous avons besoin de spécifier beaucoup plus de choses.
//      <xsd:schema
//              xmlns:xsd="http://www.w3.org/2001/XMLSchema"            --> URI du xsd, c'est le nom de l'espace de noms auxquels sont attachés tous les éléments et sous-éléments d'un XML Schema.
//              xmlns:t3="http://t3.paris13.fr/"                        --> Nous définissons l'espace de noms dans lequel nous allons travailler, ainsi que le préfixe de cet espace de noms.
//              targetNamespace="http://t3.paris13.fr/"                 --> L'espace de noms cible de ce que nous sommes en train de spécifier. C'est un attribut standard du XML Schema.
//      >
//          <xsd:element name="user">
//              <xsd:complexType>                                       --> Puisque 'user', est composé de deux sous-éléments et d'un attribut, dans le jargon du XML Schema, il est complexe.
//                  <xsd:sequence>                                      --> Puisque nous avons une 'séquence' de deux sous-éléments.
//                      <xsd:element name="nom" type="xsd:string"/>
//                      <xsd:element name="age" type="xsd:integer"/>
//                      <xsd:attribute name="id" type="xsd:integer"/>
//                  </xsd:sequence>
//              </xsd:complexType>
//          </xsd:element>
//      </xsd:schema>

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Types disponibles pour les éléments et attributs en XML Schema ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu que dans notre attribut nous avions déclaré les choses de cette manière : <xsd:attribute name="id" type="xsd:integer"/>.
// XML Schema définit tout un tas de type que nous pouvons insérer dans ses balises :
// --> xsd:string.
// --> xsd:integer.
// --> xsd:decimal.
// --> xsd:boolean.
// --> xsd:date (nous pouvons préciser le format de celle-ci).
// --> xsd:time (nous pouvons aussi préciser le format de celle-ci).

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser les simple types pour étendre les types de bases en XML Schema ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernier point sur ces XML Schema, nous avions également spécifié un sous-élément que nous avions appelé 'age', et nous avions seulement spécifié que ce type devait être un integer.
// Toutefois, nous ne pouvons pas avoir d'âge négatif, ainsi que supérieur à disons 150. C'est quelque chose que nous pouvons spécifier dans XML Schema.
//      <xsd:element name="age">
//          <xsd:simpleType>                                --> Nous pouvons spécifier que c'est un simpleType, à contrario du complexType qui contient un ou plusieurs sous-élément ou attribut.
//              <xsd:restriction base="xsd:integer">
//                  <xsd:minInclusive value="0" />
//                  <xsd:maxInclusive value="150" />
//              </xsd:restriction>
//          </xsd:simpleType>
//      </xsd:element>

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer des types nommés en XML Schema //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que dans notre document XML, nous avons plusieurs sous-éléments âge, du moins plusieurs entiers compris entre 1 et 150.
// Nous pouvons en fait donner un nom à un simpleType, tel que celui que nous avons vu précédemment.
// Plutôt que d'englober ce type simple à l'intérieur d'un élément, nous allons le mettre au niveau 0 de notre document XML et lui donner un nom.
// Et nous allons ainsi pouvoir associer nos éléments de type 'âge', au nom de ce type.
//      <xsd:simpleType name="ageType">
//          ...
//      </xsd:simpleType>
// Ainsi, n'importe où dans notre XML Schema, nous allons pouvoir définir n'importe quel type d'élément :
//      <xsd:element name="age" type="ageType"/>

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur l'écriture de XML Schema ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Que pouvons-nous retenir sur XML Schema ?
// --> Les choses sont ecrites en "pur XML.
// --> Beaucoup plus précis que les DTD.
// --> Beaucoup plus complexe.
// --> C'est le standard qui s'impose à l'heure actuelle.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// XPath /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire des requêtes sur des documents XML avec XPath //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comme nous l'avons vu, les documents XML nous servent à stocker et à transporter des données.
// Nous avons vu comment les lire et comment les écrire avec un modèle DOM et un modèle SAX.
// Nous avons vu aussi comment les spécifier avec des grammaires en utilisant deux formats différents, DTD et XMLSchema.
// Nous avons également associé aux XML un moteur de requêtes --> XPath.
// Celui-ci permet d'aller chercher des informations directement par requête à l'intérieur du document XML.
// Comment fonctionne t'il ?
// Une requête XPath est en fait une chaîne de caractères qui suit une certaine syntaxe.
// Cellle-ci va nous permettre d'aller explorer un document XML, en fonction de son noeud racine, de ses sous-éléments et de ses attributs.
// XPath est normalisé par le W3C, de la même façon que XML, DTD, XSMSchema, SGML, CSS, HTML, XHTML et que bien d'autres.
// Nous avons trois versions de XPath : V1, V2 & V3. La version 3 étant devenue très complexe, nous allons voir quelques éléments de la version 2.
// Enfin, c'est supporté par les API Xerces et DOM4J. Nous allons ici utiliser DOM4J.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pattern d'utilisation de XPath avec Dom4J /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment peut-on requêter des documents XML avec des requêtes XPath en suivant l'API DOM4J ?
//     Document doc = ...
//     String xpath = "...";
//     List<Node> nodes = doc.selectNodes(xpath);           --> Retourne tous les noeuds correspondant à la requête XML.
//     Node node = doc.selectSingleNode(xpath);             --> Retourne un seul noeud, mais il faut être certain qu'il n'y en ai qu'un seul, sinon cela jettera une exception.
//     String value = doc.valueOf(xpath);                   --> Retourne la valeur textuelle, par exemple d'un élément ou d'un sous-élément ou d'un attribut.
// --> Mais la façon optimale de faire et de séléctionner tous les noeuds afin d'en avoir une liste pour après faire nos opérations sur celle-ci.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Sélection simples de noeuds avec XPath ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons maintenant comment nous pouvons écrire une requête XPath, c'est à dire comment on écrit la chaîne de caractères XPath, qui va être passée à l'API que nous venons de voir précédemment.
// Pour l'exemple nous allons prendre le document XML suivant :
//     <A>
//         <B>
//         </B>
//         <B>
//             <C>
//                 <D />
//             </C>
//             <D />
//         </B>
//         <C />
//         <D>
//             <C />
//         </D>
//     </A>
// Une requête XPath, donc une chaîne de caractères, commence soit par un '/', soit par '//'.
// Si elle commence par un '/', cela signifie que le reste de la requête sera un chemin absolu dans notre document XML qui commencera à partir de la racine.
// --> /A : Ici nous sélectionnons le noeud XML 'A' qui est par ailleurs le noeud racine de notre document XML.
// --> /A/B : Ici nous sélectionnons l'intégralité des noeuds 'B' qui sont enfants de 'A' qui doit être le noeud racine de notre document XML. Ici il retournera 3.
// --> /A/B/C : Ici nous sélectionnons un seul noeud.
// Nous traçons donc un chemin avec cette technique en partant de la racine.
// Si nous utilisons lr '//', nous partons de n'importe quel noeud en dehors de la racine.
// --> //B : Sélectionnera l'intégralité des noeuds 'B' de notre document, ici 2.
// --> //C : Sélectionnera l'intégralité des noeuds 'C' de notre documeent, ici 3.
// --> //C/D : Sélectionnera l'intégralité des noeuds 'D' enfants de n'importe quel noeud 'C', ici un seul.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation du caractère * dans une requête XPath /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons rajouter aux requêtes de base précédentes, des étoiles :
// --> /A/B/* : Sélectionnera l'ensemble des éléments XML enfants de 'B', enfants de 'A', qui est notre élément racine, ici, deux éléments, un 'C', et un 'D'.
// --> //B/* : Sélectionne l'ensemble des éléments enfants de n'importe quel élément 'B'.
// --> /A/*/C : Sélectionne les noeuds 'C', enfants de n'importe quels éléments eux-même enfant de 'A'.
// --> /A/*/*/D : Sélectionne les noeuds 'D', enfants de n'importe quels éléments, lui-même enfant de n'importe quels éléments, eux-même enfants de 'A'.
// --> //*/*C : Sélectionne les noeuds 'C' qui ont des parents et qui ont eux-mêmes des parents.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Requête sur la position d'un sous-élément dans une liste de sous-éléments /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous nous rappelons qu'en XML, la position des éléments dans l'arbre XML à une importance.
// --> /A/B[2] : Sélectionnera le deuxième élément 'B', enfant de 'A'.
// --> //B/*[2] : Sélectionnera le deuxième élément qui sera fils d'un élément 'B'.
// --> /A/B[last] : Sélectionnera le dernier élément 'B' de la liste, même quand nous ne connaissons pas la longueur de cette liste.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Requête sur les attributs en XPath ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons également utiliser les attributs en XPath, en utilisant '@' :
// --> //@id : Ici nous sélectionnons un attribut qui se nomme id, dans n'importe quel élément du document XML, nous sélectionnons donc ici un ou des attributs, et non un ou des éléments avec cet attribut.
// Attention : il faut bien différencier la sélection d'un élément qui possède un attribut, et la sélection de l'attribut en lui-même.
// --> //B[@id] : Sélectionnera tous les éléments 'B' de notre document XML qui possèdent l'attribut 'id', nous sélectionnons donc ici un ou des éléments, et non un ou des attributs.
// --> //C[@id='15'] : Sélectionnera tous les éléments 'C' dont l'attribut 'id' est égal à 15.
// --> A/C[@id='12'] : Sélectionnera tous les éléments 'C', enfants d'un élément 'A', et dont l'attribut 'id' est égal à 12.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définition des axes XPath dans un document XML ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le dernier point à comprendre dans les requêtes XPath, la notion d'axe / axes. C'est une relation entre deux noeuds.
// Ce n'est pas nécessairement une relation entre deux éléments, mais entre deux noeuds.
// Par exemple nous avons un axe qui se nomme 'attribut' et qui indique que tel attribut est en relation avec tel élément.
// --> ancestor : lien avec l'élément parent.
// --> descendant : donne tous les éléments enfants et enfants d'enfants etc. d'un élément.
// --> following-sibling : frères de l'élément ciblé qui suivent celui-ci dans l'ordre du document XML.
// --> preceding-sibling : frères de l'élément ciblé qui précèdent celui-ci dans l'ordre du document XML.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser les axes dans des requêtes XPath /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment pouvons-nous utiliser ces noms d'axes, qui sont définis dans la norme XPath dans une requête XPath :
// --> /A/B/descendant::* : Sélectionnera l'intégralité des descendants de 'B', lorsqu'il est fils de 'A'.
// --> /A/B/* : ne sélectionnera que les enfants directs de B.
// --> /A/B/child::* : ne sélectionnera que les enfants directs de B aussi.
// Avec cette syntaxe particulière, nous pouvons ajouter de la sémantique aux requêtes XPath que nous pouvons éxecuter sur notre document XML.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur API Java pour XML ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Faisons à présent un bilan de ce que nous avons vu dans cette partie sur XML.
// --> La notion de document XML : qui n'est pas nécéssairement un fichier, mais peut aussi juste être de l'information qui transite d'un serveur à un autre.
//      - Sa structure : composée d'un unique élément racine, et de sous-éléments, nous pouvons rattacher si nous voulons un ou plusieurs attributs sur un élément.
//          Nous pouvons aussi attacher un ou des éléments et/ou un ou des attributs à ce que nous appelons des 'espaces de noms'.
//      - Sa validité : la structure ne peut pas être n'importe comment, les sous-éléments sont imbriqués dans des éléments parents, etc.
// --> Nous avons vu deux façons de lire / créer / analyser des documents XML.
//      - DOM / SAX : l'approche DOM consiste à créer en mémoire qui reflète la structure du document XML.
//          L'approche SAX consiste à scaner un document au travers d'une fenètre, puis l'analyseur SAX génère des évènements par rapport à ce qu'il analyse.
//          Nous pouvons ensuite capter ces évènements à l'aide de callback. En Java, ces callback dans le cas de Xerces sont des instances de la classe abstraite 'DefaultHandler'.
// --> Nous avons vu la notion d'espace de noms.
// --> Nous avons vu la notion de grammaire, qui constitue un contrat entre deux serveurs qui veulent échanger des informations en XML. Nous en avons vu deux méthodes : DTD & XMLSchema.
// --> Nous avons enfin vu la notion de XPath, qui est un langage qui permet de requêter directement le contenu de documents XML.
// A savoir que nous pouvons faire à peu près la même chose en XPath que ce que nous pouvons faire en SAX.
// La différence est que le XPath repose sur des API qui peuvent avoir été grandement optimisées par rapport à ce que nous pouvons programmer nous-même en SAX.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : Programmation concurrente //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à la programmation concurrente ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La programmation concurrente consiste à programmer des applications qui font plusieurs choses en même temps.
// Il y a deux points important dans la phrase précédente :
// - Plusieurs choses.
// - En même temps.
// Qu'est ce que cela signifie pour une application et même pour un processeur, pour un CPU, de faire plusieurs choses en même temps ?
// C'est ce que nous allons commencer par examiner dans un premier exemple :
// Supposons que nous sommes en train de saisir un document texte, par exemple un fichier word sur notre machine de travail.
// En même temps que nous saisissons le texte dans le fichier word, nous avons le correcteur orthographique qui est en train de scanner le texte que nous saisissons, et qui nous propose des corrections.
// Nous pouvons aussi avoir en même temps, la sauvegarde automatique qui est effectuée en background.
// Enfin, au niveau de notre machine, nous avons aussi d'autres processus en cours, comme par exemple notre outil de boite d'e-mail qui va recevoir de temps en temps de nouveaux e-mails.
// Ces 4 processus sont donc en cours et sont effectués en même temps sur notre machine.
// Si nous regardons à présent comment les choses se déroulent au niveau de notre processeur.
// Il s'avère que ces tâches ne s'exécutent pas en même temps, mais l'une après l'autre.
// A un instant t, le CPU effectue une seule tâche à la fois.
// Ce qui nous donne l'impression que ces tâches s'effectuent en même temps est en réalité l'échelle de temps.
// En effet, si nous regardons l'échelle de temps, chaque tâche s'effectue en quelques centaines de milli-secondes.
// Donc par conséquent en réalité, rien n'est concurrent, rien n'est exécuté en même temps. C'est la rapidité du temps accordé à chaque tâche qui donne cette impression à l'utilisateur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Exécutions de plusieurs tâches en même temps sur un CPU ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment est-ce que toutes ces choses se déroulent ? En fait au niveau du modèle, nous avons deux notions importantes :
// --> Tâche.
// --> Thread (fil d'exécution).
// Un thread est une ressource qui est gérée par le système d'exploitation et qui peut prendre en charge des tâches.
// Une tâche dans le modèle de la programmation sera un objet, mais dans notre exemple ce sera par exemple : 'activer le correcteur automatique', 'sauvegarder le document'...
// Comment est-ce que le système d'exploitation va décider que ce sera plutôt la tâche 'activer le correcteur automatique', que 'sauvegarder le document' qui va avoir la priorité sur le CPU ?
// Pour cela, il va utiliser un mécanisme qui se nomme le 'Thread Scheduler', qui agit un peu comme un chef d'orchestre et qui va répartir les tâches sur les différentes tranches horaires.
// Ainsi, c'est la mission du Thread Scheduler que de diviser, que de répartir la ressource en CPU entre les différentes tâches a exécuter.
// Qu'est ce qui va faire dire au Thread Scheduler 'j'ai donné assez de temps à une tâche, maintenant je vais allouer de la CPU à une autre tâche' ? Il y a plusieurs raisons :
// --> L'équilibrage entre les tâches.
// --> La tâche en question est en attente, c'est à dire qu'elle est en attente de données.
// Ces données peuvent soit provenir du réseau, soit provenir du disque (et aussi parfois de la mémoire), car ce sont des ressources lentes.
// --> La synchronisation.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Interface Runnable et classe Thread ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous venons de voir que la programmation concurrente s'appuye sur deux notions, la notion de tâche, et la notion de thread.
// Nous pouvons considérer une application Java comme un tâche en elle-même, et celle-ci est exécutée dans un thread particulier, par la JVM.
// --> Donc notre méthode main elle-même qui est une tâche est exécutée dans un thread qui s'appelle par ailleurs le 'thread main'.
// --> La notion de tâche en Java est modélisée par une interface (en fait plusieurs interface).
// --> Cette interface est l'interface 'Runnable' qui à une unique classe abstraite void run() ne prenant pas de paramètres, c'est donc une interface fonctionnelle (lambda expression).
// Donc à partir de Java 8 nous pouvons implémenter Runnable à l'aide de Lambda Expressions.
// --> La notion de thread elle, est modélisée par la classe 'Thread', qui va nous permettre de créer de nouveaux threads, de confier des tâches de type Runnable à ces threads, ainsi que de les exécuter.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lancer une première tâche dans un nouveau thread //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons écrire l'interface Runnable ainsi qu'une première de ses implémentations :
//      public interface Runnable{
//          void run();
//      }
//      Runnable task = () -> System.out.println("Hello World!");
// --> Ici nous avons simplement déclaré une tâche qui écrit sur la console 'Hello World!'.
//      task.run();     : ici nous lançons notre task.
// Toutefois nous n'avons pas instancié d'objet thread, donc notre task va être instancié dans ce que nous appelons le thread courant.
// Donc cette task ne s'exécute pas dans un thread séparé du thread 'main'.
//      Thread t = new Thread(task);
// --> Ainsi, ce thread t, va être capable d'exécuter cette tâche. Maintenant, comment l'exécuter ? Pour cela, nous devons démarrer le thread.
//      t.start();
// --> La méthode start va exécuter la méthode run de la tâche que nous passons en paramètre du thread concerné, mais dans un thread différent du thread main.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Exécution d'un thread, notion de thread daemon ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'avons-nous fait dans l'exemple précédent ?
// Nous avons un thread, le thread 'main' qui exécute la méthode 'public static void main' qui est la méthode de notre application.
// A l'intérieur nous avons créer notre tâche 'task' de type 'Runnable', puis nous avons créé un autre objet qui était notre thread 't'.
// Cet autre thread, à créé en fait un thread différent du thread 'main' dans lequel nous sommes en train de nous exécuter.
// Le fait d'avoir appelé la méthode 'start()' sur ce thread, et bien le thread 't' était construit sur la tâche 'task', et ça a exécuté la méthode task.run() dans cet autre thread.
// C'est donc cet autre thread 't' qui a exécuté la tâche 'task'.
// Arrivé à un moment, le thread t aura terminé d'exécuter la tâche task, et donc il va tout simplement se clôturer puisqu'il aura terminé son travail.
// Il en va de même pour le thread main. Mais à quel moment est-ce que ce dernier va s'arrêter ?
// Dès qu'il n'aura plus rien à faire, donc après la méthode start(), il va mourrir également.
// Il y a une convention dans la JVM, qui est que lorsque le thread main s'éteint, à ce moment-là, la JVM va se poser la question, est-ce que je dois quitter ? Ou est-ce que je dois continuer à m'exécuter.
// La règle en fait est qu'elle va décider de s'arrêter de s'exécuter si il n'y a plus aucun thread de type 'daemon' en fonctionnement.
// En fait, dans la JVM, quand on la démarre, il y a tout un tas de thread qui démarrent en même temps. Il n'y a pas que le thread 'main'.
// Par exemple, il y a au moins un thread qui s'occupe du 'garbage collector'. Il s'occupe de libérer la mémoire des objets qui ne sont plus utilisés.
// De plus, le thread qui s'occupe du garbage collector, lui, ne bloque pas la fermeture de la JVM, et ce, parce qu'il est de type 'daemon'.
// Le type daemon est une propriété boolean de la classe Thread. Donc sur la classe thread nous avons les méthodes setDaemon() et isDaemon().
// Donc la présence de ce thread daemon, vivant dans la JVM, ne vas pas bloquer l'extinction de la JVM.
// A l'évidence, le thread main n'est pas un thread daemon, et tant qu'il est vivant, la JVM est vivante.
// Si nous faisons juste une application dans une méthode main, comme nous l'avons fait jusqu'à présent, qui ne génère pas d'autres thread, et qui n'envoies pas d'autres tâches dans ces autres threads.
// Dans ce cas là, tous les autres thread que main, étant des thread daemon, le JVM s'éteindra dès que le thread main s'arrêtera.
// Toutefois, concernant le thread t, nous n'avons pas du tout fixé le fait qu'il soit de type daemon ou pas. Donc, est-il daemon ?
// Il y a une façon très simple de le voir. En effet, si nous programmons l'application comme dans l'exemple précédent.
// Notre thread main va s'arrêter immédiatement après que la méthode start() aura rendu la main.
// Si nous ne voyons pas l'exécution de la méthode task.run(), cela veut dire que le thread t n'est pas un thread daemon.
// Effectivement, le thread main s'est arrêté avant que ce thread t ait eu la chance de pouvoir exécuter la méthode run() de la tâche qui lui a été passée en paramètre.
// Si au contraire nous voyons la méthode run() s'exécuter cela veut dire que ce thread à de bonnes chances d'être un thread daemon.
// Nous pouvons aussi aller l'interroger directement avant, c'est à dire avant de faire t.start(), afficher, cette fois-ci dans le thread main :
// --> System.out.println(t.isDaemon());
// Comme ça nous saurons si un thread créé par défaut est un thread daemon ou pas.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Exécution d'un thread, notion de thread daemon ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons avoir une idée du thread dans lequel nous nous exécutons de la manière suivante :
// Runnable task = () -> System.out.println(Thread.currentThread().getName());
// --> La méthode static currentThread() retourne une référence sur le thread qui est en train de s'exécuter en tant que tâche.
// Donc si nous exécutons ce code dans une méthode main, nous allons retrouver le nom du thread qui l'exécute, donc le thread main.
// Dans la méthode main, nous pouvons afficher task.run();.
// Nous pouvons aussi faire :
// Thread t = new Thread(task);
// t.start();
// --> Cette fois-ci, c'est l'appel à la méthode start() qui va déclencher l'appel à la méthode run(), mais dans un thread différent.
// Ainsi, nous verrons s'afficher le nom du thread qui est en train d'exécuter la méthode run().
// Ces deux lignes doivent donc nous retourner un thread différent.
// Nous pouvons aussi afficher le boolean suivant :
// boolean b = t.isDaemon();
// Ainsi, nous pourrons voir si le thread qui l'exécute est un thread daemon ou non.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Synchronisation et Singleton //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Première écriture du pattern Singleton ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons créer une classe, la classe 'Service'. Elle implémente un pattern très classique en programmation, le pattern 'Singleton'.
//     public class Service {
//         private static Service service;
//         private Service(){};
//         public static Service getInstance(){
//             if(service == null) {
//                 service = new Service();
//             }
//             return service;
//         }
//     }
// Ce pattern Singleton est un pattern dans lequel nous ne voulons qu'une seule instance d'une classe donnée.
// Pour notre exemple, cela signifie qu'à l'échelle de notre application, nous ne voulons qu'une seule instance de cette classe.
// Pour cela nous devons faire plusieurs choses :
// - Tout d'abord, il nous faut interdire au code extérieur à cette classe, la possibilité de créer des instances de cette classe :
// Nous avons donc l'unique constructeur de cette classe ici : private Service(){};
// Celui-ci est un constructeur privé, donc le code se situant à l'extérieur de la classe Service(), ou même qui étendrait cette classe Service(), ne pourront pas instancier cette classe.
// Ils ne pourront donc pas faire 'new Service()'. Donc la seule manière d'instancier Service() est de le faire de l'intérieur de la classe Service().
// Mais étant donné que nous ne pouvons pas avoir d'intérieur dans une instance créée de l'extérieur, nous sommes obligés de mettre ce code dans une méthode static 'getInstance()'.
// - C'est donc cette méthode public static Service getInstance() qui va se charger d'instancier notre unique objet Service().
// Donc si Service() est null, nous l'instançons et nous retournons service. Ceci est la méthode, disons historique d'instancier le pattern Singleton.
// Si nous devons nous en rappeler, c'est parce qu'en fait elle ne fonctionne pas.
// Ce pattern est bugué et ne permet pas de garantir que nous n'avons qu'une seule instance de service dans notre application.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Concurrence d'accès du pattern Singleton, notion de race condition ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pourquoi cela ne fonctionne pas, c'est à cause de quelque chose de très important dans la programmation concurrente, en programmation multi-thread : la 'Race concurrence'.
// Supposons que nous avons deux threads T1 et T2 qui s'exécutent en "même temps" sur le CPU. En même temps au sens où nous l'avons vu précédemment, c'est à dire, pas tout à fait en même temps.
// Donc à un moment, c'est T1 qui s'exécute, puis nous avons le thread scheduler qui va passer la main à T2.
// Imaginons que T1 exécute la méthode getInstance() de notre exemple précédent. Avant que T1 exécute 'new Service()', manque de chance, le thread scheduler passe la main à T2.
// Lorsque le task scheduler va rendre la main à T1, évidemment, il va exécuter l'intérieur du bloc if, car la condition était préalablement validée avant le passage à T2.
// Le thread T2 lors de son exécution va exécuter getInstance() aussi, et ne pas trouver d'instance de service, donc il va en créer une, puis la retourner.
// Puis le thread T1 va reprendre son exécution et créer une seconde instance de Service() et va donc écraser l'instance de Service() qui a été créée par le thread T2.
// Le problème ici, est que déjà, notre implémentation de Singleton ne fonctionnera pas, puisque nous ne voulions qu'une seule instance de classe, et nous nous retrouvons avec deux d'entre elles.
// De plus, l'instance que référence T2, finalement n'est plus l'instance de Service() qui va bien, car c'est l'instance de T1 qui va gagner.
// Donc il va arriver un moment ou l'instance de T2 va disparaître de l'application. Ceci peut donc provoquer des problèmes, donc des bugs.
// Ces deux points, sont le problème tels que nous le constatons, ce sont les symptômes du problème. Mais quel est le problème racine ? Quelle est la cause de ce problème ?
// La source de notre problème est donc que nous avons à faire à une 'Concurrence d'accès' ou une 'Race condition'.
// Nous avons deux threads qui font la course pour savoir qui va gagner pour instancier cette variable Service().
// Qu'est-ce qu'une concurrence d'accès ?
// --> C'est lorsque deux threads peuvent lire et écrire une même variable en même temps.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'un bloc synchronisé pour empêcher une race condition ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons sur certaines portions du code, empêcher le task scheduler d'interrompre l'exécution du code.
// Donc le thread scheduler peut interrompre un thread, mais tant que le thread interrompu est dans le bloc de code, aucun autre thread ne peut entrer dans ce bloc de code, une fois protégé.
//     public class Service {
//         private static Service service;
//         private Service(){};
//         public static Service getInstance(){
//              synchronized {
//                  if(service == null) {
//                        service = new Service();
//                  }
//                  return service;
//              }
//         }
//     }
// Ceci peut être fait en utilisant la méthode 'synchronized{}'. Ainsi, le bloc de code compris dans les accolades de synchronized ne pourra pas être interrompu par le task scheduler.
// Ce mécanisme est un mécanisme purement Java, et nous allons voir précisémment comment il fonctionne, car cela va nous permettre de comprendre l'intégralité de la synchronisation dans l'API Java.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Garder un bloc de code par synchronisation, notion de moniteur ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment la synchronisation fonctionne t'elle en Java ? Nous allons prendre l'exemple suivant :
//      Object lock = new Object();
//      synchronized(lock) {
//
//      }
// L'objet 'lock', que nous passons en paramètre va être utilisé comme verrou sur le block synchronized, lock peut être n'importe quel type d'objet.
// Donc tout le code contenu dans le bloc synchronized va être protégé par l'objet lock, du fait de la présence de cet objet synchronisé.
// Comment cela se passe si nous avons un premier bloc T1 qui cherche à exécuter ce code, suivi de près par un second bloc, T2 ?
// --> En fait l'objet 'lock', comme tous les objets Java, possède une clef. Cette clef est unique.
// Lorsque T1 lance ce bloc, il va prendre la clef de lock, donc T1 possèdera cette clef, mais lock ne la possèdera plus puisqu'il l'a donnée à T1.
// Si le task scheduler décide d'interrompre T1, et donne la main à T2. Une fois arrivé au bloc synchronisé, T2 va interroger l'objet lock pour lui demander sa clef.
// Sauf que cette dernière a déjà été donnée à T1. Donc T2 est bloqué en attente de la clef de l'objet lock, à l'entrée du bloc synchronisé.
// Le thread scheduler va s'en rendre compte, et la nous avons un comportement différent, selon si le processeur est mono-coeur ou multi-coeur, mais dans tous les cas, il va dire à T2 de laisser la place.
// Ainsi, à un moment, T1 va reprendre la main, terminer l'exécution, et terminer sa lecture du bloc synchronisé, puis rendre la clef à l'objet lock.
// A présent, lorsque T2 reprendra la main, si la clef est disponible, il pourra lire le bloc de code synchronisé.
// Ainsi, ce mécanisme de clefs est assez simple, il permet de bloquer les thread à l'entrée d'un bloc synchronisé, lorsqu'un thread est déjà en train d'exécuter le contenu de ce bloc synchronisé.
// Nous avons une file d'attente particulière qui s'appelle la 'WAIT_LIST' qui permet de parquer les threads dans cette liste lorsqu'ils sont en attente de cette clef.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Méthodes d'instance et statiques, synchronisées ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La méthode que nous avons vu précédemment pour écrire le bloc de code est une méthode explicite.
// --> synchronized(lock){...}
// Nous avons aussi deux autres méthodes, celles-ci, implicites pour l'écrire :
// --> public synchronized void increment() {...}
// Le mot clef synchronized doit ici être écrit nécessairement avant le type de retour renvoyé par la méthode, ici 'void'.
// Ce mot clef indique que l'intégralité du code de la méthode va être synchronisé.
// Ici nous ne passons pas d'objet lock, mais celui-ci existe et sera implicite, alors que précédemment il était explicite.
// Cet objet lock, étant donné qu'il s'agit d'une méthode d'instance, sera l'instance de la classe dans laquelle nous nous trouvons, donc en fait, c'est le mot clef 'this' en lui-même.
// --> public synchronized static void getInstance(){...}
// Le mot clef static peut se trouver avant ou après synchronized, toutefois, synchronized doit se trouver avant la méthode de retour, ici void, comme précédemment.
// De la même façon que pour la méthode d'instance, l'intégralité de cette méthode statique va être synchronisée.
// La différence est que vu que nous sommes dans une méthode statique, nous ne sommes plus dans l'instance de la classe dans laquelle cette méthode a été écrite.
// Donc l'objet qui porte la clef en question n'est plus 'this', mais l'objet 'Class'.
// C'est à dire l'instance de la classe qui s'appelle Class qui modélise la classe de l'objet dans lequel nous nous trouvons.
// --> La méthode préférée pour avoir un bloc synchronisé restera la méthode explicite, car c'est la méthode avec laquelle nous pouvons 'cacher' l'objet qui va servir à la synchronisation.
// En effet, l'objet qui sert à la synchronisation ne doit pas être exposé de préférence, car cela augmente les chances d'avoir des 'deadlock'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Synchronisation réentrante ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Examinons l'exemple suivant, nous avons une méthode getService() qui est synchronisée, c'est une méthode d'instance, donc elle vit dans une classe.
// Donc l'objet de synchronisation est l'objet 'this'. Dans cette méthode, nous appelons une autre méthode, isNull, qui est elle aussi synchronisée.
// public synchronized Service getService(){
//      if (isNull(service)){
//          ...
//      }
// }
// public synchronized boolean isNull(Service s){
//    ...
// }
// Cette dernière méthode d'instance est aussi synchronisée, donc celle-ci à donc pour objet de synchronisation, l'objet 'this'.
// Que se passe t'il si nous appliquons isNull, nous avons besoin de demander à l'objet this, donc au 'moniteur' si il possède la clef souhaitée.
// Or, de toute évidence il ne peut pas l'avoir puisque nous sommes en train d'exécuter précisémment sur 'this'.
// Cela dit nous sommes dans un cas particulier, il ne possède pas son moniteur, car c'est le thread T1 qui le possède.
// Le thread qui est en train d'exécuter isNull, est forcément le thread qui possède le moniteur de l'objet this.
// Ceci est un cas d'exception qui va autoriser le thread qui exécute getService() à également exécuter la méthode isNull().
// Pourquoi, car le thread possède déjà le moniteur qui est nécessaire à l'exécution de la méthode isNull().
// Nous appelons cette méthode, qui est que nous puissions exécuter un bloc de code synchronisé sur la même clef que celle que nous possèdons déjà en tant que thread : le fait d'être 'Réentrant'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Synchronisation de plusieurs blocs de code avec la même clé ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il y a de petites subtilités sur les mécanismes de synchronisation.
// Lorsque nous regardons des blocs synchronisés dans une application qui existe, ou lorsque nous concevons une application synchronisée, il faut bien vérifier certaines choses.
// Imaginons que nous avons une classe User, avec deux méthodes publiques synchronisées, pour diverses raisons.
//      public class User {
//          synchronized String getName(){
//              ...
//          }
//          synchronized int getAge(){
//              ...
//          }
//      }
// Comme nous l'avons vu précédemment, ces deux blocs synchronisés vont être tous deux synchronisés sur 'this'.
// Imaginons qu'un thread T1 est en train d'exécuter getName(), il possède donc la clef de l'objet 'this'.
// Maintenant arrive un thread T2, qui essaye d'exécuter getName() mais il ne peut pas puisqu'il y a déjà le thread T1 qui l'exécute et qui possède la clef de l'objet 'this'.
// Si par contre il essaye d'exécuter getAge(), il va faire une requête sur la clef de l'objet 'this', or celle-ci est déjà utilisée.
// Donc notre thread T2 va devoir attendre, il va donc être mis sur la fameuse 'WAIT_LIST' par le mécanisme de gestion des threads dans la JVM.
// Ici, nous sommes donc sur un cas où nous avons deux blocs synchronisés différents, mais qui sont synchronisés sur le même objet.
// C'est donc assez délicat car ici, cet objet est implicite, il n'est pas explicite.
// Donc l'exécution du premier bloc est exclusive de l'exécution du second bloc, du fait que ces deux blocs sont synchronisés sur le même objet.
// Dans certains cas, c'est effectivement l'objectif souhaité, mais dans d'autre cas, les choses ont été écrites sans forcément trop réfléchir.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Synchronisation avec une même clé d'instance ou une clé statique //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Seconde situation qu'il faut penser également à évaluer. Cette fois-ci nous avons la classe user, avec deux méthodes, getName() et getAge:(), à l'intérieur de chacune, un bloc synchronisé.
//      public class User {
//          Object lock = new Object();
//          public String getName(){
//              synchronized(lock){
//                  ...
//              }
//          }
//          public int getAge(){
//              synchronized(lock){
//                  ...
//              }
//          }
//      }
// Ces deux méthodes sont synchronisées explicitement, avec l'objet lock, définie au début de la classe.
// Regardons à présent comment les choses fonctionnent dans ce cas présent :
// Nous avons un thread T1, qui à créé une instance de User u1, et qui est en train d'exécuter getName(). L'objet monitor qu'il possède, la clef qu'il possède est la clef possédée par l'objet u1.lock.
// Donc l'instance lock de l'instance de u1 que ce thread T1 est en train de manipuler.
// Par la suite, nous avons un thread T2 qui est en train de créer une instance de u2, et d'utiliser la méthode getAge().
// Sur quel objet l'instance de la méthode getAge se synchronise t'elle ? Sue l'objet lock de l'instance de User u2 : u2.lock.
// Cet objet u2.lock est différent de l'objet u1.lock, donc il possède toujours sa clef.
// Cela signifie que deux threads vont pouvoir exécuter les deux blocs synchronisés de cette classe en concurrence d'accès, dès l'instant qu'il s'agisse de deux instances de User différentes.
// Toutefois, il se peut aussi que ce soit un bug car, lorsque nous écrivons les choses de cette manière, il n'est pas forcément évident de voir que getName() n'est pas protégé.
// Effectivement il n'est pas protégé pour les accès concurrent sur les instances différentes, et c'est pourtant ce que le code dit à cet endroit-là.
// Si nous voulons rendre getName() protégé quelle que soit l'instance, il faut que l'objet lock soit partagé par toutes les instances de User.
// La bonne façon de partager cet objet lock par toutes les instances de User, est de le rendre statique :
// --> static Object lock = new Object;
// Si nous disons que l'objet lock est statique, cela signifie que toutes les instances de User vont le partager.
// Ainsi, aucun thread ne pourra exécuter la méthode getName() de n'importe quelle instance de User, dès l'instant qu'un thread est déjà en train de l'exécuter.
// Donc, sur les deux exemples que nous venons de voir, les manipulations d'objets lock, sont des choses assez subtiles et délicates, sur lesquelles il faut bien réfléchir.
// De par ce fait, derrière, il est possible que des bugs de malfonctionnement soient créés, soit des bugs de deadlock. Et ceci peut être extrèmement ennuyeux.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Situation de deadlock /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'est ce qu'un deadlock ? C'est une situation dans laquelle nous ne voulons pas arriver, car en général, pour sortir d'un deadlock, la seule solution est de redémarrer l'application.
// Nous avons une classe User, qui possède deux objets qui sont des champs d'instances (lock1 et lock2), qui vont servir à la synchronisation des méthodes.
//      public class User {
//          lock1, lock2
//          m1(){
//              synchronized(lock1){
//                  m2();
//              }
//          }
//          m2(){
//              synchronized(lock2){
//                  m3();
//              }
//          }
//          m3(){
//              synchronized(lock1){
//                  ...
//              }
//          }
//      }
// Cet exemple est une situation qui est très mauvaise. Il ne faut surtout pas chercher à l'écrire ou à la reproduire pour la raison suivante.
// Imaginons que nous avons un thread T1, qui fait appel à la méthode m1(), il va donc prendre l'objet moniteur possédé par l'objet lock1 pour se synchroniser.
// Viens ensuite un thread T2, qui pendant ce temps là, appelle la méthode m2(), ce faisant, il va prendre l'objet moniteur possédé par l'objet lock2 pour se synchroniser.
// T2, souhaiterais pouvoir exécuter la méthode m3(), mais malheureusement, il a besoin de la clef possédée par l'objet lock1 qui n'est pas disponible, puisque le thread T1 la possède.
// Ainsi, T2 passe dans un état, WAIT, et duquel il ne peut sortir que si T1 libère L1.
// Or, T1 est en train d'exécuter m1 qui appelle m2(), mais il ne peut pas exécuter m2() car la clef de ce dernier n'est pas disponible puisqu'elle est utilisée par T2, qui est dans l'état WAIT.
// Donc T1 va aussi passer dans l'état WAIT en attendant que T2 libère m2(). Ainsi nous sommes dans un état bloqué car T1 et T2 ne seront jamais débloqués, pas même avec des exceptions.
// Nous sommes dans une situation de blocage que nous appelons la situation de Deadlock. Dans ces cas là, la seule option qui nous reste est de redémarrer notre JVM, et donc notre application.
// Ces situations peuvent être anticipées par certains IDE, tels qu'Eclipse. Les JVM, elles mêmes peuvent elles aussi détecter ce genre de choses.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment éviter les situations de deadlock /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une manière pour éviter de se retrouver dans cette situation, c'est d'analyser le code que nous avons écrit.
// Il faut aussi faire des blocs synchronisés sur des membres, ou des objets privés des classes.
// Faire des blocs synchronisés directement sur des méthodes, ou des méthodes statiques, cela veut dire que nous exposons les objets nécessaires à la synchronisation.
// Le fait de les exposer fait que d'autres parties de notre application vont pouvoir les utiliser, ce qui augmente les chances d'avoir des situations de deadlock.
// Ainsi, le fait d'avoir des objets de synchronisation qui sont privés aux classes permet de contrôler exactement qui peut utiliser ces objets, donc uniquement les méthodes qui se trouvent dans la classe.
// Et par ce fait de mieux analyser les situations de synchronisation et éventuellement, les situations fautives de type deadlock.
// Donc il faut préférer la synchronisation sur des objets privés, plutôt que sur des objets exposés explicitement (public par exemple).
// Ou encore implicitement en créant des méthodes synchronisées ou des méthodes statiques synchronisées.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le pattern Producteur / Consommateur //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Présentation du pattern Producteur / Consommateur /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons à présent appliquer tout ce que nous avons vu à un pattern qui s'appelle le pattern Producteur / Consommateur.
// Supposons que nous avons une classe, Buffer, qui contient un buffer de tableau d'entiers avec sa déclaration, ainsi qu'un index qui va pointer sur une des cases de ce buffer.
// Nous avons aussi une première méthode qui s'appelle add() qui va ajouter des éléments dans ce buffer, ainsi qu'une méthode remove() qui va supprimer des éléments du buffer.
// Nous n'avons pas mis le type de retour des deux méthodes, mais peu importe.
// Nous pouvons supposer que add() retourne void, et remove retourne int, puisque ce sera un des éléments du buffer qui sera retourné.
//      class Buffer{
//          int[]buffer = ...;
//          int index = 0;
//          public void add() {
//              buffer[index] = index;
//              index++;
//          }
//          public int remove() {
//              int i = buffer[index];
//              index--;
//          }
//      }
// Nous avons deux éléments auxquels nous devons faire attention, premièrement, buffer est 'fini', donc nous ne pouvons exécuter la méthode add() que s l'index est inférieur à cette limite.
// La seconde chose est que nous ne pouvons exécuter remove() que si index est supérieur à 0.
// Supposons à présent que ces deux méthodes sont exécutées par deux threads différents, un thread Producer pour la méthode add(), et un thread Consumer pour la méthode remove().
// A présent nous avons une catégorie supplémentaire de problèmes qui survient, c'est que la variable index, présente dans les deux méthodes, est soumise à une concurrence d'accès.
// Il en va de même pour le tableau buffer qui va être lu et écrit de deux threads différents.
// D'une part nous devons faire gaffe à éviter que le buffer soit vide pour la méthode remove(), ou saturé pour la méthode add().
// D'autre part il va falloir que nous synchronisions ces deux méthodes de sortes à garantir de ne pas avoir de problèmes comme nous avions eu avec le Singleton, précédemment.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Erreurs possibles du Producteur / Consommateur et solutions ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La première chose à faire va être de garantir que nous exécutons le code de la méthode add(), alors qu'il reste de la place dans le buffer.
// Nous pouvons ajouter la clause suivante : while(isFull(buffer)){};. Ainsi, rien ne se passe lorsque le buffer est plein.
// Pour la méthode remove(), nous pouvons ajouter une boucle de la même façon : while(isEmpty()){};.
// Que se passe t'il si nous ne prenons pas de précautions, si nous ne cherchons pas à synchroniser les choses ?
// Nous pouvons avoir une race condition sur la valeur d'index, et finir par avoir une valeur corrompue.
// Nous devons donc mettre en place deux blocs synchronisés, dans chacune des méthodes de cette classe.
// En effet, si nous avons plusieurs threads qui ont le rôle de producer, ils vont être en concurrence.
//      class Buffer{
//          int[]buffer = ...;
//          int index = 0;
//          public void produce() {
//              synchronized(lock) {
//                  while(isFull(buffer)){};
//                  buffer[index] = index;
//                  index++;
//              }
//          }
//          public int consume(lock) {
//              synchronized(l){
//                  while(isEmpty()){}
//                  int i = buffer[index];
//                  index--;
//              }
//          }
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Première synchronisation du Producteur / Consommateurs et problèmes ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous nous retrouvons donc avec la situation précédente, dans laquelle une méthode produce() est synchronisé sur le même objet lock que le bloc synchronisé de la méthode consume().
// La méthode produce() attends que le buffer ne soit plus plein, donc tant qu'il est plein, nous nous trouvons dans une boucle while() d'attente.
// En mirroir à cette méthode, la méthode consume() attends que le buffer ne soit plus vide, et tant qu'il est vide, nous nous trouvons dans une boucle while() d'attente.
// Bien que ce système semble assez séduisant au premier abord, il se trouve que malheureusement il ne fonctionne pas.
// Vu que les boucles se situent dans les blocs synchronisés, étant donné que ceux-ci se partagent la même clef, l'un finira forcément par être bloqué par l'autre.
// Donc le problème viens du fait que lorsque nous sommes dans une boucle d'attente, nous le sommes en gardant la clef de l'objet lock, bloquant par conséquent les autres threads.
// Nous avons donc besoin d'un système dans lequel nous puissions mettre un thread de production en attente en rendant la clef.
// De sorte qu'un thread de consommation puisse venir exécuter son code avec cette clef.
// Une fois le buffer consommer, il faudrait notifier le thread de production qui est en attente, de manière a ce qu'il puisse exécuter son code.
// Nous avons un mécanisme de ce type, fourni par le JDK qui se nomme 'WAIT / NOTIFY'.
// Plutôt que de ne rien faire lorsqu'il est en attente, nous allons mettre le thread en méthode WAIT.
// Une fois que le consommateur aura consommé un élément et libéré de la place dans le buffer, il va utiliser la méthode NOTIFY, et réveiller le thread qui a été mis en sommeil avec la méthode WAIT.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation du Wait / Notify pour implémenter le Producteur / Consommateur ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//      class Buffer{
//          int[]buffer = ...;
//          int index = 0;
//          public void produce() {
//              synchronized(lock) {
//                  while(isFull(buffer)){
//                      lock.wait();
//                  }
//                  buffer[index] = index;
//                  index++;
//                  lock.notify();
//              }
//          }
//          public int consume(lock) {
//              synchronized(l){
//                  while(isEmpty()){
//                      lock.wait();
//                  }
//                  int i = buffer[index];
//                  index--;
//                  lock.notify();
//              }
//          }
//      }
// La méthode wait() est une méthode qui ne peut être appelée que sur un objet dont le thread courant possède le moniteur.
// - Si nous appelons la méthode wait() à l'extérieur d'un bloc synchronisé, nous sommes certains d'avoir une exception.
// - Nous devons être dans un bloc synchronisé sur l'objet sur lequel nous appelons la méthode wait().
// - Le thread courant est ainsi mis en sommeil, et va donc cesser de s'exécuter, et se mettre dans une file différente de celle qui se trouve à l'entrée d'un bloc synchronisé.
// - Le thread rends le moniteur de l'objet lock.
// Cela dit, il nous manque un élément de code pour venir sortir le thread qui a été mis en attente, précisémment de cet état d'attente.
// La seule manière pour sortir ce thread de cette mise en attente est d'utiliser la méthode notify() sur cet objet lock.
// Cette méthode va prendre les threads qui sont dans la wait list de lock.wait(), donc tous les threads qui ont appelé la méthode lock.wait().
// Ainsi, la méthode notify() va prendre un de ces threads et le réveiller, lui donner son moniteur, et ce thread va pouvoir continuer l'exécution de son code synchronisé.
// Nous avons aussi une méthode 'notifyAll()', qui va réveiller l'intégralité des threads.
// Maintenant que se passe t'il dans l'état inverse, c'est à dire si le buffer est vide. Nous devons ajouter aussi lock.notify() sur notre producteur, et lock.wait() sur notre consommateur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Singleton et multicoeurs //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fonctionnement du Pattern Singleton synchronisé sur un CPU multicoeur /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Reprenons l'exemple de notre pattern Singleton du début de ce chapitre. Nous avions donc une Classe service avec un champs statique instance de type service.
// Et comme nous ne voulions qu'une seule instance de notre objet service, nous avions cette méthode statique getInstance().
// Nous avions vu qu'il fallait que nous en synchronisions le contenu, pour tester si l'instance était nulle, et dans ce cas là pour l'instancier avant de la retourner.
// Supposons que nous ayons deux threads T1 et T2 qui cherchent à accéder à ce service, réellemnet en même temps, et que ce service n'a pas encore été instancie.
// Que va t'il se passer au niveau du CPU ? Supposons que T1 rentre dans le bloc synchronisé et va instancier service, éventuellement le task sceduler va l'interrompre avant qu'il termine.
// Mais même si il donne la main à T2, ce dernier ne pourras pas rentrer dans le bloc synchronisé tant que T1 n'en est pas encore sorti.
// Ainsi, lorsque T1 reprends la main et termine son bloc synchronisé, par la suite T2 pourra entrer dans le bloc synchronisé avec l'instance de service créée par T1.
// --> Ceci est le pattern lorsque nous sommes avec un CPU monocoeur. Or depuis 2005 les CPU sont à présent multicoeur de 4 physiques à 8 coeurs virtuels.
// - Que se passe t'il sur deux coeurs ?
// Supposons que T1 rentre dans le bloc synchronisé, et au même moment, T2 est exécuté dans le deuxième CPU.
// A présent, le task sceduler va attendre un petit peu pour voir si le moniteur du bloc synchronisé va se libérer pour T2, plutôt que de rendre la main tout de suite.
// Manque de chance, le moniteur ne se libère pas, donc le second CPU va passer la main à un autre thread.
// Au bout d'un moment le thread T1 reprends la main sur le premier CPU et va sortir du bloc sychronisé pour ainsi rendre le moniteur à T2 sur l'un ou l'autre CPU.
// Ici nous avons une des différences entre les CPU monocoeur et multicoeur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Impact de la lecture synchronisée du Singleton sur un CPU multicoeur //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons à présent que notre objet service a déjà été instancié et que nous cherchons seulement à le lire.
// Si nous sommes dans un cas monocoeur, T1 va entrer dans le bloc synchronisé, et va sortir avec la valeur, sans l'avoir créée, et tout va bien se passer.
// Si T2 cherche à faire le même chose, il ne pourra pas la faire en même temps, mais juste après que T1 ait rendu la main puisque nous n'avons qu'un seul coeur.
// Que se passe t'il sur un CPU multicoeur ?
// T1 va s'exécuter sur le premier CPU, mais va toujours prendre le moniteur, puis le rendre lorsqu'il en aura terminé avec lui, en sortie du bloc synchronisé.
// Supposons que T2 veut lire cette instance, exactement au même moment que T1 sur le second CPU.
// Comme T1 possède le moniteur, T2 va devoir attendre que le moniteur soit disponible pour lire le bloc synchronisé.
// Là nous ne pouvons plus avoir de race condition, de concurrence d'accès étant donné que l'objet service à déjà été créé, mais nous voulons le lire en même temps en parallèle sur tous les coeurs du CPU.
// Malheureusement, comme nous avons synchronisé la lecture de notre Singleton de notre variable instance, nous ne pouvons pas faire autrement qu'attendre que la première lecture ait lieu.
// Ceci est extrèmement embêtant car cela nous pose un sérieux problème de performances.
// --> Plus nous avons de coeurs, plus il va falloir attendre pour pouvoir accéder à ce Singleton.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tentative de résolution de ce problème par le Double Check Locking ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Plutôt que d'avoir un bloc synchronisé qui gère à la fois la lecture et l'écriture, nous commençons par écrire un premier bloc non-synchronisé de lecture :
//     public Service getInstance(){
//         if(instance!null){
//             return instance;
//         }
//         synchronized(lock){
//             if(instance==null){
//                 instance = new Service();
//             }
//             return instance;
//         }
//     }
// Ainsi, si l'instance est null, à ce moment là nous entrons dans un bloc synchronisé, à l'intérieur duquel après avoir retesté si l'instance est bien nulle nous créons l'instance.
// Ce pattern là se nomme le 'Double-Check Locking'. Celui-ci toutefois est bugué, c'est une fausse bonne idée, avec ce pattern nous risquons de buguer l'application.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Impact des structures multicoeurs sur les performances des CPU ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'hypothèse sur laquelle nous avons travaillé jusqu'à présent est que nos processeurs sont monocoeur. Cette hypothèse n'est plus valide à partir de 2005, ceux-ci peuvent aussi être multicoeur.
// Ce sont des processeurs qui ont en général 4 coeurs physiques. Un coeur est en fait une unité capable de faire des calculs en entiers et en virgule flotante.
// Les catalogues peuvent annoncer 8 coeurs virtuels hyperthreadés avec un mécanisme particulièrement rapide pour switcher le contexte d'un thread vers un autre sur un coeur donné.
// Ces processeurs multicoeur ont un impact énorme sur le fonctionnement et les pattern de la programation concurrente.
// Le second élément est la vitesse des processeurs :
// Dans les années 90, les processeurs sont connectés directement à la mémoire vive RAM, et nous accédons à cette dernière avec un délai d'environ 70 ns.
// Aujourd'hui les CPU ne sont plus connectés directement à la mémoire, et cette dernière a toujours un accès avec un délai de 70 ns.
// La différence est qu'aujourd'hui les CPU peuvent traiter les données à environ 1 ns par donnée, alors que dans les années 90, la vitesse des CPU était directement compatible avec celle de la mémoire.
// Donc nous avons d'un côté un CPU avec disons 4 coeurs C1, C2, C3 & C4.
// Chaque coeur a ses propres unités arithmétiques et logiques (une dizaine environ), et a ses propres unités de calcul en virgule flottante.
// De l'autre côté nous avons la RAM avec des constantes de temps qui ne sont pas les mêmes 70 ns pour la mémoire et 1 ns pour le CPU.
// Nous avons donc un problème d'adaptation entre la vitesse à laquelle nous pouvons sortir les données de la mémoire centrale.
// Et ce, avec la vitesse à laquelle il faut fournir des données aux coeurs de notre processeur pour qu'il puisse calculer à vitesse maximale.
// Nous avons ainsi environ un facteur 300 entre la RAM et le processeur.
// Comment est-ce que ce problème d'adaptation a t'il été traité ?
// --> Il a été traité avec un empilement de caches pour chacun des coeurs en trois couches :
// --> L1 et L2 qui contiennent chacun un cache pour chacun des coeurs, et une troisième L3 qui est partagée entre les 4 coeurs.
// C'est ici une version assez simplifiée de la réalité des choses.
// Tout ceci est sur le silicium du CPU, et c'est connecté via un BUS à la RAM avec un temps d'accès de 70 ns.
// Au niveau de la quantité de mémoire, le cache L3 va contenir environ 8 Mo, les caches L2 vont contenir environ 256 ko, et les caches L1 vont contenir environ 32 ko.
// La taille de chaque cache diminue au fur et à mesure que nous nous rapprochons du processeur, mais la vitesse à laquelle nous pouvons accéder à chaque cache va augmenter grandement.
// Typiquement, les caches L1 vont avoir une vitesse de 1 ns, les caches L2 vont avoir une vitesse de 3 ns, et le cache L3 va avoir une vitesse de 15 ns environ.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisation des caches mémoire dans les CPU, lien Happens Before /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tout ceci à un impact sur la manière dont nous programmons. Supposons que nous avons :
// - T1 : i = 0.
// - T2 : j = i + 1.
// Notre variable i sera déclarée dans la mémoire centrale de la machine.
// Supposons à présent que le task sceduler installe le thread T1 sur le coeur C2 de notre processeur. Le thread T2, lui sera installé sur le coeur 3 de notre processeur.
// Le thread T1 va se faire physiquement dans le cache L1 du coeur C2. T2 va s'exécuter dans le cache L1 du coeur C3.
// Or nous pouvons voir à présent que la variable i, vit dans trois endroits différents, dans la mémoire, dans le cache L1 du coeur C2 et dans le cache L1 du coeur C3.
// --> Comment est-ce que le cahce L1 du coeur C3 va savoir dans quel cache se trouve la valeur de i, c'est à dire le cache L1 du coeur C3.
// --> Ceci est donc une question de visibilité : comment un thread voit-il les modifications effectuées dans un autre thread.
// Ce problème ne peut exister que sur les processeurs multicoeur.
// Ce problème peut être résolu par la spécification de l'aspect théorique du langage.
// --> A l'intérieur du language Java, nous avons la définition d'une notion qui est celle du 'Happens-Before'. C'est un lien entre une écriture et une lecture.
//      --> i = 0. Nous avons une écriture de la variable i.
//      --> j = i + 1. Nous avons une lecture de la variable i, suivi d'une incrémentation de celle-ci pour écrire la variable j.
// Si le lien Happens-Before existe entre ces deux opérations, alors nous avons la garantie que j va correctement lire la valeur de i.
// Si nous avons un lien Happens-Before entre une écriture et une lecture, alors cette lecture a la garantie de retourner la valeur qui a été écrite juste avant dans la variable ciblée.
// La question est à présent la suivante : Comment créer ce lien Happens-Before ?

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisation des caches mémoire dans les CPU, lien Happens Before /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le lien Happens-Before est défini dans la spécification du langage, la JLS : Java Language Specification, et elle dit :
// Un lien Happens-Before existe entre toute écriture synchronisée ou volatile et toute lecture synchronisée ou volatile qui suit.
// Donc nous avons déjà écrit des liens Happens-Before, sans le savoir.
// Dès l'instant que notre opération d'écriture se fait dans un bloc synchronisé, et que l'opération de lecture qui suit se fait également dans un bloc synchronisé, le lien Happens-Before existe.
// Ainsi nous avons la garantie que la valeur lue est bien la dernière valeur pour une variable.
// Nous allons à présent voir quelques exemples très simples pour pouvoir expliquer ce lien.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Premier exemple simple d'écriture / lecture avec et sans lien Happens Before //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous avons les deux méthodes suivantes :
//     public void increment(){
//         i++;
//     }
// --> Une première méthode qui prends la variable i de la classe a laquelle elle est apparentée et qui l'incrémente.
//     public void display(){
//         System.out.println(i);
//     }
// --> Une seconde méthode qui s'occupe d'afficher i sur la console.
// La première méthode va être exécutée dans un thread T1 dans une boucle qui va boucler 100 fois. La seconde méthode sera exécutée dans un thread T2, aussi dans une autre boucle, disons 10 fois.
// Par contre, nous n'avons aucun lien Happens-Before, entre la méthode d'écriture de la variable i, et sa méthode de lecture.
// La méthode de d'écriture, ainsi que la méthode de lecture, n'est ni synchronisée, ni volatile. Donc T2 n'a aucune garantie de lire la valeur correcte de i.
// Nous n'avons aucun moyen de savoir comment ce code va s'exécuter. Si nous voulons que ce code s'exécute correctement, il doit être synchronisé :
//      public void increment(){
//          synchronized(lock){
//              i++;
//          }
//     }
//     public void display(){
//         synchronized(lock){
//             System.out.println(i);
//         }
//     }
// Attention : le lien Happens-Before n'existe que lorsque l'écriture et la lecture sont synchronisés.
// Ainsi, nous pouvons constater que pour communiquer entre eux, les caches L1 des coeurs C2 et C3 doivent nécessairement communiquer par le cache commun à tous les coeurs, le L3.
// Par conséquent, la vitesse est 15 fois plus lente pour échanger ces informations, puisque L3 a une vitesse de 15 ns, et L1, de 1 ns.
// Donc cette synchronisation est coûteuse en terme de performance, mais elle est nécessaire si nous souhaitons que les variables soient bien visible à partir de n'importe quel thread.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième exemple de lien Happens Before au résultat aléatoire /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Prenons à présent un second exemple, un peu plus sophistiqué :
//      m1(){
//          x = 1;
//          synchronized(lock){
//              y = 1;
//          }
//      }
//      m2(){
//          synchronized(lock){
//              r1 = y;
//          }
//          r2 = x;
//      }
// Nous avons ici une première méthode qui fait une écriture sur x qui n'est ni synchronisée, ni volatile, puis une seconde écriture sur y, qui elle est synchronisée.
// Nous avons ensuite une seconde méthode qui fait une lecture de y dans une variable r1, qui est synchronisée, puis une lecture de x, dans une variable r2, qui elle n'est pas synchronisée.
// Nous allons supposer que m1 est exécutée dans un premier thread T1, et que m2 est exécutée dans un second thread, T2.
// Que se passe t'il si T1 s'exécute avant T2 :
// --> x = 1; puis y = 1. Nous avons la garantie que cela va s'exécuter dans cet ordre là, dans la mesure où c'est l'ordre dans lequel notre code a été écrit.
// Nous avons donc un lien Happens-Before entre l'écriture de x, et l'écriture de y. Ensuite nous changeons de thread, c'est donc T2 qui s'exécute.
// --> r1 = 1, car l'écriture et la lecture de x se font dans des blocs synchronisés, nous avons donc un lien Happens-Before. Puisque T2 est exécuté après T1, r2 = 1.
// Supposons à présent que T2 s'exécute avant T1 :
// --> r1 = 0, car y n'a pas été initialisé, et il prends la valeur par défaut, donc 0, et r2 = ? car x peut valoir 0 ou 1, nous ne le savons pas.
// Etant donné que nous avons bien un Happens-Before entre r1 et y, r1 va bien être égal à 0 et y sera par la suite bien égal à 1, lorsque T1 sera exécuté.
// En revanche, nous n'avons aucune opération sur l'ordonnencement des opérations r2 = x et x = 1. Nous ne saurons pas si x = 1 s'exécute avant r2 = x ou après.
// C'est une information que nous n'avons pas. Donc si nous exécutons ce code, le résultat sera aléatoire, tantôt r2 sera égal à 0, tantôt il sera égal à 1.
// Et ce, dépendamment de l'ordre que le task sceduler aura choisi pour l'ordre d'exécution des threads T1 et T2. C'est donc une très mauvaise pratique.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création de champs volatiles, différence entre volatilité et synchronisation //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons parlé de synchronisation et de volatilité. Qu'est-ce qu'une écriture, ou une lecture volatile ?
// Il s'agit tout simplement d'une écriture ou d'une lecture sur un champs qui est déclaré volatile.
// --> volatile int index = 0;
// Il faut bien comprendre que la volatilité et la synchronisation ne sont pas la même chose :
//      volatile int index = 0;
//      index++;
// Ceci n'est pas la même chose que si nous écrivons :
// synchronized(lock){
//     i++;
// }
// Du point de vue de la visibilité, les choses sont bien équivalentes, c'est à dire que nous avons bien des lecture et des écritures,volatiles ou synchronisées.
// En revanche nous n'avons pas l'atomicité : index++ est en fait deux opérations : index = index + 1.
// Nous avons en effet une lecture de index, l'incrémentation de la valeur lue, puis l'écriture de la valeur incrémentée dans index.
// Donc c'est une lecture et une écriture qui se suivent. Ainsi, le task scheduler peut très bien interrompre l'exécution du code, entre l'incrémentation de index, et l'écriture de la valeur incrémentée.
// Et ce, de telle sorte que si nous sommes en concurrence d'accès sur ce genre de chose, nous allons avoir une race condition. Donc une concurrence d'accès en écriture sur la variable index.
// Dans le bloc synchronisé ce n'est pas possible, même si i++ équivaut bien à i = i + 1.
// Ainsi, la volatilité donne de la visibilité.
// La synchronisation, elle donne de la visibilité ainsi que de l'atomicité, c'est à dire l'impossibilité de donner la main à un autre thread, sur le même bloc synchronisé.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Retour sur le Double Check Locking, pourquoi est-il buggé ? ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant que nous avons vu ce qu'est le lien Happens-Before, revenons à présent sur le Double Check Locking :
//     public Service getInstance(){
//         if(instance!null){                   --> opération de lecture : READ
//             return instance;
//         }
//         synchronized(lock){
//             if(instance==null){
//                 instance = new Service();    --> opération d'écriture : WRITE
//             }
//             return instance;
//         }
//     }
// La relation Happens-Before existe entre une opération d'écriture synchronisée ou volatile, et une opération de lecture synchronisée ou volatile.
// L'opération de lecture a la garantie de retourner la dernière valeur écrite à condition qu'elle était synchronisée ou volatile.
// Ici, l'opération d'écriture intervient à l'intérieur d'un bloc synchronisé, donc il s'agit bien d'une opération d'écriture synchronisée.
// En revanche, l'opération de lecture ne se fait ni à l'intérieur d'un bloc synchronisé, ni sur une variable déclarée volatile.
// Donc nous n'avons pas de lien Happens-Before entre l'opération de lecture et l'opération d'écriture.
// En effet, le problème n'est pas dans le bloc synchronisé, mais dans le bloc de lecture.
// Le bloc de lecture peut nous retourner non-null, alors que le constructeur situé dans le bloc synchronisé est encore en train de s'exécuter.
// En effet, l'opération d'écriture 'new Service()', revient a exécuter plusieurs choses :
// - Nous effectuons un 'malloc', pour réserver de la mémoire pour répondre à notre demande de Service.
// - Nous exécutons le constructeur.
// - Nous copions le pointeur dans la variable 'instance'.
// --> Nous pouvons être sûrs que le constructeur s'exécutera après le malloc, car le constructeur ne peut pas s'exécuter dans une zone de mémoire qui n'a pas été réservée.
// --> Mais entre l'exécution du constructeur et la copie du pointeur, laquelle des opérations va s'exécuter en premiere ?
// Si c'est le constructeur qui est exécuté le premier, nous sommes dans un bon cas, car si 'instance' est non-null, cela signifie que le constructeur a déjà été exécuté.
// Toutefois, c'est un pari, nous n'avons pas la certitude que cela se déroulera de cette manière.
// Si le pointeur est copié avant que le constructeur soit exécuté, il se peut très bien que dans le bloc READ, nous ne retournons pas la bonne information.
// En effet, nous retournons une instance vers une zone de la mémoire dans laquelle le constructeur est encore en train d'être exécuté.
// Donc vers un objet qui n'est pas encore construit, donc qui sera corrompu. Ce qui rends ce pattern buggé.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan intermédiaire ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Faisons à présent un bilan sur ce que nous avons vu jusqu'à présent :
// --> Nous avons vu la notion de tâche en programation concurrente, implémentée par la classe Runnable.
// --> Nous avons aussi vu la notion de thread implémentée par la classe Thread.
// --> Nous avons vu la notion de synchronisation, rendue nécessaire par le phénomène de Race Condition.
// --> Nous avons aussi vu que nous avons un task sceduler, objet sur lequel nous n'avons pas la main, et qui décide quel thread doit s'exécuter à quel moment.
// --> Nous avons vu les problèmes de visibilité qui sont propres aux CPU multicoeur, réglés par la notion de lien Happens-Before, s'appuyant sur la synchronisation ou sur la volatilié.
// Ainsi, jusqu'en 2005, et l'arrivée des CPU multicoeur, ceci est l'état des lieux.
// Toutefois, à présent, il faut revoir l'utilisation des classes Thread et Runnable en fonction de l'arrivée de ces CPU multicoeur, pour les adapter aux conséquences qui en découlent.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// ExecutorService ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Problèmes posés par le pattern Thread / Runnable //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Revenons sur la manière dont nous créons des Thread, et la façon dont nous soumettons des tâches à des Threads, dans le cadre du pattern Runnable.
//      Thread t = new Thread(task);
//      t.start();
// Ici, la méthode start sur notre thread va appeler la méthode run() sur la task que nous avons passé en paramètre du Thread, pour exécuter cette méthode run() dans un thread séparé.
// Nous avons vu qu'un thread est une ressource système, donc nous sommes en train de créer un objet sur une ressource système qui elle-même est créée par la machine Java avec une requête sur l'OS.
// Une fois que la tâche que nous aurons exécuté dans ce thread aura terminé son exécution, le thread que nous avons créer va simplement disparaître et donc se détruire.
// --> Donc nous laissons un thread s'autodétruire. Ce qui est un peu dommage car si nous avons une deuxième task a exécuter dans un thread séparé, nous serons obligés de créer un second thread séparé.
// Nous ne pourrons donc pas récupérer celui qui a terminé sa tâche, et qui va disparaître.
// Sachant qu'un thread est assez coûteux à créer, du fait qu'il s'agit d'une ressource système, nous sommes en train de faire deux fois le même travail, un peu pour rien.
// Donc ce pattern nous pose un premier problème :
// - Il est coûteux : du fait de ses requêtes faites sur l'OS.
// - Il laisse l'application créer des threads "à la demande".
// En effet, nous sommes dans une espèce de libre service : si un module de notre application à besoin d'un thread, il en demande, et il en créé lui-même.
// Pour de petites applications sans trop de thread, cela se passe bien. Pour de grosses applications nous aurons vite des problèmes de charge, au niveau de la JVM, de notre application, et de notre OS.
// C'est pourquoi, à partir de Java 5, en 2004, ce pattern de création de threads, et revu par un autre pattern : le pattern 'Executor'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction de la notion d'ExecutorService ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment ce nouveau pattern Executor fonctionne ? Techniquement, ce pattern peut être appelé 'Executor' ou 'ExecutorService'.
// Qu'est-ce qu'un Executor ? C'est une réserve de threads qui va être construit sur un certain nombre de threads, imaginons 4, qui vont être créés au moment ou l'Executor est créé.
// Ces 4 threads restent disponible pendant toute la durée de vie de cet Executor.
// Donc pour ecécuter une tâche, nous allons créer une tâche, comme précédemment avec la classe Runnable, puis soumettre cette tâche à l'Executor.
// Celui-ci va prendre un de ses threads existant et disponible, exécuter notre tâche dans ce thread existant, et une fois que notre tâche est terminée, jeter la tâche et rendre le thread à l'Executor.
// Ainsi, avec ce nouveau pattern, nous règlons deux problèmes :
// --> Nous récupérons les threads.
// --> Nous n'autorisons plus la création de threads à la demande.
// Le pattern précédente est toujours disponible, toutefois, il est fortement recommandé d'utiliser le pattern ExecutorService pour s'assurer d'avoir les meilleurs performances.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'ExecutorService par utilisation de la factory Executors ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Techniquement, comment pouvons-nous créer une instance d'Executor ?
// --> Executor & ExecutorService sont des interfaces.
// --> L'interface ExecutorService étends l'interface Executor.
// --> Dans le cadre du JDK, l'implémentation d'Executor et ExecutorService sont en réalité les mêmes objets.
// --> Nous n'avons pas besoin d'implémenter ces interfaces nous-mêmes, nous pouvons le faire, mais c'est un peu technique. Nous avons pour ça une classe factory : Executors.
// Sur cette classe factory, nous avons tout un tas de méthodes factory, donc de méthodes statiques, qui vont nous permettre de retourner des instances d'ExecutorService.
// - .newSingleThreadExecutor();
// - .newFixedThreadPoolExecutor(x); : va nous créer une pool de x threads.
// --> Ce sont les deux méthodes factory que nous allons utiliser préférentiellement, notamment dans nos exemples, et ce sont celles qui sont probablement le plus utilisées.
// Il en existe de nombreuses autres, dont des réserves de threads qui peuvent créer des threads à la demande.
// Ou encore des réserves de threads avec des comportements particuliers, par exemple qui peuvent exécuter des tâches à des dates prédéfinies dans le futur, ou encore avec des intervalles de temps.
// Comment peut-on choisir la taille d'un Executor ? Cela va dépendre de deux paramètres :
// - Cela dépends de ce que font les threads, donc la nature des tâches.
// - Cela dépends du nombre de coeurs dans notre CPU.
// --> Si nous avons des threads qui font essentiellement des traitements de calculs, c'est à dire des traitements qui ne sortent pas de la mémoire.
// Dans ce cas là nous allons essayer de régler notre nombre de threads, sur le nombre de coeurs de notre CPU.
// Si nous avons un CPU à 8 coeurs, nous choisirons 6, 7, ou 8 threads, peut-être une dizaine, mais pas plus, car cela ne sert à rien d'en prendre trop.
// --> En revanche si nous avons des threads qui font des opérations d'entree / sortie, donc typiquement lecture / écriture sur le disque ou sur le réseau.
// A ce moment-là nos threads vont peu utiliser le CPU car ils vont passer leur temps à attendre. Ainsi nous pourrons ici avoir plus de threads que le nombre de coeur dans notre CPU.
// Le réglage de la taille d'une réserve de thread est un point assez délicat et qui nécessite un peu d'expérience et de réflexion.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Exécuter des tâches de type Runnable dans un ExecutorService //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment faisons nous à présent pour soumettre une tâche ?
//      ExecutorService es = ...;           --> Nous avons un objet de type ExecutorService que nous nommons es.
//      es.execute(runnable);               --> Nous pouvons appliquer la méthode execute() en passant une tâche en paramètre.
//      Runnable runnable = ...;            --> Cette tâche créée précédemment est un objet de type Runnable.
// Cette méthode execute() va ainsi prendre la tâche et la confier à notre objet Executor. Celui-ci va choisir un thread disponible dans sa réserve et l'assigner à la tâche passée en paramètre.
// Une fois que la tâche va être exécutée, elle sera jetée, et le thread sera remis dans la réserve de threads disponibles de l'Executor.
// Que se passe t'il si nous confions 20 tâches d'un seul coup à l'ExecutorService. Et bien celui-ci va les mettre dans une file d'attente de tâches.
// Ainsi, il les affectera au fûr et à mesure que des threads se libèrent, et ce, jusqu'à ce que la file d'attente soit vide.
// La méthode Executor est donc plus rapide et efficace en termes de performance car les threads utilisés ne sont pas jetés, mais réutilisés au fur et à mesure.
// De cette manière, il n'est pas nécessaire de faire des requêtes au système d'exploitation pour créer de nouveaux threads pour chacune des tâches.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer et exécuter des tâches de type Callable /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comme nous avons pu le voir précédemment, Java 5 nous a permis de revoir la façon dont nous gérons les threads, et la façon dont nous soumettons des tâches à des threads.
// Cela n'est pas la seule chose qui a été revisitée lors de Java 5, mais aussi le Modèle de tâche a été revisité.
// Avant Java 5, le modèle de tâche est l'interface Runnable, supportée par le pattern ExecutorService, et l'interface Runnable a une unique méthode abstraite : void run();.
// Cette méthode ne retourne pas de valeur (ce pourquoi elle est void), elle ne prends pas de paramètres et ne jette pas d'exceptions.
// --> C'est un point important car cela signifie qu'une tâche ne peut pas produire de valeur, si elle produit une valeur, elle n'a aucun moyen de la retourner dans le thread qui a produit cette tâche.
// --> Un second point est que si jamais cette tâche fait des écritures sur le réseau ou sur le disque, des requêtes sur des bases de données ou encore des services.
// Si toutefois une exception est jetée dans la tâche, telle qu'une IOException par exemple, la tâche n'a aucun moyen de faire remonter cette exception dans le thread qui a généré cette tâche.
// Ces deux inconvéniants sont ainsi des problèmes majeurs de l'interface Runnable.
// A partir de Java 5, l'interface Callable<V>, qui est donc une interface paramétrée (<V>), est introduite. C'est également une interface fonctionnelle qui n'a qu'une seule méthode abstraite.
// Celle-ci s'appelle call() et elle retourne V, elle ne prends pas de paramètres et elle jette une Exception :
// --> V call() throws Exception;
// Ainsi, les inconvéniants de la méthode run() qui ne retourne rien et qui ne jette pas d'exception, sont réglés avec cette nouvelle interface Callable.
// Cette nouvelle méthode peut retourner, soit une valeur normale, soit une valeur exceptionnelle, si jamais quelque chose se passe mal.
// Comment est-ce que Callable peut être implémentée ? Exactement de la même façon que Runnable : Avec une Lambda Exception :
// --> Callable<String> c = () -> "Bonjour";
// Comment est-ce que cette implémentation de Callable peut être passée à un ExecutorService ? Quasiment de la même manière, mais au lieu de la méthode execute(), il s'agit de la méthode submit() :
// --> es.submit(c);
// Ainsi un ExecutorService peut à la fois exécuter des tâches de type Runnable, et des tâches Callable.
// Maintenant une nouvelle question se pose : comment la méthode call() peut elle communiquer la valeur normale ou exceptionnelle qu'elle à retourné, au thread appelant ?

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récupérer le résultat d'une tâche Callable au travers d'un Future /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons à présent que nous avons l'exemple suivant :
//      ExecutorService es = ...
//      Callable<String> task = () -> "Bonjour";
//      Future<String> future = es.submit(task);
// Ici, l'objet Future<String> modélise la transmission, ou la communication entre le thread qui à créé la tâche, et le thread qui va exécuter cette tâche.
// Supposons que notre tâche soit créée dans le thread Main. Cette tâche va être transmise à l'un des threads du pool de threads de l'ExecutorService, et va être exécutée par exemple dans le thread T2.
// Cela signifie que la chaîne de caractère "bonjour" va être créée dans ce thread. Or nous avons besoin d'un moyen de retourner cette chaîne de caractères de T2 jusqu'à notre méthode main.
// Pour cela, il nous suffit d'invoquer la méthode get() sur notre objet future : String s = future.get();
// La méthode get() nous retourne l'objet généré par Callable<> qu'il soit un string, un integer...
// C'est donc cet objet future qui fait le lien entre T2 et notre classe main.
// Cette méthode get() n'est pas censée retourner la valeur immédiatement. Elle constitue un appel 'bloquant'.
// En effet, elle va bloquer tant que la valeur souhaitée n'est pas disponible dans le thread de l'ExecutorService.
// Supposons que ce soit une lecture sur un disque, c'est une opération qui peut prendre du temps, donc la méthode get() ne pourra pas aller plus vite.
// A tel point qu'il existe aussi des versions de get() qui utilisent des timeout : String s = future.get(timeout);.
// Ce timeout utilise deux objets, un objet qui est un nombre, par exemple 2, et un objet qui est l'unité de ce nombre, par exemple des secondes.
// Si à l'issue du timeout, le résultat n'a toujours pas été généré, la méthode get() va générer une TimeoutException.
// Ceci est le cas où la méthode get() nous retourne un résultat normal. Mais la méthode get() peut aussi nous retourner un résultat exceptionnel.
// Supposons que notre tâche get() soit la lecture d'une donnée sur le disque, le disque n'est pas disponible, nous avons donc une IOException qui est générée.
// Cette exception va être captée par l'objet future et va être wrappée dans une exception d'un autre type qui est une 'ExecutionException'.
// Celle-ci va être jetée par la méthode get() dans le thread T2, et nous allons pouvoir la récupérer avec un try / catch dans le thread main.
// La cause racine, donc la root cause de l'exception attrappée dans le thread main, sera l'exception qui aura été attrappée à l'intérieur de cet objet future.
// Cette méthode get() est donc bloquante, elle nous retourne un résultat normal si le résultat a été généré et nous pouvons lui donner un timeout.
// Si jamais une exception a été jetée pendant l'exécution de la tâche, nous la récupérons enveloppée dans une ExecutionException.
// Ce pattern Callable / Future résout des problèmes que nous avions avec Runnable qui ne nous retournais rien, et qui ne nous disait pas quand il avait rencontré une exception.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Soumettre plusieurs tâches à la fois dans un ExecutorService //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A ce stade, nous pouvons nous poser la question suivante : quel est l'intérêt de soumettre une tâche à un ExecutorService pour juste faire future.get().
// Cette méthode qui nous retournera la valeur générée ou calculée par cette tâche. En sachant que le get() va attendre que la tâche ait fini de s'exécuter.
// L'intérêt est que nous allons pouvoir aussi faire autre chose avec notre objet Future<> :
// --> Soumettre d'autres tâches.
// --> Procéder à d'autres traitements.
// Donc pendant que nos tâches s'exécutent dans un autre thread, nous sommes libre de faire d'autres choses.
// Si nous soumettons d'autres tâches, nous aurons alors :
// --> future1.get()
// --> future2.get()
// --> future3.get() ...
// Le temps que nous soumettons ces autres tâches, les premières vont s'exécuter, sans attendre que nous ayons soumis l'intégralité de ces tâches.
// Le but est donc bien de mener des traitements en parallèle, téléguidés du thread main, et exécutés dans les threads de notre ExecutorService.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Etats d'un Thread, transitions entre ces états ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons déjà vu qu'un thread pouvait se trouver dans différents états :
// - Un thread qui est en attente dans un bloc synchronisé se trouve dans un liste d'attente.
// - Nous avons aussi vu que lorsque nous appelons la méthode wait() sur un objet lock dont un thread possède le moniteur, cela met ce thread dans un liste d'attente, qui est cette fois-ci différente.
// --> Nous allons à présent formaliser tout ces états en regardant le diagramme d'états de la classe thread :
// - NEW : état transitoire d'un thread lorsqu'il est créé.
// - RUNNABLE : état lorsqu'un thread est en train d'exécuter une tâche (n'a rien a voir avec l'interface Runnable qui sert de modèle de tâche).
// - TERMINATED : état dans lequel se trouve le thread lorsqu'il a terminé sa tâche.
// Pourquoi a t'on besoin de ce dernier état, et bien lorsque nous lançons un thread sur un tâche, en appelant t.start(), la tâche va s'arrêter une fois terminé et le thread ne sera plus en fonctionnement.
// Mais du point de vue de la programmation, nous pouvons toujours avoir une référence sur ce thread.
// Ainsi, si nous cherchons à appeler start() sur un thread qui est TERMINATED, les choses ne vont pas bien se passer, cela ne pourra pas fonctionner.
// --> Ceci est le mode de fonctionnement normal d'un thread : NEW --> RUNNABLE --> TERMINATED.
// - Pourtant nous avons vu qu'un thread qui est dans l'état RUNNABLE, pouvait également être mis en attente dans une file d'attente spéciale lorsqu'il est à l'entrée d'un bloc synchronisé.
// --> Dans ce cas la, le thread sera dans l'état BLOCKED.
// Le seul moyen de remettre le thread de l'état BLOCKED à l'état RUNNABLE est de le laisser rentrer dans le bloc synchronisé, donc de libérer la clef de l'objet qui sert à la synchronisation de ce bloc.
// Si jamais cette clef pour une raison ou pour une autre n'est jamais libérée, le thread ne pourra jamais sortir de l'état BLOCKED, et nous ne pourrons en fait jamais le récupérer.
// Pour le récupérer il faudra vraiment aller hacker à l'intérieur de la JVM.
// - Lorsque nous avons un thread qui est en attente d'un lock.lock donc la méthode lock de l'interface lock, il n'est pas mis dans l'état BLOCKED.
// Ainsi nous aurons les moyens d'aller le sortir de cet état si jamais nous en avons besoin pour le débloquer.
// - Un thread qui est mis en attente du fait de l'appel de la méthode wait(), est mis dans un état qui s'appelle WAITING.
// La seule façon de sortir un thread de l'état WAITING pour la ramener dans l'état RUNNABLE, est d'appeler la méthode notify() ou notifyAll() de l'objet qui a servi a le mettre dans cet état WAITING.
// - Nous avons un troisième état d'attente, duquel nous pouvons sortir également qui s'appelle TIMED_WAITING.
// En effet, sur la classe Thread, nous avons une méthode qui s'appelle sleep(timeout), qui prends un timeout en paramètre. Elle permet de mettre le thread courant en sommeil.
// Ainsi, soit de façon naturelle, lorsque le timeout est écoulé, le thread va repasser de TIMED_WAITING à l'état de RUNNABLE.
// De façon exceptionnelle, si nous appelons la méthode interrupt() de la classe Thread, nous pouvons aussi repasser le thread de l'état de TIMED_WAITING à l'état de RUNNABLE.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Arrêt et interruption d'un thread /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernier point sur la classe Thread : comment pouvons-nous faire pour arrêter un thread ?
// --> Dans un premier temps, nous pouvons dire qu'il n'est pas possible pour nous d'arrêter un thread.
// Un code qui aurait une référence sur un thread, par exemple : thread t = new Thread();, ainsi nous avons une référence t sur le thread que nous nous sommes créés.
// Au travers de cet objet t, nous ne pouvons pas décider d'arrêter le thread, de stopper son exécution de l'extérieur.
// --> Sur la classe Thread, nous avons une méthode : stop();. Mais il est INTERDIT de l'utiliser.
// Par ailleurs, cette méthode est dépréciée, et dans la JavaDoc, il y a l'explication complète de pourquoi il ne faut pas l'utiliser.
// Mais alors, comment pouvons-nous faire pour arrêter un thread, en cas d'urgence.
// --> La bonne façon de faire est d'appeler la méthode interrupt();. Interrupt peut donc être appelée sur un thread en cours, et cette méthode va effectuer les choses suivantes :
// Il va donner la valeur 'true', au boolean 'interrupt' de la classe Thread.
// Lorsque nous programmons des tâches qui sont exécutées par des threads, si ces tâches sont censées être longues, nous sommes sensés scuter régulièrement la valeur de ce boolean.
// Ainsi nous saurons si nous pouvons mettre un terme à la tâche que nous sommes en train d'exécuter ou non.
// Toutefois, cela suppose que notre thread est en train de s'exécuter, donc qu'il soit dans l'état RUNNABLE Nous avons vu précédemment que certains threads n'étaient pas dans l'état RUNNABLE.
// Nous avons en effet, des threads qui sont dans l'attente d'entrer dans un groupe synchronisé, ainsi que des threads en attente de sortir de la liste d'attente dû à l'appel de la méthode wait().
// Pour les threads qui sont dans l'état WAITING, et pour ceux qui sont dans l'état TIMED_WAITING, appeler la méthode interrupt() va jeter une InterruptedException.
// Les threads qui sont dans l'état BLOCKED sont "perdus". Nous n'avons aucun moyen de les sortir de cet état blocké autre que de leur rendre la clef du moniteur pour lequel ils sont synchronisés.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Arrêter un ExecutorService de façon normale et urgente ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernier point sur l'ExecutorService : comment pouvons-nous faire pour arrêter un ExecutorService ?
// Comme nous avons vu nous ne pouvons pas arrêter un thread directement en récupérant une référence sur ce thread, et en lui disant qu'il doit s'arrêter.
// Ainsi, nous n'allons pas demander aux threads en tant que tel de s'arrêter, mais à l'ExecutorService : es.shutdown();
// Cette méthode doit absolument être appelée à la fin d'une application, lorsque nous avons créé un ExecutorService.
// Ceci, car, par défaut, les threads créés par un ExecutorService sont des threads pour lesquels daemon est false.
// Donc le thread Main va s'exécuter jusqu'à son terme, mais les threads daemon de l'ExecutorService vont être toujours vivants, ce qui va garder la JVM en marche.
// Ainsi, il est indispensable a la fin d'une méthode Main d'appeler la méthode shutdown() sur un ExecutorService si nous en avons créé dans cette méthode Main.
// Le comportement de la méthode shutdown() est un peu particulier :
// - Si il reste des tâches dans la file d'attente, elles vont être exécutées.
// - Les nouvelles tâches soumises vont être refusées.
// - Les tâches en exécution vont être exécutées jusqu'au bout.
// Ceci est la méthode lorsque nous avons le temps d'effectuer toutes les actions ci-dessus. Si nous sommes plus préssés nous avons la méthode es.shutdownNow() :
// - Les tâches dans la file d'attente, qui n'ont donc pas encore commencer a s'exécuter vont être interrompues.
// - Les nouvelles tâches ne seront pas acceptées.
// - Les tâches en cours d'exécution vont s'exécuter jusqu'à leur terme, normalement, si tout se passe bien.
// Il existe aussi une méthode d'interruption avec timeout, celle-ci va laisse les tâches en cours s'exécuter uniquement pendant la durée du timeout, et à la fin de celui-ci va les interrompre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Application du pattern Compare and Swap aux variables atomiques ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Plusieurs fois dans nos exemples, nous avons eu a gérer des compteurs :
//      public void increment(){
//          index++;
//      }
//      public int getIndex(){
//          return index;
//      }
// En sachant qu'index est un champs privé de cette classe, qui est un int.
// Nous avons vu que si plusieurs threads s'amusent à incrémenter en même temps cet index, puisque nous n'avons rien synchronisé et qu'index n'est pas volatile, nous aurons de la concurrence d'accès.
// Aussi, comme la lecture de la méthode getIndex(), n'est ni synchronisée ni volatile, nous ne pouvons pas garantir d'avoir la bonne lecture d'index.
// Donc il nous faut créer un lien HappensBefore en ajoutant soit deux blocs synchronisés, soit en déclarant index comme volatile :
//      public void increment(){
//          synchronized(lock){
//              index++;
//          }
//      }
//      public int getIndex(){
//          synchronized(lock){
//              return index;
//          }
//      }
// Ceci est la manière classique de faire, qui fonctionne correctement, mais qui en terme d'efficacité et de performance, n'est pas idéal.
// En effet, des requêtes coûteuses en temps, sont effectuées sur l'objet lock, etc.
// A partir de Java 5, nous avons un jeu de classe, qui commence par Atomic, qui va en fait gérer exactement ce problème, mais de façon beaucoup plus efficace.
// - AtomicInteger.
// - AtomicLong.
// - AtomicReference.
// Comment est-ce que cela fonctionne ?
//      AtomicLong index = new AtomicLong(0L);                  --> Nous créé un objet AtomicLong de valeur 0, 0L car c'est un Long.
// Sur cet objet, nous avons tout un jeu de méthodes :
// --> index.incrementAndGet();                                 --> Va nous faire l'équivalent de la méthode increment() et la méthode getIndex().
// --> index.get();                                             --> Va nous retourner uniquement la valeur qui est wrappée.
// Quelle est la différence entre ces deux techniques ? D'un point de vue informel, il n'y en a quasiment pas : nous incrémentons, et nous retournons la valeur.
// Du point de vue de l'implémentation, cela n'a rien à voir, car la partie Atomic va être compilée en une seule instruction assembleur ASM.
// Ceci est fondé sur un mécanisme qui se nomme le CASing : Compare And Swap.
// Ce CASing signifie garder en mémoire la valeur d'index en supposant que la valeur d'index est la valeur précédente qui avait été lue par ce même thread.
// Si par exemple ce thread a fait sa dernière incrémentation, qu'il à trouvé la valeur 5, il va aller regarder la mémoire, et si il y a toujours la valeur 5, il va passer automatiquement à la valeur 6.
// Ceci, sans synchronisation, ni sans rien faire d'autre. Il va juste en déduire qu'aucun autre thread, dans son dos, n'est venu modifier cette mémoire.
// Ainsi, cette opération là, le CASing, qui va swapper la valeur 5 avec la nouvelle incrémentation qui est la valeur 6, est seulement une seule opération assembleur.
// C'est donc une opération extrèmement efficace. AtomicInteger et AtomicLong, sont très bien pour faire des compteurs, ou ce genre de choses.
// AtomicReference permet de swapper des pointeurs vers des objets avec un autre jeu de méthodes.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Synchronisation depuis Java 5 /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Primitives de synchronisation introduites en Java 5 ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A partir de Java 5, en 2004, nous avons 4 primitives supplémentaires qui vont nous permettre de faire de la synchronisation.
// Nous les examinerons une par une, mais pour le moment nous allons les lister :
// - Lock : qui est une interface, adossée à une classe d'implémentation ReentrantLock.
// - ReadWriteLock : qui est un autre type de lock.
// - CyclicBarrier.
// - Latch : qui a une implémentation CountDownLatch, qui ressemble a la barrière mais qui n'est pas cyclique.
// - Semaphore : qui est un objet qui existait bien avant Java, dans les anciens temps du C++.
// Nous allons regarder rapidement, chacun de ces objets un par un, avec les patterns d'utilisation, et avec ce qu'ils apportent par rapport au mot clef synchronized qui date de Java 1.
// Ce mot clef, est rendu quasiment obsolète, face a toutes ces nouvelles primitives.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Synchronisation interruptible avec l'interface Lock ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le premier de ces objets est l'objet 'lock', c'est une interface avec une classe d'implémentation : ReentrantLock.
// Le lock peut en fait remplacer complètement le bloc synchronisé. Attention, ce n'est pas le même objet lock que nous utilisions en paramètre de synchronized().
//      Lock lock = new ReentrantLock();
//      lock.lock();
//          ...
//      lock.unlock();
// Nous avons juste une précaution à prendre, il est impératif que la méthode unlock() soit appelée après la méthode lock().
// Ainsi, si jamais une exception est générée à l'intérieur de ce bloc de code, il se peut très bien que la méthode unlock() ne soit pas exécutée si nous l'écrivons comme ci-dessus.
//      Lock lock = new ReentrantLock();
//      try{lock.lock();
//          ...
//      }catch(...){...}
//      finally{
//          lock.unlock();
//      }
// De cette manière, en mettant la méthode unlock() dans un bloc finally, nous pouvons garantir qu'elle sera exécutée même si il y a une exception jetée dans le bloc try.
// Ceci est donc la même chose qu'un bloc synchronisé, au moins du point de vue formel. Quel est l'intérêt d'utiliser ceci plutôt qu'un bloc synchronisé ?
// L'intérêt est que sur l'objet lock, nous avons d'autres méthodes que nous pouvons utiliser :
// - tryLock();
// - tryLock(timeout);
// Cette méthode fonctionne telle que si un thread se présente dessus et que le lock n'est pas disponible, qu'il y a déjà un thread en train d'exécuter ce code là, ce thread ne va pas aller dans ce bloc.
// Donc il ne va pas aller dans la file d'attente. Il va continuer son chemin et directement continuer son exécution. Chose que nous ne pouvons pas faire avec le bloc synchronisé.
// La seconde méthode va laisser le thread qui s'est présenté alors que le lock n'est pas disponible, passer un certain temps dans la file d'attente.
// Cette API lock apporte des fonctionnalités supplémentaires par rapport au bloc synchronisé.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pattern Producteur / Consommateur avec Lock et Condition //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons ici le pattern Producer / Consumer, tel que nous l'avions vu avec le bloc synchronisé et le pattern Wait / Notify, en remplaçant les blocs synchronisés par des lock() et des unlock() :
// Lock lock = new ReentrantLock();
//      try {
//          lock.lock();
//          while(isFull(buffer)){
//              ...
//          }
//          buffer[index++]=...;
//      }catch(...){
//          ...
//      }finally{
//          lock.unlock();
//      }
//
//      try {
//          lock.lock();
//          while(isEmpty(buffer)){
//              ...
//          }
//          buffer[--index];
//      }catch(...){
//          ...
//      }finally{
//          lock.unlock();
//      }
// Le problème est que sur cet objet lock, nous avons une méthode wait() et une méthode notify(), car elles sont définies sur la classe object, donc elles sont disponibles sur tous les objets Java.
// Toutefois, nous nous souvenons que nous ne pouvons appeler ces méthodes wait() et notify() que dans des blocs synchronisés. Or nous n'en avons pas ici.
// Donc nous ne pouvons plus appeler lock.wait() ou lock.notify(), comme nous le faisions dans le premier pattern.
// Il se trouve que dans le pattern lock / ReentrantLock, nous avons un substitut du pattern wait() / notify(), qui utilise des conditions.
// Un objet condition que nous pouvons récupérer sur l'objet lock avec la méthode 'newCondition()'.
// Dans le premier bloc try nous attendons que le buffer soit plein. Tant que celui-ci est plein, nous ne faisons rien, et dès qu'une place se libère dans le buffer, nous le remplissons.
// C'est là que nous devons signaler au second bloc que nous avons une case qui s'est remplie dans notre buffer, donc nous pouvons mettre : notEmpty.signal();.
// Cette méthode .signal() est l'équivalent du notify() dans nos blocs synchronisés. C'est une méthode de l'objet Condition.
// Cette méthode doit ainsi réveiller le code consumer, qui sont endormis dans la boucle while : notEmpty.await(); tant que le buffer est vide.
// Dès que le buffer ne sera pas vide, nous pourrons consommer un élément, et notre buffer ne sera plus plein. Nous aurons donc besoin d'un second objet Condition : notFull.signal();.
// Celui-ci va réveiller le premier bloc try. Ainsi, tant que le buffer est plein, dans la boucle while, nous nous mettons en sommeil : notFull.await();.
// Donc même en utilisant le Lock, nous pouvons utiliser le pattern Producer / Consumer, avec l'objet Condition, et ses méthodes await() et signal().
// Le piège dans ce genre de pattern est de continuer à appeler les méthodes wait() et notify(), car elles jetteront des exceptions puisqu'elles ne seront pas dans des blocs synchronisés.
// Lock lock = new ReentrantLock();
//      try {
//          lock.lock();
//          while(isFull(buffer)){
//              notFull.await();
//          }
//          buffer[index++]=...;
//          notEmpty.signal();
//      }catch(...){
//          ...
//      }finally{
//          lock.unlock();
//      }
//
//      try {
//          lock.lock();
//          while(isEmpty(buffer)){
//              notEmpty.await();
//          }
//          buffer[--index];
//          notFull.signal();
//      }catch(...){
//          ...
//      }finally{
//          lock.unlock();
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation de ReadWriteLock pour autoriser les lectures concurrentes /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Seconde primitive, les ReadWriteLock. Nous allons prendre l'exemple suivant dans lequel nous sommes en train de gérer un cache d'objets.
// Chaque objet est associé à une clef sous forme d'une chaîne de caractères et peut être enregistré dans ce cache, et peut être lu dans ce cache :
//      Map<String, Object> cache = ...;
//      public void put(String key, Object o){
//          map.put(key, o);
//      }
//      public object get(String key){
//          return map.get(key);
//      }
// Nous pouvons penser à un cache en entrée d'une base de données, notre chaîne de caractères, notre clef est en fait la clef primaire de l'objet.
// Avant d'aller chercher cette objet dans la base de données, nous allons vérifier que nous n'avons pas déjà vu cet objet, que nous ne l'avons pas déjà chargé en mémoire.
// Dans ce cas là, nous pourrons venir le chercher dans ce cache, plutôt que de venir le chercher dans la base de données, ce qui serait beaucoup plus coûteux.
// Evidemment, ce genre de chose va être typiquement attaqué en concurrence d'accès, en multi-threads.
// Donc si nous voulons faire les choses convenablement, nous avons besoin de synchroniser la lecture et l'écriture dans la table de hashage.
// Ceci, car nous avons besoin d'avoir de la visibilité. Toutes les opérations, tout le code qui est déclaré dans la méthode put() doit être visible par la méthode get().
// Cela à pour conséquence que si quelqu'un fait un put(), personne d'autre ne peut faire un put() pour un moment, cela encore est raisonnable.
// Mais cela veux aussi dire que si quelqu'un fait un get(), personne d'autre ne peut faire un get() au même moment.
// Or, ceci n'est pas du tout ce que nous voulons. Ce que nous voulons est de protéger les écritures, nous ne voulons pas d'écritures concurrentes dans cette table de hashage.
// La seconde chose est que nous voulons de la visibilité entre les opérations de type get() et les opérations de type put().
// Ce que nous souhaitons également, mais que la synchronisation va nous empêcher de faire, est le parallélisme sur les opérations de type get().
// Si nous avons quinze threads à la fois qui font des get() sur notre table de hashage, nous voulons pouvoir servir ces quinze threads en concurrence d'accès.
// Nous ne voulons pas de concurrence d'accès en écriture, nous en voulons en lecture, et nous voulons de la visibilité entre les méthodes get() et put().
// Ceci n'est pas possible avec de la synchronisation, car nous n'aurons pas de concurrence d'accès en lecture. En effet, avec de la synchronisation, un seul thread à la fois pourra faire get().
// Si nous faisons de la synchronisation avec le lock que nous venons de voir, le résultat sera également le même, nous n'aurons pas de concurrence d'accès sur le get().
// --> D'où cette primitive : ReadWriteLock, qui est une interface ayant pour classe d'implémentation : ReentrantReadWriteLock();
// --> ReadWriteLock lock = new ReentrantReadWriteLock();
// A partir de cet objet lock, nous pourrons récupérer deux objets :
//     - Lock readLock = lock.readLock();
//     - Lock writeLock = lock.writeLock();
// L'objet readLock() n'a pas tout à fait la même sémantique que l'objet writeLock(), et ils seront utilisés de la manière suivante :
//      Map<String, Object> cache = ...;
//      public void put(String key, Object o){
//          try{
//          writeLock.lock();
//          map.put(key, o);
//          }catch(...){
//              ...
//          }finally{
//              writeLock.unlock();
//          }
//      }
//      public object get(String key){
//          try{
//              readLock.lock();
//              return map.get(key);
//          }catch(...){
//              ...
//          }finally{
//              readLock.unlock();
//          }
//      }
// Ces deux objets readLock() et writeLock() fonctionnent ensemble, ils fonctionnent comme une paire puisqu'ils sont issus du même objet lock.
// La sémantique est exactement celle-ci, premièrement l'objet writeLock() impose une exclusivité sur le code map.put(), donc quand un thread exécute ce code, aucun autre ne le pourra.
// Et aucun autre thread ne pourra non plus exécuter le code map.get(). Donc la modification, ou l'écriture sur notre table de hashage est bien exclusive.
// La seconde règle est que le readLock() n'impose pas d'exclusivité sur le bloc qu'il garde. En revanche, il empêche l'exécution du bloc protégé par le writeLock().
// Enfin, nous avons bien le lien HappensBefore, entre le put() et le ou les get().
// Donc les get() ont bien la visibilité sur les modifications qui ont été effectuées sur la table de hashage auparavant.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Autoriser plusieurs threads dans un même bloc de code avec un sémaphore ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Troisième primitive de synchronisation introduite en Java 5, la classe 'Semaphore'.
//      Semaphore semaphore = new Semaphore(5);
// Nous lui passons en paramètre un entier, qui en fait est un nombre de permis.
// En réalité un semaphore correspond exactement à un lock, cela fonctionne de même. En effet, il autorise un thread, dans un bloc de code particulier gardé par ce lock.
// Le semaphore lui va autoriser ici 5 threads dans ce bloc de code, étant donné que nous lui avons assigné en paramètres 5 permis.
// Si nous regardons le pattern de cette façon :
//      try{
//          semaphore.tryAcquire();
//          // code gardé par le semaphore
//      }catch(...){
//          ...
//      }finally{
//          semaphore.release();
//      }
// Nous avons en plus un certain nombre de méthodes qui nous permettent de demander au semaphore, combien de permis il a de disponible.
// Donc combien de threads sont présents dans la liste d'attente, sur l'acquisition d'un permis.
// Nous avons aussi la possibilité de demander un permis avec un timeout.
// Un semaphore est utile lorsque nous voulons garder un bloc de code, et que nous voulons imposer un nombre maximal de thread qui peuvent exécuter ce bloc de code en même temps.
// Ceci est intéressant lorsque nous gardons les ressources physiques comme des canaux de communication particuliers ou des disques particuliers et que nous voulons limiter le nombre de threads par canal.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Patterns d'utilisation de CyclicBarrier ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La quatrième primitive de synchronisation introduite en Java 5, la classe CyclicBarrier.
//      --> CyclicBarrier barrier = new CyclicBarrier(4);
// L'entier qui lui est passé en paramètre représente le nombre de thread que la barrière peut gérer.
// Supposons que nous avons un ensemble d'entiers sur lesquels nous cherchons à extraire les nombres premiers, les primes numbers.
// Vu que c'est une tâche assez lourde en calcul, nous allons diviser notre nombre d'entiers en quatre paquets. Et chacun des paquets aura une tâche qui y sera associée : task 1, task2, task3 et task4.
// Dans l'idée de confier chacune de ces tâches à un thread, donc de confier ces 4 tâches à un ExecutorService construit sur 4 threads.
// Ce que nous souhaitons est d'avoir un signal, lorsque ces 4 tâches seront terminées.
//      CyclicBarrier barrier = new CyclicBarrier(4);
//      Callable<List<Integer>> task = () -> {
//          List<Integer> primes = findPrimes(...);
//          try{
//              barrier.await();
//          }catch(Exception e){
//              ...
//          }
//          return primes;
//      }
//      es.submit(task1);
// Callable va nous retourner une liste d'entiers qui va correspondre au nombre premiers qui ont été trouvés dans le paquet d'entiers que nous lui fournissons.
// Il faut mettre le barrier.await() dans un bloc try/catch. Enfin, nous soumettons la tâches, ainsi que les trois autres qui ont le même code à l'ExecutorService.
// Une fois que quatre appels auront été faits sur la méthode await() de cette même barrier, cette méthode va simplement rendre la main, elle est donc bloquante.
// Cette méthode va compter le nombre de fois qu'elle a été appelée, et quand elle sera appelée quatre fois, les 4 threads vont rendre la main, et le code va pouvoir continuer à s'exécuter.
// Donc derrière, nous retournerons l'ensemble de nos nombre premiers quand nos quatre tâches auront terminé leur exécution.
// Par la suite nous pourrons passer un post-traitement sur les quatre résultats partiels pour les fusionner pour ainsi donner notre résultat global.
// La barrière fonctionne donc comme ça : nous lui passons un entier, et la barrière va compter le nombre de threads qui arrivent sur cette barrière, donc qui vont être en attente sur cette barrière.
// D'où le nom de cette méthode .await(), et quand le nombre de thread atteint le nombre que nous lui avons fixé, à ce moment-là la barrière s'ouvre et les threads peuvent reprendre leur exécution.
// Ceci a une conséquence : le nombre que nous passons en paramètre doit être nécessairement inférieur au nombre de threads de l'ExecutorService qui va exécuter ces tâches.
// --> Quand nous construisons une barrière, nous pouvons également lui passer une tâche en paramètre, à côté de l'entier en premier paramètre.
// Cette tâche qui sera exécutée entre le moment où la barrière aura compté les quatre threads en attente et le moment ou elle s'ouvrira.
// --> Cette barrière s'appelle CyclicBarrier car elle est resetted à chaque fois qu'elle s'ouvre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation du CountDownLatch pour lancer une application /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernière primitive de synchronisation amenée par Java 5 que nous allons voir : CounDownLatch qui est aussi une classe.
// Un CountDownLatch va fonctionner un petit peu comme une barrière cyclique que nous allons créer sur un nombre.
// A chaque fois que nous appelerons une certaine méthode sur cet objet, ce nombre va être décrémenté en interne.
// Lorsque celui-ci sera égal à 0, le Latch, qui se comporte comme une serrure va s'ouvrir et va laisser passer le thread qui est en attente dessus.
// Nous allons supposer que nous sommes en train de lancer une grande application, celle-ci a un certain nombre de services à initialiser avant qu'elle puisse fonctionner proprement.
//      public class ServiceLauncher implements Runnable {
//          private CountDownLatch latch;
//          private Service service;
//          public ServiceLauncher(...){...}
//          public void run(){
//              service.init();
//          }
//      }
// Pour cela, nous avons créé une classe ServiceLauncher qui a deux champs privés, latch, de type CountDownLatch, et le service que ce ServiceLauncher est sensé lancer.
// Ce ServiceLauncher implémente Runnable, et il possède une méthode public void run(), dont l'objet est de lancer la méthode init du service que nous voulons lancer.
// Supposons que nous ayons trois services, un service d'e-mail, un service pour accéder au disque, et un service pour accéder à la base de données.
// --> mailService, diskService et dbService.
// Nous voulons lancer l'initialisation de ces trois services dans trois threads différents, nous aurons donc besoin d'un ExecutorService.
//      ExecutorService es = new ExecutorService(4);
//      CountDownLatch latch = new CountDownLatch(3)
//      mailLauncher = new ServiceLauncher(mailService, latch);
//      diskLauncher = new ServiceLauncher(diskService, latch);
//      dbLauncher = new ServiceLauncher(dbService, latch);
// Donc a chaque fois que le service sera initialisé, donc la méthode init() de ces trois services peut mettre un certain temps à s'exécuter.
// Une fois que la méthode init() a terminé de s'exécuter nous pouvons appeler la méthode latch.countDown() pour indiquer que le service géré par le Launcher est correctement lancé.
// Donc si nous appelons cette méthode trois fois, le compteur interne du CountDownLatch va passer à 0.
//      public class ServiceLauncher implements Runnable {
//          private CountDownLatch latch;
//          private Service service;
//          public ServiceLauncher(...){...}
//          public void run(){
//              service.init();
//              latch.countDown();
//          }
//      }
//      ExecutorService es = new ExecutorService(4);
//      CountDownLatch latch = new CountDownLatch(3)
//      mailLauncher = new ServiceLauncher(mailService, latch);
//      diskLauncher = new ServiceLauncher(diskService, latch);
//      dbLauncher = new ServiceLauncher(dbService, latch);
//      es.execute(mailLauncher);
//      es.execute(diskLauncher);
//      es.execute(dbLauncher);
//      latch.await();
//      application.start();
// --> La méthode await() va bloquer tant que le compteur interne de notre latch n'atteint pas 0.
// A partir de là, le code pourra continuer à s'exécuter et nous pourrons lancer notre application puisque les trois services seront initialisés.
// La différence principale avec la CyclicBarrier est qu'une fois qu'un latch est ouvert, il ne se referme jamais.
// A noter que la méthode await() peut aussi prendre un timeout en paramètre. Si jamais le CountDownLatch n'est pas arrivé à 0 à la fin du timeout, c'est qu'il y a quelque chose qui s'est mal passé.
// A ce moment-là nous pourrons donc jeter une exception et probablement décider de ne pas lancer l'application.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les Collections concurrentes //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction aux collections concurrentes /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour conclure ce chapitre sur la programmation concurrente en Java nous allons voir les Collections Concurrentes. Dont nottamment trois Collections Concurrentes :
// - CopyOnWriteArrayList.
// - BlockingQueue.
// - ConcurrentHashMap.
// Ces trois Collections Concurrentes sont des collections qui sont fournies par le JDK, que nous pouvons utiliser directement dans nos applications.
// Elles ont la propriété d'être 'ThreadSafe', c'est à dire qu'elles peuvent être utilisées dans un contexte multi-thread.
// Et ceci conservant toutes les garanties de performance, de visibilité et de synchronisations qui sont attendues.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fonctionnement et utilisation de CopyOnWriteArrayList /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// CopyOnWriteArrayList est un tableau en mémoire, encapsulé à l'intérieur d'un objet de type ArrayList.
// Il a la particularité d'avoir un pointeur particulier :
// --> Lorsque nous effectuons une opération de type modification, add(), remove(), set()... :
// Le tableau est copié en interne avec l'élément modifié. Le pointeur sera à présent sur la nouvelle version du tableau.
// Cette modification est donc très coûteuse car elle implique la duplication du tableau en interne.
// La paricularité est qu'une fois que le tableau est en mémoire, il n'est jamais modifié, il est donc 'immutable'.
// Dans la mesure où il est immutable, nous pouvons le lire gratuitement, nous n'avons pas besoin de synchronisation, puisque nous savons que ce que nous lisons ne pourra jamais être modifié.
// Cet outil est donc utile lorsque nous avons peu d'écritures, et beaucoup de lectures.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisation de l'API des files d'attente concurrentes en Java 5 //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'un des agents importants dans le domaine des collections concurrentes, est le travail qui a été fait sur les files d'attentes de type LIFO et de type FIFO.
// --> LIFO : Last In First Out : stack classique.
// --> FIFO : First In First Out : file d'attente classique.
// Nous avons deux implémentations non-concurrentes classiques pour LIFO et pour FIFO sont modalisés par les interfaces :
// - Queue : file d'attente classique avec les méthodes classiques, comme ajouter un élément, regarder l'élément qui est en attente, ou encore sortir un élément.
// - Deque : est une extension de queue et signifie double-ended queue, et implique que nous pouvons accéder des deux extrémités de la file pour ajouter, regarder ou sortir un élément.
// A partir de Java 5, nous avons :
// - BlockingQueue : une extension de queue.
// - BlockingDeque : une extension de Deque, sachant que celui-ci étends également BlockingQueue.
// Ces deux éléments sont aussi des interfaces. Ces deux nouvelles interfaces ont une implémentation concurrente, donc doivent supporter la concurrence.
// Ainsi elles doivent présenter toutes les garanties que si ces implémentations sont attaquées par plusieurs threads en concurrence d'accès, tout se passera bien, y compris au niveau de la visibilité.
// Au niveau des implémentations de BlockingQueue, nous en avons trois :
//      --> ArrayBlockingQueue : pour BlockingQueue, une file d'attente synchronisée construite sur un tableau. Attention, cette interface à une taille fixe.
//      --> LinkedBlockingQueue : également pour blocking queue, donc une autre file d'attente synchronisée, celle-ci construite sur une liste chaînée, et non pas sur un tableau.
// Cette dernière interface peut avoir une taille fixe ou non-fixe. Toutefois, ce n'est pas toujours une bonne idée d'avoir des files d'attentes infinies.
// En effet, si nous avons trop de producteurs par rapport à nos consommateurs, nous pouvons exploser la mémoire de notre application et de notre serveur.
//      --> SynchronousBlockingQueue : cette file d'attente à la particularité d'avoir pour taille 0. Nous ne pouvons pas ajouter d'éléments dans cette file d'attente, nous verrons par la suite pourquoi.
// Au niveau des implémentations de BlockingDeque, nous avons :
//      --> LinkedBlockingDeque : qui tout comme son homologue, aura une taille fixe ou non-fixe, définie à sa construction.
// Ensuite nous avons une bizarrerie : une implémentation concurrente de Queue qui n'implémente pas BlockingQueue :
//      --> ConcurrentLinkedQueue : dont la taille n'est pas fixée, et qui peut ainsi grandir autant que nous le souhaitons.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisation de l'API des files d'attente concurrentes en Java 5 //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ces piles et ces files d'attente synchronisées vont en fait servir à implémenter le patter Producer/Consumer.
// Donc nous allons rencontrer exactement les mêmes problèmes en les utilisants, que ceux que nous avons rencontré quand nous avons implémenté ça avec les wait()/notify() et les lock conditions.
// --> Le premier problème est la saturation.
// --> Le second problème est que cette file d'attente peut devenir vide.
// A partir de là, il faut définir des comportements.
// - Que se passe t'il lorsque nous cherchons à ajouter des éléments, dans une structure qui est pleine ?
// - Que se passe t'il lorsque nous cherchons à retirer un élément d'une telle structure alors qu'elle est vide ?
// En fait, BlockingQueue et BlockingDeque définissent trois comportements plus un :
//      --> Nous retournons une valeur particulière, donc ce sera un boolean, pour un ajout il retournera false, car la file est déjà pleine.
//      --> Nous bloquons, si nous sommes en ajout, jusqu'à ce qu'une case se libère. Ou si nous sommes en retrait, jusqu'à ce que nous puissions retirer un élément.
//      --> Nous pouvons également bloquer avec un timeout. Par exemple si nous cherchons à ajouter un élément dans une file d'attente saturée, et nous sommes prêts à attendre le timeout.
// Si le timeout s'est écoulé et qu'une case ne s'est pas libérée, une timeoutException sera jetée.
//      --> Nous jetons une exception directement.
// Ces quatres comportements sont ainsi implémentés par BlockingQueue et BlockingDeque, de façon à pouvoir gérer le problème des files d'attentes saturées, ou des files d'attentes qui sont vides.
// Maintenant nous avons le cas particulier :
// --> SynchronousBlockingQueue : celle-ci n'a pas de buffer interne.
// Comment cette SynchronousBlockingQueue fonctionne t'elle ?
// Supposons qu'un producer cherche à mettre un élément dans cette file d'attente, il va bloquer éventuellement avec un timeout.
// En effet, il n'y a pas de buffer à l'intérieur de la file d'attente donc il ne peut la stocker nulle part.
// Cet élément sera consommé au moment où un consommateur arrive pour venir prendre cet élément.
// Ainsi, l'élément va passer directement d'un producteur à un consommateur sans passer par un buffer.
// Curieusement, ce genre de système fonctionne très bien, et c'est même très performant lorsque nous avons beaucoup de producteurs et beaucoup de consommateurs.
// De même il faut toutefois que nous ayons aussi un équilibre entre la vitesse de production et la vitesse de consommation.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Présentation de ConcurrentHashMap /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La dernière structure concurrente qui mérite d'être signalée est la ConcurrentHashMap. Il y en a deux :
//      --> Une qui est dipsonible du JDK 5 au JDK 7. C'est une ConcurrentHashMap qui est adaptée au multi-threads jusqu'à environ 16 threads avant d'avoir des problèmes de performance.
//      --> Une qui est disponible à partir du JDK 8. Celle-ci fonctionne pour beaucoup de threads. L'implémentation a été entièrement refaite et expose tout un tas de nouvelles fonctionnalités.
// Notamment des fonctionnalités de traitement de données, y compris de traitement de données en parallèle, directement dans la table de hashage qui sont extrèmement performantes.
// Ces ConcurrentHashMap implémentent une interface particulière qui s'appelle 'ConcurrentMap' qui est en Map et qui impose à ses implémentations d'être concurrentes.
// Donc de pouvoir être utilisées en multi-thread de façon sûre avec tout ce qu'il faut de synchronisation et de visibilité entre les opérations.
// Nous avons deux implémentations particulières de ConcurrentMap qui sont :
//      --> ConcurrentHashMap.
//      --> ConcurrentSkipListMap.
// Cette dernière est une table de hashage concurrente construite sur un algorythme particulier qui s'appelle la SkipList.
// La SkipList est en fait une liste chaînée, indexée par des objets qui sont comparables, ce qui implique par ailleurs quelques contraintes.
// Ce qui est joli est qu'elle est entièrement "synchronisée", c'est à dire qu'elle peut être utilisée en concurrence d'accès, mais sans utiliser de synchronisation.
// Tout est construit sur des AtomicReference, c'est à dire sur le pattern Compare and Swap que nous avons vu précédemment.
// Donc voici les trois principales choses qu'il faut retenir sur les collections concurrentes :
// - Le CopyOnWriteArrayList, qui est efficace lorsque nous voulons faire des tableaux concurrents avec peu d'écritures et beaucoup de lectures, car les écritures sont très coûteuses.
// - Des files d'attentes BlockingQueue, nous en avons toujours besoin lorsque nous construisons des systèmes concurrents.
// - Lorsque nous avons besoin de faire des caches, nous pouvons nous appuyer sur la ConcurrentHashMap qui est une table de hashage tout à fait classique.
// Sauf qu'en plus elle met en place des garanties de concurrences, c'est à dire de "synchronisation" et de visibilité entre les opération.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Conclusion et récapitulatif ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Conclusion et récapitulatif sur la programmation concurrente //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'avons-nous vu dans ce chapitre sur la programmation concurrente en Java ?
//      --> Tout d'abord, nous avons vu le pattern 'Runnable', avec la façon de créer des tâches en implémentant l'interface Runnable.
// Ainsi que de lancer des threads, un par un, en confiant nos Runnable à ces threads.
//      --> Ce pattern Runnable a rapidement été remplacé par le pattern 'Executor'. Celui-ci fonctionne aussi avec des tâches de type Runnable, mais également de type Callable.
// Nous avons vu comment créer des ExecutorService, comment soumettre des tâches de type Runnable à ces ExecutorServices, de même pour les tâches de type Callable.
//      --> Nous avons vu comment ces objets de type Runnable et Callable nous retournaient des objets de type 'Future'.
// Ces objets Future nous permettent de communiquer des données entre le thread qui fait le traitement à l'intérieur de l'ExecutorService, et le thread qui lance le traitement.
//      --> Nous avons vu différentes façon de synchroniser le code. Soit avec le pattern 'synchronized()', soit avec les primitives de synchronisation qui nous sont amenées à partir de Java 5.
//      --> Nous avons vu l'importance, à la fois de l'exécution exclusive de blocs de code que nous avons appelé 'atomicité'.
//      --> Nous avons aussi vu les problèmes de visibilité entre les modifications qui sont faites par un thread, et les lectures qui sont faites dans un autre thread.
// Ces problèmes ont été amplifiés par l'arrivée des processeurs multi-coeurs étant donné qu'une même variable peut vivre dans plusieurs physiques disponibles.
//      --> Nous avons vu de même les primitives de synchronisation amenées par Java 5 :
//              - Lock.
//              - ReadWriteLock.
//              - Semaphore.
//              - Barrier.
//              - Latch.
//      --> Enfin, nous avons vu les collections concurrentes, avec un focus sur trois collections concurrentes :
//              - CopyAndWriteArrayList.
//              - Les files d'attente synchronisées, ou tout du moins concurrentes.
//              - Les tables de hashage concurrentes, pour faire des caches.
// Ces collections concurrentes ont également été ajoutées à l'API Collection, à partir de Java 5, notamment en Java 6, puis en Java 8 pour une refonte complète de la ConcurrentHashMap.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Sixième Partie :  Java et les bases de données ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cette sixième partie aborde un point essentiel de l'informatique de gestion, la persistance des données, en proposant les trois modules suivants :
//      - API JDBC.
//      - JPA et Hibernate.
//      - JDBC et JPA par la pratiques.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : API JDBC ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ce module est une présentation de l'API JDBC de Java. Nous allons y découvrir :
//      - Ce qu'est l'API JDBC et quel est son rôle.
//      - Les concepts de base contenus dans l'API JDBC.
//      - Les méthodes de chargement des Drivers des bases de données.
//      - Les différentes façons d’exécuter du SQL à travers les objets Statement.
//      - Comment manipuler le résultat des requêtes à travers un objet ResultSet.
//      - Comment gérer les différents niveaux de Transaction avec les connexions aux bases.
// Types de bases de données :
//      - Hierarchical databases.
//      - Network databases.
//      - Object-oriented databases.
//      - Relational databases.
//      - NoSQL databases.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Présentation de JDBC //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// JDBC : Java DataBase Connectivity.
// Pouvoir accéder à des données en base, aujourd'hui pour une application d'informatique de gestion, ou tout autre type d'application est absolument critique.
// Pourquoi ? Car une application acquiert des données, lis des données éventuellement d'une base de données ou d'ailleurs, elle les transforme pour créer de l'information à partir de ces données.
// Et ceci pour les envoyer vers d'autres applications ou vers des utilisateurs.
// Donc, pour une application, avoir le moyen de lire, écrire, mettre à jour des données dans une base de donnée est très important.
// Nous avons plusieurs types de base de données, en grosso modo deux catégories :
//      - Les bases de données relationnelles, dites SQL avec lesquelles nous intéragissons avec le langage SQL.
//      - Les bases de données non-relationnelles, dites NoSQL (NotOnlySQL) qui sont une autre catégorie à part.
// --> Depuis les toutes premières versions de Java, nous avons une API qui se nomme 'JDBC'.
// C'est une API qui permet à une application Java d'intéragir de façon standard avec des données enregistrées dans une base relationnelle, donc avec laquelle nous pouvons interragir via le langage SQL.
// Nous avons aussi d'autres API qui nous permettent d'intérragir avec des bases de données non-relationnelles, mais qui sortent du cadre de JDBC.
//      --> Comment est-ce que cette API JDBC fonctionne ?
//      --> Comment est-elle structurée ?
//      --> Quelle est son architecture ?
//      --> Quels sont les pattern qu'elle autorise ?
//      --> Quel type de code nous allons avoir besoin d'écrire pour pouvoir interragir avec des données en base ?
// C'est ce que nous allons voir dans ce chapitre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Architecture d'accès à une base ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment les choses fonctionnent-elles en JDBC, comment sont-elles organisées ?
// Nous allons supposer que nous avons une application écrite en Java, et donc elle dépends de ce que nous appelons le JDK.
// Ce dernier contient l'intégralité des classes et des API que toute application Java doit utiliser.
// De l'autre côté nous avons par exemple une base de donnée MySQL. Notre application a donc besoin d'aller lire et écrire un certain nombre de données sur cette base de données.
// Pour cela, elle va utiliser un sous-ensemble du JDK qui s'appelle JDBC, c'est donc une API du JDK. Donc nous n'avons besoin de rien puisque tout est dans le JDK.
// En revanche, si nous voulons interragir avec une base MySQL, nous allons avoir d'un module, fourni par MySQL, que nous appelons un 'Driver'. Plus précisémment, un driver JDBC.
// Notre application communique avec l'API JDBC, cette API JDBC va interagir en interne avec le driver MySQL. Ce dernier va nous permettre d'accéder aux données enregistrées dans la base de données.
// Si nous voulions interragir avec une autre base de données, par exemple de type PostgreSQL, nous aurons besoin d'un autre driver, qui lui sera fourni par la base de données PostgreSQL.
// Cet autre driver va pouvoir interagir avec l'API JDBC du JDK, et au travers d'elle, avec l'application.
// Donc, du point de vue de notre application Java, nous ne voyons que notre API JDBC, qui est commune à l'intégralité des bases de données que nous pouvons utiliser.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Détails des interfaces et implémentations JDBC ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'avons-nous en fait à l'intérieur de cet API JDBC ?
// Ce sont essentiellement des interfaces, tous les éléments que nous allons voir sont toutes des interfaces.
// Pour pouvoir fonctionner, un jeu d'interface à besoin d'une implémentation.
// En effet, par exemple, pour pouvoir mettre des données dans une liste, nous avons besoin de la classe ArrayList qui implémente l'interface List.
// Il se trouve que dans l'API Collection, le JDK fourni à la fois les interfaces et les classes qui implémentent les interfaces.
// Dans l'API JDBC les choses sont différentes : le JDK fourni les interfaces et les implémentations sont fournies par les éditeurs de base de données.
//      --> MySQL fourni un Driver, et ce driver est une implémentation des interfaces de JDBC.
//      --> PostGreSQL fourni un autre driver, et ce driver de la même façon fourni les interfaces de JDBC.
// Evidemment, les implémentations ont des noms différents, et fonctionnent de manière différente selon les bases de données, et donc selon leur éditeur.
// Donc le modèle de fonctionnement de notre application est le suivant : nous allons construire une application qui utilisent les interfaces de JDBC.
// Et à l'exécution, ces interfaces vont être implémentées par l'un des driver, celui qui correspond à la base de données à laquelle nous souhaitons nous adresser.
// Le code que nous allons écrire dans notre application va rester indépendant, "raisonnablement indépendant" du fait que nous nous adressons à une base de données ou à une autre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les concepts dans JDBC ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fonctionnement Général de JDBC ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Techniquement, comment les choses vont-elles se dérouler ?
// Comment pouvons nous faire pour evoyer une requête SQL générée dans une application Java, vers une base MySQL, et comment récupérons nous les résultats de cette requête ?
//      --> Il nous faut établir une Connexion à la base de données. Pour ce faire, nous avons besoin de plusieurs informations :
//              - L'URL à laquelle cette base de donnée est disponible. Nous allons interagir avec une base de données au travers de TCP/IP, donc tout est géré avec des URL.
//                  Nous pouvons aussi intervenir directement en mémoire, mais c'est moins fréquent.
//              - Un mot de passe et un nom d'utilisateur. Dans les bases de données vraiment professionnelles, nous allons plutôt utiliser des mécanismes plus avancés que ceux-ci, comme des certificats.
//          Donc il nous faut quelque part une base de données, disponible, qui écoutes un port sur un URL, et dans cette base, que nous ayons un compte avec un nom d'utilisateur et un mot de passe.
//          --> Une fois que nous avons établi la connexion, nous allons obtenir un objet de JDBC qui est une implémentation de l'interface 'Connection'. Celle-ci dépendra de la base de données.
//      --> Nous allons maintenant pouvoir récupérer deux type d'objets qui sont des 'Statement', ce sont des interfaces de JDBC, implémentées par le driver de la base de donnée.
//              - Statement
//              - PreparedStatement
//          Ces deux objets vont nous permettre de transporter des requêtes SQL vers la base de données.
//      --> Nous pourrons ensuite récupérer les résultats de la requête, en général sous la forme d'un objet de type 'ResultSet'.
//          ResultSet est une interface implémentée par un objet particulier propre à la base de données que nous allons utiliser.
//          Cet objet peut être considéré comme une table qui va contenir les lignes de résultats de requête, et chaque ligne va être structurée en colonne exactement comme une table de base de données.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Se connecter à une base de données ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans un premier temps nous allons commencer par envoyer nos requêtes SQL assez simples vers une base de données, récupérer les résultats, et voir comment les analyser.
// Pour se connecter nous avons besoin d'un objet particulier qui est une chaîne de caractères et qui s'appelle : connectionString.
//      String connectionString = "jdbc:mysql://127.0.1:3306/db";           --> "jdbc:typeDeDB://adresse:port/nomDeLaDB"
// Une fois que nous avons cette chaîne de caractères de connection, nous allons la passer en paramètre d'une méthode factory, donc statique : DriverManager.
// Cette méthode est un objet de type classe fourni par JDBC, donc c'est la même classe pour toutes les applications, vers toutes les bases de données.
//      DriverManager.getConnection(connectionString, username, password);
// Quel va être le travail de ce DriverManager ? Il va constater que nous essayons de nous connecter à une base de données de type MySQL.
// Il va donc regarder si il connaît, si l'application dans laquelle il vit, possède sur son classpath, le pilote JDBC pour MySQL.
// Si la réponse est non, il va tomber en erreur car il n'a pas les moyens de se connecter à la base MySQL.
// Si la réponse est oui, il va interroger ce pilote MySQL, et lui demander de construire un objet, instance de l'interface Connection :
//      Connection conn = DriverManager.getConnection(connectionString, username, password);
// Cette interface connection est une interface standard de l'API JDBC, et tous les pilotes JDBC fourni par les bases de données doivent implémenter les interfaces de JDBC.
// Donc, ce que nous voyons à la compilation est une interface JDBC, un nom de variable, DriverManager qui est un objet JDBC, l'appel d'une méthode statique avec des chaînes de caractères en paramètre.
// Ainsi, tout ce code peut compiler avec JDBC, sans le pilote MySQL.
// --> A la compilation nous avons juste besoin du JDK qui contient JDBC.
// --> A l'exécution, donc quand la méthode getConnection() va faire son travail, cette méthode va interroger les pilotes JDBC que le DriverManager connaît. Nottament le pilote pour MySQL.
// Donc à l'exécution nous avons besoin du Driver JDBC dans MySQL. Nous pouvons le trouver sur le site de MySQL.
// Techniquement, le driver JDBC est en fait un .jar. Ce .jar, doit être mis sur le classpath de notre application. Ainsi, l'objet Connection va bien pouvoir être construit.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Envoi d'une requête avec un Statement /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous avons construit un objet Connection, comme nous venons de le voir.
// La première chose que nous souhaiterions faire est de pouvoir lancer une requête SQL simple, vers une base de donnée, par exemple MySQL.
// Pour ça nous allons avoir besoin d'un objet de transport, qui s'appelle un Statement.
//      Statement smt = conn.createStatement();
// Cette méthode createStatement(), son implémentation est dans le driver JDBC de la base de données à laquelle nous nous adressons, ici MySQL.
// Donc, l'implémentation de Statement qui va être choisi sera propre à MySQL. Mais cet objet Statement sera manipulé au travers de son interface.
//      ResultSet rs = smt.executeQuery("select ID.name from User");
// Il va de soit que dans la base de données, il existe une table User dans laquelle se trouvent les colonnes ID et name.
// Si il y a une erreur de syntaxe dans la requête, ou si la table ou une des colonnes n'existe pas dans la base de données, une SQLException sera jetée depuis la méthode executeQuery().
// Encore une fois, executeQuery() est une implémentation propre à MySQL, qui nous retourne un objet dont la classe implémente ResultSet.
// Mais cet objet ResultSet, nous ne l'utilisons qu'au travers de son interface.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Résultat d'une requête avec ResultSet /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment à partir de cet objet ResultSet pouvons nous analyser les résultats de notre requête ?
// Supposons que nous ayons envoyé la requête précédente en utilisant la connection créée précédemment aussi.
// Nous avons donc obtenu notre objet :
//      ResultSet rs = ...
// Notre résultat rs va donc encapsuler quelque part les deux colonnes ID et name de la table User.
// Le pattern d'analyse de l'objet ResultSet est le suivant :
// D'abord, nous devons appeler la méthode next() sur notre objet rs. Cette méthode à deux rôles.
//              --> Elle va nous retourner true, si jamais nous avons des lignes à analyser. Elle retournera donc false, si la requête ne retourne rien.
//              --> De plus, elle va positionner une espèce de pointeur interne, vers la première ligne du résultat.
// Donc si nous n'appelons pas next() sur notre objet rs, le pointeur va pointer vers une ligne fictive vide, se trouvant avant la première ligne du résultat.
// Nous allons ainsi encapsuler cette méthode dans un while pour être sûr d'avoir un résultat derrière notre pointeur.
// Maintenant, comment allons nous interpréter les colonnes de notre résultat ?
//      while(rs.next()){
//          int id = rs.getInt("ID");
//          String name = rs.getString("name");
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Détails sur le Driver /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Chargements des drivers JDBC //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Revenons un peu plus en détail sur le fonctionnement du DriverManager.
// Par quel moyen le DriverManager va t-il savoir qu'il possède sur son classpath un pilote MySQL dont il a besoin pour instancer cette Connection vers la base de données MySQL.
// En fait, il y a un mécanisme du JDK qui a été introduit en Java 6, qui s'appelle le ServiceLoader.
// Sur le classpath de l'application sur laquelle nous travaillons, nous avons besoin d'avoir un JAR particulier qui va contenir le DriverM MySQL puisque nous nous adressons à une base de données MySQL.
// A l'intérieur de ce .jar, nous avons un répertoire particulier, qui s'appelle 'META-INF' (a bien écrire en majuscules). Il contient des métadonnées sur les classes qui se trouvent dans le .jar.
// Dans META-INF, nous avons un répertoire particulier qui se nomme 'services', qui est un répertoire standard, utilisé par le ServiceLoader du JDK.
// Dans ce répertoire META-INF/services, nous avons un fichier 'java.jdbc.Driver' qui est le nom complet de l'interface Driver de JDBC. C'est un fichier texte.
// Ce fichier texte, par convention va contenir le nom des classes du Driver que nous sommes en train de regarder qui implémente l'interface java.jdbc.driver.
// En l'occurrence, pour MySQL, il y a au moins une de ces classes qui s'appelle : com.mysql.jdbc.Driver.
// Donc, quand la machine Java va ouvrir ce .jar, elle va explorer le répertoire services, regarder les fichiers .txt qui s'y trouvent, et elle va enregistrer que :
// --> Pour l'interface Driver, il y a cette classe d'implémentation qui existe : com.mysql.jdbc.Driver.
// Cette classe d'implémentation à un mécanisme particulier qui va faire qu'elle va se déclarer, auprès du DriverManager du JDBC, comme étant un pilote MySQL.
// Le travail de chargement, est fait par le ServiceLoader, donc qui est indépendant de JDBC. Effectivement il peut très bien charger d'autres implémentations pour d'autres interfaces.
// Mais ensuite, cette classe d'implémentation particulière va s'enregistrer auprès de l'objet DriverManager qui nous à servi à récupérer l'objet Connection.
// --> Donc, au chargement de l'application, le DriverManager sait que cette classe est une implémentation de l'interface Driver de l'API JDBC.
// Ainsi, lorsque nous lui demandons getConnection(), et que nous lui passons le mot clef 'mysql', il va interroger en fait une espèce de registry interne, pour constater qu'il a bien la bonne classe.
// De ce fait, il pourra l'instancier par réflexion, et la retourner en tant qu'objet de type 'Connection'.
// Ainsi, derrière tout ça, il n'y a pas de magie, il y a un mécanisme standard du JDK qui s'appelle le ServiceLoader, et un fonctionnement standard du DriverManager JDBC.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Chargement manuel d'un driver JDBC ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cela dit, le mécanisme de ServiceLoader, nous ne l'avons qu'a partir de Java 6. Que se passe t'il si nous avons une application Java 5 ?
// Nous pouvons toutefois charger la classe qui implémente ce driver à la main, grâce à l'API Reflexion, et à la méthode forName() de la classe Class :
//      Class driverClass = Class.forName("com.mysql.jdbc.Driver");             --> Toutefois il nous faut quand même évidemment que le .jar de MySQL soit dans le classpath.
// Nous pouvons ensuite instancier ce driverClass de deux manières différentes :
//      Driver mySQLDriver = driverClass.newInstance();                                              --> Cette méthode newInstance(), de la classe Class va instancier la classe sur laquelle elle est appellée.
// Ceci fonctionne jusqu'en Java 9, et à partir de Java 9, nous avons un nouveau pattern :
//      Driver mysSQLDriver = driverClass.getConstructor().newInstance();                             --> Ici nous invoquons la méthode newInstance() sur le constructeur vide de l'objet de la classe Class.
// Quelle est la différence ? Celle-ci est un peu subtile, elle tiens en fait à la manière dont la sécurité est gérée dans l'API Reflexion.
// Ces deux méthodes nous retournent un objet de type Driver. Donc une instance de l'interface Driver de JDBC. Il va maintenant falloir que nous l'enregistrions auprès du DriverManager.
//      DriverManager.registerDriver(mySQLDriver);
// Donc ce DriverManager possède aussi la méthode statique registerDriver(), et qui prends des instances de driver JDBC en paramètre.
// Une fois que ce code là est exécuté, le DriverManager va constater qu'il possède bien un driver MySQL, il va l'associer à la bonne chaîne de caractères, passée en paramètre de getConnection().
// Ainsi, en passant cette méthode au DriverManager, il pourra nous retourner une instance de connection vers la base MySQL, donc nous aurons donné l'url, identifiant et mot de passe en paramètre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Détails sur le fonctionnement de Statement ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation de Statement pour lancer une requête //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons quelques détails sur cet objet Statement. Pour créer un objet Statement, il nous faut appeler la méthode createStatement() sur l'objet Connection :
//      Statement smt = conn.createStatement();
// Ensuite nous avons vu que pour envoyer une requête de type select, nous avions une première méthode : executeQuery(), qui prends en paramètre une requête SQL.
//      ResultSet rs = smt.executeQuery(...);
// Nous avons deux autres méthodes sur l'objet Statement :
//      int update = smt.executeUpdate(...);
//          --> Celle-ci prends également une chaîne de caractères en paramètre, mais elle doit être une requête SQL de type mise à jour (update ou delete par exemple).
//          --> Elle nous retourne un entier, car c'est l'entier qui nous est retourné par les requêtes SQL de type mise à jour, et qui correspond au nombre d'enregistrements affectés par la requête.
//      boolean select = smt.execute(...);
//          if(select){
//              ResultSet rs = statement.getResultSet();
//          }else{
//              int update = statement.getUpdateCount();
//          }
//          --> Celle-ci est valide pour les requêtes de type select et pour les requêtes de type mise à jour.
//          --> Elle nous retourne un boolean, car si il est vrai, la requête qui a été exécutée est de type select, et si il est faux, elle a été de type mise à jour, d'où le nom du boolean 'select'.
//          --> Toutefois, nous allons devoir pousser un peu plus l'analyse car nous voudrons récupérer le ResultSet, ou l'integer selon le résultat du boolean, doù le if / else.
// A présent nous avons tout de même un petit inconvéniant avec cette méthode statement, qui réside dans le fait que ce que nous passons en paramètre est une chaîne de caractères.
// C'est ce que nous allons voir à présent.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation de Statement pour passer une requête SQL //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent quel est cet inconvéniant. Ici nous sommes en train d'écrire une méthode getUserByName.
// Dans notre application nous avons donc des objets de type User, ces objets sont écrits dans des bases de données.
// A partir du nom d'un utilisateur, nous voudrions être capable de reconstruire l'objet User de façon complète.
//      User getUserByName(String Name){
//          Statement smt = ...;
//          String sql = "select ID from User" + "where name = '"+ name + "'";
//          ResultSet rs = smt.executeQuery(sql);
//      }
// Donc ici, notre requête SQL est construite par concaténation d'un nom d'utilisateur avec une chaîne SQL écrite en dur dans notre code.
// Ceci est quelque chose qu'il ne faut ABSOLUMENT JAMAIS FAIRE. Car c'est une faille de sécurité, qui rends notre code sensible à une attaque du nom de 'SQL Injection'.
// --> Nous sommes en train de récupérer une chaîne de caractères qui nous vient de l'extérieur de notre application, et nous la concaténons à notre chaîne pour créer une requête SQL.
// --> Il ne faut donc jamais construire des requêtes SQL par concaténation.
// Tant que nous utilisons des statements avec des requêtes entèrement écrites en dur dans notre application ne dépendant pas de morceaux de chaînes de caractères venant de l'extérieur, tout va bien.
// Il faut donc utiliser les statements de façon limitée, avec beaucoup de précautions, voire d'éviter de les utiliser, et d'utiliser plutôt les PreparedStatements.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer un PreparedStatement sur une requête SQL simple /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quelle est la différence entre l'objet Statement et l'objet PreparedStatement ? A priori, elle est assez mince.
// Les deux sont créées à partir de l'objet Connection avec la méthode prepareStatement() qui va nous retourner l'objet PreparedStatement.
// La première différence est que nous créons un PreparedStatement sur une chaîne SQL, comme par exemple "select ID.name from User".
// Alors qu'un objet Statement est un objet de transport qui va nous permettre de transporter n'importe quelle requête SQL, de type select ou de type mise à jour.
// Un objet PreparedStatement, lui est construit sur une requête unique :
//      PreparedStatement psmt = conn.prepareStatement("select ID.name from User");
// Si nous voulons exécuter ce PreparedStatement nous avons en fait trois méthodes, qui sont analogues aux méthodes équivalentes de l'interface Statement :
//      - ResultSet rs = psmt.executeQuery();          --> Cette méthode ne prends pas de paramètres car la requête est déjà déclarée dans l'objet PreparedStatement.
//      - int i = psmt.executeUpdate();
//      - boolean select = psmt.execute();
// Donc c'est ainsi qu'un PreparedStatement fonctionne, il est construit sur une requête fixée à la création du statement, que nous allons ensuite pouvoir exécuter en utilisant une de ces trois méthodes.
// Mais quelle est donc la différence entre un Statement et un PreparedStatement ?
// La requête que nous passons dans le PreparedStatement n'est en fait pas tout à fait une requête SQL, c'est une requête que nous allons pouvoir paramétrer.
// Ainsi, nous pourrons aussi fixer la valeur des paramètres.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser un PreparedStatement /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous voulions faire comme précédemment. Créer une requête SQL, qui aille chercher des utilisateurs en base de données à partir de leurs noms.
//      PreparedStatement psmt = conn.prepareStatement("select ID from User" + "where name = ?");
// Ici, nous remplaçons donc notre variable, qui était concaténée dans le Statement, en '?' dans le PreparedStatement. Donc '?' devient un paramètre de notre chaîne de requête.
// Comment allons nous pouvoir fixer la valeur de ce paramètre ?
//        psmt.setString(1, "Paul");
// Ici, nous injectons "Paul", au premier emplacement de variable. Sauf que cette fois-ci, nous ne l'avons pas fait par concaténation.
// En effet, la chaîne de requête est générée par l'API JDBC, qui elle, va mettre en oeuvre, tout un tas de mesures de sécurité pour garantir la non-injection de SQL.
// Ensuite, nous allons pouvoir faire :
//      ResultSet rs = psmt.executeQuery();
// Et comme il s'agit d'un PreparedStatement, nous pouvons très bien éxecuter de nouveau la requête avec une autre valeur de variable.
//      psmt.setString(1, "Ines");
//      ResultSet rs2 = psmt.executeQuery();
// PreparedStatement peut donc être utilisé autant de fois que nous le voulons, dans lequel nous pouvons mettre des paramètres, en ajoutant des '?' à l'intérieur.
// Nous pouvons fixer la valeur de ces paramètres avec de nombreuses méthodes, setString(), setInt(), setLong(), ...
// Une fois que nous avons fixé l'intégralité des paramètres, nous pouvons appeler la méthode executeQuery() ou les deux autres méthodes pour exécuter la requête SQL correspondante.
// A chaque exécution évidemment, nous aurons un nouvel objet ResultSet qui nous sera retourné, que nous pourrons ensuite analyser.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Batch en JDBC /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Intérêt des requêtes en Batch /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Parlons un instant des requêtes en batch. Mais avant d'en parler, parlons performance, et de ce qui coûte cher lorsqu'une requête est envoyée d'une application vers une base de données.
// Peu importe le type de la base de données, entre les deux il va y avoir une connection qui sera typiquement faite en TCP/IP.
// Si c'est du TCP/IP local, la connection ne va pas quitter la machine sur laquelle nous sommes, mais potentiellement, nous pouvons avoir une connection réseau entre ces deux machines.
// Donc c'est bien souvent le temps de transit entre les deux machines plutôt que la requête elle-même qui est coûteuse.
// Notamment plus lors de l'échange de la base de données vers l'application plutôt que dans le sens contraire, surtout si le résultat de la requête est volumineux.
// Donc nous souhaitons éviter au maximum qu'il y ait trop d'allers-retours entre l'application et la base de données pour maximiser la performance.
// --> C'est donc là que les requêtes en batch vont intervenir.
// Supposons que dans notre application, nous ayons à un moment ou à un autre, de nombreuses requêtes de mises à jour : update ou delete.
// Les requêtes de mises à jour sont des requêtes qui partent vers la base de données, qui met à jour des données, et qui retourne un entier qui décrit le nombre d'enregistrements mis à jour.
// Ce que nous voulons éviter à tout prix est bien sûr le nombre de requêtes, puisque les efforts des deux machines sont moindres, et que seul le transit est gourmant en temps.
// Si nous avons beaucoup de petites requêtes à faire, c'est ce nombre de requêtes qui va avoir un impact sur la performance globale de notre traîtement.
// --> C'est pourquoi JDBC offre la possibilité d'effectuer ces traitements en batch. C'est à dire d'encapsuler toutes ces requêtes en une seule requête JDBC.
// Ainsi, toutes les requêtes seront envoyées en une seule, et un seul échange entre la base de données et l'application sera effectué, plutôt qu'une par petite requête.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Envoyer un ensemble de requêtes en Batch //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Techniquement, comment les choses vont-elles se passer ? Et bien nous avons deux manières de le faire :
//      - La première en utilisant des Statement :
// Nous avons vu qu'un Statement peut encapsuler n'importe quelle requête, nous pouvons en fait à partir de ce même objet, envoyer autant de requêtes que nous voulons, et autant de requêtes différentes.
//          statement.addBatch(sql);        --> Cette méthode addBatch() prends une chaîne de requêtes SQL en paramètre, cette chaîne de requête peut être différente, d'un appel de cette méthode à l'autre.
// Nous pouvons faire autant d'appel addBatch() que nous voulons, ce faisant nous allons encapsuler toutes les requêtes SQL dans cet unique objet Statement.
//      - La seconde en utilisant des PreparedStatement :
// Pour le PreparedStatement, les choses sont un peu différentes parce que celui-ci est construit sur une espèce de modèle de requête. Sur une requête qui a été paramétrée.
//          preparedStatement.setInt(1, 10);
//          preparedStatement.addBatch();
//          preparedStatement.setInt(1, 20);
//          preparedStatement.addBatch();
// Ici, nous allons prendre la requête paramétrée sur lequel ce PreparedStatement a été construit, fixer le paramètre '1, 10', qui va en interne générer une requête SQL, puis l'ajouter au batch.
// Si nous voulons lancer d'autres requêtes, il nous suffit de réitérer les deux lignes de code comme ci-dessus.
// --> Enfin, une fois le batch préparé, pour les deux manières de faire, il nous suffit d'exécuter la méthode :
//          int[] <-- .executeBatch();
// Et ceci est commun pour les deux manières de faire des requêtes en batch. Cela nous retournera un tableau d'entiers, dans l'ordre dans lequel les requêtes ont été faites.
// Nous pourrons ensuite analyser ce tableau dans notre application Java.
// ATTENTION : Les batchs sont tout à fait adaptés aux groupes de requêtes de type mise à jour, mais pas du tout aux groupes de requêtes de type select.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Détails sur le fonctionnement de ResultSet ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Analyser un ResultSet simple //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le dernier objet qu'il nous reste a examiner est l'objet ResultSet. Nous allons supposer que nous avons déjà fait une requête SQL sur une base de données.
// Celle-ci est du type "select ID.nam from User", qui nous retourne : 1, Paul ; 2, Sarag ; 3, NGolo ; 4, Ines.
// Ce résultat est rendu disponible, au travers de l'objet Statement dans un objet rs, qui est de type ResultSet.
// Nous avons vu que le premier pattern, consiste à appeler rs.next(), qui a en fait deux rôles :
//      - Premièrement, cette méthode va retourner true, si il reste des lignes à consommer dans la table de résultats.
//      - Deuxièmement, va faire pointer un curseur interne a cet objet ResultSet, vers le prochain enregistrement disponible.
// Nous pouvons ainsi encapsuler rs.get() dans une boucle while pour pouvoir analyser les résultats dans le bloc de code concerné par la boucle while :
//      while(rs.next()){
//          long id = getLong("id");
//          String name = rs.getString("name");
//      }
// Nous avons plein de méthodes différentes pour récupérer les éléments du ResultSet. Nous pouvons soit passer le nom de la colonne, soit le numéro de la colonne en paramètre des méthodes de retour.
// Toutefois, passer le numéro de la colonne peut poser des problèmes : si nous avions fait "select * from User", nous ne pourrons pas prévoir quelle colonne va sortir en première.
// En effet, nous pourrons ainsi avoir des exceptions si nous exécutons getLong() sur une colonne name qui contient des chaînes de caractères et non des long.
// Nous pouvons utiliser ces index si ous avons une requête du type : "select ID.name from User".

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Analyse d'un ResultSet avec ResultSetMetaData /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous avons un objet ResultSet que nous avons récupéré à l'aide d'un Statement, ou d'un PreparedStatement.
// De plus, la requête que nous avons effectué est par exemple un "select * from User", ce qui fait que nous ne connaissons pas exactement quelles colonnes nous avons récupéré.
// Rien n'est perdu car nous avons la méthode getMetaData() que nous pouvons passer sur l'objet ResultSet :
//      ResultSetMetaData md = rs.getMetaData();
// Sur cet objet de type ResultSetMetaData, md, nous avons plusieurs méthodes que nous pouvons appliquer.
//      Nombre de colonnes --> md.getColumnCount();
//      String name = md.getColumnName(index);
//      int type = md.getColumnType(index);         --> Ceci est un type SQL, donc cela peut être un CHAR, VARCHAR, INT, ...
// En fonction du type récuprér par cette méthode, nous pouvons choisir le type Java dans lequel ce type va être translaté.
// Par exemple, si nous savons que le type retourné est CHAR, nous allons pouvoir appeler :
//      String s = rs.getString(name);
// Ce string est donc la chaîne de caractères qui se trouve dans la colonne dont nous avons récupéré le name pour la ligne ResultSet que nous regardons.
// Donc, cet objet ResultSetMetaData, nous permet d'explorer exactement les données que nous avons récupéré dans ce ResultSet.
// A la fois le nombre de colonnes, le nom de chaque colonne, et le type SQL de chacune de ces colonnes.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Naviguer dans un ResultSet ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons donc une méthode rs.next() qui permet de faire progresser le curseur interne dans le sens croissant des rangées.
//      --> rs.previous(); : cette méthode permet de revenir sur une rangée que nous avons déjà visitée dans notre ResultSet.
// Cette fois-ci il faut être un peu subtil car tous les objets ResultSet, toutes les implémentations de l'interface ResultSet ne supportent pas nécessairement cette fonctionnalité.
// Nous nous rappelons que ResultSet est une interface, que son implémentation est fournie par le driver JDBC que nous utilisons. Ce driver JDBC étant propre à chaque base de données.
// Cette méthode existe donc dans l'API JDBC, mais elle n'est pas forcément implémentée par tous les drivers de base de données. Comment pouvons nous savoir si notre driver supporte cette méthode.
// Nous pouvons l'interroger en utilisant la méthode suivante :
//      --> int i = rs.getType(); : l'entier qui nous est retourné par cette méthode est une constante, et elle peut prendre trois valeurs entières qui correspond aux noms suivants :
//              - TYPE_FORWARD_ONLY : ce type nous indique que rs.previous() ne fonctionne pas pour cette implémentation de ResultSet.
//              - TYPE_SCROLL_INSENSITIVE : si nous retournons avec rs.previous() sur une valeur déjà lue, elle sera identique à la première lecture.
//                                          Comme si ces valeurs étaient dans un cache déconnecté de la base de données. Les valeurs déjà lues ne changent pas lorsque nous revenons dessus.
//              - TYPE_SCROLL_SENSITIVE : si nous retournons avec rs.previous() sur une valeur déjà lue, elle peut être différente à la valeur de la première lecture.
//                                          Comme si ces valeurs étaient en permanence connectées à la base de données, et que si celle-ci à eu un changement de valeur, nous pouvons le voir.
// Avec ce dernier type, nous pouvons ainsi avoir deux valeurs différentes en lisant la même ligne.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mettre à jour des données avec ResultSet //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Seconde chose que nous pouvons faire avec des ResultSet, ce sont les opérations de mises à jour.
// Non seulement un ResultSet peut être utilisépour regarder, pour scruter des données dans une base de données, au travers de requêtes de type "select".
// Mais lorsqu'un ResultSet pointe vers une ligne, il peut également mettre à jour les valeurs des colonnes de cette ligne.
// Nous savons si nous possédons cette fonctionnalité en interrogeant une propriété de l'objet ResultSet qui est la suivante :
//      --> int i = rs.getConcurrency() : l'entier retourné peut avoir deux valeurs qui sont également des constantes définies dans l'interface ResultSet :
//              - CONCUR_READ_ONLY : cela signifie que notre ResultSet est en lecture seule, nous ne pouvons donc pas faire de mises à jour sur cet objet.
//              - CONCUR_UPDATABLE : cela signifie que notre ResultSet peut nous permettre de mettre à jour des données qui sont dans notre base de données.
// A ce moment là nous pourrons utiliser toutes nos méthodes setInt(), setString(), setLong(), ... disponibles sur l'interface ResultSet pour faire ces mises à jour.
// Nous avons même une méthode qui peut nous permettre de rajouter des éléments dans une table, en rajoutant des lignes dans notre objet de type ResultSet.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérer les dates avec ResultSet ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il y a un aspect lorsque nous échangeons avec des bases de données qui est toujours très amusant, jusqu'à parfois être même un peu énervant a gérer qui est le problème des date, time, timestamp.
// En fait, lorsque nous parlons de dates, nous parlons de plusieurs choses à la fois :
//      --> Nous pouvons dire qu'une personne est née le 04/07/2001, c'est une date qqui n'a pas d'ambiguïté lorsque nous voulons parler de la date de naissance d'une personne ou de son anniversaire.
//      --> Chaque jour, le déjeûner à lieu à 12h00, c'est aussi un point dans le temps qui est fixe et qui n'a pas d'ambiguïté.
// Il s'agit bien de deux dates, mais pouvons nous les comparer l'une à l'autre ? Cela n'a pas de sens.
//      --> Si nous prenons rendez-vous quelque part nous préciserons aussi l'heure comme le 04/07/2001 à 11h30.
// Ces trois types de dates correspondent en fait à trois types de dates en SQL, qui se translattent à trois classes différentes dans l'univers Java.
//      - Date : est un objet qui contient un jour, un mois et une année.
//      - Time : est un objet qui contient des heures, des minutes, éventuellement des secondes et milli-secondes et correspond à un moment à l'intérieur d'une Date.
//      - TimeStamp : est un objet qui contient à la fois la date sur un calendrier, et à l'heure dans la journée de la date.
// Ces trois types sont trois classes Java, qui sont gérées par l'API JDBC, et qui se translattent aux trois types équivalents à l'intérieur des bases de données.
// Comment savons nous quel type nous allons avoir de retourné lorsque nous effectuons une requête sur un ResultSet.
// Pour rappel, sur les ResultSet, nous avons des méthodes get(), auxquelles nous passons soit un numéro de colonne, ce qui est un peu dangereux, soit un nom de colonne quand nous le connaissons.
// En fait nous avons trois méthodes get() possibles :
//      --> Date d = rs.getDate("...");
//      --> Time t = rs.getTime("...");
//      --> TimeStamp ts = rs.getTimeStamp("...");
// Donc il faut que nous connaissions le type de dates que nous manipulons dans la colonne correspondante, que nous appelions la méthode correspondante sur notre ResultSet pour avoir le bon type Java.
// Nous avons une dernière chose à voir, car toute cette API Time, Date & TimeStamp, correspondent à du vieux Java. A partir de Java 8, nous avons une nouvelle API :
//      --> Java 8 : API Date & Time.
// Celle-ci correspond au portage d'une API opensource à l'intérieur du JDK qui s'appelait JodaTime.
// Cette API Date & Time apporte tout un tas de nouvelles fonctionnalités à la manipulation des objets de type Date, Time et TimeStamp à l'intérieur du JDK.
// Malheureusement, vu que l'API JDBC est antérieure à l'API Date & Time, et donc elle travaille avec ces vieilles versions de Date, Time et TimeStamp.
// Toutefois, nous avons des méthodes 'pont', entre ces trois objets et les objets de l'API Date & Time.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gestion des dates avec JDBC ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser Date et Time avec JDBC ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Parlons rapidement et brièvement de l'API Date & Time qui est apparue en Java 8. C'est une API qui est très vaste et complexe, et nous allons nous concentrer sur la partie en rapport avec JDBC.
// D'abord, cette API expose trois objets :
//      - LocalDate ldate = LocalDate.of(2001, Month.APRIL, 17);
//      - LocalTime ltime = LocalTime.of(15, 37, 12 );
//      - LocalDateTime ldatetime = LocalDateTime.of(LocalDate, LocalTime);
// Comment pouvons-nous passer de l'univers de l'API Date & Time, à l'univers de la vieille API utilisée par JDBC ?
// Quand nous possédons un objet de type LocalDate, nous pouvons le passer en paramètre d'une méthode .valueOf() qui va nous retourner un objet de type Date :
//      --> Date d = Date.valueOf(ldate);
//      --> Time t = Time.valueOf(ltime);
//      --> TimeStamp ts = TimeStamp.valueOf(ldatetime);
// Maintenant si nous voulons faire l'inverse :
//      --> LocalDate ld = d.toLocalDate();
//      --> LocalTime lt = t.toLocalTime();
//      --> LocalDateTime ldt = ts.toLocalDateTime();

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A propos des fermetures de ressources JDBC ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fermeture des Connection, Statement et ResultSet //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tous les objets que nous venons de voir, les Connections, les PreparedStatements, les Statements et les RestulSets sont en fait des ressources système.
// Comme toutes les ressources systèmes que nous utilisons dans les applications Java, il y a une règle que nous devons absolument respecter :
//      --> Quand nous en ouvrons une, il est indispensable de la fermer après utilisation.
// A partir de Java 7, nous avons un mécanisme particulier, le pattern 'try-with-ressources' :
//      try(Connection conn = DriverManager.getConnection(...)){
//          ...
//      }
// En écrivant les choses de cette manière, nous avons la garantie que lorsque nous sortons du bloc try, la ressource système utilisée sera fermée.
// Ceci fonctionne, car l'objet Connection étends l'interface AutoCloseable.
// Il se trouve que Statement, PreparedStatement et ResultSet, étendent elles aussi, l'interface AutoCloseable.
// Nous pouvons ainsi utiliser ces trois interfaces dans le même genre de pattern que celui-ci.
// Maintenant, nous avons une règle supplémentaire, qui est que lorsque nous fermons une connection, donc une connection en tant qu'instance de l'interface Connection.
// Cela implique une fermeture également, des Statements, PreparedStatements et ResultSet qui ont été ajoutés à cette connection, donc qui ont été ouverts, ou créés à partir de cette connection.
// Maintenant, il y a un pattern qui consiste à dire que nous allons ouvrir notre connection au lancement de notre application, et la maintenir ouverte durant la durée de vie de cette application.
// Lorsque nous sommes dans ce cas là, il faut penser à fermer les Statements, PreparedStatements qui vont fermer les ResultSets automatiquement au fur et à mesure que nous les ouvrons.
// Car, lorsque nous ouvrons une connection, nous ne pouvons avoir qu'une certaine quantité de Statements et de PreparedStatements ouverts à un instant donné.
// Il y a une petite subtilité supplémentaire sur les ResultSets : lorsqu'il est fermé, dans certains cas, un ResultSet va conserver les résultats qu'il transportait de la base de données.
// Nous allons ainsi pouvoir continuer à les regarder et à les interroger, dans certains autres cas, ces résultats vont être perdus.
// Cette propriété s'appelle : 'Holdability'
//      - HOLD_CURSORS_AT_COMMIT : le contenu du ResultSet sera toujours disponible après la fermeture du ResultSet ou du Statement ou PreparedStatement sur lequel ce ResultSet a été construit.
//      - CLOSE_CURSORS_OVER_COMMIT : si nous fermons le Statement, PreparedStatement ou ResultSet, les résultats que portaient ce ResultSet ne seront plus disponible.
// En effectuant la méthode : .getHoldability(), cela nous retournera un entier qui va prendre l'une ou l'autre constante comme valeur.
// Autre subtilité, nous ne pouvons ouvrir qu'un seul ResultSet par Statement ou PreparedStatement.
// Si nous lançons une seconde requête avec un Statement ou PreparedStatement, le ResultSet précédent sera écrasé, et donc ne sera plus disponible.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transactions avec JDBC ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transactions ACID /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Parlons à présent d'une notion fondamentale en base de données, la notion de 'Transaction', elle est définie dans les bases de données relationnelles, donc dans les bases de données SQL.
// Cette notion a été translattée vers les bases de données NoSQL, mais comme ce type de base de données à souvent des problèmes de charges et de volumes de données, cette notion a été un peu relachée.
// Les transactions en bases SQL sont caractérisées par l'acronyme A.C.I.D., ainsi, les transactions ont donc 4 propriétés :
// La première chose qu'il faut comprendre est qu'une transaction est un ensemble d'opérations en base de données, et en général, des opérations de modifications.
// Par exemple, comme ensemble d'opérations, nous pouvons avoir un transfert d'argent entre un compte A et un compte B.
//      - A : Atomicité : cela signifie qu'une transaction est 'indivisible'.
//      - C : Cohérence : le respect de toutes les contraintes d'intégrité que nous pouvons avoir dans une base de données.
//              Nous avons deux contraintes d'intégrités auxquelles nous pouvons penser : les contraintes de 'clés primaires' et les contraintes de 'clés étrangères'.
//              - Clef primaire signifie que dans une colonne donnée, toutes les valeurs sont non-nulles et doivent être différentes.
//              - Clef étrangère signifie qu'une colonne donnée référence forcément la clef primaire qui est la clef d'une autre table.
//              A l'intérieur d'une transaction, nous pouvons très bien lever ces contraintes :
//              Donc lorsque nous effectuons l'insertion d'un objet dans une table, il se peut que celui-ci n'ait pas de clef primaire, et puis après nous n'en aurons qu'une.
//              En revanche, lorsque nous sortons de notre transaction, toutes les contraintes de clef primaires et de clefs étrangères, ainsi que les autres doivent être vérifiées.
//      - I : Isolation : Ceci est un point fondamental dans les bases de données.
//              Si nous avons un premier utilisateur qui fait des insertions dans une table, il les fait dans le cadre d'une transaction. Lorsqu'il à fini ses insertions, il termine sa transactions.
//              Ainsi, les résultats de sa transaction sont que les données ont bien été insérées. Toutefois nous avons un autre utilisateur qui est en train de faire des requêtes sur cette même table.
//              Et ce, en même temps que des insertions sont effectuées par le premier utilisateur. A partir de quel moment est-ce que le second utilisateur va voir les données insérées par le premier.
//      - D : Durabilité : Si nous mettons des données en base de données et que nous éteignons la machine sur laquelle elle se situe, en la rallumant, nous nous attendons a toujours y avoir les données.
//              Cela signifie donc que les données ne sont pas volatiles, et qu'une fois qu'elles sont écrites, elles le sont "pour toujours".

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transaction manuelle avec JDBC ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Techniquement, comment est-ce que ce mécanisme de transaction est-il géré par l'API JDBC ?
// La première chose à savoir est que dans JDBC, les transactions sont gérées par l'objet Connection.
// Ce n'est pas forcément très intuitif puisqu'en fait, le transfert de données SQL est assuré par l'objet Statement, ou PreparedStatement.
// Par défaut, les connections sont en mode 'AUTO_COMMIT'.
// Cela signifie que dès que nous exécutons une requête SQL au travers d'un Statement ou d'un PreparedStatement, qu'elle soit de type select ou de type mise à jour.
// Le commit de la transaction va être demandé à la fin de l'exécution de la transaction, et ce, pour chaque transaction.
// Le commit est l'action qui consiste à dire que la transaction est terminée, il faut valider les écritures ou les lectures et éventuellement passer à une autre transaction.
// Le commit veux donc dire que les choses se sont bien passées au niveau de la requête SQL. Si jamais nous avons une exception, la transaction va être au statut 'ROLLBACK'.
// Nous pouvons changer ce mécanisme d'AUTO_COMMIT avec une méthode sur l'objet Connection : setAutoCommit(boolean), et en passant false.
// Cet AUTO_COMMIT est une propriété de l'objet Connection donc nous pouvons la tester avec une méthode isAutoCommit().
// Si nous passons false à la méthode setAutoCommit(), nous devrons gérer nos transactions nous-même et nous devrons passer une autre méthode sur l'objet Connection : conn.commit();.
// Si jamais nous oublions de le faire, les actions en base de données pourront très bien être rollbackées par la base de données elle-même.
// Nous pouvons également appeler de notre application Java : conn.rollback(), qui annulera les modifications effectuées sur la base de données SQL.
// Si nous gérons les commit à la main, cela signifie que notre objet Connection devient propre à une transaction.
// Donc nous ne pourrons plus avoir un objet Connection qui est commun à l'intégralité de notre application et dans laquelle nous allons faire tous nos Statements, PreparedStatements et ResultSets.
// Nous pouvons également ajouter dans notre objet Connection des SavePoints :
//      SavePoint savePoint = conn.setSavePoint();
// Un SavePoint est un point intermédiaire dans une série d'opérations d'une transaction que nous allons pouvoir passer en paramètres d'une méthode .rollback().
// Si nous effectuons un rollback() sans paramètre, cela va annuler l'intégralité de la transaction.
// Si nous passons un SavePoint en paramètre à un rollback(), cela va annuler uniquement les opérations entre le SavePoint et le moment ou la méthode rollback() est appelée.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transactions NONE et READ UNCOMMITTED /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons comment les transactions sont gérées dans l'API JDBC, c'est un mécanisme assez subtil, et les difficultés qu'il y a dans les bases de données vont être translattées dans l'API JDBC.
// Supposons que nous avons deux transactions T1 et T2, menées par deux utilisateurs User1 et User2.
// T1 va faire trois insertions puis un commit. T2 va faire un select sur la même table qui est écrite par T1, puis va s'arrêter par un commit qui a lieu avant le commit de T1.
// Nous parlons de niveau d'isolation des transactions, à la fois en base de données et dans JDBC, voici les différents niveaux d'isolation :
//      --> NONE : aucune isolation, dans ce cas là, les transactions ne sont pas gérées.
//      --> READ_UNCOMMITED : nous avons des transactions, et par exemple, T2 va lire les données insérées par T1 au fur et à mesure que T1 les insères, et ce, avant le commit de T1.
// Ceci pose problème car nous ne savons pas encore si T1 va commiter sa transactions au moment où elles sont lues par T2. Donc les données lues peuvent être corrompues.
// Nous appelons ceci des "dirty reads".

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transaction READ COMMITTED ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Troisième niveau d'isolation :
//      --> READ_COMMITED : cela signifie que nous sommes protégés contre les dirty reads.
// Donc par rapport à notre exemple précédent, si User1 fait des insertions sur T1, tant qu'elles ne sont pas commitées, User2 ne pourra pas les lire et lire la version non commitée.
// Toutefois cela ne veux pas dire que nous ne pourrons pas voir d'artefact. En effet, T2 pourrait se voir retourné un objet 'A', d'une de ses requêtes select.
// Or il se trouve que T1 est précisémment en train de faire un update sur l'objet A. Donc si T2 lis A après la mise à jour de A par T1, il ne lira pas A mais A'.
// --> Donc les updates ne sont pas protégés par le niveau d'isolation READ_COMMITED.
// Nous appelons cela les "non repeatable reads", dans lesquels les valeurs d'un champs peuvent être différents d'un select à un autre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Transactions REPEATABLE READ et SERIALIZABLE //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le quatrième niveau d'isolation que nous allons voir est le suivant :
//      --> REPEATABLE_READ : ce niveau d'isolation nous garantie de ne pas avoir de non-repeatable reads dans notre transaction.
// Supposons que T1 fait toujours des insertions, et T2 fait des select, mais des select différents des précédents.
// Ce sont des select between, donc des select sur des plages d'objets entre deux bornes à chaque fois.
// Si jamais T1 à inséré des objets dans la plage d'objets que lis T2, User2 va les voir.
// Ces objets insérés par T1 qui apparaissent dans les plages de lecture de T2 sont nommés des 'phantom reads'.
// Enfin, nous avons un dernier niveau d'isolation :
//      --> SERIALIZABLE : tout se passe comme si aucune transaction n'avait lieu en même temps qu'une autre.
// Ce niveau est très coûteux à mettre en oeuvre car il faut prévenir tous les artéfact de lecture qu'il peut y avoir entre les données écrites par une transaction et les données lues par une autre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Isolation des transactions JDBC ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment pouvons-nous gérer ces 5 niveaux d'isolation dans l'API JDBC ?
// C'est géré directement sur l'objet Connection :
//      --> conn.getTrasactionIsolation();
// Cette méthode va nous retourner un integer qui représente une des 5 constantes que nous avons vu précédemment.
// Les constantes ont les noms exacts suivants :
//      - TRANSACTION_NONE.
//      - TRANSACTION_READ_UNCOMMITTED.
//      - TRANSACTION_READ_COMMITTED.
//      - TRANSACTION_REPEATABLE_READ.
//      - TRANSACTION_SERIALIZABLE.
// Nous pouvons également appeler la méthode suivante :
//      --> conn.setTransactionIsolation(...) : En lui passant la valeur de la constante que nous souhaitons fixer.
// Toutefois, tous les drivers JDBC ne gèrent pas forcémment l'intégralité de ces niveaux d'isolation.
// Lorsque nous créons une connection, nous avons un niveau d'isolation par défaut qui est choisi par le driver et qui est en général : READ_COMMITTED ou REPEATABLE_READ.
// Cette information, nous l'avons dans la documentation du driver, ou lorsque nous créons un objet Connection et que nous lui passons la méthode getTransactionIsolation().
// Il est important de comprendre quels sont les impacts de performance sur nos serveurs de base de données liés à ces niveaux d'isolation des connections.
// Plus nous demandons un niveau d'isolation précis, plus nous allons mettre de contraintes sur nos serveurs de base de données, plus cela engendrera des problèmes de performance.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan de l'API JDBC ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Effectuons à présent un bilan sur ce que nous avons vu sur l'API JDBC :
// Nous avons vu tout d'abord, les trois objets fondamentaux de l'API :
//      - Connection.
//      - Statement, et son extension PreparedStatement.
//      - ResultSet.
// Nous avons vu que nous pouvions gérer les transactions, et que leur isolation était un point très important.
// Nous avons aussi vu qu'il était possible de récupérer les méta-données d'un ResultSet.
// De plus, nous avons vu quelques points sur la sécurité, et notamment comment se prémunir contre le SQL-Injection : Nous banissons la concaténation des chaînes de caractères.
// Nous avons aussi vu comment est gérée la date : l'API Date & Time et comment passer de l'ancienne API à celle-ci étant donné que JDBC travaille avec l'ancienne.
// Aussi, nous avons vu la possibilité de créer des batch à partir de ces objets statements lorsque nous avons de nombreuses petites requêtes de petite taille a effectuer.
// JDBC est la brique de construction sur laquelle est basée JPA, qui est une autre API implémentée par Hibernate.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : JPA et Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ce module est une présentation de JPA et Hibernate. Nous allons découvrir :
//      - La définition de JPA et à quoi servent JPA et Hibernate dans vos applications.
//      - Les différents concepts sous-jacents à JPA.
//      - Comment gérer le mapping de nos objets (Entités) avec le monde relationnel.
//      - Le cycle de vie d'une entité JPA.
//      - Comment gérer avec JPA les relations entre Entités.
//      - La gestion du mapping objet/relationnel avec les structures de l'API Collection.
//      - Le mapping de l'héritage Objet.
//      - Comment écrire des requêtes SQL Natives et des requêtes via le langage JPQL.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à JPA et Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définition de JPA, Hibernate et au mapping objet relationnel //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Parlons à présent d'une API qui s'appelle JPA pour Java Persistence API.
// Faire de la persistance, ou persister un objet consiste à prendre un objet dans notre application, et nous allons écrire l'état, donc les champs de cet objet dans une base de données.
// Les opérations de persistance vont consister bien sûr à faire cette écriture, puis à faire des lectures, faire des sélections, et des mises à jour, voire à écraser ces champs par d'autres.
// C'est probablement une des API les plus importantes de Java en dehors évidemment des API coeur de Java telles que Stream ou Collector.
// JPA est associé à une autre API qui s'appelle Hibernate. Celui-ci est un outil universel dans les applications Java.
// Techniquement, JPA est la spécification. Tout comme JDBC, ce sont essentiellement des interfaces, et des annotations.
// Hibernate est une implémentation de JPA, il en existe d'autres comme EclipseLink ou OpenJPA.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A quoi servent JPA et Hibernate ? /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avant de rentrer dans les détails technique. Quels services JPA et Hibernate rendent-ils dans une application ?
// Supposons que nous avons des objets dans une application, de type User, qui ont des champs tels que nom et date de naissance. Ceci appartient à l'application Java.
// D'un autre côté nous avons une table qui se nomme User, qui contient une clef primaire ID, puis une clef nom et une clef date de naissance.
// Nous avons donc une correspondance entre notre classe User, et notre table User.
// Une classe s'instantie, cela permet de créer des objets, et dans une table nous pouvons rajouter des lignes, ou encore des enregistrements.
// Donc les objets vont correspondre à une ligne dans notre table.
// Hibernate ou JPA sont l'outil qui vont nous permettre de faire la mise en relation entre l'objet et sa ou ses tables.
// Ces API font donc du mapping ORM, de l'Object Relationnal Mapping entre ce qu'il se passe dans notre application, et ce qu'il se passe dans notre base de données relationnelle.
// En quoi consiste cette association ?
// Plutôt d'écrire du code JDBC pour par exemple faire une insertion d'un objet instance de User dans la table User, nous allons utiliser JPA et son implémentation Hibernate pour l'automatiser.
// Techniquement, nous allons faire des déclarations au niveau de notre classe User pour signifier qu'elle est associée à la table User.
// Nous allons associer chaque champs à une colonne. Hibernate et JPA vont nous fournir les classes et le code pour générer automatiquement les requêtes SQL pour le faire.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Problème de l'impedance mismatch //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avant d'aller plus loin, voyons quels sont les problèmes posés par ce mapping d'objets relationnels.
// Qu'avons nous dans nos classes quand nous sommes dans l'espace de nos objets Java : Nous avons des List, des Map et de l'Héritage (il est normal qu'une classe puisse hériter d'une autre classe).
// Quand nous sommes dans l'espace de nos bases de données, nous disposons de relations entre les tables : 1:1, 1:p, p:1 et n:p, nous n'avons pas d'héritage.
// Comment est-ce que la relation va se faire avec l'aide d'Hibernate ? Elle va se faire un peu dans la douleur.
// C'est ce que nous appelons 'Impedance Mismatch', ou le problème d'adaptation d'inpédance.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les concepts dans JPA /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'une première Entité JPA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Afin de voir dans quelle direction nous allons aller, nous allons commencer par voir un exemple vraiment très simple d'application mapping objet relationnel.
// Nous avons une classe User qui à un champs nom et un champs âge, et à coté de cela nous avons une table, qui à pour colonnes les mêmes noms que les champs de notre classe.
// La première chose qu'il faut faire pour qu'une classe soit associée à une table via JPA :
//      - Il faut que cette classe soit associée à un Bean, pour être un bean, il nous faut trois choses :
//              --> Il faut que la classe implémente Serializable. Celle-ci n'est toutefois pas absolument nécessaire, mais elle est très fortement recommandée.
//              --> Il nous faut avoir un constructeur vide. Celui-ci est présent si nous ne mettons pas de constructeur dans notre classe (il est ajouté automatiquement).
//                  Toutefois, si nous créons un constructeur non-vide dans notre classe, il nous faudra aussi ajouter un constructeur vide en plus.
//              --> Il nous faut un getter et un setter pour chaque champs de notre classe. Ceux-ci n'ont pas forcément le même nom que le champs, il peut être différent.
//                  En général nous lui donnons le même nom, mais ce n'est pas obligatoire. En revanche, il faut que le getter et le setter se correspondent l'un à l'autre.
//      - Dans l'univers des bases de données, toute table doit posséder une clef primaire (ID en général). Cette clef primaire doit correspondre à un champs de notre classe.
//      - Nous avons besoin de dire à JPA que cette classe est associée à une table en base dans de données, et que le champs primaire, est le champs ID.
//          Pour cela nous ajoutons une annotation : @Entity. En faisant cela, JPA et Hibernate vont savoir que cette classe est en fait une entité JPA.
//          Une entité JPA est une classe qui peut aller en base de données. Dans un premier temps elle sera associée à une table en particulier, mais nous verrons que les choses sont plus riches que ça.
//          Pour préciser quel est le champs primaire, nous effectuons une annotation aussi : @Id. Ces deux annotations doivent être importées dans un fichier Java pour que cela fonctionne.
//          Donc techniquement, une entité se comporte presque comme une interface puisque nous devons l'importer.
// --> Une fois que tout cela est fait, notre classe est une entité JPA, prête a être traitée par Hibernate et prête a être associée à une table en base de données.
//      @Entity
//      public class User implements Serializable {
//          @Id private int id;
//          private String name;
//          private int age;
//          // constructeur vide
//          // Getters & Setters
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Unité de persistence avec persistence.xml /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour construire une classe JPA, il nous manque encore une chose, un descripteur xml, qui se nomme 'persistence.xml', et qui va vivre dans un répertoire particulier de notre application Java : META-INF.
//      --> META-INF/persistence.xml : c'est un fichier qui va contenir la description et le paramétrage de notre application JPA, de nos entités JPA entre autres.
// Tous les documents .xml ont un unique élément racine : 'persistence', qui est associé à un namespace, il a aussi des attributs techniques, notamment des versions, en fonction de la version de JPA.
// Nous allons trouver dans cet élément racine, un premier élément qui s'appelle 'persistence-unit', nous pouvons d'ailleurs en avoir plusieurs de ces sous-éléments là.
// Une unité de persistence, techniquement c'est un ensemble d'entités JPA qui en fait appartiennent à la même application JPA.
// Cette persistence-unit va donc référencer des classes qui en général sont dans le même projet Java, mais elles peuvent en fait être dans différents package ou différents projets.
// Cet élément a deux attributs :
//      --> name="test-jpa" : qui représente le nom logique de cette unité de persistence. Ce nom est très important car c'est lui que nous allons référencer dans notre code.
//      --> transaction-type="..." : elle peut prendre l'une ou l'autre des deux valeurs suivante, mais pas les deux :
//              - "JTA" : qui signifie que dans le contexte de notre application, les transactions vont être gérées automatiquement.
//              - "RESSOURCE_LOCAL" : qui signifie que dns le contexte de notre application, nous allons gérer les transactions à la main.
// Dans un premier temps nous allons nous intéresser au type RESSOURCE_LOCAL, nous utiliserons JTA par la suite.
// Cet élément persistence-unit a d'autres sous-éléments, dont un qui se nomme 'provider' est qui est très important. Il va fixer le type de l'implémentation de JPA dont nous avons besoin.
// JPA est une spécification, un peu comme un standard, cela défini des interfaces et des implémentations, et pour que cela fonctionne, nous avons besoin d'une implémentation.
// Exactement comme avec JDBC, avec JDBC, nous avions des classes, et beaucoup d'interfaces, et nous avions besoin du driver MySQL pour JDBC qui contenait les implémentations de ces interfaces.
// Pour JPA c'est exactement la même chose, nous avons les interfaces JPA, et Hibernate (ou EclipseLink) en contient les implémentations.
// Cette classe provider est une classe particulière qui implémente une interface JPA qui s'appelle 'PersistenceProvider'. Pour Hibernate cela sera : org.hibernate.jps.HibernatePersistenceProvider.
// Le fait de faire cette déclaration signifie que notre entité JPA va être gérée par Hibernate.
// Ensuite, nous avons un ensemble de sous-éléments qui s'appellent 'class', et qui vont lister les classes gérées par JPA.
// Nous ne sommes pas obligé de lister nos classes une par une comme ci-dessous, nous pouvons aussi donner des noms de .jar, avec un certain nombre de règles par défaut.
// Ainsi, notre unité de persistence va être capable d'aller découvrir les classes annotées par JPA dans notre système.
// Mais disons que d'une façon ou d'une autre (et celle-ci est la plus simple), nous devons indiquer à notre unité de persistence quelle classe doit être gérée.
// Il est important de le faire car sinon, cela va provoquer des erreurs.
//      <persistence ...>
//          <persistence-unit
//              name="test-jpa"
//              transaction-type="JTA" // transaction-type="RESSOURCE_LOCAL"
//              >
//              <provider>
//                  org.hibernate.jps.HibernatePersistenceProvider
//              </provider>
//              <class>
//                  org.vitu.model.User
//              </class>
//          </persistence-unit>
//      </persistence>
// Il y a aussi quelques autres éléments que nous pouvons mettre dans ce fichier, et nous allons le voir tout de suite.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Configurer une unité de persistence ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Autre sous-élément que nous allons voir dans persistence-unit, le sous-élément 'properties'. C'est un sous-élément supplémentaire que nous pouvons ajouter aux sous-éléments vus précédemment.
// C'est un sous-élément wrapper, pour envelloper autant de sous-éléments 'property' que nous le souhaitons. Sachant qu'une propriété est juste une paire clef-valeur.
// Cette paire à un nom, et une valeur qui correspond à la valeur de ce nom. Ce nom et cette valeur sont évidemment des chaînes de caractères puisque nous sommes dans un document XML.
// Ces properties sont très importantes, il y en a même qui sont obligatoires, sans lesquelles notre système ne pourra pas fonctionner.
// Nous avons deux types de propriétés :
//      - Standard JPA : certaines sont optionnelles et certaines sont obligatoires. Celles-ci commencent toutes par 'javax.persistence'.
//      - Propres à l'implémentation choisie. Les implémenteurs ont le droit d'utiliser des propriétés que les utilisateurs ont le droit de fixer dans le persistence.xml.
// Nous allons tout de suite voir quelques propriétés très importantes :
//      --> javax.persistence.jdbc.url : jdbc:mysql:localhost3306/nomDeLaBaseDeDonnees.
//      --> javax.persistence.jdbc.driver : com.mysql.driver.mysqldriver.
//      --> javax.persistence.jdbc.user.
//      --> javax.persistence.jdbc.password.
// Pour se connecter à une base de données, JDBC à besoin d'une url, d'une implémentation qui lui est fournie sous la forme d'un nom de driver, d'un password et d'un user.
// Donc les noms de ces 4 propriétés vont être placées dans le champs 'name' de chacune des property, et les valeurs dans chacuns des champs 'value' des sous-éléments property.
// Dans le cas d'Hybernate, nous allons avoir d'autre propriétés propres à Hibernate, et qui sont par conséquent toutes préfixées par 'hibernate' :
//      --> hibernate.hbm2ddl : ce qui va permettre de fixer le comportement d'hibernate vis à vis de l'existence ou non des tables associées à nos entités JPA.
//          Cette propriété peut prendre différentes valeurs :
//              - validate : Hibernate va juste faire de la validation, si la table est absente il va partir en erreur et l'application ne se lancera pas.
//              - update : Hibernate va mettre la table à jour.
//              - create : Hibernate va chercher à créer la table.
//              - create-drop : Hibernate va chercher à créer la table, et quand l'application va se fermer, il va droper la table.
//                  Ce dernier comportement est à la fois pratique et un petit peu déroutant. En effet, lorsque l'application s'éteint, toutes les données en base de données auront disparu.
//      --> hibernate.dialect : Hibernate, comme toutes les implémentations de JPA, va générer des requêtes SQL vers la base de données.
//          Si nous ne lui disons pas que la base de données est par exemple une base de données MySQL 5, SQL Server, ou PostGres, Hibernate va utiliser un SQL très basique.
//          Mais celui-ci fonctionnera sur toutes les bases de données. En précisant un dialect, précisées dans la documentation Hibernate, ce sera beaucoup plus performant.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer un entity manager pour un unité de persistence //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous avons créé une classe User, qui à été annotée avec une entité et un id pour en faire une entité JPA.
// Et dans notre projet, nous avons également créé ce descripteur xml, persistence.xml, rangé au bon endroit, META-INF/persistence.xml, de manière à créer une unité de persistence Java avec cette classe.
//      @Entity
//      public class User{
//          @Id
//          private int id;
//          private String name;
//          // getters & setters
//      }
// Maintenant quel code pouvons nous écrire pour écrire nos instances de la classe User en base de données et pour les relier ?
// Tout part d'une classe particulière de l'API JPA qui s'appelle 'Persistence', qui possède une méthode factory qui s'appelle 'createEntityManagerFactory(...)'.
// Nous allons lui passer une chaîne de caractères en paramètres qui porte le nom de l'unité de persistence que nous voulons référencier dans notre fichier persistence.xml :
//      --> EntityManagerFactory emf = Persistence.createEntityManagerFactory("jpa-test");
// Ceci nous retourne donc un objet EntityManagerFactory. Il sera correctement construit si :
//      - Si la connection à la base de données est correcte.
//      - Si la configuration de notre entité de persistence est correcte.
//      - Si les entités qui sont référencées dans le fichier persistence.xml sont correctement configurées.
// A partir de là, tous les aspects techniques de notre module JPA sont d'équerre et ont été correctement écrits.
// Cet objet emf à un rôle en particulier, qui est de créer un objet qui est un 'EntityManager'.
// C'est cet objet EntityManager qui va nous permettre de mener à bien toutes les opérations de persistence dont nous avons besoin (création, mise à jour, récupération ou effacement des objets).
//      --> EntityManager em = emf.createEntityManager();
// Toutes les méthodes de persistence sont définies sur l'interface EntityManager.
// Au niveau technique, Persistence est une classe, qui expose une méthode factory a laquelle nous passons le nom de notre unité de persistence en paramètre.
// L'unité de persistence est définie dans le fichier persistence.xml.
// Or dans l'unité de persistence, nous avons le nom d'une classe qui est une chaîne de caractères qui est une implémentation de PersistenceProvider.
// Donc, cette méthode factory createEntityManagerFactory va pouvoir instancier cette classe par réflexion et créer les différents objets dont nous avons besoin.
// EntityManagerFactory est une interface, la classe qui implémente cette interface va être fournie par Hibernate, et c'est Hibernate qui est référencée dans le fichier persistence.xml.
// EntityManager est également une interface, dont l'implémentation est propre à chaque implémentation de JPA que nous allons utiliser.
// Donc à partir de tout cela, nous pourrons mener à bien toutes nos opérations de persistence.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un premier bean en base à l'aide d'un entity manager ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous avons une entité JPA au travers d'une classe User, avec son annotation @Entity, sa clef primaire @Id qui a été définie, et associée à un fichier META-INF/persistence.xml.
// Nous avons aussi déjà créé une instance de notre bean User, ainsi que créé un EntityManager.
// La première opération que nous allons voir est l'opération 'Create'. Elle consiste à écrire ce bean User, dans la base de données.
// Etant donné qu'il s'agisse d'une opération de modification de la base de données, elle doit se dérouler dans le contexte d'une transaction.
//      User user = ...;
//      EntityManager em = ...;
//      em.getTransaction().begin();
//      em.persist(user);
//      ...
//      em.getTransaction().commit();
// Nous n'avons pas besoin de mettre cette transaction dans une variable car en fait, un EntityManager est toujours associé à une seule transaction.
// Donc quand nous éxecutons em.getTransaction(), nous récupérons la transaction portée par l'EntityManager em.
// Sur la transaction que nous récupérons, nous pouvons appeler la méthode begin(), qui marque le démarrage de la transaction.
// Dans cette transaction, nous allons pouvoir appeler la méthode persist() en lui passant notre bean User en paramètre.
// Eventuellement, nous pouvons avoir d'autres actions de persistence dans cette transaction. Puis nous pouvons appeler la méthode commit(), sur l'objet transaction de notre EntityManager.
// Ceci nous permet de valider les opérations en base de données qui sont dans cette transaction. Si nous voulons annuler les choses, nous avons également une méthode rollback().

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Extraire un bean d'une base en fonction de sa classe et de sa clé primaire ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième opération, l'opération de type 'Retrieve'. Supposons que nous souhaitons récupérer l'utilisateur dont la clef primaire est 12.
// Pour ça nous avons une méthode sur EntityManager qui s'appelle 'find()' et qui prends deux paramètres : la classe de l'utilisateur, puis l'objet qui correspond à sa clef primaire.
//      --> User user = em.find(User.class, 12);
// Il s'agit d'une opération de type 'select', donc elle n'est pas nécessairement attachée à une transaction.
// Nous pouvons très bien l'exécuter à l'extérieur du contexte d'une transaction aussi.
// Cette méthode nous retourne un bean User complètement constitué. En effet, étant donné que la méthode find() prends la classe de l'élément en paramètre, nous n'avons pas besoin de faire de 'cast'.
// Ce find() va ainsi nous retourner un objet du même type.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mise à jour des champs d'un bean //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Troisième type d'opération, l'opération 'Update'. C'est à dire l'opération de mise à jour.
// Supposons que nous souhaitions mettre l'âge de notre utilisateur user dont la clef primaire est 12, à jour :
//      User user = em.find(User.class, 12);
//      user.setAge(12);
// D'abord nous allons devoir récupérer notre utilisateur via la méthode find(), comme vu précédemment. Puis nous allons devoir effectuer la méthode setAge(12), puisqu'il vient d'avoir 12 ans.
// Comme il s'agit d'une mise à jour, le setAge() au minimum, car ce n'est pas obligatoire pour le find() comme vu précédemment, doit être effectué dans le contexte d'une transaction :
//      em.getTransaction().begin();
//      User user = em.find(User.class, 12);
//      user.setAge(12);
//      em.getTransaction().commit();
// Nous pouvons voir que quelque chose d'un petit peu magique se passe car nous n'avons pas de méthode 'update' sur notre EntityManager.
// Le simple fait de prendre un objet JPA, donc un bean persistent, qui a été récupéré ou qui a été persisté au travers d'un EntityManager, va générer une requête update en base de données.
// Et ce, dès l'instant que nous modifions l'un de ces champs. C'est comme ça que cela fonctionne.
// --> En fait, le bean que nous récupérons a été instrumenté par JPA, Hibernate ou EclipseLink.
// Et ceci, de sorte que dès qu'une modification est faite sur l'un de ses champs interne, Hibernate ou EclipseLink vont être en quelque sortes 'mis au courant', ou encore notifiés.
// Et donc quand nous allons demander un commit() de la transaction, toutes ces modifications vont générer des updates automatiquement pour nous dans la base de données.
// Ceci est une des grandes forces de JPA. Toutefois, cela peut aussi être un risque ou un danger.
// Par exemple, si dans nos utilisateurs nous avons une liste d'objets qui sont des objets persistents, il faut aussi nous protéger contre les modifications intempestives de cette liste en interne.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Effacement d'un bean d'une base, bilan sur les opérations CRUD en JPA /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernière opération, l'opération de type 'delete'. Supposons que nous voulons supprimer le user dont la clef primaire est 12.
//      em.getTransaction().begin();
//      User user = em.find(User.class, 12);
//      em.remove(user);
//      em.getTransaction().commit();
// Cette méthode remove, prends un bean JPA, une entité JPA entièrement constituée, et elle va générer un 'delete' dans la base de données.
// Comme il s'agit d'une opération de modification de la base de données, elle doit être faite dans le cadre d'une transaction.
// Avant que nous puissions faire un remove(), nous devons faire un find(), ce qui est un peu un inconvéniant.
// Nous aurions peut-être préféré effectuer notre remove(), en y passant juste la classe et la clef primaire, mais ce n'est pas comme ça que cela fonctionne.
// Cette méthode remove() va générer une requête de type 'delete' dans la base de données.
// Lorsque nous allons récupérer cette instance d'utilisateur pour ensuite l'effacer, il faut faire attention a éviter de récupérer tous les objets qu'il a en relation.
// Nous verrons cela par la suite, notamment pour un soucis de performance, car nous ne voulons pas supprimer l'ensemble des objets qu'il a en relation mais juste le bean User.
// L'ensemble de ces 4 opérations SQL basiques sont souvent utilisées via l'acronyme CRUD :
//      - C : Create.
//      - R : Retrieve.
//      - U : Update.
//      - D : Delete.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Confier la génération des valeurs de clés primaires à JPA /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous avons notre bean User qui est une entité JPA. Que se passe t'il si nous faisons :
//      @Entity
//      public class User
//      @Id
//      private int id;
//      ...
//      User user = new User(...);
//      em.persist(user);
// Donc la nous sommes sensés avoir créé notre user avec ses attributs, ou ses champs. Puis par le persist(), nous l'avons écris en base de données. Ou tout du moins sur le commit() de la transaction.
// Et là nous nous attendons a ce que l'insertion fonctionne. Toutefois, nous avons quand même un problème avec la valeur de la clef primaire.
// Si nous n'y prenons pas garde, si nous ne fixons pas nous-mêmes la valeur de la clef primaire, nous avons toutes les chances pour que les choses se passent mal.
// Car si la clef primaire est égale à 0, la base de données va nous dire qu'elle à déjà une ligne avec une clef primaire qui a cette valeur là.
// Si nous avons énormément de lignes dans notre table User, cela va devenir assez compliqué très rapidement, de trouver des valeurs de clefs primaires qui ne sont pas déjà utilisées.
// En fait lorsque nous construisons des bases de données, en général, la génération des valeurs des clefs primaires est quelque chose qui est confié à la base de données directement.
// Ici, en JPA, nous avons deux solutions, soit nous le confions à la base de données, et nous récupérons la valeur que la base de données a généré pour nous.
// Soit, nous le confions à Hibernate qui va utiliser lui-même des mécanismes de base de données pour générer ces valeurs de clefs primaires, et nous donner la valeur qu'il aura généré.
// Dans tous les cas, nous fixons cela avec une annotation qui s'appelle '@GeneratedValue', pour dire que ce n'est pas nous qui allons nous occuper de la génération des valeurs de clef primaires.
// Cette annotation prends un attribut qui s'appelle 'strategy', et cet attribut prends comme valeur une constante 'GenerationType' qui peut prendre plusieurs valeurs :
//      - AUTO : qui confie la génération de valeurs de clefs primaires à Hibernate, ce qui fonctionne très bien.
//      - IDENTITY :
//      - TABLE :
//      - SEQUENCE :
// Donc, en fonction de ce que nous avons dit à Hibernate, et en fonction de la base de données sur laquelle nous nous trouvons, Hibernate va choisir la meilleur stratégie pour générer nos clefs primaires.
// Dans certains cas il va choisir des colonnes incrémentables, ou il va lui même créer des tables pour simuler des séquences.
// Ou encore si il est sur une base de données qui supporte les séquences nativement, il va pouvoir également utiliser ces séquences.
// Donc ceci est un point très important, cette annotation là n'est pas obligatoire mais dans la pratique nous l'utilisons quasiment tout le temps.
// En effet, gérer soi-même les valeurs des clefs primaires à la main n'est vraiment pas possible.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Choisir le mode d'accès aux valeurs des champs d'une entité JPA ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Par quel tour de magie, Hibernate va être capable de lire les éléments qu'il y a dans une classe, et en création, d'aller lire les éléments qu'il y a dans la base de données.
// Donc de lire les valeurs d'un User en particulier qui est dans la classe, de façon à recréer une instance de User.
// En fait il n'y a pas du tout de magie, il y a seulement une utilisation particulière de l'API Reflection. Hibernate est un framework qui utilise massivement l'API Reflection.
// Pourquoi imposons nous un constructeur vide, dans chaque entité JPA ? C'est tout simplement pour qu'Hibernate et les autres implémentations puissent instancier ces classes.
// Et ce, en appelant un constructeur dont ces framework sont absoblument certains qu'il est toujours là et qu'il est un constructeur vide. Ceci, grâce à l'API Reflection.
// Ensuite, ils peuvent aller chercher les champs, obtenir les valeurs des annotations qui se trouvent sur les champs, et associer les colonnes de la table aux champs qui se trouvent dans les classes Java.
// Si jamais nous avons une annotation colonne, Hibernate va aller chercher la bonne valeur de l'attribut dans cette annotation et donc associer un nom de colonne à un champs.
// Et il y a un comportement par défaut qui est le nom du champs qui correspond au nom de la colonne.
// Cela dit, il y a une petite subtilité, car pour lire un champs il y a deux méthodes en utilisant l'API Reflection :
//      --> Nous pouvons utiliser la classe 'Field', qui nous donne directement accès au champ privé.
//      --> Nous pouvons également utiliser la classe 'Method'. Etant donné que nous avons un bean, nous savons que les propriétés sont associées a des getters et des setters.
//          Et ceux-ci, une fois que nous avons construit leurs noms, nous pouvons aller chercher la méthode correspondante.
// Quelle façon de faire, Hibernate va t-il choisir ?
// Dans le standard JPA, il est imposé que toutes les implémentations JPA doivent être capables de supporter les deux types d'accès. Soit directement sur les champs, soit en passant par les méthodes.
// L'accès aux champs privés est quelque chose qui peut éventuellement poser problème. Il y a des contrôles de sécurité sur l'accès aux champs privés par reflection.
// Donc si jamais ces contrôles de sécurité doivent être activés, parce que l'application globalement doit être sécurisée, il est possible que l'accès par les champs ne soient pas disponibles.
// Donc que nous soyons obligés d'utiliser l'accès par les méthodes. Ce n'est pas un problème, nous pouvons annoter nos classes avec une annotation qui s'appelle '@Access'.
// Celle-ci prends en paramètre, une constante de type AccessType, cette constrante peut prendre deux valeurs :
//      - Field : auquel cas l'implémentation JPA va faire de la reflection directement sur les champs, donc en utilisant la classe 'Field' de l'API Reflection.
//      - Property : auquel cas l'implémentation JPA va utiliser les getters et les setters pour aller lire les valeurs des propriétés.
// Les deux fonctionnent, les deux répondent à des besoins qui sont différents.
// Quand nous sommes dans un environnement sécurisé, il arrive que l'accès par les champs, ne soient tout simplement pas disponibles, auquel cas nous allons utiliser l'accès par les propriétés.
// Cela signifie que toutes les annotations que nous avons mises pour l'instant sur les champs, si jamais nous choisissons l'accès 'PROPERTY', nous pouvons les mettre égalements sur les getters.
// C'est éventuellement un petit peu moins lisible, mais ça va tout de même fonctionner.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérer le mapping d'une Entité /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Annotation @Table et @Column //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons donc vu les bases du mapping objet relationnel, comment prendre des classes Java qui sont des bean, et en faire des entités JPA.
// Comment configurer notre application Java pour en faire une unité de persistence.
// Nous avons aussi vu comment mener à bien à partir de l'objet EntityManager, les opérations de persistence.
// Nous allons maintenant rentrer un peu dans les détails, comment pouvons-nous particulariser, le schéma de base de données, et le modèle objet.
// Notamment, commet nous allons pouvoir faire dialoguer les deux, malgré leurs différences.
// La première différence que nous allons avoir est que, si nous prenons l'entité suivante telle qu'elle est, nous avons deux colonnes qui sont des chaînes de caractères.
// La convention de nommage firstName, lastName, écrite de cette manière là et que nous appelons le Camel Case, c'est une convention de nommage Java.
// Dans l'espace des bases de données, nous aurons peut-être envie d'utiliser des underscores pour séparer les mots, plutôt que du Camel Case.
// Ce qui signifie que ces champs ne vont pas s'associer avec des colonnes qui vont porter exactement le même nom.
// Ceci est quelque chose que nous pouvons préciser dans la déclaration de notre classe avec @Column(name="first_name", length=40).
// Ainsi, nous précisons le nom de la colonne dans la base de données, ainsi que la longueur de caractères maximale pour les valeurs qui s'y trouveront.
// Cette annotation @Column, nous pouvons la mettre dans beaucoup d'endroits dans une classe, en particulier dans les champs d'une classe.
// Ceci va nous permettre de particulariser la façon dont ce champs va être associé à une colonne de la base de données.
// Il y a une petite chose qu'il faut comprendre : l'attribut length est une contrainte qui s'applique à la colonne de la base de données que nous allons utiliser.
// Si jamais nous sommes en mode 'Creation', à ce moment-là nous disons à Hibernate de nous créer une colonne dans la table User, qui à une longueur de type VarChar de 40 caractères.
// Si cette colonne existe déjà, et est un VarChar de 250, Hibernate ne fera rien, et ne cherchera pas à la mettre à jour.
// Il y a une autre subtilité : si jamais nous avons un prénom qui fait plus de 40 caractères, au moment de l'écriture en base de données, nous allons avoir un problème.
// Ceci car en fait, cette contrainte est une contrainte de base de données, et pas du tout une contrainte sur notre bean User.
// Donc nous pouvons parfaitement créer un prénom qui fasse plus de 40 caractères, mais au moment de l'écriture sur la base de données, nous aurons une exception.
// --> Lorsque nous imposons des contraintes sur la base de données au travers des annotations, il faut penser a transférer avec du code ces contraintes par des processus de validation dans les bean.
// Nous pouvons aussi faire la même chose avec @Table(name="Personne",
// En SQL nous pouvons imposer des contraintes sur les valeurs des champs sur les tables. Par exemple, il faut que le couple firstName/lastName soit unique dans la table, pas de firstName ou lastName seul.
// --> @Table(name="Personne", uniqueConstraints={@UniqueConstraint(name="nomPrenomUnique", columnNames={"first_name", "last_name"})})
// Nous pouvons ainsi exprimer au travers de l'annotation @Table, des contraintes d'intégrité sur notre base de données.
// Toutefois nous retombons sur le même problème, la contrainte est une contrainte SQL, et non Java, il faut donc créer des bean User avec des contraintes et processus de validation.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper les dates avec @Temporal ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La plupart des champs que nous pouvons créer dans des classes sont gérés par défaut par JPA.
// Tous les champs de type primitifs : les entiers (int, long, short, byte, ...), les chars, double, ainsi que le type String, qui n'est pas primitif, sont gérés par automatiquement par JPA.
// JPA va prendre ces champs, il n'a pas besoin d'annotations, et il va les associer a des colonnes de la base de données qui porte le même nom que le champs.
// Il y a des types pathologiques, et parmis les types pathologiques il y en a un qui est bien connu : Date.
// Supposons que nos utilisateurs ont une date de naissance, pour des raisons propres à notre application, nous avons besoin d'enregistrer ces dates de naissances dans la table User.
// Déjà il y a un premier piège auquel il faut faire attention, c'est qu'il y a deux types Date dans JPA :
//      - java.util.Date.
//      - java.sql.Date, qui étends le type Date. Et il a été créé pour JDBC.
// Malheureusement, pour un certain nombre de raisons, il n'est pas utilisable par JPA. Donc nous ne pouvons utiliser que java.util.date avec JPA.
// Second point, mais nous le savons déjà, nous avons en fait trois type date :
//      - DATE.
//      - TIME.
//      - TIMESTAMP.
// Il est obligatoire lorsque nous faisons du JPA, de dire quel type de Date nous utilisons, en utilisant une annotation qui s'appelle '@Temporal'.
// Cette annotation est obligatoire et elle prends une constante qui s'appelle 'TemporalType', qui contient les trois valeurs, il faut en choisir une du type DATE pour les dates de naissances :
//      @Temporal(TemporalType.DATE)
//      Date dateOfBirth;
// Maintenant, JPA sera satisfait, et sera capable de l'associer à une colonne du bon type dans la base de données. Cette annotation @Temporal est OBLIGATOIRE.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper les énumération avec @Enumerated ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième type d'élément qui a besoin d'être traité particulièrement, le type 'enum'. Nous pouvons créer des énumérations en Java.
// Il y a une énumération très classique que nous utilisons souvent, notamment lorsque nous avons des bean User :
//      enum Civility {
//          MRS,MR
//      }
//      ...
//      @Column(Length=3)
//      @Enumerated(EnumType.STRING)
//      Civility civility;
// Et ce champs puisqu'il est enuméré, nous allons pouvoir préciser comment est-ce qu'il va pouvoir aller en base de données.
// Nous allons le préciser avec une annotation qui s'appelle '@Enumerated', cette annotation prends en valeur une constante de type 'EnumType' qui prends deux valeurs, STRING ou ORDINAL.
// Quelle est la différence entre dire que nous enregistrons nos énumérations sous forme de chaînes de caractères ou sous forme ordinale ?
// Ordinal signifie que ce que nous enregistrons en base de données est en fait le numéro d'index de la valeur énumérée dans la civilité.
// Tels que nous l'avons écrit précédemment, MRS à pour index 0 et MR à pour index 1.
// Si nous choisissons le type ordinal, notre colonne en base de données aura un type entier et contiendra des 0 et des 1.
// JPA, qui connaît l'énumération, sera capable de nous remettre civility.MR ou civility.MRS dans notre bean User.
// Si nous choisissons le type String, ce qui sera stocké sera le nom de la valeur énumérée, MRS ou MR.
// Quelle est la différence entre les deux, en fait il y en a deux qui sont assez importantes :
//      --> La première est que si nous utilisons le type String, en regardant notre table User, nous savons exactement quelles sont les civilités sur chaque ligne de notre table.
//      --> La seconde chose est la stabilité. Si jamais par mégarde, les deux valeurs, donc les deux index sont inversés, à la lecture, JPA va interpréter des valeurs qui sont corrompues.
//          En effet, notre base de données ne va pas se mettre à jour du fait que nous avons fait cette inversion.
// Il est donc généralement préférable d'utiliser l'EnumType STRING plutôt que l'EnumType ORDINAL.
// Puisque notre chaîne de caractères la plus grande fait trois caractères, nous pouvons rajouter l'annotation @Column(Length=3).

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper les champs Serializable dans des BLOB avec @Lob ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Au point ou nous en sommes, nous savons gérer les champs de type primitif, de type date, de type string et de type enumerate.
// Il nous reste les champs qui sont des références vers d'autres champs JPA. Nous verrons ceux-là par la suite.
// Mais avant cela, il nous reste un autre type de champs, qui sont tous les autres champs, par exemple :
//      int[] securityKey;
// Ces champs qui nous restent peuvent être classés dans deux catégories :
//      - Les champs sérialisables, avec lesquels nous allons pouvoir faire quelque chose.
//      - Les champs non-sériablisables, avec lesquels nous ne pourrons rien en faire. Ils ne pourront pas aller en base de données.
// Le tableau d'int précédent est quelque chose de sérialisable, un tableau de String aussi est sérialisable.
// La seule façon de mapper ces champs, est de les mapper dans ce que nous appelons des 'Binary Objects'.
// Ils s'annottent avec l'annotation '@Lob' qui signifie 'Large Object Binary'. Ce champs là va aller dans une base de données vers un champs de type BLOB, ou de type GLOB ou ce genre de chose.
// Ceci est quelque chose qui à un coût, en effet les écritures et les lectures de ce type de champs sont gourmandes en performance et plus coûteuses que pour les champs de type primitif par exemple.
// Autre contrainte, cette fois-ci venant du SQL, nous ne pouvons pas faire de requête sur ces champs.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cycle de vie de l'entité //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Opérations detach, merge et refresh, hypothèse optimiste //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous ayons un bean User, une entité JPA comme nous avions jusqu'à présent, et un EntityManager em qui a déjà été ouvert, et qui est disponible à l'emploi.
// Nous avons déjà vu deux opérations de persistence, persist(), et remove(), qui permettent respectivement d'écrire et de supprimer le User de la base de données :
//      User user = ...
//      EntityManager em = ...
//      em.persist(user);
//      em.remove(user);
// En fait nous avons trois autres unités de persistence :
//      --> em.detach(user);
// Supposons que nous ayons notre base de données et notre EntityManager qui est connecté à notre base de données, et notre bean User, lui connecté à notre EntityManager.
// Supposons que nous ayons besoin d'afficher notre bean User dans une IHM, dans un formulaire que nous allons présenter à notre opérateur, et cet opérateur, va faire des modifications sur ce bean User.
// Base de données <--> EntityManager <--> Bean User <--> IHM.
// Cette opération va prendre probablement un temps assez long, quelques minutes. Une fois que l'utilisateur aura fini d'examiner les valeurs de User, va peut être finalement ne pas les modifier.
// Donc nous ne sommes même pas certains qu'il faille réecrire les résultats de cette opération en base de données.
// Etant donné que cette opération est longue, il peut être assez coûteux de la faire en intégralité dans le contexte d'une transaction.
// Donc pour éviter de devoir gérer une transaction sur cette partie là, nous allons couper le lien qu'il y a entre notre EntityManager et notre bean User. Ceci est l'objet de l'opération detach(user).
// Le bean User va être détaché de l'EntityManager, et celui-ci sera donc libre de pouvoir faire d'autres choses. Notre utilisateur va pouvoir travailler et prendre le temps dont il a besoin.
// Eventuellement, si il a modifié des valeurs, et qu'il faudra les retourner en bases de données, il faudra qu'il recréé le lien entre le nouveau bean User et l'EntityManager qu'il avait avant.
// Ou éventuellement un autre EntityManager, avec l'opération merger() :
//      --> em.merge(user);
// Ceci nous permet d'attacher une entité JPA à l'EntityManager sur lequel nous appelons cette méthode. Nous pouvons avoir envie de faire cela pour deux raisons.
// Soit le bean User a été au préalable détaché, et auquel cas nous pouvons le réattacher sur n'importe quel EntityManager.
// Soit ce bean User est attaché à un autre EntityManager, nous l'avons récupéré avec un premier EntityManager, et puis en fait nous avons besoin de le transférer à un autre EntityManager.
// Est-ce que cette opération de détachement / réatachement fonctionne bien ? Pas tout à fait, car cela dépends d'une hypothèse dîte OPTIMISTE.
// Cette hypothèse optimiste nous explique que tandis que l'utilisateur à fait son opération sur son IHM, il n'y a pas un autre opérateur qui a effectué une modification sur la même entité JPA.
// Au cas contraire, une exception sera jetée, et elle sera du type 'OptimisticLockException'.
// A ce moment-là il nous faudrait que nous récupérions ces modifications pour mettre à jour ce bean, et que nous repartons dans le cycle de modifications.
// Donc que nous mettons à jour ce bean User avec les modifications faîtes en base de données. Ce qui nous amène à la dernière méthode :
//      --> em.refresh(user);
// Si nous effectuons un refresh() de notre User, nous prenons les modifications qui ont été faîtes en base de données et nous venons mettre à jour l'objet Java sur lequel nous travaillons.
// Donc le cycle est le suivant :
// --> detach(user), merge(user).
// Si cela fonctionne, c'est tout bon. Si une OptimisticLockException est jetée :
// --> detach(user), merge(user), OptimisticLockException, refresh(user), detach(user), merge(user).
// Nous avons donc ces 5 opérations de persistence sur l'EntityManager.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cycle de vie d'une entité JPA /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant que nous avons vu les différentes opérations de persistence, nous allons pouvoir comprendre le cycle de vie d'une entité JPA dans une application.
// Supposons que nous créeons une nouvelle instance de User :
//      User user = new User(...);
// Cette instance de User est dans un état particulier que nous appelons l'état 'NEW'.
// NEW, c'est l'instance d'une entité JPA qui n'a pas encore vu la base de données, qui n'a été attachée à aucun EntityManager.
// A un moment ou à un autre, si possible dans le contexte d'une transaction, nous allons faire :
//      em.persist(user);
// Notre bean User va passer de l'état 'NEW' à 'MANAGED', signifiant qu'il est géré par un EntityManager.
// Par la suite, notre User sera inutile, donc nous allons faire :
//      em.remove(user);
// A présent, notre bean User sera dans l'état 'REMOVED'.
// Nous pouvons, avant de faire remove(), faire l'opération :
//      em.detach(user);
// Notre bean User va passer de l'état 'MANAGED' à l'état 'DETACHED'.
// Cela signifie que dans ce bean User détaché, nous avons toujours des informations, nous connaissons sa classe, ainsi que sa clef primaire, donc nous sommes capable de le localiser en base de données.
// Mais il y a une autre information dedans qui est une information de version. Cette version nous permet de savoir si l'hypothèse optimiste a été violée ou pas.
// En effet, à chaque fois que nous effectuons une modification sur un objet JPA, ce numéro de version est incrémenté.
// Si nous voulons le réatacher :
//      em.merge(user);
// L'opération refresh(), n'a de sens que sur un objet MANAGED. En effet, si il est DETACHED, il n'est pas connecté à la base de données donc nous ne pouvons pas faire de refresh() du tout.
// Donc nous en venons au schéma suivant :
// NEW --> persist() --> MANAGED <--> refresh()
//                          | --> detach() --> DETACHED
//                          | <-- merge() <-- DETACHED
//                          | --> remove() --> REMOVED

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Clés primaires Composite dans JPA /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser des clés primaires composites ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il arrive que dans certaines applications, les clefs primaires soient 'composites'.
// --> Une clef primaire composite est une clef primaire qui possède plusieurs champs. Ceci est un peu embêtant car jusqu'à présent nous avons vu qu'une clef primaire à un seul champs.
// Nous n'en avons pas parlé, mais les clefs primaires sont généralement des entiers, donc des int, ou des long, parfois des String, mais pas trop longs.
// Il peut être assez dangereux de prendre des clefs primaires d'autres types. Mais il arrive malgré tout que ces clefs puissent être composites, et qu'elles soient donc composées de plusieurs champs.
// Nous pouvons faire cela en JPA :
//      class User {
//          @Id int pid;
//          @Id int uid;
//      }
// Si nous écrivons cela, JPA sera confus car une classe ne doit avoir qu'une seule clef primaire. Nous pouvons l'écrire comme cela mais avec un peu de code supplémentaire.
//      @IdClass(PrimaryKey.class)
//      @Entity
//      class User {
//          @Id int pid;
//          @Id int uid;
//      }
//      @Embeddable
//      class UserPrimaryKey {
//          int pid;
//          int uid;
//      }
// A présent JPA va être content, il va récupérer la class se trouvant en paramètre de l'annotation '@IdClass()'.
// Cette fameuse classe peut être embarquée dans une autre, du fait qu'elle est annotée '@Embeddable'.
// Cette classe a bien deux champs, et ces champs correspondent bien aux deux annotations '@Id' de la classe User.
// Nous pouvons mapper des champs avec des noms différents, en ajoutant des annotations particulières.
// Ceci est la première façon d'avoir des clefs primaires composites, il en existe toutefois une deuxième :
//      @IdClass(PrimaryKey.class)
//      @Entity
//      class User {
//          @EmbeddedId
//          PrimaryKey pk;
//      }
//      @Embeddable
//      class UserPrimaryKey {
//          int pid;
//          int uid;
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gestion des relations /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Relation unidirectionnelle ou bidirectionnelle ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu jusqu'à présent comment associer des classes que nous appelons des entités JPA, à des tables dans les bases de données.
// Nous avons aussi vu comment, de manière quasi automatique, nous pouvions lire et écrire des instances de ces classes dans des lignes particulières des tables de ces bases de données.
// Nous avons vu de même qu'il y avait quelques subtilités avec les champs mais que nous pouvions associer les choses de l'univers Java vers l'univers des bases de données relationnelles.
// Nous allons maintenant nous intéresser à des cas un peu plus sophistiqués, qui portent sur la mise en relation d'entités Java versus la mise en relation de données dans ces bases de données.
// Pour cela nous allons prendre un exemple simple, une classe Commune avec un nom, et une classe Maire avec un nom également :
//      public class Commune {
//          String name;
//          Maire maire;
//      }
//      public class Maire {
//          String name;
//      }
// Il se trouve que dans la classe Commune, nous avons aussi un champs de type Maire, puisque chaque commune à un maire.
// Si nous regardons ceci d'un point de vue de base de données, comment allons nous mapper cette classe ?
// Commune : ID, name, ID_Maire.
// Maire : ID, name.
// Nous avons la colonne ID_Maire qui sera une 'colonne de jointure' pour modéliser la relation entre Commune et Maire.
// A cette colonne ID_Maire il va y avoir une contrainte, dite contrainte de clef étrangère qui va y être associée.
// Cette contrainte dira globalement que l'ID_Maire référencé dans la commune, doit correspondre à une valeur d'ID dans la table Maire. Ceci est une contrainte de clef étrangère tout à fait classique.
// Comment dire à nos entités JPA que nous voulons modéliser ces deux classes par deux tables équivalentes à celles ci-dessus ?
// En fait nous avons vu que les champs simples, sont mappées directement dans des colonnes de table.
// Pour modéliser une relation, nous allons avoir une annotation spéciale, et comme ici nous avons une relation '1-1', car une commune est associée à un maire : '@OneToOne'.
// Ceci va nous donner une structure de table qui aura a peu près ce que nous avons fait précédemment.
// La classe Commune, connaît la classe Maire, la relation entre Maire et Commune est tenue par la classe Commune. La classe Maire elle, ne connaît pas la classe Commune.
// Donc nous pouvons dire que le côté Commune de la relation est le côté 'Maître', c'est celui qui tient la relation, qui ici est 'uni-directionnelle'.
// Par convention, JPA va créer sa colonne de jointure du côté Maître de la relation. Ceci nous permet de créer une relation de type '1-1'.
// Il y a quelques subtilités sur cette relation, car si par exemple, nous voulons également créer un champs Commune dans la classe Maire, nous aurions donc une relation 'bi-directionnelle'.
//      public class Commune {
//          String name;
//          @OneToOne
//          Maire maire;
//      }
//      public class Maire {
//          String name;
//          @OneToOne                   --> Uniquement si relation bi-directionnelle.
//          Commune commune;            --> Uniquement si relation bi-directionnelle.
//      }
// Le problème est que si nous faisons ça, JPA va regarder la classe Commune, voir une relation 1-1, vers la table Maire, et va donc créer cette colonne de jointure ID_Maire.
// Puis en regardant la classe Maire, il va faire exactement le même résonnement, donc il créera également une colnne de jointure ID_Commune.
// Toutefois, si nous faisons cela, nous n'aurons pas une relation bi-directionnelle. Nous avons une relation 1-1 de Commune vers Maire, donc une commune A peut être en relation avec un maire M.
// Aussi, nous avons aussi une relation 1-1 de Maire vers commune donc rien n'empêche que le maire M soit en relation avec une commune B.
// Donc, si nous voulons créer une relation bi-directionnelle, il ne nous faut pas la colonne ID_Commune dans la table Maire, créée par l'annotation @OneToOne dans la classe Maire sur l'objet Commune.
// Pour le dire, nous allons devoir rajouter un attribut dans l'annotation de la classe Maire : @OneToOne(mappedBy="maire") auquel nous passons le nom du champs qui est l'autre morceau de la relation.
// Comment est-ce que fait JPA pour décider de quel côté il va créer cette colonne de jointure ?
// Par convention, nous allons dire que le côté où nous avons le 'mappedBy', sera le côté esclave de la relation, et l'autre côté sera le côté maître de la relation, qui possède la colonne de jointure.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérer la persistence d'une relation ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment utiliser ce modèle de classe avec notre EntityManager ?
// Supposons que nous ayons une instance de Commune dans l'état NEW, et une instance de Maire, dans le même état.
//      public class Commune {
//          String name;
//          @OneToOne(cascade=CascadeType.PERSIST)
//          Maire maire;
//      }
//      public class Maire {
//          String name;
//          @OneToOne(mappedBy="maire")
//          Commune commune;
//      }
// Nouvelles instances :
//      Commune c = ...;
//      Maire m = ...;
// Dans un premier temps, nous allons supposer que nous avons une relation uni-directionnelle, donc le champs retour '@OneToOne(mappedBy="maire")' n'existe pas.
// Nous allons donc nous créer notre EntityManager, et nous supposons que nous sommes dans un contexte transactionnel :
//      EntityManager em = ...;
//      c.setMaire(m);
//      em.persist(c);
// Si nous exécutons le code, tel qu'il est écrit ici, nous aurons une erreur au niveau du commit() de notre transaction, associée à notre EntityManager.
// Quelle va être l'erreur ? Il se trouve que nous avons un objet persistent 'c', qui a été mis en relation avec un objet non persistent 'm'.
// En fait le 'c' va passer dans l'état MANAGED, mais le 'm', lui va rester dans l'état NEW, puisque nous n'avons pas fait de persist() sur cet objet 'm'.
// Il faudrait donc que nous fassions également 'em.persist(m);' avant d'exécuter le commit() lié à cet EntityManager.
// Si nous faisons les choses comme cela, cela va fonctionner car nous avons le droit de mettre en relation deux objets qui sont 'MANAGED'.
// Cela dit, le fait de devoir persister des grappes d'objets un par un de cette manière n'est pas extrèmement pratique.
// Ce que nous aimerions pouvoir faire serait de dire que nous persistons notre objet Commune, qui est un objet racine et qui a tout un tas d'objets qui sont également dans l'état NEW en relation.
// Et nous aimerions que l'EntityManager aille explorer tout seul toutes ces relations, et qu'il fasse des persist() automatiquement dès qu'il rencontre un objet en relation qui n'a pas été persisté.
// Cela nous pouvons le faire en ajoutant un attribut à notre annotation @OneToOne, qui s'appelle 'cascade', et qui prends en paramètre une constante qui vit dans une énumération.
// Effectivement, tous les paramètres d'annotations vu jusqu'à présent font de mêmes et vivent dans une énumération.
// Cette énumération se nomme 'CascadeType' et a pour valeur 'PERSIST' : @OneToOne(cascade=CascadeType.PERSIST)
// A présent le fait de faire un persist() sur l'objet 'Commune', va automatiquement transmettre le persist() sur l'objet 'Maire', à condition que celui-ci ne soit pas déjà MANAGED.
// Donc dans ce cas là, nous n'aurons pas besoin d'écrire : em.persist(m);. Quand nous commiterons notre transaction, tout sera envoyé en base de données automatiquement.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Charger une relation avec les modes LAZY et EAGER /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons une question à peu près analogue qui se pose quand nous souhaitons charger un objet, nous avons un EntityManager, et nous allons faire :
//      EntityManager em = ...;
//      Commune c = em.find(Commune.class, 12);     --> En supposant que nos clefs primaires sont des entiers.
//      Maire m = c.getMaire();
// Que se passe t'il lorsque nous écrivons ce code ?
// Dans un premier temps nous avons un SELECT qui va partir en base de données et qui va charger la ligne de la table Commune qui correspond à la clef primaire 12.
// Ensuite, JPA va nous créer une instance de Commune avec les valeurs de champs qu'il à lu. Derrière, nous effectuons un getMaire() dessus.
// Donc maintenant nous allons explorer la relation maire de la classe Commune. Maintenant nous avons deux comportements qui peuvent se passer :
//      - 'm' a déjà été lu, puisque quand nous avons chargé notre objet Commune, une jointure a été faite vers la table maire, et le maire en relation avec cette commune a été embarqué avec la commune.
//          Le premier comportement, est ce que nous appelons le comportement 'EAGER', il consiste à prendre tous les objets en relation, lorsque nous chargeons un objet racine.
//      - 'm' n'a pas été chargé, et donc nous avons un SELECT qui part vers la base de données pour charger 'm'.
//          Le second comportement est ce que nous appelons le comportement 'LAZY', il consiste à ne rien prendre, et a charger les objets en relation à la demande.
//          Cela nous pouvons le fixer avec un autre attribut à l'annotation dans la classe maître qui a une constante de type énumération aussi, et prenant deux valeurs : @OneToOne(fetch=fetchType.EAGER).
// -->  public class Commune {
//          String name;
//          @OneToOne(fetch=fetchType.EAGER)
//          Maire maire;
//      }
//      public class Maire {
//          String name;
//          @OneToOne(mappedBy="maire")
//          Commune commune;
//      }
// Quand nous avons un comportement de type EAGER, le fait d'aller chercher une commune, va générer une requête SELECT avec une jointure, et la création de deux objets, un objet Commune et un objet Maire.
// Le fait d'être dans un comportement de type LAZY, ne va pas charger les objets en relation, cela va charger un objet Commune 'incomplet'.
// Si jamais nous appelons la méthode getMaire(), à ce moment-là le getMaire() va être intercepté par JPA et va générer un SELECT pour peupler la relation Maire.
// Ceci nous amène à un problème de performance : car si à chaque fois que nous chargeons un objet maître et que nous avons de nombreux objets en relation, le chargement sera manifestement plus lent.
// En revanche, si nous ne chargeons rien et que nous passons notre temps à explorer les relations, à chaque exploration nous allons payer le temps d'un aller retour vers la base de données.
// Donc le comportement est à choisir selon les cas d'utilisation des relations dans les classes.
// Petit détail, si l'objet Commune a été chargé en LAZY, la méthode getMaire() va retourner à la base de données pour charger l'objet Maire, uniquement si notre objet Commune est dans l'état MANAGED.
// Si dans l'intervalle, nous avons DETACHED notre objet Commune, donc si il n'est plus rattaché à notre EntityManager, getMaire() ne pourra plus aller chercher l'objet Maire en base de données.
// Dans ce cas là, getMaire() retournera null, alors que si ça se trouve, nous avons un objet Maire en relation avec notre objet Commune dans notre base de données.
// Donc le choix de comportement réside aussi dans le fait que nous devons traiter l'objet Commune en mode MANAGED ou en mode DETACHED.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gestion du caractère bidirectionnel d'une relation en création et en lecture //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Plaçons-nous dans le cas où nous avons une relation bi-directionnelle entre les classes Maire et Commune.
// Donc dans le cas où nous avons un champs Commune annoté correctement pour faire cette relation bi-directionnelle.
//      public class Commune {
//          String name;
//          @OneToOne
//          Maire maire;
//      }
//      public class Maire {
//          String name;
//          @OneToOne(mappedBy="maire")
//          Commune commune;
//      }
//      Commune c = ...;
//      Maire m = ...;
//      c.getMaire(m);
//      em.persist(c);
// A présent que vas t-il se passer ? Nous allons supposer que nous sommes en mode 'CascadePersist', notre objet Commune et notre objet Maire vont bien être enregistrés en base de données.
// Comme nous avons créé la relation au travers du champs Maire dans la classe Commune, la colonne de jointure de la classe Commune, va bien être peuplée avec la clef primaire du maire qui vient d'être créé.
// Par contre, si nous affichons : m.getCommune(), cela va nous retourner null.
// Et ceci, car le caractère bi-directionnel de la relation, lorsque nous sommes en mode création, dans notre code Java, c'est à notre code applicatif de le gérer.
// Si nous faisons juste le setMaire(), mais sans faire le setCommune() dans le sens inverse, et bien JPA ne le fera pas pour nous. Et donc en faisant getCommune(), la relation sera null.
// Et ce, quand bien même elle a bien été traitée dans la base de données. Donc il faut bien penser à faire comme ceci, du moins lorsque nous sommes en mode création :
//      c.setMaire(m);
//      m.setCommune(c);
// Lorsque nous faisons l'opération inverse, après un relancement de l'application :
//      Commune c = em.find(Commune.class, 7);
// Cette fois-ci, l'objet Commune a été créé et initialisé par JPA, et JPA sait qu'il y a une relation bi-directionnelle à cet endroit là. Donc si nous faisons :
//      c.getMaire();       --> retourne bien un objet Maire 'm'.
//      m.getCommune();     --> retourne bien un objet Commune 'c', et ne retourne donc pas null.
// Pourquoi cela fonctionne t'il maintenant, c'est car c'est bien JPA qui a pris en charge la création de cette objet Commune.
// Donc il faut vraiment faire attention à ces relations bi-directionnelles, le caractère bi-directionnel de la relation, c'est au code applicatif de le gérer.
// Et ce, en création, et en lecture lorsque nous récupérons des objets, là c'est JPA qui le gère, et qui le gère correctement.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur la gestion des relations one to one /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Effectuons à présent un petit résumé sur tout ce que nous avons dit sur cette relation @OneToOne, ou relation dite 1:1 :
//      - Nous avons une colonne de jointure qui est créée dans la table dite 'Maître'. Le côté Maître est toujours celui qui porte l'opération de jointure, en l'occurrence ici, la colonne de jointure.
//      - Côté JPA, nous avons vu le comportement 'Cascade', et notamment le 'CascadePersist', qui permet de mettre les objets en relation en base de données automatiquement.
//      - Nous avons vu le comportement 'Fetch', qui est un peu le comportement symétrique du comportement Cascade, ayant deux valeurs : 'LAZY' et 'EAGER'.
//      - Nous avons vu le côté bi-directionnel de la relation avec deux points importants :
//              --> Si nous voulons une relation bi-directionnelle nous avons besoin d'ajouter un attribut 'mappedBy' dans cette annotation @OneToOne, et ceci du côté 'esclave'.
//              --> Cette relation bi-directionnelle doit être gérée 'manuellement'. Lorsque nous créons des objets, c'est à l'applicatif Java de garantir le caractère bi-directionnel de la relation.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Relation one to many unidirectionnelle et bi-directionnelle ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Regardons à présent ce qu'il se passe pour les relations multi-valuées. Pour un certain nombre de raisons nous allons commencer par la relation p:1.
// Nous avons toujours la classe Commune avec toutes les propriétés et les annotations dont elle a besoin, et a côté, nous avons une classe Département, qui possède donc plusieurs Communes.
// Une Commune quand à elle, ne peut être rattachée qu'à un seul Département. Donc si nous regardons la relation entre Commune et Département, il s'agit bien d'une relation de type p:1.
// Comment est-ce que nous mappons une relation p:1 lorsque nous sommes dans l'univers de base de données SQL.
//      Commune : ID, nom, ID_Dept.
//      Département : ID, nom.
// Donc ici pour mettre notre colonne de jointure, nous n'avons pas vraiment le choix, c'est dans la classe Commune.
// Donc en fait, cette structure de table, si nous suivons les conventions que nous avons donné auparavant, mappe bien cette structure de Classe :
//      public class Commune {
//          ...
//          @ManyToOne(...)
//          Departement departement;
//      }
//      public class Departement {
//          ...
//          @OneToMany(...
//              mappedBy="departement")
//          List<Commune> Communes;
//      }
// Les attributs pour @ManyToOne vont être le 'Fetch' type, le 'Cascade' type, exactement comme nous avons fait pour les relations @OneToOne.
// Si jamais nous voulons mettre une relation bi-directionnelle, cette fois-ci nous n'aurons non-pas une Commune unique, mais une List<Communes> avec une annotation de type '@OneToMany'.
// Cette dernière aussi avec les attributs dont elle peut avoir besoin tels que le 'Fetch' type, le 'Cascade' type, etc.
// Nous pouvons voir cette fois-ci que le mappedBy qui est du côté esclave de la relation, nous ne pouvons pas le mettre n'importe où.
// Il n'est pas question de le mettre du côté de la classe Commune, puisque Commune est nécessairement le côté maître.
// Donc le mapped by peut-être mis dans le @OneToMany, mais il n'existe pas dans l'annotation @ManyToOne.
// Donc cette relation di-symétrique p:1, elle existe en version uni-directionnelle et en version bi-directionnelle.
// Mais nous voyons que cette fois-ci, par rapport à l'annotation 1:1, nous n'avons pas de possibilité de choix, pour mettre le côté maître, d'un côté ou de l'autre.
// Le côté maître est donc nécessairement du côté 'muti-valué'.
// En dehors de ça, tout ce que nous avons vu sur la relation 1:1 translate exactement sur la relation p:1, en particulier le 'Fetch' type, et le 'Cascade' type.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cas des relations one to many uni-directionnelles /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons une petite subtilité dans ces relations 1:p, p:1 en JPA et qui génère un comportement différent, entre ce qu'il se passe dans l'univers objet et ce qu'il se passe dans l'univers relationnel.
// Ici nous allons supposer que nous avons juste une relation '@OneToMany', donc 1:p, entre une classe Departement qui possède une liste de Communes.
// Et avec une classe Commune, qui elle, n'a pas de lien retour avec ces départements. Donc nous avons un cas 1:p uni-directionnel.
// Ici, la logique voudrait que nous ajoutions une colonne de jointure, dans la classe Commune.
// Or, cela voudrait dire que dans l'univers relationnel, la table Commune dépends de la table Departement, par le biais de la clef étrangère qui va être définie.
// Alors que dans l'univers objet, la classe Commune, elle, ne dépends pas de la classe Departement. C'est même l'inverse, c'est la classe Departement qui dépends de la classe Commune.
// Le choix qui a été fait en JPA pour essayer d'aligner ce qui a été fait dans l'univers relationnel avec les contraintes de l'univers objet est de créer à cet endroit là une 'table de jointure' :
//      --> Commune : ID, nom.
//      --> Departement : ID, nom.
//      --> Departement-Commune : ID_Departement, ID_Commune.
// Ceci peut tout d'abord choquer un peu car nous ne comprenons pas pourquoi une relation 1:p, doit être mappée avec une table de jointure.
// Mais en fait cela vient de cette spécificité, que cette structure de tables est l'image, d'une structure de classes qui se trouve dans notre application.
// Si pour une raison ou pour une autre dans cette configuration, nous voulions supprimer notre classe Departement, nous n'aurions pas besoin de toucher à la classe Commune.
// Si nous avions créé une colonne de jointure dans la table Commune, le fait de supprimer la table département aurait généré une modification, un 'alter-table' de la table Commune.
// Alors que dans la configuration actuelle, si nous voulons supprimer la classe Departement, nous supprimons les deux dernières tables de la liste, et la table Commune reste intègre.
// C'est la raison poourquoi ce choix un peu spécial a été fait, pour les relations @OneToMany uni-directionnelles en JPA.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Protéger le contenu d'une relation multivaluée par copie défensive ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il y a un point un petit peu subtil qu'il nous faut aborder à présent, au sujet de cette classe Departement.
// Supposons que nous fassions :
//      List<Commune> Communes = departement.getCommunes();
// Nous avons vu précédemment que quand nous modifions un champs persistant d'une entité JPA, c'est quelque chose qui génère automatiquement un UPDATE dans la base de données.
// Ce qui veux dire qu'à ce stade là, si nous effectuons :
//      communes.clear();
// Si nous ne faisons pas attention, nous sommes en train d'effacer le champs Communes de la classe Departement. Un champs qui est persistant et qui se trouve dans la base de données.
// Donc qui est susceptible de générer des modifications dans cette base de données. Il faut donc que nous fassions attention, pour deux raisons :
//      --> Si nous n'avons pas de transaction lorsque nous effectuons cette opération, nous allons avoir une exception qui va être générée.
//          Pourquoi ? Car, toutes les modifications d'entités persistentes doivent se faire dans le contexte d'une transaction.
//      --> Nous sommes en train de modifier la base de données. Est-ce vraiment ce que nous souhaitons faire.
//          Est-ce que le fait d'exposer cette liste persistente à l'extérieur de notre objet n'est pas un petit peu dangereux.
//          Et que cela n'expose pas des détails interne de notre objet Departement à des mauvaises manipulations ou a des bugs dans notre application.
//          La réponse est oui. Ca nous ne voulons pas le faire. Toutes les modifications de la liste Communes, par précaution, doivent avoir lieu à l'intérieur de la classe Departement.
// Donc lorsque nous retournons la List<Commune>, nous ne voulons pas que ce soit la liste persistente de Communes de notre Departement.
// Par contre, si quelqu'un a besoin de cette liste pour itérer dessus, et afficher la liste des communes par département par exemple dans une interface graphique, dans une grille d'affichage.
// Il faut quand même que nous lui retournons quelque chose. Ce que nous allons lui retourner est systématiquement une COPIE.
// Donc notre méthode getCommunes() qui nous retourne une List<Communes>, va avoir la forme suivante :
//      List<Commune>.getCommunes() {
//          return ArrayList<> (this.commune);
//      }
// Donc nous retournons une List<> qui a le bon contenu, mais qui est une copie de la vraie liste persistente.
// Donc faire des clear(), ajouter des éléments ou en retirer n'aura aucun impact sur notre base de données.
// Ainsi, nous protégeons notre base de données, et nous nous protégeons, contre les exceptions dûes au fait que ces modifications se font à l'extérieur d'une transaction.
// Cette copie s'appelle une 'COPIE DEFENSIVE'.
// Nous nous protégeons contre les problèmes qui pourraient intervenir si des utilisateurs chercheraient à modifier la liste des communes qui se trouvent dans notre département.
// Ceci est un pattern auquel il faut penser lorsque nous gérons des relations mutli-valuées en JPA.
// Systématiquement, les listes que nous exposont sont des copies de listes de sortes à ce qu'il n'y ait pas de problèmes à l'utilisation.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérer manuellement le caractère bidirectionnel d'une relation multivaluée /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ce que nous venons de voir, ce mécanisme de copie défensive, va avoir un impact sur la manière dont nous voulons gérer le caractère bi-directionnel d'une relation.
// Supposons que dans notre classe Commune, nous avons une méthode :
//      void setDepartement(Departement d) {
//          this.departement = d;
//          d.getCommunes().add(this);
//      }
// Ici, nous essayons de dire que nous voulons rajouter l'objet Commune dans lequel nous sommes à la liste des communes associée à ce département.
// Or, si nous faisons les choses comme cela, ça ne fonctionnera pas car 'd.getCommunes().add(this);' est une copie défensive.
// Donc, rajouter la commune dans laquelle nous sommes à cette copie, ne vas pas générer de modifications dans la base de données. Or, précisémment dans ce cas là, c'est ce que nous voulons faire.
// Nous voulons mettre à jour la liste de communes de ce département dans la base de données.
// Donc en fait, nous allons avoir besoin de modifier ce pattern, et probablement d'avoir une méthode addCommune(this) qui va prendre la vraie liste de communes et la mettre à jour :
//      d.addCommune(this);
// Donc cette copie défensive, qui consiste à masquer les éléments internes de cette classe, notamment les éléments internes multi-valués.
// Ceci nous impose également d'exposer dans cette classe des méthodes qui vont permettre de muter ces éléments internes : addCommune(), removeCommune(), clearCommune(), etc.
// Second point, il ne faut pas que la méthode addCommune(), fasse la même chose que la méthode citée précédemment :
// Soit nous voulons gérer notre relation bi-directionnelle, directement dans les classes, auquel cas, la méthode setDepartement(){} va gérer la relation bi-directionnelle.
// Ce qui est logique dans le sens où la classe Commune est l'élément maître de la relation.
// Par contre la méthode addCommune(), ne doit pas le faire à son tour parce que si elle le fait en appelant setDepartement(){}, nous aurons deux méthodes qui s'appeleront de l'une à l'autre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur les relations one to many et many to one en JPA /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Effectuons à présent un bilan sur ce que nous avons vu sur les relations 1:p, et p:1 :
//      --> C'est géré par deux annotations : @OneToMany et @ManyToOne. Seul l'annotation @OneToMany(mappedBy) peut porter l'attribut mappedBy.
//          Nous avons vu que cela a un impact au niveau du mapping, c'est à dire au niveau des tables générées. Nous pouvons avoir :
//                  - Soit une structure à deux tables : dans le cas p:1, et dans les deux cas bi-directionnels.
//                  - Soit une structure à trois tables, dont une table de jointure : dans le cas 1-p, uni-directionnel.
//      --> Nous avons mentionné que nous avons les mêmes comportements 'Cascade' et 'Fetch', avec les mêmes problématiques de performance que dans le cas 1:1.
//      --> Nous avons vu que le caractère bi-directionnel de la relation devait être géré à la main en création.
//          En revanche, quand nous chargeons une entité Departement, automatiquement, les communes vont être, si ce n'est chargées, au moins, explorables.
//          Et quand nous allons lire les communes, le champs retour sera positionné correctement par JPA, exactement comme dans le cas 1:1.
//      --> Nous avons aussi vu la copie défensive des champs multi-valués, donc typiquement des champs de type List<>.
//          Effectivement, l'implémentation de Commune à l'intérieur de Departement est une implémentation propre à l'implémentation de JPA que nous utilisons.
//          Ce n'est donc pas une ArrayList, mais une liste construite par Hibernate ou par EcliseLink.
//          Ainsi, lorsque nous ajoutons ou nous retirons un élément de cette liste, Hibernate va le capter et va générer les UPDATES nécessaires pour mettre à jour la base de données.
//          Cette implémentation particulière, en général, nous ne voulons pas l'exposer à l'extérieur de la classe Departement.
//          Ainsi, en créant un getter sur ce champs, nécessairement, nous créons une copie défensive, pour nous protéger contre les modifications intempestives qu'il pourrait y avoir dans notre code.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Relation Many to Many /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dernier type de relation bien sûr, la relation many to many, ou relation n:p. Celle-ci va fonctionner en fait de façon assez classique.
// Prenons un exemple, un ensemble de musiciens qui jouent un ensemble d'instruments.
// Chaque musicien peut éventuellement jouer de plusieurs instruments, et un instrument peut être joué par plusieurs musiciens.
//      public class Musicien {
//          @ManyToMany(cascade=..., fetch=...)
//          List<Instrument> inst;
//      }
//      public class Instrument {
//          @ManyToMany(mappedBy="...")                         --> Nous plaçons ce champs retour si nous avons une relation bi-directionnelle.
//          List<Musicien> mus;
//      }
// Ce qui va être mappé en base est :
//      Musicien : ID, nom.
//      Instrument : ID, nom.
//      Musicien_Instrument : ID_Musicien, ID_Instrument.
// Ainsi, JPA va être capable de nous créer cette structure de base de données avec les bonnes clefs étrangères qui vont pointer vers les bonnes colonnes de clefs primaires.
// Exactement comme dans les autres cas, il faut faire attention au caractère bi-directionnel des relations.
// C'est donc à l'applicatif Java en création de gérer cet aspect bi-directionnel.
// Il va falloir être également précautionneux sur le côté copie défensive étant donné que nous avons des collections qui sont internes aux deux classes, et que nous ne voulons pas exposer à l'extérieur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Relation de composition avec @Emdedded et @Embeddable /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent un type de relation 1:1 un peu particulier dans lequel l'entité qui porte la relation, donc l'entité maître, est liée de façon très forte à l'entité en relation, donc l'entité esclave.
// Si jamais l'entité maître disparaît, cela n'a pas de sens de garder l'entité en relation. En fait nous disons que cette entité en relation partage le même cycle de vie que l'entité maître.
// Par exemple, nous avons une classe User qui possède un champs adress, qui pointe vers la classe Adress.
// Lorsque nous créons un User, nous créons son adress, mais si nous supprimons un utilisateur, il n'y a pas lieu de conserver son adresse.
// Cette relation est parfois appelée une relation de 'Composition', par opposition à une relation 'Association', dans laquelle les deux côtés de la relation ont leur vie propre.
// Il serait assez coûteux d'enregistrer cette relation de composition dans deux tables séparémment. En effet, à chaque fois que nous insérons un utilisateur, nous aurons deux insertions qui vont partir.
// De plus à chaque fois que nous voudrons récupérer un utilisateur, nous allons payer le prix du passage d'une jointure entre la table User et la table Adress.
// Enfin, lorsque nous allons effacer un utilisateur, nous aurons deux delete qui partiront en base de données.
// --> La bonne façon de faire serait de mapper cela dans une seule table :
//      User : ID, Name, Adress, ID_Commune.
// Ceci est quelque chose que nous pouvons faire en JPA : En fait la classe adresse n'est pas une classe entité, mais une classe 'embeddable', donc une classe qui peut être embarquée.
// Les contenus de cette classe, les instances de cette classe vont être embarquées dans une entité JPA :
//      @Entity
//      public User {
//          String name;
//          @Embedded
//          Adress adress;
//      }
//      @Embeddable
//      public Adress {
//          String adress;
//          @OneToMany
//          Commune commune;
//      }
// Ceci ne fonctionne toutefois que si nous sommes en 'Composition'. C'est à dire quand le cycle de vie de Adress est le même cycle de vie que User.
// La conséquence aussi est que Adress et User vont partager la même clef primaire.
// Ces objets de type 'Embeddable' sont des classes JPA, et non des entités JPA.
// Nous avons deux types de classe JPA : @Entity et @Embeddabble.
// C'est très important car lorsque nous allons faire des requêtes, nous allons nous rendre compte que nous ne pouvons en faire que vers des @Entity JPA.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper l'API Collection ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper les structures de l'API Collection en base avec JPA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons donc vu comment mapper des relations de type 1:1, 1:p, p:1 et n:p, entre des entités avec JPA.
// Mais nous n'avons pas répondu à toutes les questions qui peuvent se poser lorsque nous voulons mapper des bean Java qui ont des relations entre eux de ce type là.
// Notamment pour créer des relations avec les bean Java, nous avons l'API Collection. Celle-ci nous propose de gérer essentiellement les List<>, Set<>, SortedSet<> et les Map<>.
// Si nous supposons que nous avons une classe qui possède un champs de type List<> ou de type Set<>, comment allons nous pouvoir le mapper avec JPA dans une base de données.
// Comment un champs existant multi-valué, d'un de ces types là va pouvoir s'acoquiner avec la base de données ?
// C'est une vraie question, et nous allons voir que les choses ne se passent pas si bien que ça. Typiquement, les List<> ne sont pas des types d'objets très appréciés par JPA.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Associer une relation one to many à un Set ou à une List //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Prenons un exemple pour essayer de voir un peu l'étendue du problème.
// Nous allons supposer que nous avons un bean departement sur lequel nous avons une méthode addCommune. Un département peut avoir plusieurs communes, donc nous avons ici une relation 1:p.
//      departement.addCommune(Paris);
//      departement.addCommune(Nantes);
// Nous savons que quand nous avons une relation 1:p, nous allons ici supposer qu'elle est bi-directionnelle, dans notre table Commune :
//      Commune : ID, nom, ID_Departement.
//                12, Paris, 9.
//                13, Nantes, 9.
// Que se passe t'il du côté de la base de données si nous ajoutons de nouveau une Commune du nom de Paris au même département ?
//      departement.addCommune(Paris);
// Elle va nous indiquer qu'elle possède déjà cette Commune, elle ne va pas créer une deuxième Commune avec la même clef primaire, et elle est déjà en relation avec ce département.
// Donc pour ce deuxième ajout, la base de données va nous dire que ce n'est pas la peine de le faire car elle l'a déjà fait.
// Ceci nous amène au fait que la manière dont les relation 1:p sont gérées du côté des bases de données fait que notre département à une structure de 'Set'.
// Donc c'est un ensemble dans lequel nous ne pouvons pas avoir de doublons. Mécaniquement, la base de données nous empêche d'avoir des doublons dans notre département.
//      --> Par défaut, lorque nous créons des relations 1:p en JPA, il faut utiliser un Set.
// Par contre, le Set nous garantie que nous n'avons pas de doublons, par contre, il ne nous garantie pas l'ordre dans lequel nous pouvons itérer sur les éléments qu'il contient.
// Les bases de données fonctionnent exactement comme ça :
//      departement.getCommunes(); --> Ceci va nous retourner l'ensemeble des Communes, en utilisant une requête SQL du type : "select * from Commune where ID_Departement = 9".
// Si nous voulons garantir un ordre en SQL, il nous manque un 'orderBy' quelque part dans notre requête.
// L'ordre dans lequel ce sera trié ne sera pas l'ordre par date d'ajout, mais par ordre alphabétique ou quelque chose comme cela.
// Donc effectivement cette relation departement/commune, si nous ne faisons rien, elle ne va pas conserver l'ordre des éléments qui ont été ajoutés dedans.
//      --> Cette relation 1:p à vraiment toutes les caractéristiques d'un Set : pas de doublons, et pas d'ordre.
// C'est comme ceci que les choses se passent en Java. Maintenant que se passe t-il lorque nous avons besoin d'une 'List' ?
// Dans une List, nous pouvons avoir des doublons et nous avons aussi un ordre, celui dans lequel les éléments ont été ajoutés grâce à l'index.
// Ceci est assez complexe à faire, et plutôt coûteux, et c'est ce que nous allons voir à présent.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer une structure de liste à l'aide d'une colonne portant un index //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous voulons une vraie List, c'est à dire que nous allons conserver l'ordre d'ajout lorsque nous allons itérer, et que nous pourrons aussi avoir des doublons.
// A ce moment-là, nous avons besoin d'ajouter une colonne technique dans notre table, ici 'Index', pour enregistrer le moment de l'ajout.
// Lorsque nous ferons getCommunes(), la requête sera la suivante : "select * from Commune where ID_Departement = 9 orderBy Index".
// Ceci est ainsi quelque chose que nous pouvons faire en JPA, mais il faut que nous soyons extrèmement précautionneux lorsque nous faisons ce genre de choses.
// Et ce, parce que dans une List, nous pouvons faire des opérations qui vont être très coûteuses pour la base de données.
//      departement.add(0, Lyon);
// Imaginons que nous avons la même chose que précédemment dans notre base de données :
//      Commune : ID, Nom, ID_Departement, Index.
//                12, Paris, 9, 0 --> 1.
//                13, Nantes, 9, 1 --> 2.
//                14, Lyon, 9, 0.
// Donc ce n'est pas simplement une insertion qui va partir en base de données lorsque nous ajoutons Lyon, c'est une insertion, plus autant d'updates que nous avons dans notre List.
// C'est donc très coùuteux du point de vue de la base de données. Et ceci est pareil lorsque nous effections un remove en utilisant un index :
//      departement.remove(1);
// Il va donc falloir que nous mettons l'ID departement et l'index de Paris à Null, ce qui est simple, mais pareil, nous allons devoir faire des updates sur de nombreux index pour se mettre à jour.
// Donc cette façon de gérer des List est quelque chose d'extrèmement coûteux. Nous avons une technique un peu hybride qui se rapproche plus du Set, mais qui est beaucoup moins coûteuse.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer une liste en garantissant l'ordre des éléments //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que la seule chose qui nous intéresse dans cette structure de List est d'avoir un ordre.
// Ce n'est pas tellement de savoir que si nous avons ajouté Paris, puis Nantes, puis Lyon, nous allons garder cet ordre quand nous allons itérer.
// Mais c'est le fait de garantir que si nous effectuons deux itérations et que nous n'avons pas eu de changement dans le contenu de notre List, ces deux itérations vont se faire dans le même ordre.
// Ceci, nous pouvons le faire en disant qu'en fait, notre List est ordonnée par un de ses champs. Par exemple, le champs nom.
// Cela, nous pouvons le dire, et nous allons voir techniquement comment nous pouvons le faire. Ainsi, lorsque nous allons faire nos addCommune(), cela va se passer exactement comme si c'était un Set.
// Nous n'aurons plus cette colonne Index, dont nous avons vu qu'elle était en fait très coûteuse à entretenir.
// Quand nous ferons notre getCommunes(), nous aurons : "select * from Communes where ID_Departement = 9, orderBy Nom".
// Si nous faisons cela, nous n'aurons pas de surcharge à l'insertion, pas de surcharge pour les opérations de mutations de notre List.
// Nous avons juste un tri qui part et cela est parfaitement acceptable, les serveurs savent très bien trier les bases de données.
// Nous avons juste ce tri qui part pour nous garantir que les éléments seront toujours dans le même ordre.
// Ceci est une espèce de compromis entre les vraies List que nous avons en Java, et les listes qui vont être possible de faire dans l'univers des bases de données.
// Cette List se comporte plutôt comme quelque chose qui ressemblerait à un 'SortedSet'. C'est presque un SortedSet sur lequel nous pourrions choisir le comparateur dont nous avons besoin.
// Il y a un point sur lequel il faut faire très attention ici : malgré tout, lorsque nous sommes en train de créer notre liste de Commune dans notre Departement, cela reste une List Java.
// Elle ne va donc pas se trier toute seule du fait que nous avons simplement précisé que c'était une List triée au niveau de JPA.
// Nous sommes en création, donc l'ordre dans lequel nous ajoutons les éléments, est l'ordre dans lequel nous allons itérer.
// Si jamais cette List disparaît de la mêmoire, et qu'elle est rechargée au niveau de la base de données, là, l'orderby va se mettre en action et nous allons effectivement avoir nos éléments triés.
// Mais quand nous sommes en création, c'est à nous de garantir que les éléments sont triés, et si nous ne le faisons pas, il ne vont pas se trier tout seul.
// Donc voila pour les relations 1:p à partir de List, de Set, et de cette espèce de List un peu hybride, qui ressemblent à des SortedSet mais qui sont quand même des List.
// Maintenant nous allons voir comment nous pouvons annoter nos Collections dans nos classes Java pour expliquer à JPA ce qu'il doit faire exactement.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Annoter une relation one to many pour fixer le comportement du mapping ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment, techniquement, les choses vont-elles se passer ?
// Nous avons une classe Departement qui est une entité JPA, nous supposons aussi que nous avons un champs de type clef primaire.
// Ce Departement à une relation de type 1:p, vers une autre entité qui s'appelle Commune, par une List de Communes, annotée par @OneToMany.
// Si nous en restons là, si nous ne mettons pas d'information complémentaires, nous allons avoir un comportement de Set.
// C'est à dire que nous ne pourrons pas mettre de doublons dans cette List de communes.
// Et si nous relisons nore liste de communes après leur ajout, nous allons perdre l'ordre dans lesquels elles ont été ajoutées.
// Si nous voulons un comportement ordonné de type SortedSet, il faut que nous ajoutions l'annotation '@OrderBy("name")' auquel nous passons un champs de la classe Commune.
// Cela ne fonctionnera pas si l'attribut passé à @OrderBy n'est pas un champs de la classe Commune.
// Maintenant, nous aurons un comportement associé à ce qui ressemble à un SortedSet.
// C'est à dire qu'en création, si nous mettons nos communes dans n'umporte quel ordre, nous itèrerons dans le même ordre, tant que la List de communes est dans la mémoire de notre application Java.
// Si la List de communes quitte la mémoire et est relue à partir de la base, l'@OrderBy va partir et va mettre les communes dans l'ordre par l'attribut passé dans le OrderBy, ici par 'name'.
// Cet ordre ne correspond pas nécéssairement à l'ordre dans lequel nous les avons ajoutées, mais cela reste quand même un ordre prédéfini.
// --> C'est donc plus un tri qu'un ordre.
// Maintenant si nous voulons un vrai comportement de List, avec un index, donc ordonné avec un index, et bien là ce n'est pas @OrderBy qu'il va falloir mettre, mais '@OrderColumn("Index")'.
// A cette annotation nous passons donc le nom de la colonne technique par laquelle nous voulons que la List soit ordonnée.
// JPA va donc créer cette colonne en base de données, et elle va porter le numéro d'index de chaque commune dans la List que nous avons créé.
// --> Cette manière-ci est la seule façon d'avoir un comportement de List exactement comme le comportement de List que nous avons dans une application Java.
// Attention, ceci est toutefois coûteux en performance, et il faut éviter de le faire.
// Donc voici comment nous pouvons mapper des List, de ces trois façons dans une base de données avec JPA.
// Si jamais plutôt qu'une List, nous avons un Set de communes, là il nous suffit de mettre @OneToMany et nous allons avoir le comportement de Set.
// C'est à dire, sans doublons, et sans être ordonné à chaque itération.
// Donc nous voyons que le choix par défaut qu'il faut faire lorsque nous créons des relations 1:p entre des entités JPA est sans aucun doute le choix du Set.
// C'est celui qui ressemble le plus au comportement 1:p en base de données, mais c'est également le plus simple à gérer.
//      @Entity
//      class Departement {
//          @OrderColumn("Index")
//          @OrderBy("name")
//          @OneToMany
//          List<Commune> communes;
//          @OneToMany
//          Set<Commune> communes2;
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper une table de hachage dont les clés sont des types primitifs ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième structure de l'API Collection que nous pouvons trouver dans les classes, ce sont les structures de tables de hashage, les Map.
// Nous avons toujours notre classe Departement qui est une entité JPA avec sa clef primaire, même si nous ne l'avons pas écrite, mais elle y est quelque part.
// Et nous avons aussi un champs de type Map, qui est une Map d'entiers et de communes.
// Qu'est ce que c'est que ce champs de type Map, comment est-ce que cela rentre dans le contexte de ce que nous avons déjà vu ?
// En fait, cette Map, met en relation des départements et des communes, et un département peut avoir plusieurs communes en relation.
// Ceci étant donné que nous pouvons mettre plusieurs paires clefs-valeurs dans une Map.
// Donc en fait une Map dans une entité va être une relation 1:p. Eventuellement si la relation retour est une List ou également une Map, cela pourra être une relation n:p.
// Donc il est parfaitement légal en JPA de dire que c'est une relation @OneToMany.
// Mais maintenant que va t'il se passer, en fait il y a plusieurs cas à distinguer :
// Lorsque nous allons faire par exemple : departement.put(75, Paris);, JPA va traiter cela exactement comme une relation 1:p.
// Donc dans notre table commune :
//      ID, Nom, ID_Departement.
//      12, Paris, 9.
// Il va aussi falloir faire quelque chose avec l'entier 75 que nous avons passé dans la méthode .put(). En fait nous avons deux cas possibles :
//      - Ce 75 est juste un entier qui peut avoir n'importe quelle valeur, et qui n'est pas relié notamment à l'entité commune.
//          Dans ce cas là nous allons avoir besoin d'une colonne technique supplémentaire pour stocker la valeur de cet entier.
//              ID, Nom, ID_Departement, Key.
//              12, Paris, 9, 75.
//          A présent pour dire à JPA à quelle colonne technique ajouter cet entier, nous allons rajouter une annotation : '@MapKeyColumn(name="Key")'.
//          Cette colonne technique va nous permettre de récupérer à partir de la valeur de cette clef, les départements qui y sont associés.
//          Effectivement, si nous faisons 'departement.get(75)', nous avons juste un 'select', avec l'ID_Departement, et la valeur de la clef qui vont être référencés dans la clause 'where'.
//      - Nous avons également une deuxième solution qui consiste à dire que cet entier n'est pas n'importe quoi.
//              ID, Nom, CodePostal, ID_Departement.
//              12, Paris, 75, 9.
//          Donc, l'entier 75 est un champs de l'entité Commune. Ceci est quelque chose de très fréquent.
//          En effet, lorsque nous faisons des tables de hashage, c'est très souvent pour faire des 'registries', ou des caches.
//          Donc nous allons prendre un champs des entités que nous voulons stocker dedans et y associer la valeur de ce champs à la valeur de l'entité.
//          Maintenant si nous voulons dire que l'entier est un champs de l'entité Commune, nous allons rajouter l'annotation '@MapKey(name="CodePostal")'.
// Ce sont les deux façons les plus importantes de traiter les tables de hashage en JPA.
// Et cela fonctionne dès l'instant que la clef est un type primitif ou une chaîne de caractères ou éventuellement un des types numériques BigInt ou BigDec.
// Ce ne sont pas exactement des types primitifs, mais des classes wrapper de types primitifs.
// Il y a une autre façon de faire dans le cas où la clef n'est pas un type primitif, mais une entité JPA, que nous allons voir par la suite.
//      @Entity
//      class Departement {
//          @MapKey(name="CodePostal")
//          @MapKeyColumn(name="Key")
//          @OneToMany
//          Map<Integer, Commune> map;
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper une table de hachage dont les clés sont des entités JPA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Que se passe t'il lorsque la clef est n'importe quel type d'objet. Par exemple, une classe qui modélise nos codes postaux.
//      Map<CodePostal, Commune> map2;
// Donc cette classe est nécessaire à la relation il va falloir que nous référençions d'une façon ou d'une autre notre classe CodePostal dans notre table Commune en base de données.
// Ceci est toujours une relation @OneToMany au sens ou c'est toujours une relation entre un département et un ensemble de communes. Seul le mode d'accès diffère.
// Donc, ce qui va se passer est que à côté de la table Commune, nous aurons une table CodePostal qui nécessitera une colonne de jointure entre la table Commune et la table CodePostal :
//      Commune
//          ID, Nom, ID_Departement, ID_CodePostal
//          12, Paris, 9, 7.
//      CodePostal
//          ID, Nom.
//          7, 75000.
// C'est comme cela que cela va fonctionner, nous n'avons rien à faire de plus, pas d'annotations supplémentaires à mettre en plus de ce @OneToMany.
// C'est ainsi que JPA va prendre en compte ce type de mapping, qui est plus complexe que les précédents.
// En effet, à chaque fois que nous voulons faire un .get() sur notre relation, potentiellement, nous allons avoir besoin de faire une jointure.
// Si nous effectuons un .get() sur un code postal, il va falloir que nous cherchions la clef primaire, la valeur du code postal, vérifier que c'est bien la même, etc.
// C'est donc quelque chose qui est plus complexe à gérer, à mettre en oeuvre, et qui va éventuellement générer plus de problèmes de performances.
// Quand nous voulons gérer des registries pour des relations 1:p en JPA, nous préférons une des deux premières solutions que nous avons vu dans la partie précédente.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper des collections d'objets qui ne sont pas des entités ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons également avec JPA mapper des List qui ne sont pas des List d'entités.
// Toutes les annotations que nous avons vu, @OneToOne, @OneToMany, @ManyToOne et @ManyToMany, permettent d'associer entre elles des entités JPA.
// Que se passe t'il si notre classe User possède en fait une List de chaînes de caractères avec par exemple le nom de ses amis ?
// Ces chaînes de caractères ne peuvent pas être des entités car la classe String ne peut pas être annotée avec @Entity.
// Nous avons une annotation particulière qui est '@ElementCollection' et qui va nous permettre malgré tout de mapper cette chaîne de caractères dans une table dans la base de données.
// Nous pouvons même y ajouter une annotation @OrderColumn(name="index"), pour garantir que les chaînes de caractères seront bien relues dans l'ordre dans lequel elles ont été écrites.
//      @Entity
//      class User {
//          @OrderColumn(name="index")
//          @ElementCollection
//          List<String> friends;
//      }
// Que va t-il se passer en base de données :
//      User
//          ID, Name.
//          12, James.
//      User_friends
//          ID, index, User_ID, friends.
//          0, 0, 12, Sarah.
//          1, 1, 12, Bob.
//          2, 2, 12, Rebecca.
// De cette manière là nous pouvons enregistrer automatiquement en base de données des List de type primitif.
// Cette fonctionnalité n'est pas très utilisée en JPA, toutefois elle est disponible et nous pouvons l'utiliser si nécessaire.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur le mapping des structures de API Collection /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Faisons un petit rappel sur ce que nous avons vu concernant la relation entre JPA et l'API Collection :
//      - Set : pour les relations 1:p :
//          Si nous voulons vraiment exploiter des List, à ce moment-là nous avons deux stratégies possibles :
//              --> Les List sont ordonnées par un champs de l'entité.
//              --> Les List sont ordonnées par un index, mais attention car cette solution est assez coûteuses, surtout si nous devons les modifier.
//      - Map : nous avons deux grandes catégories de Map :
//              --> Les Map dont les clefs sont des types "primitifs" (type wrapper d'un type primitif), ou des String, BigInteger ou BigDecimal.
//                  Dans ce cas là, la clef peut être aléatoire, donc prendre n'importe quelle valeur, ou alors être un champs de l'entité.
//              --> La clef est une entité, mais ceci a un coût car cette entité créé une jointure supplémentaire au niveau de la table destination de la relation gérée par cette Map.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper l'Héritage /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction au mapping de l'héritage /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons déjà parlé du problème d'impédance mismatch dans le mapping objet relationnel.
// L'impédance mismatch, c'est la difficulté que nous avons a associer certains concepts de la programmation objet avec des concepts des bases de données relationnelles.
// Si il y a un concept qui a vraiment du mal à passer d'un univers à un autre, c'est le concept de l'héritage.
// En programmation objet, il est très naturel d'avoir des classes qui héritent les unes des autres.
// En base de données relationnelle, une table qui est le concept qui correspond à la classe ne va pas hériter d'une autre table.
// Comment allons-nous faire pour mapper en base de données, pour associer à des tables de la base de données des classes qui étendent d'autres classes dans notre modèle objet.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Trois stratégies de mapping de l'héritage /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons partir d'un exemple très simple, une classe Employee qui étends une classe User, qui est une entité JPA, avec sa clef primaire.
// Comment pouvons-nous dire que notre classe Employee est aussi une entité JPA, puisqu'elle étends User, nous pouvons juste l'annoter avec l'annotation @Entity.
// Nous n'avons pas besoin de lui rajouter de clef primaire car lorsque JPA considère la classe Employee, il se rends compte qu'elle étends User, et que User à déjà une clef primaire.
// A présent, comment allons-nous mettre ces deux classes dans la base de données. Ceci est une vraie question.
//      @Entity
//      public class User {
//          @Id
//          int id;
//
//          String name;
//      }
//      @Entity
//      public class Employee extends User {
//          int salary;
//      }
// Donc nous pouvons pour voir cela créer une instance de User et une instance de Employee :
//      User user = new User(...);
//      Employee employee = new Employee(...);
// Si nous regardons les choses du point de vue des instances, nous nous rendons compte que dans user, nous avons un champs id et un champs name qui sont définis.
// Dans employee, nous avons également un champs id et un champs name, en plus d'un champs salary.
// Qu'est ce que cette façon de faire peut nous inspirer ?
//      --> Elle pourrait nous inspirer une première solution qui pourrait être de créer :
//          Employee
//              id, name, salary.
//          User
//              id, name.
//          Ainsi quand nous voudrons persister un Employee il ira dans la table Employee, et quand nous voudrons persister un User il ira dans la table User.
//      --> Eventuellement nous pourrions aussi faire comme ceci :
//          User
//              id, name, salary.
//          Ainsi, dans cette table User nous allons mélanger les instances de User et de Employee.
//      --> Nous pourrions aussi dire qu'un Employee est en fait un User, et en programmation objet c'est effectivement le cas.
//          Nous pouvons donc voir du point de vue des tables, la relation entre Employee et User comme une relation 1:1 : un Employee dépends d'un User pour exister.
//          User
//              id, name.
//          Employee
//              id, salary.
//          Ainsi, la colonne id de la table Employee sert à la fois de clef primaire et de colonne de jointure entre les deux tables.
// Ces trois façons de mapper l'héritage dans une base de donnée sont supportées par JPA.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Stratégie TABLE_PER_CLASS /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La première de ces trois stratégies consiste à dire qu'une entité JPA va correspondre à une table dans la base de données.
//      User
//          Id, name.
//      Employee
//          Id, name, salary.
// Nous allons regarder les différentes opérations de persistence que nous pouvons effectuer sur cette façon de mapper les classes dans des tables.
//      - Création : em.persist(...) : à laquelle nous pouvons passer soit User, soit Employee.
//          En passant un User à la méthode persist(), nous ajoutons un User dans la table User, et en passant un Employee, nous ajoutons un Employee à la table Employee.
//      - Retrieve : em.find(User.class, 12) : Par exemple ici, nous recherchons l'instance d'utilisateur dont la clef primaire est 12.
//          Ici, nous n'avons pas trop de problèmes, nous savons que les User se trouvent dans la table User, donc nous allons simplement faire un 'select User where Id = 12'.
//      - Update : user.setName(...) : Ici, nous n'aurons pas de problèmes non plus. Nous savons que nous nous adressons à une instance, ici de la classe User.
//          Nous connaissons la propriété à metttre à jour. Donc nous avons un objet qui va partir vers la bonne table.
//      - Delete : em.remove(user) : Là, pareil, nous connaissons l'instance de l'objet que nous voulons retirer de la base de données. Nous savons où cet objet est enregistré.
//      - Requête : polymorphiques : En JPA nous pouvons faire des requêtes, au sens requête SQL avec un langage particulier qui s'appelle le JPQL.
//          Ces requêtes ont la propriété d'être polymorphiques, c'est à dire que quand nous effectuons un 'select user User user', nous nous attendons à récupérer les instances de User.
//          Mais également les instances des classes qui étendent User. Et ce, car il n'y a pas d'héritage en SQL. Ces requêtes vont être un peu plus délicates.
//          En effet, nous allons devoir prendre toutes les tables qui correspondent aux classes qui étendent User, et il va falloir autant de requêtes select que nous avons de tables.
//          Ainsi, nous allons mettre toute ces requêtes select dans une seule et unique requête qui sera une requête de type 'union'.
//          Donc les requêtes polymorphiques, dans ce type de mapping vont être assez coûteuses.
// --> Donc pour ce genre de mapping, tout se passe bien, sauf pour les requêtes polymorphiques, qui peuvent-être assez coûteuses.
// --> Ce type de mapping s'appelle le mapping 'TABLE_PER_CLASS'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Stratégie SINGLE_TABLE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Second type de mapping, si nous avons deux entités, dont une qui hérite de l'autre, donc nous allons nous créer une seule table pour ces deux entités :
//      User
//          Id, Name, Salary.
// Nous voyons tout de suite que si nous mettons des instances de User dans cette table, nous n'allons utiliser que les deux premières colonnes de cette table.
// Si nous y mettons des instances d'Employee, nous remplirons les trois colonnes. Ceci pose déjà un petit problème car parmi les annotations @Column(...) que nous pouvons mettre, nous pouvons écrire :
//      @Column(nullable=false)
//      int salary;
// Ainsi, nous spécifions par l'annotation @Column, que la valeur de ce champs doit toujours être spécifié.
// De plus, qu'en tout cas en base de données, il nous faut une contrainte d'intégrité qui nous dit que la colonne salary ne peut pas contenir de valeur null.
// Par conséquent, nous aurons des problèmes en base de données lorsque nous mettrons des instances de User dans la table User puisqu'il nous faudra une valeur dans la colonne Salary.
// Alors que mécaniquement, la valeur dans la colonne Salary sera nulle pour les instances de User.
// --> Donc si nous choisissons ce schéma de mapping, nous n'allons pas pouvoir utiliser l'annotation avec la contrainte ci dessus.
//      - Create : em.persist(...) : JPA sait que les instances de User et les instances d'Employee vont dans la même table, donc nous avons une requête d'insertion qui va partir.
//      - Retrieve : em.find(User.class, 12) : JPA sait aussi qu'il trouvera l'instance de User dans la table User. Mais il a quand même besoin d'une précaution.
//          En effet, dans cette table User, nous avons un mélange d'instance d'Employee et d'instances de User.
//          Est-ce que l'User dont l'Id est 12 est bien un User. Nous pourrions nous dire de simplement regarder si son champs Salary est null.
//          Le problème est que JPA doit vérifier que cette ligne là est bien une ligne qui a correspondu au moment de l'insertion à une instance de la classe User et non Employee.
//          Pour ceci, nous n'avons qu'une seule façon de nous en sortir, en créant une colonne supplémentaire 'DTYPE', qui nous dira si l'objet est une instance de User ou de Employee.
//          Le nom de cette colonne est fixée par un standard, et se nomme toujours 'DTYPE', nous pouvons le surcharger avec des annotations.
//          Par défaut, la valeur de DTYPE est le nom complet de la classe qui correspond à la ligne sélectionnée, donc ici : org.emile.model.User et non juste User.
//          Donc le fait que le 'retrieve', fonctionne avec des classes impose la présence de cette colonne technique quand nous voulons mélanger plusieurs entités dans une même table.
//      - Update : employee.setSalary(10_000) : Ici, cela va fonctionner correctement, et nous n'avons pas besoin de la colonne DTYPE.
//      - Remove : em.remove(employee) : Ici, nous savons que c'est une instance d'Employee, donc nous savons qu'elle se situe dans cette table, donc tout va bien.
//      - Requêtes polymorphiques : Ici, toutes nos classes d'héritage se trouvent dans la même table, donc avec un seul select, nous allons pouvoir récupérer ce que nous souhaitons.
//          De plus, grâce à notre colonne technique, nous pourrons filtrer le résultat, ou mettre un filtre dans la requête pour obtenir exactement ce que nous souhaitons, avec une seule requête select.
// SINGLE_TABLE : signifie que nous mettons toutes les classes d'une même hiérarchie dans une même table.
// Dans la pratique, outre la contrainte de la colonne technique pour le retrieve, nous avons aussi une autre contrainte, dans les limites de la base de données en elle même.
// Limites dans le sens du nombre de colonne d'une table, et d'occupation en mémoire d'une seule ligne de la table, un record ou enregistrement, qui est un paramètre de la base de données.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Stratégie JOINED //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le dernier type de stratégie de mapping consiste à dire qu'à une entité correspond une table, et qu'une entité qui étends une autre entité est en relation 1:1 avec cette entité.
// Dans la stratégie TABLE_PER_CLASS, nous mettions tous les champs d'Employee dans la table Employee. Ici, nous n'allons mettre uniquement le champs salary et la clef primaire :
//      User
//          Id, Name.
//      Employee
//          Id, Salary.
// Comment les choses vont-elles se passer ?
//      - Création : em.persist(employee) : Ceci va nous forcer à enregistrer la clef primaire et le nom dans la table User, mais aussi la clef primaire et le salaire dans la table Employee.
//          Ici, nous avons donc deux insertions qui se passent lorsque nous souhaitons persister un Employee dans la base de données.
//      - Retrieve : em.find(Employee.class, 7) : Ici, il va falloir que nous fassions une jointure pour avoir le nom, l'id, et le salaire.
//          Une jointure 'inner join' est donc toujours un petit peu plus coûteux qu'un select classique.
//      - Update : employee.setSalary(10_000) : Ceci va bien se passer, car nous savons que la propriété salaire est dans la classe Employee, qui est associée à une table particulière.
//          Nous avons la clef primaire de l'Employee donc, nous n'aurons qu'un seul update qui va partir en base de données.
//      - Delete : em.remove(employee) : Etant donné que notre Employee est en fait distribué sur autant de tables que nous avons d'étage dans notre héritage, nous aurons ici deux requêtes delete.
// --> Donc sur ces quatre opérations, nous voyons qu'en terme de performance nous sommes un petit peu moins bien que dans les autres types de mapping :
//      --> Création : plusieurs insertions.
//      --> Retrieve : une jointure.
//      --> Update : se passe bien.
//      --> Delete : plusieurs delete.
// --> Le vrai intérêt de ce type de mapping, est que dans la table Employee, nous n'avons que des instances d'Employee.
//      --> Ainsi, si nous voulons mettre une contrainte d'intégrité signifiant que le contenu d'une colonne de la table Employee ne soit pas nulle, nous pouvons le faire.
//      - Requêtes polymorphiques : Ici, elles vont très bien se passer. En effet elles n'auront lieu que sur la table de base de notre hiérarchie, donc ici, sur la table User.
//          En fait, dans ce schéma là, le choix a été fait d'ajouter aussi une colonne technique 'DTYPE'. Ainsi, au niveau de la table de base, nous pouvons connaître le vrai type de l'objet.
// Ainsi, sur les trois stratégies que nous avons vues, aucune n'est parfaite. Ce pourquoi il y en a trois, pour pouvoir s'adapter selon les besoins de l'application.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Configurer la stratégie ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment peut-on dire à JPA que nous voulons mapper notre hiérarchie de classe dans un schéma de type JOINED, SINGLE_TABLE ou TABLE_PER_CLASS ?
// En JPA, tout passe par des annotations, donc nous avons une annotation pour cela '@Inheritance', qui prends un attribut 'strategy'.
// Cet attribut prends un type énuméré en paramètre qui s'appelle 'InheritanceType' et qui possède trois valeurs énumérées : JOINED, SINGLE_TABLE ou TABLE_PER_CLASS.
//      @Inheritance(strategy=InheritanceType.JOINED)
// Nous avons également deux autres annotations supplémentaires pour fixer le nom de la colonne technique qui va porter le type de l'entité :
//      @DiscriminatorColumn(...) : qui prends un attribut qui s'appelle name et qui va porter le nom de la colonne.
//      @DiscriminatorValue("...") : qui prends en attribut la valeur qui va nous permettre de discriminer User d'Employee.
// Pour la classe Employee, nous ne répétons pas l'annotation @DiscriminatorColumn(...), en revanche, nous répétons l'annotation @DiscriminatorValue("EMP").
// Ce qui fait que par exemple les instances d'Employee seront caractérisés par la valeur 'EMP' dans la colonne de discrimination qui va être automatiquement créée par JPA.
//      @Inheritance(strategy=InheritanceType.JOINED)
//      @DiscriminatorColumn(...)
//      @DiscriminatorValue("USER")
//      @Entity
//      public class User {
//          @Id
//          int id;
//          String name;
//      }
//      @DiscriminatorValue("EMP")
//      @Entity
//      public class Employee extends User {
//          int salary;
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper des champs factorisés dans une classe abstraite avec MappedSuperClass //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons un cas un petit peu plus compliqué que le cas très simple que nous avons vu auparavant.
// Nous allons supposer que nous avons trois classes, qui sont des entités JPA, une classe User, une classe Product et une classe Contract.
// Dans notre application, toutes nos entités JPA ont une clef primaire qui s'appelle 'id', et elles ont toutes un champs technique qui est la date de création à laquelle cette entité JPA a été créée.
// La programmation objet dit que quand nous avons un ensemble de classes qui partagent la même propriété, nous pouvons créer une classe éventuellement abstraite qui va être étendue par toutes ces classes.
// Ainsi, cette classe abstraite va pouvoir factoriser ces propriétés.
//      @Entity
//      class AbstractPersitent{
//          @Id
//          int id;
//          @Temporal(TemporalType.DATE)
//          Date creationDate;
//      }
//      @Entity
//      class User {}
//      @Entity
//      class Product {}
//      @Entity
//      class Contract {}
// Le problème est que si nous indiquons que la classe AbstractPersitent est une entité, cela va énormément nous contraindre au niveau de notre choix de type de mapping.
// Nous n'avons pas envie que cela nous contraigne spécialement car nous savons que dans notre application, nous n'aurons jamais d'instance de cette classe.
// La question est donc, est-ce que cela aurait un sens que cette classe soit une entité. Cela pourrait avoir un sens si nous voulions nous créer des List<AbstractPersistent>.
// Par exemple, dans Contract, mettre Contract en relation avec n'importe quel type d'entité JPA de notre application avec une relation de type 1:p.
// Pourquoi cela aurait un sens, car dans ces List<> nous ne pourrons mettre que des entités JPA en relation et rien d'autre.
// Nous ne ferions cela que si cela avait un sens métier à notre application. Or ici, ce n'est pas le cas. Donc comment allons nous faire ?
// --> Nous n'allons pas dire qu'AbstractPersistent est une entité, mais nous allons mettre à la place une autre annotation : @MappedSuperClass.
// Celle-ci implique que JPA connaît cette classe, mais qu'elle n'est toutefois pas une entité. Donc nous ne pourrons pas créer de List<> persistente avec cette classe.
// Dans la mesure où cette classe est une entité, nous n'avons pas de contrainte sur le schéma de mapping que nous allons choisir pour mapper l'héritage.
// En fait, tout ce que veux dire @MappedSuperClass, est que les champs de la classe sont des champs persistants, et vont être héritées par toutes les classes qui l'étendent.
// Cette annotation est la troisième annotation que nous avons vu que nous pouvons poser sur des classes :
//      - @Entity.
//      - @Embeddable.
//      - @MappedSuperClass.
// Seule les classes annotées par @Entity sont des entités JPA et donc peuvent faire partie des relations 1:1, 1:p, p:1 et n:p et peuvent également faire l'objet de requêtes.
// Il y a une petite subtilité qui est que @MappedSuperClass n'est pas reliée au fait que la classe soit une classe abstraite. En effet, cette annotation peut aussi être posée sur une classe concrète.
// De même que @Entity peut elle aussi être mise sur une classe abstraite ou concrète, nous n'avons aucune contrainte qui nous y oblige en JPA.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur le mapping de l'héritage en JPA /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Faisons à présent un petit bilan sur ce que nous avons vu sur le mapping de l'héritage, nous avons trois stratégies :
//      - JOINED.
//      - TABLE_PER_CLASS.
//      - SINGLE_TABLE.
// Nous avons vu que pour analyser quelle est la meilleure stratégie de mapping pour une application, il fallait se poser la question des opérations de type CRUD et des requêtes polymorphiques.
// Ainsi qu'éventuellement des opérations de lecture dans le cadre des relations 1:p, par exemple.
// Nous avons aussi vu que le mapping d'une hiérarchie jouait en fait avec deux annotations :
//      - @Entity, pouvant être mise sur une classe abstraite ou une classe concrète.
//      - @MappedSuperClass, qui fait de la classe annotée par cette annotation, une classe connue par JPA, mais qui n'est pas une entité.
// Au niveau de l'ordre dans lequel nous pouvons mettre ces classes et leurs annotation, il n'y en a pas vraiment.
// Nous avons aussi vu que cette stratégie est valable pour toute une hiérarchie de classes données, nous ne pouvons pas changer de stratégie en cours de route.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire des Requêtes avec JPA //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Présentation des requêtes SQL et JPQL avec JPA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// JPA est donc une solution qui nous permet d'associer un modèle objet qui vit dans une application Java à un schéma de base de données relationnelle.
// Nous avons vu que les informations que nous pouvons donner à JPA sur notre modèle objet, des métadonnées, sous forme d'annotation.
// Qui peuvent permettre de particulariser la manière dont ces classes vont être associées à certaines tables de notre base de données.
// JPA nous permet aussi de faire quelque chose qui est extrèmement utile, qui sont des requêtes.
// Nous avons une API particulière, qui est l'API 'Query', et qui va nous permettre de faire des requêtes dans cette base de données.
// Il y a deux manières de faire des requêtes avec JPA :
//      - La première est d'écrire des requêtes SQL 'Simple Query Language', de manière classique, de les confier à certaines méthodes de certains objets JPA.
//          Ces requêtes SQL vont nous permettre d'obtenir des résultats que nous allons pouvoir analyser.
//          Ces requêtes SQL sont très intéressantes, et il faut comprendre qu'elles sont écrites en fonction d'une base de données.
//          Donc le langage SQL n'est pas propre à Java ou à JPA, mais il est propre au serveur de base de données auquel nous nous adressons.
//              --> Ce SQL est relié au type de base de données auquel nous nous adressons, les références des tables, des colonnes, etc. qui se trouvent dans la base de données.
//      - JPA propose un deuxième langage, qui s'appelle JPQL 'JPA Query Language', un langage de requêtage, qui va nous permettre également d'interroger des bases de données et d'obtenir des résultats.
//          Ce langage ne dépends pas du serveur de base de données auquel il s'adresse. Les requêtes que nous allons écrire en JPQL dépendent des entités JPA qui ont été définies dans notre application.
//              --> La où SQL permet de lancer des requêtes sur des tables, JPQL permet de lancer des requêtes sur des entités JPA, et avec comme paramètres, les valeurs des champs de ces entités.
//          Cela signifie que si nous voulons faire des requêtes sur des classes, celles-ci doivent être des @Entity, et non des @MappedSuperClass ou des @Embeddable.
// Nous allons ainsi voir comment nous pouvons écrire des requêtes SQL avec JPA et les envoyer dans la base de données, et de la même façon avec JPQL.
// Une dernière remarque avant de commencer, nous avons deux façons de spécifier une requête SQL :
//      - Soit nous les spécifions directement dans une chaîne de caractères qui vont être directement intégrées dans notre code.
//      - Soit nous utilisons des requêtes nommées, donc de placer ces requêtes dans des annotations, et de donner des noms à ces requêtes.
//          Ensuite le code qui va exécuter ces requêtes va référencer ces noms plutôt que de donner le nom des requêtes directement.
// Nous avons donc quatre point à voir :
//      --> Les requêtes classiques SQL.
//      --> Les requêtes nommées SQL.
//      --> Les requêtes classiques JPQL.
//      --> Les requêtes nommées JPQL.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Exécuter une Requête Native ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Commençons par regarder les requêtes natives car d'une certaine façon ce sont les plus simples.
//      String sql = "select count (*) count from Maire"; : Ici nous comptons l'ensemble des éléments que nous appelons count de la table Maire.
// Pour lancer cette requête sur la base de données, nous passons par l'objet EntityManager, donc nous allons supposer que nous avons un EntityManager qui est prêt et que nous allons pouvoir utiliser.
// Cet EntityManager va nous permettre de créer une requête native, par la méthode à laquelle nous allons passer notre chaîne de caractères sql en paramètre :
//      Query query = em.createNativeQuery(sql);
// Cet objet de type Query porte la requête SQL, et va permettre de la lancer sur la base de données, et de l'exécuter sur la base de données.
// Toutefois, pour le moment, le fait d'avoir créé cet objet requête n'exécute aucune requête sur la base de données.
// Pour pouvoir exécuter cette requête, nous allons devoir appeler une méthode particulière de cet objet Query. Nous avons plusieurs méthodes sur cet objet pour le faire.
// Ici, nous savons que le résultat de cette requête est juste un entier, donc dans ce résultat nous n'avons qu'une ligne comprenant un seul élément.
//      Object result = query.getSingleResult();
// Cette méthode getSingleResult() peut retourner n'importe quel type d'élément. Donc cette méthode va nous retourner un Object, en l'occurrence ici, de type entier.
// Le type de cet entier dépends de l'implémentation de JPA que nous utilisons. Nous n'avons pas le même type d'élément retourné selon que nous utilisons Hibernate ou autre chose.
// Une fois que nous avons cet objet result, il va porter la valeur de count et nous allons pouvoir l'exploiter dans notre application comme nous le voulons.
// Nous pouvons donc voir que pour lancer une requête avec JPA, nous avons trois étapes :
//      --> Définition de la requête.
//      --> Construction de l'objet Query.
//      --> Exécution de la requête et récupération du résultat.
// Ces trois étapes sont donc un peu plus simple que ce que nous faisions en JDBC.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Résultat d'une requête native : une ligne avec plusieurs éléments /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Prenons une requête un petit peu plus compliquée :
//      String sql = "select name, age from Maire where id=12";
// Ici, nous aurons toujours une seule ligne comme résultat de requête, par contre nous aurons deux éléments dans cette ligne.
// Un de type chaîne de caractères, et l'autre de type entier probablement.
//      Query query = createNativeQuery(sql);
//      Object[] res = query.getSingleResult();
// Le reste ne change pas, puisque nous n'avons qu'une seule ligne, nous pouvons rester sur la méthode getSingleResult().
// Toutefois, cette méthode sur notre objet Query va nous retourner un tableau d'objets, qui va contenir une chaîne de caractères pour le nom, et un entier pour l'âge.
// Si nous voulons analyser correctement cet objet res, nous avons besoin d'avoir une visibilité sur la requête.
// En effet, c'est celle-ci qui va nous préciser que le premier élément du tableau est le nom du maire, et que le second est son âge.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Résultat d'une requête native : plusieurs lignes //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A présent nous allons créer une requête renvoyant plusieurs lignes.
//      String sql = "select name, age from Maire";
//      Query query = em.createNativeQuery(sql);
// Si nous appelons getSingleResult() avec un résultat de plusieurs lignes et non une seule, nous aurons une exception qui sera jetée.
//      List result =  query.getResultList();
// Cette List qui nous est retournée, n'est pas typée, ce qui veut dire que nous pouvons caster le résultat de cette List dans n'importe quelle List que nous voulons.
// Ici, nous avons un résultat composite, c'est à dire que nous aurons chaque ligne encodée sur un tableau d'objets, son premier élément étant une chaîne de caractères, et le second un entier.
// Donc en fait le vrai type de cette List, sera une List de tableaux d'objets : List<Object[]>.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Requêtes Natives Paramétrées //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// JPA nous permet en plus d'avoir des requêtes paramétrées.
// Supposons que nous avons une requête simple :
//      String sql = "Select codePostal from Communes where nom = ?1";
// Toutefois cette requête se fait à partir du nom de cette Commune, qui sera donc une variable notée : '?NuméroIndex'.
// Evidemment avant de lancer la requête, il va falloir que nous fixions cette variable, ce qui se fait avec l'objet Query :
//      Query query = em.createNativeQuery(sql);
//      query.setParameter(1, "Paris");
// Une fois que nous avons notre objet Query, nous pouvons exécuter la requête et récupérer les résultats comme normalement.
// Evidemment nous pouvons avoir plusieurs paramètres dans notre requête SQL, dans ce cas il vaut mieux avoir autant de numéros d'index que de paramètres.
// Et par conséquent, autant d'appels à setParameter() que nous avons de paramètres.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper le résultat d'une requête native dans une entité JPA ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Jusqu'à présent nous avons vu comment avec notre requête native, nous pouvons récupérer nos résultats en suivant les types imposés par la base de données.
// En fait, nous pouvons faire les choses d'une manière un petit peu plus sophistiquée avec JPA, et nous pouvons les faire de deux façons.
// La première façon consiste à dire que toutes les colonnes que nous venons de récupérer, sont exactement les colonnes par exemple de la classe Commune, qui est une entité JPA.
// Donc lorsque nous sommes dans ce contexte là, nous pouvons demander à JPA, de reconstituer une entité Commune. Comment ça fonctionne ?
//      String sql = "select * from Communes where codePostal = ?1"
// Ici, nous voyons bien que notre résultat requête contiendras tout le contenu d'une entité Commune, pour reconstituer l'entité JPA Commune.
//      Query query = em.createNativeQuery(sql, Commune.class);
// La classe Commune doit nécessairement être une entité JPA.
//      Object commune = query.getSingleResult();
// Ainsi, le vrai type de l'objet commune est Commune, et donc nous allons pouvoir le cater covenablement.
// Donc voici un première manière de demander à JPA, à partir d'un résultat de requête native de reconstituer une entité JPA.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Requêtes Natives Nommées //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'est-ce que c'est qu'une requête native nommée en JPA ? Premièrement, c'est une requête native normale, mais déclarée d'une certaine façon.
// Ici, nous reprenons la classe Commune, qui est une entité JPA et a bien une clef primaire. Nous supposons qu'elle a ses getters et ses setters.
// Dans ce fichier .java, et sur cette classe nous allons rajouter une autre annotation '@NamedNativeQueries({})'.
// A l'intérieur nous allons avoir autant d'annotations '@NamedNativeQuery()' que nous voulons. Celle-ci prends en paramètres deux éléments :
//      - name = "Commune.byName" : qui va décrire de façon simple, ce que fait la requête.
//      - query = "select * from Commune where name = ?1" : qui va être la requête associée à ce nom.
// Ceci constitue une requête nommée.
// Comment allons-nous pouvoir utiliser cette requête nommée ? Notre point d'entrée va toujours être notre EntityManager :
//      Query q = em.createNamedQuery("Commune-byName");
//      q.setParameter(1, "Paris");
//      Object[] o = q.getSingleResult();
// Après ce sera à nous d'analyser ce tableau d'objets.
// En fait les namedNativeQueries fonctionnent comme les nativeQueries sauf que c'est au niveau des annotations que nous déclarons nos requêtes.
// Et après dans notre code, il nous suffit d'appeler les références de ces requêtes lorsque nous en avons besoin.
// Nous pouvons mettre autant d'annotations @NamedNativeQuery que nous voulons dans l'annotation @NamedNativeQueries qui nous sert en fait d'enveloppe.
// En général, nous y plaçons les requêtes relatives aux entités dans la classe de l'entité, mais ce n'est pas une obligation.
//      @NamedNativeQueries({
//          @NamedNativeQuery(
//              name="Commune.ByName",
//              query="select * from Commune where name  = ?1"
//          )
//      })
//      @Entity
//      public class Commune {
//          @Id
//          int id;
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper le résultat d'une requête native nommée dans une entité ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il y a un petit rafinement que nous pouvons mettre dans nos @NamedNativeQuery, qui est un attribut supplémentaire : resultClass.
//      @NamedNativeQueries({
//          @NamedNativeQuery(
//              name="Commune.ByName",
//              query="select * from Commune where name  = ?1",
//              resultClass=Commune.class
//          )
//      })
// Ceci va fonctionner un petit peu de la même façon que lorsque nous avions passé notre classe Commune à notre méthode createNativeQuery(), sauf que là nous le réalisons directement à ce niveau là.
// Il va y avoir une petite différence dans le fonctionnement qui va être assez agréable.
// Toutefois nous devons aussi passer le type du résultat dans la méthode createNamedQuery() si nous voulons que cela fonctionne :
//      --> TypedQuery<Commune> tq = em.createNamedQuery("Commune-byName", Commune.class);
// Cette méthode createNamedQuery(), est différente de createNativeQuery(), car lorsqu'elle prends une classe en second paramètre, elle retourne non pas une Query normale, mais une TypedQuery<Commune>.
// Ce TypedQuery porte l'information, que le résultat de cette requête va être de type Commune. Ainsi :
//      Commue c = tq.getSingleResult();
//      List<Commune> lc = tq.getResultList();
// Nous n'allons pas avoir besoin de faire de cast pour que cela fonctionne, ce qui est très pratique pour les traitements des résultats.
// Ceci est quelque chose que nous pouvons faire avec les requêtes natives, une fois qu'elles sont nommées, car la c'est une méthode createNamedQuery() que nous appelons et plus createNativeQuery().
// Ces deux méthodes en fait ne fonctionnent pas de la même façon.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper le résultat d'une requête native nommée dans un objet quelconque ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu comment mapper le résultat d'une requête native, dans une entité JPA.
// Nous avons également la possibilité, de mapper le résultat d'une requête native dans un objet Java qui n'est pas une entité JPA, bien que ce soit un petit peu plus complexe.
//      @NamedNativeQueries({
//          @NamedNativeQuery(
//              name="Commune.stats",
//              query="select count * count, avg(population) avg from Commune",
//          )
//      })
// Ici, nous avons créé une requête native, et celle-ci nous sélectionne deux choses sur la table Commune, d'une part un champs 'count' qui nous sélectionne le nombre de communes dans la table.
// D'autres part, un champs 'avg' qui correspond à la moyenne de la population de toutes ces communes. Ceci, nous sort une ligne de résultats avec deux champs.
// Ces deux champs, nous voudrions les mettre dans un objet Statistics. Donc quelque part nous avons une classe Commune :
//      class Statistics {
//          public Statisics(count, avg)
//          ...
//      }
// Ces deux paramètres de la méthode Statistics vont être recopiés dans des champs, nous aurons aussi des getters et des setters, une méthode toString(), et tout ce qu'il faut.
// Ce que nous souhaitons faire est de mapper le résultat de cette requête dans un objet Statistics, qui n'est pas une entité JPA.
// Nous avons une solution technique pour le faire, qui est petit peu compliquée à mettre en oeuvre, mais qui est très puissante et fonctionne très bien une fois qu'elle a été correctement implémentée.
// Pour cela, nous allons ajouter une autre annotation sur notre entité Commune, en dessous de l'annotation @NamedNativeQueries({}) : '@ResultSetMappings({})'.
//      @ResultSetMappings({
//          @ResultSetMapping(
//              name = "stats",
//              classes = @ConstructorResult(
//                  targetClass = Statistics.class,
//                  columns = {
//                      @ColumResult(
//                          name = "count",
//                          type = long.class
//                      )
//                      @ColumnResult(
//                          name = "avg",
//                          type = double.class
//                      )
//                  }
//              )
//          )
//      })
// Un @ResultSetMapping() est en fait une recette de cuisine, qui va prendre le résultat d'une requête, typiquement un resultSet même si ils ne sont pas exposés en JPA.
// Puis de le ranger dans une classe qui sera référencée par ce @ResultSetMapping(). Celui-ci peut prendre plusieurs attributs :
//      - name : qui va permettre de le nommer, et donc de le référencer dans notre annotation @NamedNativeQuery().
//      - classes : permet de dire dans quelle(s) classe(s) nous allons ranger ce ResultSet, celui-ci à un type @ConstructorResult().
//          Ceci car nous allons prendre les éléments de @NamedNativeQuery() et les injecter dans le constructor particulier d'une classe.
//          Il prends pour attributs une targetClass, et des @Columns(), chacune prenant pour attribut un name et un type d'objet.
// Pour rappel, cette annotation @ResultSetMappings({}) vit sur la classe Commune, et non sur la classe Statistics.
// Ceci nous dit que les deux colonnes appelées dans la requête de la @NamedNativeQuery() vont être injectées dans le constructeur qui se trouve dans la classe Statistics.
// Toutefois, ceci ne peut fonctionner, évidemment, si le champs count est bien un long, et le champs avg est bien un double.
// Ce que va faire JPA est qu'il va chercher un constructeur dont la signature, est 'long, double'.
// Comment à présent pouvons-nous référencer ce @ResultSetMapping() dans notre @NamedNativeQuery() ?
// Tout simplement en y ajoutant un attribut 'resultSetMapping'.
//      @NamedNativeQueries({
//          @NamedNativeQuery(
//              name="Commune.stats",
//              query="select count * count, avg(population) avg from Commune",
//              resultSetMapping = "stats"
//          )
//      })
// Dès l'instant que nous avons fait cela, l'exécution de cette requête native, va déclencher cette procédure de mapping entre les colonnes qui s'y trouvent et la classe Statistics.
// Nous allons pouvoir ainsi récupérer directement un objet Statistics. Pour exécuter notre requête, nous allons bien sûr reprendre notre EntityManager :
//      Query q = em.createQuery("C.stats");
//      Statistics s = q.getSingleResult();
// Bien sûr, getSingleResult(), nous retourne un objet de typ Object, donc nous allons devoir faire un cast, mais nous pourrons le faire vers l'objet Statistics.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Plus loin avec ResultSetMapping ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// En fait, nous pouvons même aller plus loin dans ces @ResultSetMappings(), nous pouvons mettre plusieurs mapping et nous pouvons mettre des mappings de type différent.
// Précédemment, nous avons fait un mapping vers une classe qui n'est pas une entité, en faisant appel au constructeur de cette classe, directement.
// Mais si nous voulons, nous pouvons définir plusieurs classes avec plusieurs appels de constructeurs, dans un même @ResultSetMapping().
// Nous pouvons également mettre un attribut 'entities', qui prends un @EntityResult(), et qui va nous permettre de construire non pas des instances de classes quelquonques, mais des instances d'entités.
// Nous avons aussi un dernier attribut que nous pouvons mettre, 'columns', et qui prends @ColumnResult() en paramètre.
// Il va nous permettre de prendre une colonne et de la caster dans un type dont nous avons besoin.
//      @ResultSetMappings({
//          @ResultSetMapping(
//              name = "stats",
//              classes = @ConstructorResult(
//                  targetClass = Statistics.class,
//                  columns = {...}
//                  ),
//              entities = @EntityResult(...),
//              columns = @ColumnResult(...)
//          )
//      })
// Avec @ResultSetMapping(), nous pouvons prendre des résultats de requête qui comprendraient beaucoup de colonnes et sélectionner des paquets de colonnes à l'intérieur de ce ResultSet.
// Pour ensuite redistribuer ces colonnes pour construire différents objets Java.
// Celles-ci peuvent-être des classes quelquonques, des entités JPA, des colonnes qui vont rester toutes seules et qui pourront être mappées dans les types Java dont nous avons besoin.
// Ce @ResultSetMapping() est donc quelque chose d'extrèmement puissant, et qui nous permet de spécifier la façon dont nous voulons récupérer le résultats de nos requêtes natives.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le Langage de Requête JPA : JPQL //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à JPQL ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une des forces de JPA, est d'avoir un langage de requête, JPQL, et qui est indépendant des bases de données avec lesquelles nous travaillons.
// En fait, les requêtes natives sont très utiles et importantes à avoir, surtout quand nous avons déjà des requêtes sql dans une application legacy par exemple.
// Ainsi, nous pourrons récupérer ces requêtes sql et pourrons les transmettre dans une application JPA en se servant de JPQL.
// L'inconvéniant est que si nous voulons changer de serveur de base de données, ce qui est assez rare.
// Si nous voulons changer de shéma, c'est à dire de structure de table, donc des noms de tables et noms de colonnes, nous aurons besoin de changer les requêtes sql qui portent sur ces tables et colonnes.
// --> JPQL est un langage qui porte sur le modèle objet, qui est indépendant, à la fois du type de base de données auquel nous nous adressons.
// Mais également indépendant du schéma de base de données que nous avons choisi.
// Dès l'instant que le modèle objet ne change pas, les requêtes JPQL vont continuer à fonctionner. Le langage est un petit peu différent du sql.
// Par exemple, pour récupérer la commune dont le nom est Paris :
//      jpql = "select commune from Commune commune where commune.nom = 'Paris'";
//          --> select : ce mot clef va nous indiquer ce que nous voulons sélectionner, ce que nous souhaitons chercher comme information.
//          --> from : cette clause ne référence pas des tables puisque JPQL est indépendant des bases de données, mais référence des entités.
//              Donc 'Commune' est une entité JPA, donc quelque part dans notre application nous devons avoir :
//                      @Entity(name=Commune)
//                      publi class Commune{
//                          String nom;
//                      }
//              Il faut bien penser à noter l'attribut 'name', car si nous ne le mettons pas, ce sera le nom complet de la classe Commune, donc 'org.vitu.model.Commune'.
//              Ensuite, nous disons que nous sélectionnons une instance de cette entité 'commune', comme nous l'avons utilisée aussi dans la clause select.
//          --> where : nous dit que le champs qui s'appelle 'nom' dans cette entité Commune doit être égal à 'Paris'.
// Derrière, le mécanisme de JPA va prendre cette requête JPQL et va la convertir en une requête SQl. Il se peut très bien que la table ne s'appelle pas 'commune' ou la colonne ne s'appelle pas 'nom'.
// Mais comme JPA possède déà toutes ces informations grâce aux annotations, JPA va être capable de convertir cette chaîne de requête JPQL en une chaîne de requête SQl.
//      --> C'est ici que la magie s'opère car selon le type de base de données (PostGres, mySQL, SQLServer, Oracle...), le language SQL peut-être différent.
//              Mais ce n'est pas grave, car JPA, Hibernate et EclipseLink connaissent ces bases de données, ainsi que leurs spécificités du sql, et vont être capables de modifier la requête JPQL en SQL.
// Comment est-ce que cela va fonctionner ?
//      Query q = em.createQuery(jpql);
// Ainsi, nous n'aurons juste qu'à appeler getResultList() ou getSingleResult sur notre objet Query par la suite.
// --> Etant donné que ce que nous requêtons sont des entités JPA, nous n'avons plus besoin de faire du resultSetMapping, cet espèce de truc très technique et pas très beau.
//      Commune commune = q.getSingleResult();
//      List<Commune> l = q.getResultList();
// Voici donc le schéma de fonctionnement des requêtes JPQL. Nous allons nous concentrer sur ce que nous pouvons mettre dans ces requêtes JPQL.
// Car, évidemment, la syntaxe est différente du SQL, nous allons retrouver les mêmes concepts, mais nous avons quand même besoin de regarder comment techniquement, nous allons pouvoir écrire les choses.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Requêtes paramétrées en JPQL //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons également écrire des requêtes paramétrées avec JPQL, nous avons deux manières de le faire :
//      jpql = "select commune from Commune commune where commune.nom = ?1";
//          Query q = em.createQuery(jpql);
//          q.setParameter(1, "Paris");
//          --> Ceci est la première manière, qui reste classique.
//      jpql = "select commune from Commune commune where commun.nom = :nom"
//          Query q = em.createQuery(jpql);
//          q.setParameter("nom", "Paris");
//          --> Ainsi, nous donnons d'abord le nom du paramètre dont nous voulons fixer la valeur, puis sa valeur.
// L'avantage de cette seconde technique et qu'elle nous permet d'éviter les erreurs.
// Ainsi, ceci est le premier petit rafinement de JPQL par rapport a SQL, la possibilité d'avoir des requêtes paramétrées dans lesquelles les paramètres ont des noms.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Requête JPQL Simple ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons voir quelques exemples de requêtes JPQL :
//      --> select commune from Commune commune where commune.population > 100_000
//              Sélectionnera les communes dont les populations sont supérieures à 100 000.
//      --> select sum(Commune.population) from Commune commune where commune.population < 1_000
//              Sélectionnera toutes les communes de moins de 1 000 habitants, et fera la somme des habitants de toutes ces communes sélectionnées.
//      --> select commune from Commune commune where commune.population = (select max(c.population) From Commune c))
//              Sélectionnera la commune qui a la plus grande population dans toute la table Commune.
// Cette dernière requête est une requête incluse, qu'il est tout à fait possible de faire en JPQL et en SQL.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Jointure Implicite en JPQL ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent une requête JPQL avec des jointures sur un exemple un petit peu compliqué :
//      Departement
//          List<Commune> communes
//      Commune
//          Population
// Nous voudrions faire une requête qui nous donne une la liste des communes et des populations qui y sont associées. En sachant qu'il y a une relation 1:p entre Departement et Commune.
// Si nous voulions l'écrire en SQL, nous devrions faire une jointure. En JPQL nous aurons aussi besoin de faire une jointure :
//      --> select departement.nom, sum(commune.population) from Departement departement, in(departement.communes) commune where departement.nom = :name
// Ici, nous avons une première façon d'utiliser les jointures de manière implicite car nous n'avons pas mis de 'join' dans la requête JPQL.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Jointure Explicite en JPQL ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons toujours le même modèle d'entités JPA que précédemment. Ecrivons une requête JPQL assez simple :
//      --> select c.nom, c.departement.nom from Commune c
// Si nous écrivons les choses comme ça, en fait, de façon masquée nous avons écrit une jointure. Elle écrite dans la façon de suivre la relation département dans la commune 'c.departement.nom'.
// Que se serait-il passé si nous avions écrit une requête comme cela en SQL ?
//      --> select c.nom, d.nom from Commune c join Departement d on c.id_departement = d.id
// Ici nous avons une jointure explicite, et cette jointure, étant donné que nous n'avons rien mis comme jointure dessus, c'est une jointure interne.
// Une jointure interne signifie que nous ne préservons ni un côté ni l'autre de notre jointure.
// Donc si jamais dans notre liste de communes, nous avons des communes qui n'ont pas de département associé, ces communes ne sortirons pas dans notre résultat de requête.
// Supposons que nous voulions préserver le côté gauche de notre jointure, donc que nous voulons l'intégralité des résultats de communes quand bien même il ne serait en relation avec aucun département.
// A ce moment là, il faut que nous fassions une jointure externe, donc un left join à la place d'un join :
//      --> select c.nom, d.nom from Commune c left join Departement d on c.id_departement = d.id
// Ici, la jointure que nous avons écrite dans notre requête JPQL est implicite, en JPQL elles sont notées par inner join :
//      --> select c.nom, d.nom from Commune c join c.departement d
// Ici, d n'est pas n'importe quel département, mais les départements qui se trouvent dans la relation département de l'entité Commune.
// Cette fois-ci le join que nous avons indiqué est explicite, ainsi nous pourrons dire que c'est par exemple un left join, qui va préserver le côté gauche de la jointure :
//      --> select c.nom, d.nom from Commune c left join c.departement d
// Voila comment nous pouvons gérer les jointures en JPQL :
//      - Soit nous les gérons de manière implicite, ce qui donne un code très agréable, car nous traversons des jointures sans avoir besoin de les spécifier explicitement, contrairement au SQL.
//      - Soit, si nous avons besoin de fonctionnalités particulières, notamment de faire des jointures externes, à ce moment-là il faut que nous les déclarons de manière explicite.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Charger des entités en relation avec JOIN FETCH ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons un dernier point sur ces jointures en JPQL, qui est assez magique, qui est assez pratique, et qui n'existe absolument pas en SQL, en fait il n'aurait même pas de sens en SQL.
//      jpql = "select c from Commune c";
//          Query q = em.createQuery(jpql);
//          List<Commune> l = q.getResultList();
//          l --> commune.getDepartement(); (ici par exemple, nous pouvons boucler sur les communes de l).
// Le point important est qu'en fait une fois cette liste de communes récupérée, nous allons systématiquement avoir besoin, avec chaque entité commune, des entités département qui y sont liées.
// Nous allons donc systématiquement aller visiter la relation : commune.getDepartement(). Ca nous le savons systématiquement lorsque nous effectuons cette requête.
// Que va t'il se passer, il y a au moins une configuration qui n'est pas bonne pour nous ni pour les performances de notre application.
// C'est celle dans laquelle, JPA va charger la liste des communes, ne va pas peupler le champs département en allant chercher l'entité département en relation.
// Puis va nous laisser itérer sur notre liste de communes, et à chaque fois que nous allons faire getDepartement(), va aller nous chercher une par une les entités département.
// Si nous avons 35000 communes, comme c'est le cas en France, nous aurons une requête select pour récupérer les communes, puis 35000 requêtes select pour récupérer le département de chacune d'entre elles.
// Ceci, est ce que nous ne voulons pas faire, ce que nous voulons, c'est en une seule requête select, avec une jointure, récupérer nos communes ainsi que nos départements.
// La bonne nouvelle, est que nous pouvons dire à JPQL, que nous pouvons joindre notre entité Commune avec nos départements :
//      jpql = "select c from Commune c join c.departement d";
// Si nous écrivons juste cette requête, nous sommes en train de faire quelque chose d'inutile car le département que nous avons là, nous ne l'utilisons pas dans notre select.
// Nous pouvons toutefois rajouter le mot clef 'fetch' et qui va juste demander à JPA de charger en même temps que la commune, l'entité département qui y est associée :
//      jpql = "select c from Commune c join fetch c.departement d";
// Ainsi, en une seule requête nous allons charger les communes, et les départements en relation.
// Par conséquent, le code et les méthodes d'itération sur la liste n'aura plus besoin d'aller chercher les départements en base de données, ils seront déjà en mémoire dans notre application.
// Ce join fetch n'a de sens qu'en JPQL, car JPQL gère des entités, par opposition au SQL qui lui, ne gère que des tables et des colonnes.
// Ceci est quelque chose d'extrèmement pratique, qu'il faut savoir utiliser a bon escient pour optimiser les performances de nos applications.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mapper le résultat d'une requête JPQL dans un objet quelconque ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu que nous avions la possibilité avec les requêtes natives, de pouvoir mapper les résultats de requête dans des objets particuliers.
// Nous avions vu que cela peut se faire en différentes statégies. La plus technique et la plus complexe étant celle qui repose sur les ResultSetMappings.
// La notion de ResultSetMapping n'est définie que pour les requêtes natives, nous ne l'avons pas pour les requêtes JPQL.
// Toutefois, nous pouvons tout de même mapper des résultats qui ne sont pas des entités JPA dans des objets qui eux-mêmes ne seraient pas des entités JPA, seulement des objets de transport.
// Supposons que nous avons la requête suivante à traiter, qui va nous récupérer le nombre de communes, et la somme totale des populations des communes que nous avons dans notre base de données :
//      String jpql = "select count(c), sum(c.population) from Commune c";
// Nous pourrions, si nous le voulions, récupérer un Query qui nous mappe cette chose là, faire un getSingleResult(), celui-ci nous retournant un tableau d'objets, avec le count, puis la somme.
// Mais si nous voulons mapper ces deux résultats dans un objet Java particulier, nous pouvons le faire :
//      public class Statistics {
//          public Statistics (
//              long count;
//              long sum;
//              ... (qui va mapper les paramètres de son constructeur dans des champs, les exposer dans des getters et des setters etc.)
//          )
//      }
// Ce que nous souhaiterions, c'est mapper le résultat de notre requête dans un objet Statistics. Nous pouvons le faire avec une syntaxe un peu particulière :
//      String jpql = "select new org.paumard.model.util.Statistics(count(c), sum(c.population)) from Commune c";
// Cette fois-ci, cette requête select va nous retourner avec le getSingleResult() un seul objet qui sera de type Statistics.
// Comment pouvons-nous récupérer cet objet Statistics ? Nous allons pouvoir faire un petit peu comme avec les native queries :
//      TypedQuery<Statistics> query = em.createQuery(jpql, Statistics.class);
//      Statistics s = query.getSingleResult();
//      List<Statistics> ls = query.getResultList();        --> Si nous avions plus d'une ligne de résultats.
// Donc, nous pouvons également avec les requêtes JPQL, en utilisant la syntaxe ci-dessous, créer des requêtes typées, passer le type en paramètre de notre requête.
// Ceci, afin de récupérer nos résultats directement avec le bon type, ce qui nous évite d'avoir à les caster.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Requêtes JPQL Nommées /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// De la même façon que nous pouvions utiliser des requêtes natives nommées, nous pouvons aussi utiliser des requêtes JPQL nommées.
// L'annotation est presque la même :
//      @NamedQueries({
//          @NamedQuery(
//              name = "Commune.ByName"
//              query = "select c from Commune c where c.nom = :name"
//          )
//      })
//      @Entity
//      public class Commune {
//          ...
//      }
// Il est logique de mettre cette annotation sur l'entité qui est concernée, mais cela n'est même pas obligatoire.
// Comment est-ce que nous allons pouvoir utiliser cette NamedQuery ? En fait le pattern est exactement le même que le pattern des NamedNativeQuery :
//      TypedQuery<Commune> query = em.createNamedQuery("Commune.ByName", Commune.class);
// Les NamedQueries sont plus simples que les NamedNativeQueries essentiellement car nous n'avons pas besoin de ResultSetMapping à l'intérieur.
// En fait, les NamedQueries ne supportent pas le ResultSetMapping, car ceci est propre aux requêtes natives.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Paginer des résultats de requêtes JPQL et Natives /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous ayons créé une requête JPQL, et que nous l'ayons encapsulée dans un objet query de type Query.
// Nous pouvons nous attendre à ce que cet objet nous retourne énormément de résultats. Or le contexte applicatif est par exemple d'afficher les résultats dans une page web.
// Donc, nous ne pouvons pas afficher des milliers d'objets d'un coup dans une page web, donc nous aimerions faire de la pagination, par exemple récupérer nos objets par paquets de 50.
// Nous avons deux méthodes qui s'occupent de la pagination des résultats de requêtes :
//      - query.setFirstResult(index); : L'index qui est pris en paramètres est l'index du premier élément dans la liste de tous nos résultats que nous souhaitons retourner.
//          Par exemple, si nous passons 50 en paramètres, les résultats retournés le seront à partir du cinquantième résultat.
//      - query.setMaxResult(nombre); : Le nombre passé en paramètre sera le nombre de résultats par page.
//          Par exemple, si nous passons 50 en paramètre, il nous retournera 50 résultats.
// Donc, si nous exécutons la méthode getResultList() en ayant passé les deux méthodes précédentes en ayant chacune en paramètre 50, nous aurons les résultats de 50 à 100, donc la page 2 des résultats.
// Il faut faire très attention à setFirstResult(), car elle est associée avec getFirstResult() qui est souvent confondue avec getSingleResult().
// La méthode getFirstResult() retourne juste la valeur du résultat dont nous avons fixé l'index, ou la valeur du résultat d'un index par défaut si nous n'en avons pas fixé.
// Il en va de même avec getMaxResult(). Ces deux méthodes sont simplement les getters des deux méthodes 'set' qui y sont associées.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Requêtes JPQL pour Update et Delete ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Jusqu'à présent, nous avons parlé exclusivement des requêtes de type select, que ce soit en native de type SQL ou en JPA de type JPQL.
// Nous pouvons parfaitement avec des requêtes natives, passer des update ou des delete en SQL.
// Nous avons vu que pour ces requêtes là, nous avons déjà un support au travers de l'EntityManager, notamment au travers des deux méthodes, qui sont :
//      em.remove(...)
//      maire.setAge(...)
// Donc en fait, les update et les delete, sont déjà supportés au niveau fonctionnel par les fonctionnalités de l'EntityManager et par le fonctionnement même de JPA.
// Cela dit, cette façon de faire n'est pas forcément très efficace. Supposons que nous voulions effacer tous les maires de notre base de données qui n'ont pas gagné les dernières élections.
// Si nous utilisons la méthode remove, cela veut dire que nous allons devoir boucler sur tous les maires qui ont perdu les élections, et que nous les passions en paramètres de la méthode remove().
// Donc cela nous fait autant de requêtes que de maire ayant perdu les élections.
// Il serait donc plus efficace de concevoir une requête SQL qui fasse un delete massif et qui efface tous ces maires en une seule requête SQL.
// Il se trouve que delete est aussi supporté en JPQL. Et il en va de même pour les requêtes de type update.
// Nous avons une petite restriction cependant sur ces requêtes delete et update qui vient de la gestion des transactions.
// JPA nous dit qu'il veut bien une requête update ou delet écrite en JPQL, mais ce doit être la dernière opération de la transaction.
// La raison derrière ceci est la gestion des caches. En effet, JPA définit une structure de cache très précise sur deux niveaux :
//      - Un premier niveau qui est un cache associé à la transaction.
//      - Un deuxième niveau qui est un cache dit L2, qui est associé à l'ensemble des transactions.
// Si nous effectuons un update ou un delete massif, JPA va avoir du mal à mettre à jour son cache transactionnel.
// --> Ainsi, une fois que nous avons fait un update ou un delete, nous n'effectuons plus d'opérations de persistence, nous ne pouvons faire que des commit.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan JPA et Hibernate ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Faisons un petit résumé sur tout ce que nous avons vu sur cette API JPA, et qui encore une fois est tellement centrale dans les applications, qu'elle mérite du temps à étudier pleinement.
//      - Créer des entités JPA :
//          --> Mapper les champs : de type primitifs, de type String, de type date, de type énumération...
//          --> Mapper les relations : 1:1, 1:p, p:1, n:p, les cas bi-directionnels (pour lesquelles les relations 1:p ou n:1 peuvent être pathologiques). Mapping de l'héritage.
//          --> Cascade et fetch : quand nous chargeons une entité, est-ce que nous allons charger les entités en relation.
//                  Quand nous persistons une entité, est-ce que les entités en relation sont automatiquement persistées ?
//      - Gestion des entités JPA :
//          --> EntityManager : relié à la notion de transaction. C'est le point d'entrée de l'API pour toutes les opérations de persistence.
//          --> Opérations de persistence : persist, remove, detach et merge.
//      - Requêtes :
//          - SQL.
//          - JPQL.
//          - Possibilité de récupérer des résultats bruts pour les mettre dans des objets Java.
//      - Configuration :
//          - Persistence.xml : fichier central pour pouvoir configurer les applications JPA.
// Il y a pas mal d'aspects de JPA dont nous n'avons pas parlé, notamment les callback sur les cycles de vie, l'API Criteria, et encore d'autres éléments.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : JPA et Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ce module est une mise en pratique de l'API JDBC et de JPA/Hibernate à l'aide de sessions de live coding.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Initialisation et développement d'une application Java avec accès Base de données avec API JDBC ///////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Stream 1 sur JDBC 1/2 ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// - Téléchargement MySQL : www.mysql.com > téléchargements > MySQL Community (GPL) downloads > MySQL Workbench > Windows > Download > Go to download page > Download celui de 400 Mo.
// - Installation MySQL : Developper > Back > Custom (pour qu'il présélectionne les produits) > On retire Connector.NET, C++, Python, ODBC, MySQL for VisualStudio > Next > Next > Execute.
//      Next > Type and Networking : ne pas toucher au port car sinon il faut le remodifier dans le driver JDBC. > Next > Next > Rentrer mot de passe (A@3MySQL).
//      Nex > Next > Next > Execute > Next > Next > Finish.
// - Nouveau projet Maven, car notre projet va avoir besoin de la dépendance vers le driver JDBC pour MySQL. Le plus simple est de demander à Maven de faire le travail pour nous.
//      New > Project > Maven Project > Create a simple project > Group ID : org.vitu > titre-du-projet > Finish.
//      En ouvrant le dossier du projet dans l'arborescence, nous pouvons voir qu'il y a plus de dossiers que d'habitude dans un projet classique.
//      Une fois le projet Maven créé, clic-droit sur le projet > Maven > Update Project > Ok.
//      Maintenant notre projet Eclipse est configuré avec Maven.
//      Pour trouver le driver MySQL : search.maven.org > mysql-connector-java > Copier le code dependency, le coller dans notre pom.xml.
//      Une fois ajouté, dans l'arborescence, nous pouvons retrouver le connector dans les dependencies Maven.
// - Mise en place Git :
//      https://stackoverflow.com/questions/30421875/cant-connect-to-any-uri-error-while-commiting-code-from-eclipse-to-git-reposito
//      In your Eclipse Editor, Right click on your project -> Team -> Remote -> Configure Push to Upstream
//      Once the window opens, click "change..." button. Now you'll get a window called 'Select a URI'.
//      In the authentication part, Enter your GitHub username and DO NOT Enter your GitHub password.
//      For this, you need to create a 'personal access token' from Github. And ENTER the 'personal access token' instead of your GitHub password, in order to connect the repository.
//      https://github.com/settings/tokens
//      Please refer to the following websites for a better understanding:
//      https://docs.github.com/en/github/extending-github/git-automation-with-oauth-tokens
//      https://learn.microsoft.com/en-us/azure/devops/repos/git/share-your-code-in-git-eclipse?view=azure-devops
// --> Maintenant nous avons un serveur MySQL qui est up and running sur notre poste ainsi qu'une application Java qui y est connectée.
//      L'étape suivante va être d'écrire un peu de code Java qui va se connecter à ce serveur MySQL avec lequel nous allons pouvoir interragir.
// - Maintenant nous allons lancer le MySQL Workbench, qui va nous permettre d'intéragir avec un serveur MySQL > Se connecter à la Local Instance MySQL80 > Mdp > L'IHM MySQL Workbench s'ouvre.
//      - Créer un utilisateur, qui sera l'utilisateur qui sera utilisé pour le code Java, l'utilisateur autorisé à se connecter à ce serveur.
//          Menu de gauche > User and privileges > Add account (en bas) > jdbc-user, mdp : user > Apply --> Notre utilisateur est créé.
//          Nous pouvons retrouver notre nouvel utilisateur dans la liste des utilisateurs du menu Users and Privileges.
//      - Créer un schéma de base de données, dans lequel nous allons écrire les tables que nous allons utiliser pour notre application.
//          Bouton en haut 'pile' Create a new Schema in the connected Server > Name : db_jdbc > Apply > Apply > Finish > Notre base de données est créée.
//      - Maintenant nous devons indiquer que notre utilisateur peut se connecter à cette nouvelle base de données :
//          Users and Privileges > Selection de l'utilisateur > Onglet Schema Privileges > Add Entry > Selected Schema (pour qu'il ne puisse avoir que notre schéma) > Sélectionner le Schema > Ok.
//          Une nouvelle ligne apparaît avec le schéma, mais aucun privilège n'est renseigné pour le moment. > Select *ALL* en bas.
//          Maintenant l'utilisateur à tous les droits sur ce schéma, mais pas de donner des droits à d'autres utilisateurs, l'option : Grant Options > Apply.
//      - Maintenant nous allons pouvoir créer une connection directe avec cet utilisateur vers cette nouvelle base de données.
//          Pour cela nous passons dans l'écran Home (Onglet à gauche de notre instance locale en haut) > Clic sur le + à côté de MySQL Connections.
//          Nous pouvons entrer les différents paramètres :  Name : TP JDBC, Username : jdbc-user, default schema ; db_jdbc > Test Connection, puis mot de passe de l'utilisateur, donc "user".
//          Puis > Ok --> Maintenant nous avons un nouveau bouton de connection directement avec l'utilisateur souhaité sur sa base de données dans l'écran d'accueil.
//          Si nous l'actionnons, un troisième grand onglet s'ouvre avec notre connection, sur un écran "Query" > select now(); > Tout fonctionne.
//          Pour accéder à la base de données et à ses tables, nous pouvons sélectionner l'onglet 'Schema' à droite d''Administration' dans le volet gauche en bas.
//          Maintenant : create table test(id int primary key); > action réussie, clic droit sur tables > Refresh All > Notre table apparaît.
//              --> Donc toutes les commandes SQL tapées dans cet écran avec cet utilisateur fonctionnent directement sur notre base de données puisque ce sont ses privilèges.
//          Maintenant : drop table test; > Nous avons supprimé la table test.
//          Maintenant nous avons d'un côté un serveur MySQL qui est installé, nous avons créé une base de donnés, ainsi qu'un utilisateur avec un mot de passe.
//          Donc ne devrions pouvoir y connecter du code Java avec JDBC à ce serveur MySQL. Nous pouvons à présent retourner dans Eclipse.
//          A savoir que nous pouvons copier la requête create ou d'autres requêtes de notre table en faisant : clic droit sur la table > Copy to clipboard > Create Statement.
// - Eclipse : nouvelle classe dans src/main/java, package : org.vitu.jdbc, name : FirstJDBCConnection > Finish.
//      --> Le premier objet à y créer après la méthode main, est un objet de type Connection, c'est une interface, et l'implémentation de cette interface va nous être fournie par le driver JDBC.
//          Comme nous sommes en Java 6+, nous pouvons le récupérer directement à partir de la classe DriverManager avec la méthode statique getConnection().
//          Nous allons passer les arguments suivants :
//              - La chaîne de connection, qui est toujours la même, propres à chaque serveur de données, il faut donc aller les chercher sur internet : jdbc:mysql://localhost:3306/db_jdbc.
//              - Les paramètres d'authentification de l'utilisateur qui va se connecter à la base de données. Ici nous avons une faiblesse car nous devons mettre le mot de passe en clair dans le code.
//              C'est quelque-chose que nous voudrons absolument éviter, notamment si nous poussons notre code sur GitHub.
//              Nous pouvons ensuite imprimer notre objet connection pour voir si la connection se fait bien. Par contre, notre gestion de la SQLException devra être revue plus tard.
//          Nous pouvons aussi voir pour information que dans le .jar du mysql-connector dans le dossier Maven Dependencies, nous pouvons trouver le fameux fichier 'META-INF'.
//          Dans le sous-répertroire services nous avons java.sql.Driver, ceci est l'interface Driver que le driver MySQL doit implémenter.
//          Si nous ouvrons ce fichier, nous avons bien notre driver MySQL : 'com.mysql.cj.jdbc.Driver'. Si nous avions plusieurs lignes, donc plusieurs drivers, la première ligne est prise par défaut.
//          C'est ce mécanisme là qui permet au code DriverManager.getConnection() de fonctionner. Maintenant tous les drivers que nous utilisons utilisent cette fonctionnalité là.
//          Si toutefois nous tombons sur un vieux code Java avec un vieux driver MySQL, là il faudra aller chercher la classe qui est référencée ici.
//          Donc com.mysql.cj.jdbc.Driver par réflection, faire un class.forName(), puis faire un class.getConstructor().newInstance() etc. pour pouvoir instancier cette classe là.
//      --> La deuxième étape : effectuer une requête sur notre base de données.
//          Dans MySQL, nous créons une table : create table User(id int primary key auto_increment,name varchar(80));. La table est créée et visible en rafraichissant.
//          A présent dans nous allons créer une requête d'insertion dans notre nouvelle table User : insert into User(name) values ('Mariame');. Trois fois avec des noms différents.
//          Donc si nous effectuons une requête 'select count(*) count from User' à  partir d'Eclipse, nous devrions avoir un retour de 3 ayant pour nom 'count'.
//          Donc, nous pouvons soit, utiliser un objet de type 'Statement', ou alors utiliser un objet de type 'PreparedStatement'. Nous allons voir les deux solutions.
//          L'objet Statement nous sert à transporter des requêtes SQL jusqu'à notre base de données, en faisant un executeQuery() qui est utilisé pour faire des requêtes de type sélection.
//          Cette méthode va nous retourner un objet de type ResultSet qui va porter le résultat de la requête.
//          D'une manière générale, nous pouvons voir un résultat de requête comme une table. Comme ici nous savons que nous n'avons qu'une seule ligne.
//          Pour analyser un ResultSet, la méthode est toujours la même, il faut faire une boucle while ayant pour condition ResultSet.next().
//          Cette méthode next(), nous affirme qu'il y a bien une ligne suivante, et elle positionne le curseur dessus. A savoir que le curseur commence à 0 donc avec une ligne null.
//          Ensuite pour chaque ligne nous pouvons faire getLong(1), en utilisant 1 comme index de colonne, car en JDBC, l'index de colonne ne commence pas à 0 mais à 1.
//          Puisque nous n'avons qu'un seul résultat, nous pourrions même mettre un if à la place du while, en conservant la même condition bien sûr.
//          Nous pouvons ensuite ajouter une seconde requête en utilisant le même objet ResultSet, mais en passant une autre requête SQL en paramètre dans sa méthode executeQuery().
//          Mainentant nous pouvons exécuter une requête en utilisant la seconde méthode, c'est à dire le PreparedStatement, classe qui étends la classe Statement.
//          Pour ce faire, nous allons créer une requête SQL avec un point d'interrogation pour être une requête paramétrée, donc ce ne sera plus à proprement du SQL, car la requête ne sera plus valide.
//          Ce point d'interrogation, JDBC va l'interpréter comme étant un paramètre, et nous allons pouvoir fixer sa valeur, en utilisant un autre objet que le Statement, le PreparedStatement.
//          Le point d'entrée d'un PreparedStatement est toujours l'objet Connection, en lui passant la méthode prepareStatement(), il nous retournera un objet de type PreparedStatement.
//          Maintenant, en exécutant la méthode executeQuery() sur notre PreparedStatement en utilisant le même objet ResultSet que précédemment nous avons une erreur.
//          En effet, nous n'avons pas défini le paramètre variable de la requête, donc celle-ci n'a pas un format de requête SQL à cause du '?', donc elle retourne une exception.
//          Pour ce faire, avant d'appeler la méthode executeQuery(), nous devons appeler la méthode setInt(index, valeur) sur notre objet PreparedStatement, et cela fonctionne.
//          Le PreparedStatement est vraiment ce que nous devons utiliser lorsque nous devons paramétrer des requêtes. Pour des requêtes sans paramètres, nous pouvons utiliser des Statement.
//          Attention à ne surtout pas faire de concaténation de chaînes de caractères dans des Statement pour bypasser cette règle car ceci peut être très dangereux.
//      --> Nous avons oublié une dernière chose, qui est toute la partie fermeture des éléments. En effet, ce sont des ressources système, cela consomme une socket puisque c'est une connection TCC/IP.
//          Ici, le problème est que nous ne fermons jamais. Pour fermer cela, nous pouvons utiliser le pattern try-with-ressources.
//          Nous avons vu qu'il y a une relation entre une Connection et un Statement et entre un Statement et un ResultSet, relation qui est assez subtile.
//          Lorsque nous fermons un objet Statement, le ResultSet peut très bien devenir invalide. Nous ne pouvons pas avoir plusieurs ResultSet par Statements.
//          Maintenant que nous avons ajouté notre block try(){}, nous pouvons ajouter notre bloc catch(){} en prenant notre SQLException en paramètres, retirer la 'throw declaration' en début de classe.
//          Donc maintenant, notre pattern try-with-ressource va fermer la connection et donc fermer les Statements et les ResultSet qui sont derrière automatiquement.
//          De plus, nous effectuons le catch des possibles exceptions qui peuvent être jetées sur l'ensemble de ce bloc.
// - Récupération et étude des données de travail : https://github.com/josepaumard/data-tp
//      --> Nous pouvons télécharger les deux fichiers 'maires' de ce repository. Puis dézipper leurs fichiers .csv.
//          Dans Eclipse, nous pouvons créer le répertoire data dans notre dossier de projet. Maintenant nous pouvons créer une nouvelle classe : 'PlayWithMaire'.
//          Maintenant nous allons essayer de lire ce fichier ligne par ligne. Pour ce faire, nous créons un objet de type Path.
//          A présent nous pouvons créer un BufferedReader. Et sur celui-ci, en passant la méthode readLines(), nous pouvons récupérer un String, puis le passer dans une boucle while.
//          Toutefois, si nous ouvrons notre fichier .csv avec Notepad++, nous pouvons voir que celui-ci à le nom des colonnes en première ligne, nous allons donc devoir sauter la première ligne.
//          Pour ce faire, nous allons lire la première ligne en dehors de notre boucle while. Ainsi nous pourrons la laisser tomber et commencer la boucle while sur la ligne 2.
//          Dans la boucle while, nous allons spliter chaque ligne, ce qui va nous donner un tableau de String, à partir duquel nous pourrons récupérer les données que nous souhaitons.
//          Puisque nous récupérons les codes départements et codes insee, pour qu'ils soient bon, nous devons ajouter des '0' dans certains cas pour que les codes INSEE fassent bien 5 caractères.
//          Pour ce faire, nous pouvons simplement faire une concaténation avec un ou plusieurs '0' lorsque la longueur du code n'est pas celle attendue.
//      --> Attention, puisque nos données sont de l'open data, il faut quand même que nous vérifions que nous n'ayons pas de doublons dans notre fichier, donc dans nos codes postaux.
//          Pour faire cela, nous allons créer un objet de type Commune, qui prends un codePostal et un nom. Pour cela nous devons par conséquent créer une classe Commune.
//          Nous pouvons aussi créer le constructeur qui prends String et String, ces deux dernières actions étant faisables en survolant le nom de la classe ou en effectuant 'Ctrl + Shift + 1'.
//          En effectuant la même commande sur un champs de notre constructeur, il nous propose d'assigner tous les champs du constructeur à de nouveaux champs, ce qui nous fait gagner du temps.
//          Il ne nous manque plus qu'à générer les getters & setters, ainsi que la méthode toString(). Nous avons ainsi créer notre bean Commune.
//          Maintenant pour vérifier que nous n'avons pas de doublons, nous allons nous créer une Map, plus précisémment une HashMap.
//          Pour ce faire, nous allons utiliser la méthode put() sur notre HashMap, méthode qui nous retourne le nom de la valeur si celle-ci existe déjà.
//          Nous pouvons ensuite simplement mettre un syso dans un if de manière à très rapidement analyser si notre fichier comporte deux doublons.
//          En les recherchant dans le fichier, nous pouvons constater qu'ils existent car il y a deux maires pour ces deux communes.
//          Cela signifie qu'avant de commencer à écrire le code JDBC qui va permettre d'ajouter les Communes à la table commune, nous allons devoir faire un peu de nettoyage.
//          Nous allons avoir besoin d'un objet Collection, que nous pouvons créer dans le try-with-ressourcces aussi. Donc nous pouvons copier coller notre objet Connection créé précédemment.
//          Ce faisant, nous jetons une Exception aussi. Nous pouvons aussi préparer un PreparedStatement avec la requête : "insert into commune(code_postal, nom) values (?, ?)";.
//          En fin de bloc try(){}, nous pouvons définir nos deux variables, à savoir qu'il va falloir créer notre table Commune dans MySQL.
//          Donc nous pouvons mettre dans notre else sur l'existence de doublons, nos variables définies, ainsi que d'utiliser la méthode addBatch();.
//          Ainsi, en exécutant la méthode executeBatch() à la sortie de la boucle, toutes les requêtes SQL stockées dans le batch de notre PreparedStatement seront lancées en une seule fois.
// -----------
// PlayWithJDBC pom.xml :
//      <project
//      	xmlns="http://maven.apache.org/POM/4.0.0"
// 	        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
// 	        xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
//   	        <modelVersion>4.0.0</modelVersion>
//   	        <groupId>org.vitu</groupId>
//   	        <artifactId>play-with-jdbc</artifactId>
//   	        <version>0.0.1-SNAPSHOT</version>
// 	        <properties>
// 		        <maven.compiler.source>13</maven.compiler.source>
// 		        <maven.compiler.target>13</maven.compiler.target>
// 	        </properties>
// 	        <dependencies>
// 		        <dependency>
// 		            <groupId>mysql</groupId>
// 		            <artifactId>mysql-connector-java</artifactId>
// 		            <version>8.0.32</version>
// 		        </dependency>
// 	        </dependencies>
//      </project>
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Stream 1 sur JDBC 2/2 ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// --> Nous allons commencer par terminer notre travail sur la table commune. Tout d'abord nous allons la créer dans MySQL Workbench :
//      create table commune(code_postal varchar(8) primary key,nom varchar(80));
//      A présent, si nous exécutons le code de notre classe PlayWithCommunes, en principe, il va nous insérer nos Communes dans notre nouvelle table Commune.
//      Lors de son exécution qui est un peu longue, nous pouvons suivre le nombre de lignes insérées dans MySQL Workbench avec "select count(*) from commune", en réactualisant régulièrement le résultat.
// --> Par précaution, au cas ou nous détruisons les données de notre table commune, ce serait bien que nous ayons un backup.
//      Nous pouvons faire des backup de tables dans MySQL. Nous ouvrons un terminal dans Eclipse dans le répertoire de notre projet, dedans nous créons un répertoire 'sql' : "md sql".
//      Pour le voir dans le package explorer, il nous suffit de sélectionner notre projet et d'appuyer sur 'F5'. Maintenant nous voulons utiliser un utilitaire de MySQL, MySQLDump.
//      Toutefois, nous ne l'avons pas dans notre path, car il n'apparaît pas quand nous l'appelons 'mysqldump'. Nous allons devoir l'ajouter dans notre path.
//      Clic droit sur le raccourci de MySQL Workbench > Properties > Open file location > mysqldump.exe est bien ici, nous pouvons donc copier son chemin.
//      Clic droit sur l'icone du PC > Properties > Paramètres système avancés > Variables d'environnement > Path > Modifier > Ajouter le chemin du dossier > Ok > Fermer.
//      Maintenant nous pouvons rouvrir la command prompt et aller dans le dossier sql créé puis taper 'mysqldump', il va nous lister une série de commandes réalisable
//          Usage: mysqldump [OPTIONS] database [tables]
//          OR     mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]
//          OR     mysqldump [OPTIONS] --all-databases [OPTIONS]
//          For more options, use mysqldump --help
//      Nous pouvons donc taper : "mysqldump -u jdbc-user -p db_jdbc commune --add-drop-table > commune.sql" puis il nous demande le mot de passe utilisateur, et normalement le fichier est créé.
//      Si nous l'ouvrons, nous pouvons voir toutes les commandes sql, drop table, puis create table, puis insert tous nos éléments etc.
//      Ainsi, si par mégarde nous dropons la table commune (clic droit sur la table > drop table), à partir de la command prompt nous pouvons la rétablir en se servant de notre backup.
//      Il suffit de taper la commande suivante : "mysql -u jdbc-user -p db_jsbc < commune.sql", et la table se recréée et se reremplie.
//      Nous pouvons le vérifier en cliquant sur les doubles flèches de rafraichissement en haut à droite du volet gauche, onglet Schemas de MySQL Workbench, et en recomptant toutes les lignes.
// --> Comment connecter Eclipse à MySQL ?
//      Nous allons commencer par ouvrir une vue dans Eclipse : Windows > Show vue > Other... > Data Management --> Data Source Explorer & SQL Result.
//      Ce sont les deux vues qui permettent de se connecter aux bases de données à partir de l'intérieur d'Eclipse.
//      --> Data Source Explorer : Eclipse est lui-même codé en Java, donc pour pouvoir se connecter à une base de données il va avoir lui même besoin d'un driver JDBC.
//      Pour l'instant nous n'avons rien de déclaré dans cette fenètre, donc nous allons dans Database Connections > Clic droit > New > Sélectionner MySQL et nommer la connection.
//       A savoir qu'il s'agit de la création d'une connection à une base de données et non a toutes les bases de données dans MySQL Workbench.
//      Next > Eclipse nous demande un driver et n'en propose aucun > Clic sur New Driver Definition > Sélectionner le dernier Driver, puis onglet suivant 'Jar List' > Add .jar.
//      Nous savons que nous avons déjà le .jar dans notre repository Maven, donc : C: > Users > Emile > .m2 > repository > com > mysql > mysql-connector-java > Sélectionner le .jar.
//      Maintenant, nous pouvons modifier dans tous les onglets, l'url, le nom de la database, l'username et le mot de passe. A présent nous pouvons cliquer sur 'Test connection'.
//      Next > nous vérifions que tout est correct > Finish > A présent nous sommes connectés à notre base de données et nous avons accès aux données.
//      Par ailleurs, dans le dossier sql, nous allons créer un fichier que nous allons appeler 'scrapbook.sql'. Lorsque nous l'ouvrons dans Eclipse, nous avons une IHM spécigique au SQL.
//      Dans cet IHM, nous allons pouvoir définir une connection : MySql_5.1, un type et une base de données.
//      --> Nous pouvons à présent directement exécuter nos requêtes SQL à partir de cette page, les résultats s'affichant dans l'onglet 'SQL Results' en bas à droite.
//      --> Ainsi, si nous le voulons, nous pouvons ne pas sortir d'Eclipse pour tester notre code JDBC.
// --> Pour en revenir au code java, nous ajoutons un syso avant et après l'exécution du batch pour que nous voyons lorsque le batch est terminé, vu que cela peut prendre pas mal de temps.
// -----------
//      package org.vitu.jdbc;
//      import java.sql.Connection;
//      import java.sql.DriverManager;
//      import java.sql.PreparedStatement;
//      import java.sql.ResultSet;
//      import java.sql.SQLException;
//      import java.sql.Statement;
//      public class FirstJDBCConnection {
// 	        public static void main(String... args) {
// 		        try(Connection connection = DriverManager.getConnection(
// 				    "jdbc:mysql://localhost:3306/db_jdbc",
// 				    "jdbc-user",
// 				    "user"
// 				    );){
// 			        System.out.println("Connection = " + connection);
// 			        String sql = "select count(*) count from user";
// 			        Statement statement = connection.createStatement();
// 			        ResultSet resultSet = statement.executeQuery(sql);
// 			        System.out.println("\nSQL = " + sql);
// 			        while(resultSet.next()) {
// 				        long count = resultSet.getLong(1);
// 				        System.out.println("Count = " + count);
// 			        }
// 			        String sql2 = "select name from user";
// 			        resultSet = statement.executeQuery(sql2);
// 			        System.out.println("\nSQL = " + sql2);
// 			        while(resultSet.next()) {
// 				        String name = resultSet.getString("name");
// 				        System.out.println("Name = " + name);
// 			        }
// 			        String sql3 = "select id, name from user";
// 			        resultSet = statement.executeQuery(sql3);
// 			        System.out.println("\nSQL = " + sql3);
// 			        while(resultSet.next()) {
// 				        int id = resultSet.getInt("id");
// 				        String name = resultSet.getString("name");
// 				        System.out.println("Id, Name = " + id + ", " + name);
// 			        }
// 			        String sql4 = "select id, name from user where id = ?";
// 			        PreparedStatement preparedStatement = connection.prepareStatement(sql4);
// 			        preparedStatement.setInt(1, 4);
// 			        resultSet = preparedStatement.executeQuery();
// 			        System.out.println("\nSQL = " + sql4);
// 			        while(resultSet.next()) {
// 				        int id = resultSet.getInt("id");
// 				        String name = resultSet.getString("name");
// 				        System.out.println("Id, Name = " + id + ", " + name);
// 			        }
// 		        } catch (SQLException e) {
// 			        e.printStackTrace();
// 		        }
// 	        }
//      }
// -----------
//      package org.vitu.jdbc;
//      import java.io.BufferedReader;
//      import java.io.IOException;
//      import java.nio.file.Files;
//      import java.nio.file.Path;
//      import java.sql.Connection;
//      import java.sql.DriverManager;
//      import java.sql.PreparedStatement;
//      import java.sql.SQLException;
//      import java.util.Arrays;
//      import java.util.HashMap;
//      import java.util.Map;
//      import org.vitu.jdbc.model.Commune;
//      public class PlayWithCommune {
// 	        public static void main(String[] args) throws SQLException {
// 		        Map<String, Commune> communes = new HashMap<>();
// 		        Connection connection = DriverManager.getConnection(
// 				    "jdbc:mysql://localhost:3306/db_jdbc",
// 				    "jdbc-user",
// 				    "user"
// 				    );
// 		        String sql = "insert into commune(code_postal, nom) values (?, ?)";
// 		        PreparedStatement preparedStatement = connection.prepareStatement(sql);
// 		        Path path = Path.of("data/maires-25-04-2014.csv");
// 		        try(BufferedReader reader = Files.newBufferedReader(path);) {
// 			        String line = reader.readLine();
// 			        line = reader.readLine();
// 			        while (line != null) {
// 				        String[] split = line.split(";");
// 				        String codeDepartement = split[0];
// 				        if (codeDepartement.length() == 1) {
// 					        codeDepartement = "0" + codeDepartement;
// 				        }
// 				        String codeInsee = split[2];
// 				        if (codeInsee.length() == 1) {
// 					        codeInsee = "00" + codeInsee;
// 				        } else if (codeInsee.length() == 2) {
// 					        codeInsee = "0" + codeInsee;
// 				        }
// 				        String codePostal = codeDepartement + codeInsee;
// 				        String nom = split[3];
// 				        Commune commune = new Commune(codePostal, nom);
// 				        Commune previousCommune = communes.put(codePostal, commune);
// 				        if (previousCommune != null) {
// 					        System.out.println("Doublon = " + previousCommune);
// 				        } else {
// 					        preparedStatement.setString(1, codePostal);
// 					        preparedStatement.setString(2, nom);
// 					        preparedStatement.addBatch();
// 				        }
// 				        line = reader.readLine();
// 			        }
// 			        System.out.println("Executing barch");
// 			        int[] counts = preparedStatement.executeBatch();
// 			        System.out.println("Done batch");
// 			        int count = Arrays.stream(counts).sum();
// 			        System.out.println("Nombre de communes créées = " + count);
// 		        } catch(IOException e) {
// 			        e.printStackTrace();
// 		        }
// 	        }
//      }
// -----------
//      package org.vitu.jdbc.model;
//      public class Commune {
//      	private String codePostal;
// 	        private String nom;
// 	        public Commune(String codePostal, String nom) {
// 		        this.codePostal = codePostal;
// 		        this.nom = nom;
// 	        }
// 	        public String getCodePostal() {
// 		        return codePostal;
// 	        }
// 	        public void setCodePostal(String codePostal) {
// 		        this.codePostal = codePostal;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Commune [codePostal=" + codePostal + ", nom=" + nom + "]";
// 	        }
//      }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Initialisation et développement d'une application Java avec accès Base de données avec JPA et Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Stream 1 sur JPA/Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons dans un premier temps voir les questions de bases sur la configuration d'un modèle JPA, la configuration d'Eclipse et de MySQL Workbench.
// --> MySQL Workbench : Nous allons d'abord créer un autre utilisateur.
//      Nous onvrons MySQL Workbench > Nous nous connectons à la Local Instance MySQL80 > Onglet Administration > Users and Privileges > Add Acount > jpa-user, mdp: user > Apply.
//      Maintenant nous allons créer une base de données : Pile plus > nom: db_jpa > Apply > Appy > Finish.
//      Nous retournons sur notre nouvel User > Onglet Schema Privileges > Add Entry... > Selected Schema : db_jpa > Select All > Apply.
//      Retour à l'onglet Home "Maison" : Nous allons créer une nouvelle connection TP_JPA > '+' > Name : TP JPA, Username : jpa-user, Schema : db_jpa > Test Connection > Mot de passe en le sauvegardant.
//      --> Clic sur la nouvelle connection : nous sommes maintenant connectés en tant que user-jpa sur notre base de données db_jpa.
//      Nous pouvons tester que ça fonctionne en exécutant un "select now();", mais nous n'allons rien créer car nous allons demander à Hibernate ou EclipseLink de le faire pour nous.
// --> Eclipse :
//      - Maven : Tout d'abord nous allons créer un nouveau projet Maven : Clic droit sur l'arborescence > New > New Project > Maven Project > Next > Create a simple project coché > Next.
//          Group Id : org.vitu, Name : play-with-jpa > Finish.
//      - Git : Clic droit sur le nouveau projet > Team > Share Project > Créer un nouveau repository : play-with-jpa-repository > Finish.
//          Clic droit sur le repository > Remote > Push > Créer repository sur GitHub > Récupérer et entrer url http > Entrer utilisateur et mot de passe avec nouveau token dans Eclipse > Push.
//          Vérifier que le premier commit est bien enregistré dans le bon repository sur GitHub.
//      - Données : nous allons créer un répertoire 'data' dans notre nouveau projet, avec un nouveau fichier 'musiciens.txt'.
//          Dans celui-ci nous pouvons coller les données reprises sur le repo GitHub de José Paumard : https://github.com/josepaumard/data-tp en utilisant le fichier 'data-musiciens.txt'.
//      - Connection : pom.xml, nous pouvons reprendre les <properties> et les <dependencies> que dans le projet jdbc car JPA se connecte à une base de données aussi et à donc besoin du driver jdbc.
//          Maintenant clic droit sur le projet > Maven > Update Project --> Maintenant nous avons bien Java 13 sur notre JRE System Library.
//      - Nous allons commencer par créer une nouvelle classe dans src/main/java dans le package : org.vitu.jpa.model, qui se nomme 'Instrument', sans méthode main.
//      - Nous allons créer une autre classe, cette fois-ci dans le package 'model' et non 'jpa' qui se nomme 'PlayWithMusiciens', celle-ci avec une méthode main.
// --> Java / JPA  : Comment pouvons-nous nous y prendre pour faire du JPA ? Les choses sont assez compliquées et il y a pas mal de configuration à faire :
//      - Tout d'abord, nous avons besoin d'ajouter des dépendances dans le pom.xml. Comme JPA est une spécification de Java EE (à présent Jakarta EE).
//          Hibernate ou EclipseLink sont des implémentation de cette spécification, donc il nous faut ajouter une dépendance de Jakarta EE dans notre pom.xml.
//          Dans cette dépendance, nous avons l'intégralité des spécifications de jakarta EE. Si nous regardons dans la dépnedance, nous voyons que nous avons plein d'autres choses et pas que JPA.
//          Toutefois, la dedans nous n'avons que la partie spécification : les interfaces et quelques classes. Toutefois, en plus de l'interface, nous avons besoin d'une implémentation.
//      - Hibernate, est une implémentation particulièrement connue, qu'il va nous falloir donc ajouter aussi aux dépendances de notre pom.xml.
//          Nous pourrions aussi utiliser Hibernate en stand-alone, sans JPA, mais ici, nous utiliserons les deux pour pouvoir voir les deux, donc JPA au travers d'Hibernate.
//          Si la dépendance n'est plus bonne, se rendre sur https://central.sonatype.com/?smo=true pour faire une recherche de dépendances avec Maven, et fourni le code directement.
//      - EclipseLink, qui est normalement l'implémentation de référence, peut aussi être ajoutée pour avoir les deux.
// --> Première entité :
//      - Création de la classe : La classe Instruments. Nous allons créer cette classe ainsi que ses champs : nom, et TypeInstrument.
//          En faisant ctrl + 1 sur ce dernier Eclipse nous propose de créer une énumération, et c'est ce que nous allons faire : package : org.vitu.jpa.model.util.
//          De retour dans la classe Instruments, nous ajoutons les getter et les setters, ainsi qu'une méthode toString().
//          Nous ajoutons aussi un constructor using fields. Puis on en retire le super() car le compilateur nous le met automatiquement.
//          En effet, la première chose que fait le constructeur est d'appeler le constructeur de la super classe.
//      - Mise en place de l'entité sur cette classe :
//          Mais d'abord, qu'est-ce qu'une entité JPA ?
//          --> La classe, pour être une entité doit être un bean.
//              - Donc il doit avoir des getters et des setters (ctrl + shift + s), qui vont devenir une propriété pour le bean.
//                  En général, cette propriété correspond au nom du champs. Mais ce n'est pas une obligation, nous pouvons très bien ne pas avoir de champs.
//              - En second lieu, pour être un bean, la classe doit posséder un constructeur vide. Ici, nous avons un constructeur non-vide, donc ce n'est pas un bean.
//                  Soit il n'y a pas de constructeur et le compilateur en créé un vide par défaut, soit il y en a un, vide ou non, et le compilateur n'en créé pas.
//                  Effectivement, ici, si nous créons un nouvel Instrument dans la classe PlayWithMusicians, sans passer de paramètres (nom et type), le compilateur nous met en erreur.
//                  Toutefois, si nous enlevons le constructeur paramétré, et que la classe Instrument se retrouve sans constructeur (donc avec un constructeur vide par défaut), l'erreur disparaît.
//                  Donc nous devons ajouter un constructeur vide supplémentaire pour que cette classe soit bien un bean, en n'oubliant pas d'en retirer le super().
//              - Dernière chose : Il faut que la classe soit sérializable. Donc nous ajoutons que la class 'implements Serializable'.
//          Que devons-nous faire pour transformer ce bean Java en entité JPA ?
//              - Nous devons ajouter @Entity, et donc importer l'annotation. Vu que nous avons soit l'import d'Hibernate, soit celui de JPA, nous devons prendre celui de JPA : javax.persistence.Entity.
//              - Nous devons avoir une clef primaire puisque l'entité va être transmise en tant que donnée dans une base de données : private int id.
//                  Nous pouvons ainsi ajouter l'annotation @Id sur ce champs, générer ses getters & setters, et regénérer l'override de la méthode toString() qui prendra ainsi en compte ce champs.
//          --> Notre classe Instrument est à présent une entité JPA.
//          Toutefois, nous avons une erreur sur le nom de la classe Instrument car nous n'avons pas encore défini de 'serial version ID'.
//          Mais ce n'est pas grave car le compilateur va nous le générer lui-même, donc nous pourrons vivre avec ce warning.
//      - Maintenant nous pouvons créer des objets Instrument : Instrument instrument = new Instrument("Violon", TypeInstrument.CORDES).
//          A savoir qu'il faut penser à importer la classe Instrument, ainsi que l'énumération TypeInstrument, et créer une énumération 'CORDES' (en survolant les mots clefs en erreur).
// --> Associer cette entité JPA à des données se trouvant en base de données, pour cela nous avons besoin de faire un peu de configuration :
//      - Créer une unité de persistence : un ensemble d'entité JPA associées à des lignes dans des tables dans des bases de données.
//          - Pour créer une unité de persistence, nous avons besoin d'un descripteur particulier qui s'appelle 'persistence.xml'.
//              Nous allons créer son répertoire spécifique : clic droit sur src/main/ressources > New Folder > META-INF. Ce nom doit être respecté, sinons persistece.xml ne sera pas trouvé.
//              Nous pouvons y créer notre fichier persistence.xml à présent. Ce fichier est reconnu par Eclipse car celui-ci a une icone particulière.
//          - Maintenant nous allons le compléter avec tout d'abord son unique élément racine '<persistence>'. Il est attaché à un NameSpace (xmlns), et à un deuxième (xmlns:xsi).
//              Puis nous avons la location du schéma ainsi que le numéro de version. Eclipse nous dit que le fichier ne compile pas car effectivement l'élément persistence doit avoir des éléments fils.
//              En effet, le format de notre fichier n'est pas encore conforme tel qu'il l'est actuellement, au xmlSchema précisé.
//          - Donc nous allons créer un sous-élément '<persistence-unit>', à savoir que nous pouvons si nous le voulons en avoir plusieurs dans un même fichier persistence.xml, même si c'est rare.
//              Nous devons lui donner un nom en attribut 'play-with-jpa', et celui-ci est très important car c'est lui que nous allons référencer dans notre code Java.
//              Nous devons lui donner aussi un second attribut 'transaction-type', qui peut avoir deux valeurs, 'JTA' ou 'RESOURCE_LOCAL'.
//              Lorsque nous faisons de la persistence en Java EE et que nous allons mettre notre unité de persistence dans un serveur Java EE, nous utilisons 'JTA', mais ce n'est pas encore le cas ici.
//              Donc, lorsque nous utilisons Java SE, comme ici, à travers une méthode main, nous utilisons l'attribut 'RESOURCE_LOCAL'.
//          - Maintentant, vu que nous avons deux implémentations de JPA dans les dépendances de notre pom.xml, nous allons devoir choisir entre Hibernate et EclipseLink.
//              Donc, nous pouvons à présent mettre un '<provider>', qui peut prendre n'importe quelle valeur. Nous lui donnons la valeur 'org.hibernate.jpa.HibernatePersistenceProvider'.
//              Ce nom est en fait le nom d'une classe, si nous sélectionnons 'HibernatePersistenceProvider', et que nous effectuons 'Ctrl + Shift + T', Eclipse nous ouvre la classe en question.
//              En regardant cette classe, nous voyons que celle-ci étends la classe 'PersistenceProvider', cette dernière étant une implémentation de JPA car provenant du package 'javax.persistence'.
//          - A présent il faut que nous expliquions à Hibernate, dans quelle base de données est-ce que nous voulons qu'il persiste les données de cette unité de persistence dans notre application.
//              Ceci se fait avec des propriétés, donc un sous-élément '<properties>' qui aura lui-même des sous-éléments '<property>'.
//              Ces sous-éléments property ont deux attributs, 'name' et 'value', nous pouvons voir le 'name', comme une espèce de clef.
//              Ainsi, nous pouvons d'ailleurs voir ce sous-élément 'poperties' comme une table de hashage de 'property' ayant pour clef leur 'name'.
//              Par ailleurs, nous pouvons spécifier les propriétés d'une unité de persistence en remplissant une table de hashage particulière au niveau de notre code Java, mais ici nous le ferons en xml.
//              Ici, nous avons 4 propriétés à fixer, un driver jdbc, un url jdbc, un user jdbc et un password jdbc.
//                  --> Driver : est le driver que nous allons utiliser pour jdbc (MySQL).
//                  --> Url : url de connection pour jdbc.
//                  --> User : utilisateur de connection pour jdbc.
//                  --> Password : mot de passe de connection pour jdbc.
//              Effectivement, puisque JPA s'appuie sur jdbc, nous lui spécifions toutes les informations ici.
//                  --> Ainsi, nous n'aurons plus besoin de créer un objet Connection, ni d'objet Statement ou PreparedStatement, ni d'objet ResultSet.
//              La valeur du driver, nous pouvons la retrouver dans notre .jar mysqlconnector, elle à la forme d'une classe : 'com.mysql.cj.jdbc.Driver'.
//              La valeur de l'url est celle de notre base de données : 'jdbc:mysql://localhost:3306/db_jpa'.
//              Les valeurs user et mot de passe sont celles crées sur notre MySQL Workbench, l'utilisateur auquel nous avons donné tous les droits, sauf celui de donner des droits.
//              --> Maintenant, Hibernate va être capable de se connecter à la base de données.
// --> Nous pouvons à présent créer notre point d'entrée à JPA dans notre classe PlayWithMusiciens :
//          - Pour commencer, nous devons créer notre point d'entrée à la persistence : un objet 'EntityManagerFactory'. Ce point d'entrée est créé à partir d'un objet factory qui s'appelle Persistence.
//              A cet objet nous allons appliquer la méthode createEntityManagerFactory() à laquelle nous passons le nom de l'unité de Persistence dans notre fichier xml : 'play-with-jpa'.
//              Si nous l'imprimons dans la console, nous obtenons : org.hibernate.internal.SessionFactoryImpl@29be997f, ce qui signifie que tout est bon.
//              Avant de continuer, il faut absolument que ceci fonctionne, donc c'est une bonne pratique de le tester avant de continuer.
//          - Maintenant, nous pouvons demander à notre emf de nous créer un EntityManager, c'est d'ailleurs son seul rôle.
//              A présent nous pouvons appliquer la méthode persist() à notre EntityManager, en lui passant 'instrument' en paramètre.
//              Toutefois, rien ne se passe en base de données, car nous n'avons pas configuré notre classe Instrument par rapport à JPA.
//              --> Effectivement, lorsque nous sommes en RESSOURCE_LOCAL, il faut que nous gérions la transaction dans laquelle va s'écrire les modifications en base de données.
//              Ainsi, nous créons un objet EntityTransaction, puis nous lui appliquons les méthodes begin() avant le persist(), puis commit().
//          - A présent, nous allons créer une nouvelle table dans la base de données : create table instrument(id int primary key,nom varchar(80),type varchar(80));.
//              Maintenant nous avons une table d'un côté, une entité JPA de l'autre, donc nous devrions être capables de les connecter entre elles.
//              Effectivement, si nous exécutons le code Java, notre instrument 'Violon' est bien ajouté dans la table.
//          - Que se passe t-il si nous essayons de réexécuter ce code en y entrant le 'violoncelle' ? Nous avons une erreur : Duplicate entry '0' for key primary.
//              Ceci est parce que nous n'avons pas demandé ni à Hibernate, ni à MySQL de gérer les clefs primaires. Donc c'est à notre code Java de le faire, et nous ne l'avons pas fait.
//              Pour régler ce problème, nous pouvons dire à Hibernate, dans la classe Instrument, qu'il faut qu'il mette en place une stratégie de gestion des clefs primaires sur le champs id.
//              Pour ce faire, nous lui ajoutons l'annotation : @GeneratedValue(strategy = GenerationType.SEQUENCE). A savoir que chaque élément peut-être cherché et choisi dans la documentation Eclipse.
//          - Toutefois, à présent, il faut qu'Hibernate puisse s'assurer que la table ciblée puisse bien accepter le comportement 'SEQUENCE' qui a été choisi précédemment.
//              Ceci se fait dans le fichier persistence.xml : <property name="hibernate.hbm2ddl.auto" value="create" />.
//              Ici, nous disons à Hibernate que lorsqu'il charge les entités JPA, qu'il vérifie qu'il a bien les tables qui correspondent, et les éléments qui correspondent en base de données.
//              Ainsi, il pourra gérer les opérations de persistence. Ici, ce sera donc une propriété d'Hibernate et non de JPA. En commentaire nous avons mis les valeurs que cette propriété peut prendre.
//              Avec la propriété 'validate', cela ne fonctionne pas. Ceci est parce que nous avons mis la valeur 'SEQUENCE' à notre stratégie de clef primaire.
//              Donc nous passons à la propriété 'create'. De plus, nous droppons la table créée dans MySQL pour qu'Hibernate puisse la recréer.
//              Maintenant si nous réexécutons PlayWithInstruments, dans MySQL, Hibernate nous à créé deux tables, une table instrument, et une table instrument_sequence.
//              Cette denrière possède une colonne 'next_val' qui va porter la valeur suivante de clef primaire qu'Hibernate va utiliser pour générer nos données.
//          - Si nous changeons le code pour créer un violoncelle à la place du violon, la ligne va être remplacée dans la base de données. Ceci est parce que nous sommes en 'drop and create'.
//              Donc pour avoir nos deux ligne, nous devons créer deux instruments, et persister les deux.
//              Si nous imprimons nos instruments avant et après la transaction, nous pouvons voir que les clefs primaires sont passées de 0 à 1 ou 2, car Hibernate les à remodelées.
//          - Nous ajoutons trois propriétés à notre fichier persistence.xml :
//              <!-- https://www.youtube.com/watch?v=FjmuClV40A4 -->
//              <property name="hibernate.show_sql" value="true" />
//              <property name="hibernate.format_sql" value="true" />
//              <property name="hibernate.use_sql_comments" value="true" />
//                  --> Ces propriétés vont nous permettre de voir dans la console, les requêtes qu'Hibernate va lancer en base de données.
//                  --> Nous pouvons constater que ce ne sont que des PreparedStatement, car nous avons beaucoup de '?' dans les requêtes exécutées par Hibernate.
// --> Comment faire pour relire une entité de la base de données :
//          - Nous allons commencer par créer une nouvelle classe 'ReadFromInstruments' à la racine de notre projet play-with-jpa.
//              Nous y copions notre EntityManagerFactory et notre EntityManager.
//          - Nous allons passer en 'validate' dans le fichier persistence.xml, pour ne pas être en 'create' et donc dropper nos tables.
//              Il nous faut la classe de l'entité et la valeur de la clef primaire pour pouvoir relire notre entité.
//              En utilisant la méthode find() sur notre entityManager, et en lui passant la classe de l'entité et la clef primaire, nous pouvons imprimer dans la console nos deux instruments.
//              Toutefois, il faut bien noter que si nous n'avons pas ces informations, nous ne pouvons pas lire les données en base de données.
//          - En lisant les données sorties, nous constatons que la valeur du type n'est pas bonne, en effet normalement nous devrions avoir un 'ordinal', et ici nous avons '0'.
//              Nous pouvons ajouter une annotation dans notre classe Instrument : @Enumerated(EnumType.STRING).
//              Aussi nous pouvons modifier la taille des varchar des colonnes à l'aide d'annotations : @Column(length=80, nullable = false) pour le nom, @Column(length=20) pour le type.
//              Nous renommons la classe 'PlayWithInstruments' en 'CreateInstruments', puis nous repassons en create dans le persistence.xml.
//              Ainsi, nous allons pouvoir dropper puis recréer les tables avec cette nouvelle configuration.7
// -----------
//      <?xml version="1.0" encoding="UTF-8" ?>
//      <persistence
// 	        xmlns="http://xmlns.jcp.org/xml/ns/persistence"
// 	        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
// 	        xsi:schemaLocation=
// 		        "http://xmlns.jcp.org/xml/ns/persistence
// 		        http://xmlns.jcp.org/xml/ns/persistence/persistence_2_2.xsd"
// 	        version="2.2">
// 	        <persistence-unit name="play-with-jpa" transaction-type="RESOURCE_LOCAL">
// 		        <provider>org.hibernate.jpa.HibernatePersistenceProvider</provider>
// 		        <properties>
// 			        <property name="javax.persistence.jdbc.driver"
// 					          value="com.mysql.cj.jdbc.Driver"/>
// 			        <property name="javax.persistence.jdbc.url"
// 					          value="jdbc:mysql://localhost:3306/db_jpa"/>
// 			        <property name="javax.persistence.jdbc.user"
// 				        	  value="jpa-user"/>
// 			        <property name="javax.persistence.jdbc.password"
// 					          value="user"/>
// 			        <!-- validate | update | create | create-drop -->
// 			        <property name="hibernate.hbm2ddl.auto"
// 					          value="validate" />
// 			        <!-- https://www.youtube.com/watch?v=FjmuClV40A4 -->
// 			        <property name="hibernate.show_sql" value="true" />
// 			        <property name="hibernate.format_sql" value="true" />
// 			        <property name="hibernate.use_sql_comments" value="true" />
// 		        </properties>
// 	        </persistence-unit>
//      </persistence>
// -----------
//      package org.vitu.jpa;
//      import java.io.IOException;
//      import java.nio.file.Files;
//      import java.nio.file.Path;
//      import java.util.Arrays;
//      import java.util.HashMap;
//      import java.util.List;
//      import java.util.Map;
//      import java.util.function.Function;
//      import java.util.stream.Collectors;
//      import java.util.stream.Stream;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.EntityTransaction;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Instrument;
//      import org.vitu.jpa.model.Musicien;
//      import org.vitu.jpa.model.util.TypeInstrument;
//      public class MusiciensAndInstruments {
// 	        private static Map<String, Instrument> registryInstrument = new HashMap<>();
// 	        public static void main(String... args) {
// 		        List<Instrument> instruments = readInstrument();
// 		        List<Musicien> musiciens = readMusiciens();
// 		        musiciens.forEach(System.out::println);
// 		        EntityManagerFactory emf = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        System.out.println("EMF = " + emf);
// 		        EntityManager entityManager = emf.createEntityManager();
// 		        EntityTransaction transaction = entityManager.getTransaction();
// 		        transaction.begin();
// 		        musiciens.forEach(entityManager::persist);
// 		        transaction.commit();
// 		        musiciens.forEach(System.out::println);
// 	        }
// 	        private static List<Instrument> readInstrument() {
// 		        Function<String, Instrument> lineToInstrument =
// 				        line -> {
// 					        String[] split = line.split("[ ]+");
// 					        String nom = split[0];
// 					        String typeInstrument = split[1];
// 					        TypeInstrument type = TypeInstrument.of(typeInstrument);
// 					        Instrument instrument = new Instrument(nom, type);
// 					        registryInstrument.put(nom, instrument);
// 					        return instrument;
// 				        };
// 		        List<Instrument> instruments = List.of();
// 		        Path fichierInstruments = Path.of("data/instruments.txt");
// 		        try (Stream<String> instrumentLines = Files.newBufferedReader(fichierInstruments).lines();) {
// 			        instruments =
// 				        instrumentLines
// 					        .filter(line -> !line.startsWith("#"))
// 					        .map(lineToInstrument)
// 					        .collect(Collectors.toList());
// 		        } catch (IOException e) {
// 			        e.printStackTrace();
// 		        }
// 		        return instruments;
// 	        }
// 	        private static List<Musicien> readMusiciens() {
// 		        Function<String, Musicien> lineToMusicien =
// 				        line -> {
// 					        String[] split = line.split("[ ]+");
// 					        String nom = split[1];
// 					        Musicien musicien = new Musicien(nom);
// 					        String[] nomInstruments = Arrays.copyOfRange(split, 2, split.length);
// 					        Arrays.stream(nomInstruments)
// 						        .map(nomInstrument -> registryInstrument.get(nomInstrument))
// 						        .forEach(musicien::addInstrument);
// 					        return musicien;
// 				        };
// 		        List<Musicien> musiciens = List.of();
// 		        Path fichierMusiciens = Path.of("data/musiciens.txt");
// 		        try (Stream<String> musiciensLines = Files.newBufferedReader(fichierMusiciens).lines();) {
// 			        musiciens =
// 				        musiciensLines
// 					        .filter(line -> !line.startsWith("#"))
// 					        .map(lineToMusicien)
// 					        .collect(Collectors.toList());
// 		        } catch (IOException e) {
// 			        e.printStackTrace();
// 		        }
// 		        return musiciens;
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Instrument;
//      public class ReadFromInstruments {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory emf = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        System.out.println("EMF = " + emf);
// 		        EntityManager entityManager = emf.createEntityManager();
// 		        Instrument inst1 = entityManager.find(Instrument.class, 1);
// 		        Instrument inst2 = entityManager.find(Instrument.class, 2);
// 		        System.out.println("Instrument 1 = " + inst1);
// 		        System.out.println("Instrument 2 = " + inst2);
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.EntityTransaction;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Instrument;
//      import org.vitu.jpa.model.util.TypeInstrument;
//      public class CreateInstruments {
// 	        public static void main(String[] args) {
// 		        Instrument violon = new Instrument("Violon", TypeInstrument.CORDES);
// 		        Instrument violoncelle = new Instrument("Violoncelle", TypeInstrument.CORDES);
// 		        EntityManagerFactory emf = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        System.out.println("EMF = " + emf);
// 		        EntityManager entityManager = emf.createEntityManager();
// 		        EntityTransaction transaction = entityManager.getTransaction();
// 		        System.out.println("Avant transaction :");
// 		        System.out.println("Violon = " + violon);
// 		        System.out.println("Violoncelle = " + violoncelle);
// 		        transaction.begin();
// 		        entityManager.persist(violon);
// 		        entityManager.persist(violoncelle);
// 		        transaction.commit();
// 		        System.out.println("Après transaction :");
// 		        System.out.println("Violon = " + violon);
// 		        System.out.println("Violoncelle = " + violoncelle);
// 	        }
//      }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Stream 2 sur JPA/Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// --> Nous allons à présent nous créer une nouvelle classe 'Musicien' qui sera aussi une entité JPA dans le package 'model'.
//      - Nous allons en faire un bean, sauf que son constructeur n'aura que le champs nom puisque le champs id est automatiquement généré par Hibernate.
//      - Maintenant nous allons créer une relation entre Instrument et Musicien. Mais tout d'abord : quelle est le type de la relation entre ces deux entités ?
//          Un même instrument peut être joué par plusieurs musiciens, et un musicien peut jouer de plusieurs instruments.
//          --> C'est donc une relation n:p, une relation multi-valuée, à la fois d'un côté et de l'autre.
//          Etant donné qu'un musicien ne peut pas jouer deux fois du même instrument, il va nous falloir une collection du type Set. Il en sera de même pour les musiciens.
//          De manière générale, nous allons utiliser des bases de données sans doublons, donc il nous faut des collections de type Set.
//          Ainsi, nous pouvons ajouter un champs supplémentaire à notre classe Musicien : private Set<Instrument> instruments = new HashSet<>();.
//          Enfin, nous allons pouvoir lui assigner l'annotation : '@ManyToMany'.
//      - Comment allons-nous pouvoir peupler les instruments la dedans ?
//          --> 	public boolean addInstrument(Instrument instrument) {return this.instruments.add(instrument);}.
//          Nous retournons le boolean dans le but d'éviter les doublons.
// --> Maintenant nous pouvons créer une nouvelle classe : 'MusicienAndInstruments'.
//      - Dans cette classe nous alons lire le fichier instruments.txt qui a été remanié et ne contiens que les instruments et leurs types.
//          Pour ce faire, nous devons remanier la classe 'TypeInstrument' en ajoutant dans un premier temps l'ensemble des types manquants, puis en précisant le label.
//          Pour faire cela, nous devons créer un champ label, avec son constructeur, puis créer une méthode qui nous retourne la valeur du type instrument en fonction de son label (en majuscule).
//          Nous sommes obligés de faire cela puisque nous sommes dans une énumération, et que les valeurs dans le fichier sont en minuscule, contrairement aux valeurs de l'énumération.
//          --> Nous effectuons une boucle for each sur les valeurs de notre tableau, de manière à filtrer la valeur du tableau dont le label correspond au label qui a été donné en paramètre.
//          Ceci, nous pouvons également l'écrire sous forme d'un Stream : 		return Arrays.stream(values()).filter(value -> value.label.equals(label)).findFirst().orElseThrow();.
//          --> le pattern est Arrays.stream(arrayCiblé), puis filter() pour filtrer, où nous ne gardons que la valeur, donc nous pouvons faire un findFirst() puisqu'il n'y a qu'une valeur retournée.
//              Enfin, puisque findFirst(), retourne un Optional, il nous faut ajouter .orElseThrow(), pour éviter de se bloquer.
//      - Maintenant nous allons créer une fonction qui lit de notre fichier et créer des instruments.
//          Pour ce faire, nous effectuons un split() sur l'espace, qui nous retourne un tableau dont la première case est le nom, et la seconde le type.
//          Nous faisons passer ce tyype dans notre nouvelle méthode TypeInstrument.of(), qui nous retourne la valeur d'énumération équivalente.
//          Enfin, nous créons un nouvel instrument à partir des deux valeurs retournées par le split sur chacune des lignes.
//          --> Ainsi cette fonction prends n'importe quelle ligne de texte, l'analyse et retourne un instrument.
//      - Ensuite nous pouvons créer une List<Instrument> qui va recueillir les instruments avec List.of().
//      - Enfin, nous pouvons créer un BufferedReader à partir d'un Stream qui va nous lire les lignes du fichier dans un try-with-ressources.
//          Celui-ci va nous permettre de mapper notre fonction sur chaque ligne, et de les rassembler dans la List<> créée à l'aide d'un Collector.
//          Nous pouvons ensuite simplement imprimer la List<> sur la console.
//      --> Nous avons une erreur, mais non-détaillée à partir de notre optional (orElseThrow()). En fait c'est car il ne comprends pas la ligne de titre, donc il faut que nous la skippions.
//          Encore mieux, nous pouvons ajouter une ligne .filter() à notre stream<>, lui demandans de sauter les lignes commençant par '#'.
//      --> Maintenant il nous retourne un espace, donc nous devons agir sur la manière de splitter notre ligne. Or comme split() prends une expression régulière nous pouvons lui passer "[ ]+".
//      --> Pour finir nous pouvons mettre tout cela dans une méthode, clic-droit sur la sélection de tout l'intérieur > Refactor > Extract method... > 'readInstrument'.
// --> Maintenant, toujours dans la même classe, nous allons faire la même chose mais pour les musiciens en copiant collant la méthode créée.
//      - Nous devons ainsi revisiter notre Function<>, pour créer un musicien à partir du split[0], comme auparavant.
//      - Ensuite, nous devons créer un tableau de chaînes de caractères avec tout le reste de la ligne, splitée en différents instruments.
//          Ce qui est contraignant est que nous devons transformer les chaînes de caractères résiduelles en instruments.
//          --> Pour ce faire, nous allons créer une table de hashage dans le corps de notre classe. Et nous allons appeler put() à chaque fois que nous créons un instrument dans readInstrument().
//      - A présent, dans notre fonction, nous avons créé nos musiciens dans chaque ligne, et à l'aide de la méthode copyOfRange() de Arrays sur notre tableau de string, nous ajoutons les instruments.
//          Ceux-ci, sont ensuite traités dans un stream, puis mappés par instrument dans notre nouvelle table de hashage. Ainsi, chaque musicien à ses instruments associés.
//          Cette fonction retourne finalement un musicien, tout comme la fonction précédente retournait un instrument.
//      - Ensuite, nous pouvons effectuer notre try-with-ressources sur notre stream de lignes en les filtrants par ligne, puis en appliquant la fonction dessus et en les collectant dans une List<>.
//          Ainsi, en transformant cette méthode en une List<Musiciens>, elle nous retourne une liste de musiciens.
//      --> Enfin, nous pouvons dans notre méthode main, construire les deux listes en appelant les méthodes extraites précédemment, puis les imprimer dans la console.
// --> Maintenant que nous avons notre liste de musiciens, il faudrait que nous arrivions à la persister dans la base de données.
//      - Pour commencer, nous pouvons récupérer l'emf, l'em et l'et de notre classe CreateInstruments.
//      - Ensuite, entouré par un transaction.begin() et transaction.commit(), nous pouvons appeler la méthode forEach() sur les musiciens et leur appliquer persist() avec l'EntityManager.
//      - Nous arrivons à une erreur, car Hibernate n'arrive pas à persister des objets non-transcients.
//          Ceci arrive car il faut que chaque musicien persisté ait des instruments qui sont bien présents et persistés dans la table instruments.
//          Pour résoudre cela, nous devons ajouter un paramètre à la référence : @ManyToMany(cascade = CascadeType.PERSIST), dans la classe Musicien.
//      --> Maintenant si nous lançons, cela ne fonctionne pas : c'est parce qu'il faut remettre la value à 'create' de notre classe hibernate.hbm2ddl.auto dans notre fichier persistence.xmL.
//          De plus nous pouvons voir qu'une seule instance de chaque instrument a bien été créée, car quand elles sont citées dans la console pour les musiciens, elles ont les mêmes clefs primaires.
//      - Nous pouvons retrouver le code de création des tables et des tables de jointures en les sélectionnant et en faisant clic droit > Copy to clipboard > Create statement :
//          CREATE TABLE `instrument` (
//              `id` int NOT NULL,
//              `nom` varchar(80) NOT NULL,
//              `type` varchar(20) DEFAULT NULL,
//              PRIMARY KEY (`id`)
//          ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
//          CREATE TABLE `instrument_seq` (
//              `next_val` bigint DEFAULT NULL
//          ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
//          CREATE TABLE `musicien` (
//              `id` int NOT NULL,
//              `nom` varchar(80) NOT NULL,
//              PRIMARY KEY (`id`)
//          ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
//          CREATE TABLE `musicien_instrument` (
//              `Musicien_id` int NOT NULL,
//              `instruments_id` int NOT NULL,
//              PRIMARY KEY (`Musicien_id`,`instruments_id`),
//              KEY `FK9uu6h7349sfh5ubnf7qkc15hs` (`instruments_id`),
//              CONSTRAINT `FK9uu6h7349sfh5ubnf7qkc15hs` FOREIGN KEY (`instruments_id`) REFERENCES `instrument` (`id`),
//              CONSTRAINT `FKcragm41tuunlij56mki2jwq7i` FOREIGN KEY (`Musicien_id`) REFERENCES `musicien` (`id`)
//          ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
//          CREATE TABLE `musicien_seq` (
//              `next_val` bigint DEFAULT NULL
//          ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Stream 3 sur JPA/Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// --> Nous allons importer une nouvelle base de données, donc nous downloadons tout sur le site : https://github.com/josepaumard/data-tp.
//      Nous créeons un nouveau folder 'base-commune' dans le dossier racine de notre projet dans lequel nous copions tous les 6 fichiers .zip contenus dans le fichier .zip master.
//      En faisant 'Alt + Entrée' sur notre dossier, cela nous ouvre la fenêtre 'properties for 'dossier'', puis à côté de la ligne location, nous avons un bouton pour ouvrir directement le dossier.
//      - Maintenant nous pouvons déziper toutes les archives et conserver les fichiers .csv tout en supprimant les archives de notre dossier.
//          Nous pouvons reprendre du code de play-with-jdbc pour déchiffrer la table des maires que nous pouvons ajouter à une nouvelle classe 'PlayWithMaire'.
//      - A présent, nous pouvons adapter ce code à nos besoin. Tout d'abord en créant une classe bean Commune, dans le package model.
//          Nous ajoutons donc nos deux constructeurs, nos getters and setters, notre override de la méthode toString, et notre implements Serializable.
//          Pour ce qui est de la clef primaire, nous avons deux choix :
//              - Soit nous disons que notre clef primaire est un champs id de type int, et nous demandons à Hibernate de le générer pour nous.
//              - Soit nous utilisons le code postal en clef primaire, car nous savons que celui-ci est unique.
//          Nous prenons la deuxième option, et nous pouvons ajouter l'annotation @Id, ainsi que l'annotation @Entity afin d'avoir une entité JPA.
//      - Maintenant si nous retournons dans notre classe 'PlayWithMaire', tout est relativement bon.
//          Nous devons toutefois nous créer notre Map<String, Commune> qui listera toutes les communes en fonction de leur code postal qui est un String.
//          Par contre nous devons remplacer le code JDBC par du code JPA. Donc nous construisons un EntityManagerFactory, qui lui-même va créer un EntityManager.
//          Enfin, nous avons besoin de persister dans le cadre d'une transaction, donc il faut que nous créons cette transaction aussi.
//          Pour éviter de faire un commit() à chaque ligne du fichier, nous allons en faire un seul pour toutes les lignes du fichier.
//          --> Donc pour ça nous devons le faire à l'extérieur de la méthode de lecture du fichier.
//          Au lieu de commit dans le if du bloc try / catch, nous allons le faire aussi à l'extérieur, en fin de méthode : communes.values().forEach(commune -> entityManager.persist(commune));.
//          --> Or, ceci peut être mis sous forme de méthode référence : communes.values().forEach(entityManager::persist);.
//          Nous n'avons plus qu'à mettre notre EntityManagerFactory (celui qui se trouve dans le fichier persistence.xml), et tout fonctionne bien.
//              --> Nous pouvons agréablement remarquer que les 35884 communes sont persistées beaucoup plus rapidement avec JPA qu'avec JDBC.
//                  De plus, les tables musicien et instrument, et leurs tables de liaison ont bien été créées aussi.
//                                  --> Ceci est parce qu'Hibernate va chercher tout seul l'ensemble des entités persistantes pour les mettre en ligne.
//      - Si nous allons copier le create statement de cette table commune, nous pouvons trouver ce qui suit :
//              CREATE TABLE `commune` (
//                  `nom` varchar(255) NOT NULL,
//                  `codePostal` varchar(255) DEFAULT NULL,
//                  PRIMARY KEY (`nom`)
//              ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
//          Nous pouvons remarquer que les champs sont des varchar plutôt longs (255 caractères), donc nous pourrons modifier cela par la suite : @Column(length = 80) (et 8 pour le code postal).
//      - Avant de passer à la suite, nous retravaillons la classe PlayWithCommunes, en extractant deux méthodes pour pouvoir avoir un code plus propre.
// --> Maintenant nous allons essayer de faire la même chose pour les maires, maintenant que nous avons les communes. Ainsi que de créer la jointure entre cette table commune et la table maire.
//      - Pour ce faire nous allons extraire une partie du code de PlayWithCommune pour s'en resservir pour les maires à l'aide d'un Alt + Shift + M > Extract method.
//          Nous allons pouvoir ainsi réutiliser la partie du code se trouvant dans le if, concernant les codes insee et codes postaux.
//          Ainsi, nous utiliserons aussi le code postal pour déterminer à quelle communes est rattaché chacun des maires.
//      - Nous commençons par copier coller la méthode readCommunes() et en renommant la copie readMaires(). La map ne sera plus de String et de Communes mais de String et de Maires/
//          Il nous faudra donc créer la classe Maire. Puis au moment du split, il faut réadapter chaque champs aux colonnes ciblées dans notre fichier .csv.
//          A savoir que pour la date de naissance, nous allons devoir convertir le String extrait en format date. Ce qui nous permettra d'utiliser ce que nous appelons la "copie défensive".
//          Maintenant nous allons devoir créer les classes manquantes.
//      - Tout d'abord, nous allons devoir créer une énumération "Civilite". Ainsi, nous allons pouvoir mapper des énumérations, ce qui est assez basique, mais qu'il faut savoir faire.
//          De retour dans notre méthode, nous pouvons importer notre énumération, et maintenant nous allons devoir convertir une chaîne de caractère en un objet Civilite.
//          Nous n'avons que trois civilité possibles, 'MLLE, MME, M', donc nous pouvons les ajouter dans notre énumération.
//          Maintenant il nous faut une chaîne de caractères qui prends une chaîne de caractères, et nous retourne une civilité. Cette méthode nous pouvons la créer dans notre énumération.
//          Nous pouvons effectuer une boucle forEach sur la méthode factory 'values()', puis une méthode equals qui retourne une civilité si equals retourne true, et null si equals retourne false.
//          Toutefois pour ceci, nous devons déclarer un String 'label', et par la suite un Constructeur paramétré avec ce String.
//          Ainsi, entre parenthèses, nous mettons pour chaque énumération, le String équivalent trouvé dans le fichier pour chacune des énumération, pour lesquelles la méthode equals va être exécutée.
//          --> En réalité, il est mieux d'utiliser la méthode stream de values() sur l'objet Arrays, de filtrer les civilité avec equals(label), et de retourner la valeur avec .findAny().
//              De cette manière, nous ajoutons aussi, orElseThrow(), pour gérer l'optional, en lui passant un predicat qui nous retourne une Exception.
//              Ainsi, nous évitons de retourner null avec l'autre méthode, ce qui aurait pour désavantage de risquer d'intégrer une valeur null en base de données et de générer des nullPointerException.
//      - Maintenant, nous devons créer la classe Maire, nous laissons la date de naissance sous format String pour ne pas trop s'embêter.
//          Nous ajoutons chacun des champs, ses getters and setters, les constructeurs, ainsi que la méthode toString().
//          Nous ajoutons aussi les annotations, et en ajoutons pour générer les valeurs du champs 'Id', ainsi que pour préciser le type d'énumération de notre champs Civilite.
//      - Maintenant, nous pouvons réarranger finalement notre nouvelle méthode readMaires() en gardant la gestion des doublons, comme nous l'avions fait précédemment.
//          Si nous testons sans persister, cela fonctionne bien.
//      - Enfin, il ne nous manque plus qu'a nous occuper de la date.
//           --> Comment pouvons-nous faire pour créer une chaîne de caractères à partir d'une date.
//          Le plus simple est de passer par l'API de Java 8. Nous pouvons créer une variable de type LocalDate, puis, une variable de type DateFormat à laquelle nous pouvons passer "dd/MM/yyyy".
//          Ainsi, nous précisons le type de format de date que va avoir cette variable à l'aide du constructeur "new SimpleDateFormat("dd/MM/yyyy")".
//          Par la suite, il nous suffit de créer un objet de type Date, et de parser notre split[8] (colonne 8 d fichier) sur le modèle de notre objet de type DateFormat.
//          Par conséquent, nous devons ajouter un '|' dans nos paramètres catch pour ajouter la possibilité d'une ParseException.
//      - Nous allons jouer un petit peu avec les dates en se créant une nouvelle classe : HaveFunWithDate.
//          A l'intérieur, nous pouvons utiliser deux techniques différentes pour imprimer notre date de naissance sur la console.
//          - Premièrement la méthode utilisée précédemment, en utilisant le constructeur SimpleDateFormat() et en lui passant un chaîne de caractères lui précisant le format souhaité.
//          - Dans un second temps,nous avons la possibilité d'utiliser la méthode getDateInsance() sur l'objet DateFormat.
//              Cette méthode prends deux paramètres, le format de la date à afficher, et la langue et localité du format souhaité.
//              Enfin, nous devons exécuter la méthode format à ce nouvel objet, en lui passant la date en paramètre.
// --> A présent nous pouvons à partir du code postal, créer la relation 1:1 entre maires et communes.
//      - D'abord, nous pouvons ajouter un champs Maire dans le bean Commune, ses getter et setters, ainsi que de l'ajouter dans la méthode toString().
//          Aussi, nous devons lui ajouter une annotation @OneToOne.
//      - Maintenant, dans la classe PlayWithCommune, nous pouvons faire un for each sur communes.values(). Sur chaque Maire, nous pouvons recherche le maire qui possède le même code postal.
//          Enfin, en appliquant la méthode setMaire() sur la commune sélectionnée, nous établissons la relation entre les deux classes.
//          Toutefois, la relation établie à ce moment-là est une relation unidirectionnelle. En effet, notre commune connaît son maire, mais le maire ne connaît pas sa commune.
//          Donc ici, le côté maître est facile à voir dans ce type de relation, car c'est le côté maître qui tiens la relation, donc le bean commune.
//      - Si nous voulons à présent persister, nous ne persistons que les maires, donc il nous faut à présent ajouter un paramètre cascade avec la valeur 'PERSIST'.
//          Ainsi, les maires aussi seront persistés. Nous avons bien une relation 1:1 entre ces deux entités, notamment si nous regardons le create statement :
//              CREATE TABLE `maire` (
//                  `id` int NOT NULL,
//                  `civilite` varchar(5) DEFAULT NULL,
//                  `dateDeNaissance` datetime(6) DEFAULT NULL,
//                  `nom` varchar(80) NOT NULL,
//                  `prenom` varchar(80) DEFAULT NULL,
//                  PRIMARY KEY (`id`)
//              ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
//              CREATE TABLE `commune` (
//                  `codePostal` varchar(8) NOT NULL,
//                  `nom` varchar(80) DEFAULT NULL,
//                  `maire_id` int DEFAULT NULL,
//                  PRIMARY KEY (`codePostal`),
//                  KEY `FK8yi2t83o5x9on2osqgvhoke47` (`maire_id`),
//                  CONSTRAINT `FK8yi2t83o5x9on2osqgvhoke47` FOREIGN KEY (`maire_id`) REFERENCES `maire` (`id`)
//              ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
// --> Maintenant nous pouvons voir comment créer une relation 1:1 bidirectionnelle.
//      - Pour cela, nous devons ajouter un champs Commune dans la classe Maire, ainsi que de l'annoter de '@OneToOne'.
//          Il faut faire attention car pour l'instant nous avons bien une relation 1:1 qui se regarde l'une l'autre, mais cela n'en fait pas une relation bidirectionnelle.
//          Effectivement, si nous regardons les create statements pour les deux tables créées, nous remarquons que chacune des tables est maîtresse de l'autre.
//          Cela signifie qu'une commune à un maire, mais que ce maire peut aussi avoir une autre commune, ce qui n'est pas ce que nous voulons.
//      - Ainsi, nous devons ajouter le paramètre 'mappedBy' avec pour valeur le champs cible de la classe dont il est esclave, ici c'est donc le champs 'maire' de la classe Commune.
//          A présent, la relation qui relie les deux classes est bien une relation bidirectionnelle. Le côté maître est celui qui porte la colonne de jointure.
//          Donc le côté maître contient le paramètre 'Cascade', et le côté esclave contient le paramètre 'mappedBy' dans leurs annotations '@OneToOne'.
// -----------
//      package org.vitu.jpa;
//      import java.io.BufferedReader;
//      import java.io.IOException;
//      import java.nio.file.Files;
//      import java.nio.file.Path;
//      import java.text.DateFormat;
//      import java.text.ParseException;
//      import java.text.SimpleDateFormat;
//      import java.util.Date;
//      import java.util.HashMap;
//      import java.util.Map;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Commune;
//      import org.vitu.jpa.model.Maire;
//      import org.vitu.jpa.model.util.Civilite;
//      public class PlayWithMaire {
// 	        public static void main(String... args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        Map<String, Commune> communes = readCommunes("base-commune/maires-25-04-2014.csv");
// 		        Map<String, Maire> maires = readMaires("base-commune/maires-25-04-2014.csv");
// 		        for(Commune commune : communes.values()) {
// 			        Maire maire = maires.get(commune.getCodePostal());
// 			        commune.setMaire(maire);
// 		        }
// 		        entityManager.getTransaction().begin();
// 		        communes.values().forEach(entityManager::persist);
// 		        entityManager.getTransaction().commit();
// 		        System.out.println("Persisted " + communes.size() + " communes.");
// 		        System.out.println("Persisted " + maires.size() + " maires.");
// 	        }
// 	        private static Map<String, Commune> readCommunes(String fileName) {
// 		        Map<String, Commune> communes = new HashMap<>();
// 		        Path path = Path.of(fileName);
// 		        try(BufferedReader reader = Files.newBufferedReader(path);) {
// 			        String line = reader.readLine();
// 			        line = reader.readLine();
// 			        while (line != null) {
// 				        String[] split = line.split(";");
// 				        String codePostal = readCodePostal(line);
// 				        String nom = split[3];
// 				        Commune commune = new Commune(nom, codePostal);
// 				        Commune previousCommune = communes.put(codePostal, commune);
// 				        if (previousCommune != null) {
// 					        System.out.println("Doublon = " + previousCommune);
// 				        }
// 				        line = reader.readLine();
// 			        }
// 		        } catch(IOException e) {
// 			        e.printStackTrace();
// 		        }
// 		        return communes;
// 	        }
// 	        private static Map<String, Maire> readMaires(String fileName) {
// 		        Map<String, Maire> maires = new HashMap<>();
// 		        Path path = Path.of(fileName);
// 		        try(BufferedReader reader = Files.newBufferedReader(path);) {
// 			        String line = reader.readLine();
// 			        line = reader.readLine();
// 			        while (line != null) {
// 				        String[] split = line.split(";");
// 				        String codePostal = readCodePostal(line);
// 				        String nom = split[5];
// 				        String prenom = split[6];
// 				        Civilite civilite = Civilite.of(split[7]);
// 				        DateFormat dateFormat = new SimpleDateFormat("dd/MM/yyyy");
// 				        Date dateDeNaissance = dateFormat.parse(split[8]);
// 				        Maire maire = new Maire(nom, prenom, civilite, dateDeNaissance);
// 				        Maire previousMaire = maires.put(codePostal, maire);
// 				        if (previousMaire != null) {
// 					        System.out.println("Doublon = " + previousMaire);
// 				        }
// 				        line = reader.readLine();
// 			        }
// 		        } catch(IOException | ParseException e) {
// 			        e.printStackTrace();
// 		        }
// 		        return maires;
// 	        }
// 	        private static String readCodePostal(String line) {
// 		        String[] split = line.split(";");
// 		        String codeDepartement = split[0];
// 		        if (codeDepartement.length() == 1) {
// 			        codeDepartement = "0" + codeDepartement;
// 		        }
// 		        String codeInsee = split[2];
// 		        if (codeInsee.length() == 1) {
// 			        codeInsee = "00" + codeInsee;
// 		        } else if (codeInsee.length() == 2) {
// 			        codeInsee = "0" + codeInsee;
// 		        }
// 		        String codePostal = codeDepartement + codeInsee;
// 		        return codePostal;
// 	        }
//      }
// -----------
//      package org.vitu.jpa.model;
//      import java.io.Serializable;
//      import javax.persistence.CascadeType;
//      import javax.persistence.Column;
//      import javax.persistence.Entity;
//      import javax.persistence.Id;
//      import javax.persistence.OneToOne;
//      @Entity
//      public class Commune implements Serializable {
// 	        @Id@Column(length = 8)
// 	        private String codePostal;
// 	        @Column(length = 80)
// 	        private String nom;
// 	        @OneToOne(cascade = CascadeType.PERSIST)
// 	        private Maire maire;
// 	        public Commune() {
// 	        }
// 	        public Commune(String nom, String codePostal) {
// 		        this.nom = nom;
// 		        this.codePostal = codePostal;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public String getCodePostal() {
// 		        return codePostal;
// 	        }
// 	        public void setCodePostal(String codePostal) {
// 		        this.codePostal = codePostal;
// 	        }
// 	        public Maire getMaire() {
// 		        return maire;
// 	        }
// 	        public void setMaire(Maire maire) {
// 		        this.maire = maire;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Commune [nom=" + nom + ", codePostal=" + codePostal + ", maire=" + maire + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa.model;
//      import java.io.Serializable;
//      import java.util.Date;
//      import javax.persistence.Column;
//      import javax.persistence.Entity;
//      import javax.persistence.EnumType;
//      import javax.persistence.Enumerated;
//      import javax.persistence.GeneratedValue;
//      import javax.persistence.GenerationType;
//      import javax.persistence.Id;
//      import javax.persistence.OneToOne;
//      import javax.persistence.Temporal;
//      import org.eclipse.persistence.internal.jpa.parsing.TemporalLiteralNode.TemporalType;
//      import org.vitu.jpa.model.util.Civilite;
//      @Entity
//      public class Maire implements Serializable {
// 	        @Id @GeneratedValue(strategy = GenerationType.SEQUENCE)
// 	        private int id;
// 	        @Column(nullable = false, length = 80)
// 	        private String nom;
// 	        @Column(length = 80)
// 	        private String prenom;
// 	        @Column(length = 5)
// 	        @Enumerated(EnumType.STRING)
// 	        private Civilite civilite;
// 	        @OneToOne(mappedBy = "maire")
// 	        private Commune commune;
//      //	@Temporal(TemporalType.DATE)
// 	        private Date dateDeNaissance;
// 	        public Maire() {
// 	        }
// 	        public Maire(String nom, String prenom, Civilite civilite, Date dateDeNaissance) {
// 		        this.nom = nom;
// 		        this.prenom = prenom;
// 		        this.civilite = civilite;
// 		        this.dateDeNaissance = dateDeNaissance;
// 	        }
// 	        public int getId() {
// 		        return id;
// 	        }
// 	        public void setId(int id) {
// 		        this.id = id;
//      	}
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public String getPrenom() {
// 		        return prenom;
// 	        }
// 	        public void setPrenom(String prenom) {
// 		        this.prenom = prenom;
// 	        }
// 	        public Civilite getCivilite() {
// 		        return civilite;
// 	        }
// 	        public void setCivilite(Civilite civilite) {
// 		        this.civilite = civilite;
// 	        }
// 	        public Date getDateDeNaissance() {
// 		        return dateDeNaissance;
// 	        }
// 	        public void setDateDeNaissance(Date dateDeNaissance) {
// 		        this.dateDeNaissance = dateDeNaissance;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Maire [id=" + id + ", nom=" + nom + ", prenom=" + prenom + ", civilite=" + civilite + ", dateDeNaissance=" + dateDeNaissance + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import java.text.DateFormat;
//      import java.text.ParseException;
//      import java.text.SimpleDateFormat;
//      import java.util.Date;
//      import java.util.Locale;
//      public class HaveFunWithDate {
// 	        public static void main(String[] args) throws ParseException {
// 		        String s = "04/03/1951";
// 		        DateFormat dateFormat = new SimpleDateFormat("dd/MM/yyyy");
// 		        Date dateDeNaissance = dateFormat.parse(s);
// 		        System.out.println("Date de naissance = " +  dateDeNaissance);
// 		        DateFormat format = DateFormat.getDateInstance(DateFormat.LONG, Locale.FRANCE);
// 		        String dateFormatee = format.format(dateDeNaissance);
// 		        System.out.println("Date formatée = " +  dateFormatee);
// 	        }
//      }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Stream 3 sur JPA/Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// --> Pour voir la relation 1:p, nous rajoutons une méthode readDepartements().
//      - Celle-ci fonctionne de la même manière que readCommunes() ou readMaires(), à savoir qu'elle remplis une Map<String, Departement> en splitant chaque ligne.
//      - Y est ajouté une méthode readCodeDepartement() qui fonctionne de la même manière que readCodePostal(), ajoutant un '0' devant le code département lorsque celui--ci est compris entre 1 et 9.
//          Ce code département peut nous servir de clef primaire, de la même façon que notre code postal sert de clef primaire à la classe Commune.
//      - Nous devons par conséquent nous créer une classe Departement, qui sera aussi une entité JPA.
//          Dans celle-ci nous assignons l'annotation '@Id' au champs 'codeDepartement', et des paramètres de longueurs à des annotations '@Column', et un paramètre 'nullable = false' au champs 'nom'.
//      - A présent, dans notre classe PlayWithMaires que nous renommons 'PlayWithCommune', nous pouvons ajouter notre déclaration de Map<String, Departement>.
//          Enfin, nous appliquons la méthode persist de notre EntityManager sur une itération de la table de hashage 'departements', comme nous l'effectuons déjà sur la table de hashage 'communes'.
// --> Maintenant que cela fonctionne, nous voudrions rajouter nos communes à nos départements, soit une relation 1:p. Un département pour n communes.
//      - Pour commencer, nous créons un champs List<Commune> dans notre bean Departement. Nous voulons que le département soit le côté maître de la relation.
//          Donc nous devons ajouter l'annotation '@OneToMany'. Si nous ajoutons juste cela, nous avons déjà notre relation 1:p unidirectionnelle de créée.
//      - Si dans un premier temps nous exécutons notre classe PlayWithMaires, nous pouvons constater que JPA nous créé une table departement ainsi qu'une table de jointure departement_commune.
//          Ceci, car une relation 1:p, en SQL, nous ne pouvons pas mettre notre colonne de jointure n'importe où. Elle doit être du côté 'p' de la relation, donc du côté Commune.
//          Or, ici, nous n'avons aucune dépendance de la classe commune vers la classe département. La classe Departement connaît la classe Commune, mais le cas contraire n'existe pas.
//          Or nous voulons créer les mêmes dépendances dans la base de données que celles que nous avons dans le modèle objet.
//          Donc, si nous voulions retirer la table departement, il faut savoir que la colonne de clef primaire de cette table va être référencée par la colonne de jointure de la table commune.
//          Ainsi, nous serions obligé d'altérer la table commune. Donc effacer la colonne departement va impliquer d'altérer la table commune.
//          --> Alors que dans notre modèle-objet, la classe Commune ne connaît pas du tout la classe Departement.
//          --> Donc nous n'avons aucune contrainte de référence de clef étrangère dans notre code SQL de création de table.
//          --> Alors que nous l'aurions si nous avions fair un schéma de base de données classique avec une relation 1:p.
//          Donc en JPA, nous décidons de mapper les dépendances que nous avons dans le modèle objet jusque dans les tables de la base de données.
//              --> Ainsi, si nous avons une relation 1:p unidirectionnelle, nous créons cette table de jointure.
//      - Donc il nous faut ajouter un paramètre '@OneToMany(mappedBy = departement)' à la List<Commune> de notre classe Departement. L'attribut 'departement' correspondant au champs de la classe Commune.
//      - Dans la classe Commune, nous ajoutons le champs departement, qui lui à l'annotation '@ManyToOne'. Cette annotation, elle ne peut pas prendre de paramètre 'mappedBy', contrairement à @OneToMany.
//
//      - Maintenant il nous faut remplir le champs codeDepartement des Communes dans notre code, comme nous l'avions fait avec la boucle forEach sur communes.values() précédemment.
//          Nous allons donc inclure cet ajout de code dans la boucle déjà existante. Il nous faut boucler sur les communes, et en récupérer le code département pour chacune.
//          En ajoutant la méthode getCodeDepartement(), qui n'existe pas, Eclipse nous propose de créer une méthode dans la 'type' Commune, donc la classe Commune, ce que nous avons le droit de faire.
//          --> public String getCodeDepartement(){return codePostal.substring(0, 2);} : Avec ce code, nous retournons les deux premiers chiffres du code postal, soit le code département.
//          Une fois cette méthode créée, nous pouvons récupérer le code département de chaque commune, récupérer le département associé dans notre Map<String, Departement>, et l'intégrer à notre Commune.
//          Pour ce faire, nous devons créer la méthode 'addCommune', elle aussi, au sein de la classe Commune. Toutefois, nous avons une relation bidirectionnelle, donc il faut que nous le précisions :
//              --> public void addCommune(Commune commune){
//                      this.communes.add(commune);
//                      commune.setDepartement(this);
//                  }
//          De cette manière, nous appelons aussi le setter de département de la classe Commune.
// --> Maintenant nous pouvons nous créer une nouvelle classe 'FunWithCommunes' pour effectuer d'autres actions sur nos relations entre les tables de notre base de données :
//      - Tout d'abord, nous y importons notre EntityManagerFactory et EntityManager, similaire à la classe PlayWithMaire.
//      - Par la suite, nous appelons la méthode find() sur notre EntityManager pour trouver une commune spécifique en lui passant son code postal.
//          En appelant la méthode getMaire(), puis getDepartement(), nous pouvons respectivement nous créer un objet de type Maire et un objet de type Departement.
//          Enfin, nous pouvons créer une méthode getCommunes() sur notre objet de type Departement dans notre classe Departement nous retournant notre List<Commune> à l'aide d'un getter classique.
//      - Toutefois, nous devons passer notre Hibernate en mode 'update' avant de lancer ce code, car celui-ci nécessite des données déjà excistantes en base de données.
//          En effet, si nous restons en mode 'create', Hibernate 'drop' les tables avant de les recréer et il est donc impossible de lire une donnée, d'où une NullPointerException.
//      - Dernier point, nous avons vu que le getter getCommunes, nous retourne la List<Commune> du département associé. Toutefois en JPA, tout se fait normalement dans le contexte d'une transaction.
//          Or ici, si nous effectuons 'communes.clear()', puis que nous réimprimons la List<Commune> de ce département, nous aurons bien un résultat de 0 communes.
//          --> Le soucis est que notre List<Commune> est ce que nous appelons un 'contener mutable'.
//          --> De cette manière, nous donnons la possibilité à quelqu'un d'extérieur à la transaction de modifier une des unités persistentes (ici la List<Commune>).
//          Pour éviter ce genre de chose, il faut que nous nous protégions en créant ce que nous appelons une 'copie défensive'.
//              --> Ainsi, au lieu de retourner this.communes, nous retournons new ArrayList<>(this.communes). Ceci est une 'copie défensive en lecture'.
//                  De cette manière, nous ne risquons pas d'exposer notre objet mutable à des modifications effectuées par un utilisateur extérieur à la transaction.
//          Nous pouvons aussi nous en protéger lorsque nous sommes en écriture.
// --> C'est ce que nous allons voir dans notre nouvelle classe 'FunWithMaire'. Nous y créons un objet de type Maire avec le constructeur, puis nous le persistons avec l'EntityManager.
//      - Nous pouvons voir qu'en fait, le champs date qui est à l'intérieur de maire, est lui aussi mutable, nous pouvons par exemple lui ajouter un time pour en faire un timestamp plutôt qu'une date.
//          Ou encore faire un setMonth() et lui modifier le mois dans sa date.
//              --> Cela signifie que nous avons pu changer la date de naissance de ce maire, sans appeler aucune méthode sur l'objet maire en lui-même.
//          Pour ce protéger de cela, dans notre entité Maire, il nous suffit de créer un nouvel objet dans le constructeur :
//              --> this.dateDeNaissance = dateDeNaissance --> this.dateDeNaissance = new Date(dateDeNaissance.getTime());.
//      --> La copie défensive, fonctionne à la fois pour les getters et pour les setters : Quand nous avons un contener mutable, le code appelant peut garder une référence sur ce contener mutable.
//          Donc il pourra muter le contenu de ce contener alors même que nous l'avons copié dans un champs interne d'une autre classe : il faut donc s'en protéger.
// --> Maintenant, nous allons voir un exemple avec des 'objets inclus' :
//      - Nous allons commencer par nous créer une classe bean dans le package 'model' qui s'appelle 'Adress', qui possède un libelle et une Commune en relation '@ManyToOne'.
//      - A présent nous créons une classe 'PlayWithAdress', dans laquelle nous importons notre EntityMangerFactory et notre EntityManager.
//      - Nous y créons un objet de type Date, un objet de type Maire, ainsi qu'un objet de type Commune, et un objet de type Address avec une nouvelle méthode setAdress() de la classe Maire.
//          Une fois le champs Address créé dans la classe Maire, nous pouvons y ajouter aussi une méthode getAddress().
//      - A présent, comment allons-nous mapper ce champs ? Vu que c'est un objet en relation, nous pourrions dire que c'est une relation 1:1, soit une colonne de jointure dans la table maire.
//          Donc, à chaque fois que nous créons un maire, nous aurons deux insertions qui vont partir en base de données : une dans la table maire, et une dans la table address.
//          Toutefois, lorsque nous supprimons un maire, il nous faudra supprimer aussi l'adresse, car une adresse toute seule est inutile.
//          --> Donc l'objet Address partage complètement le cycle de vie de l'objet qui la porte.
//          --> Ainsi, pour le mapping, JPA nous propose de considérer l'objet de type Address non pas comme une entité, mais comme un objet qui est rattaché à une entité.
//          --> Nous pouvons le faire grâce à l'annotation '@Embeddable' dans la classe Address, et '@Embedded' sur le champs Address de la classe Maire.
//      - En repassant en mode 'create' dans notre fichier persistence.xml, et en exécutant la classe PlayWithMaire, les champs libelle et code postal apparaissent bien dans la table maire.
// --> Donc, nous avons une jointure entre Maire et Address, que se passe t-il si nous voulons créer une seconde jointure de Maire vers Commune ?
//      - Si nous enlevons le paramètre 'mappedBy' de notre classe maire et que nous l'ajoutons sur la classe Commune, de sorte à ce que ce soit la classe maire qui est maître sur Commune et non l'inverse.
//          Nous laissons notre 'CascadeType.PERSIST' du côté Commune, et nous l'ajoutons aussi du côté de Maire.
//          --> Nous remarquons qu'Hibernate ne nous laisse pas le faire en nous disant qu'il y a une 'repeated column in mapping for entity maire'.
//      - Il nous faut ajouter l'annotation suivante sur le champs Address de la classe Maire, sous l'annotation '@Embedded' :
//              @AssociationOverrides(
//                  @AssociationOverride(
//                      name = "commune",
//                      joinColumns = {@JoinColumn(name = "address_commune_codePostal")}
//                  )
//              )
//          Cette annotation nous permet de surcharger les colonnes de jointures.
//      - Par la suite nous devons surcharger la colonne dans laquelle le champs 'libelle' de l'embeddable 'address' va être mappée en utlisant l'annotation '@AttributeOverrides':
//              @AttributeOverrides({
//                  @AttributeOverride(
//                      name="address",
//                      column=@Column(name="address_libelle")
//                  )
//              })
//      - Ainsi, nous obtenons la requête SQL de création suivante :
//              CREATE TABLE `maire` (
//                  `id` int NOT NULL,
//                  `civilite` varchar(5) DEFAULT NULL,
//                  `dateDeNaissance` datetime(6) DEFAULT NULL,
//                  `nom` varchar(80) NOT NULL,
//                  `prenom` varchar(80) DEFAULT NULL,
//                  `commune_codePostal` varchar(8) DEFAULT NULL,
//                  `address_commune_codePostal` varchar(8) DEFAULT NULL,
//                  `libelle` varchar(80) DEFAULT NULL,
//                  PRIMARY KEY (`id`),
//                  KEY `FKfjaj34tep9hd99mqypw0qghja` (`address_commune_codePostal`),
//                  KEY `FKqmgxylqxfqvgev8h6o3hjo58b` (`commune_codePostal`),
//                  CONSTRAINT `FKfjaj34tep9hd99mqypw0qghja` FOREIGN KEY (`address_commune_codePostal`) REFERENCES `commune` (`codePostal`),
//                  CONSTRAINT `FKqmgxylqxfqvgev8h6o3hjo58b` FOREIGN KEY (`commune_codePostal`) REFERENCES `commune` (`codePostal`)
//              ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
// --> Concernant l'héritage ?
// -----------
//      package org.vitu.jpa.model;
//      import java.io.Serializable;
//      import java.util.Date;
//      import javax.persistence.AssociationOverride;
//      import javax.persistence.AssociationOverrides;
//      import javax.persistence.AttributeOverride;
//      import javax.persistence.AttributeOverrides;
//      import javax.persistence.CascadeType;
//      import javax.persistence.Column;
//      import javax.persistence.Embedded;
//      import javax.persistence.Entity;
//      import javax.persistence.EnumType;
//      import javax.persistence.Enumerated;
//      import javax.persistence.GeneratedValue;
//      import javax.persistence.GenerationType;
//      import javax.persistence.Id;
//      import javax.persistence.JoinColumn;
//      import javax.persistence.OneToOne;
//      import javax.persistence.Temporal;
//      import org.eclipse.persistence.internal.jpa.parsing.TemporalLiteralNode.TemporalType;
//      import org.vitu.jpa.model.util.Civilite;
//      @Entity
//      public class Maire implements Serializable {
// 	        @Id @GeneratedValue(strategy = GenerationType.SEQUENCE)
// 	        private int id;
// 	        @Column(nullable = false, length = 80)
// 	        private String nom;
// 	        @Column(length = 80)
// 	        private String prenom;
// 	        @Column(length = 5)
// 	        @Enumerated(EnumType.STRING)
// 	        private Civilite civilite;
// 	        @OneToOne(cascade = CascadeType.PERSIST)
// 	        private Commune commune;
//      //	@Temporal(TemporalType.DATE)
// 	        private Date dateDeNaissance;
// 	        @Embedded
// 	        @AttributeOverrides({
// 		        @AttributeOverride(
// 			        name="address",
// 			        column=@Column(name="address_libelle")
// 		        )
// 	        })
// 	        @AssociationOverrides(
// 		        @AssociationOverride(
// 			        name = "commune",
// 			        joinColumns = @JoinColumn(name = "address_commune_codePostal")
// 		        )
// 	        )
// 	        private Address address;
// 	        public Maire() {
// 	        }
// 	        public Maire(String nom, String prenom, Civilite civilite, Date dateDeNaissance) {
// 		        this.nom = nom;
// 		        this.prenom = prenom;
// 		        this.civilite = civilite;
// 		        this.dateDeNaissance = dateDeNaissance;
// 	        }
// 	        public int getId() {
// 		        return id;
// 	        }
// 	        public void setId(int id) {
// 		        this.id = id;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public String getPrenom() {
// 		        return prenom;
// 	        }
// 	        public void setPrenom(String prenom) {
// 		        this.prenom = prenom;
// 	        }
// 	        public Civilite getCivilite() {
// 		        return civilite;
// 	        }
// 	        public void setCivilite(Civilite civilite) {
// 		        this.civilite = civilite;
// 	        }
// 	        public Date getDateDeNaissance() {
// 		        return new Date(dateDeNaissance.getTime());
// 	        }
// 	        public void setDateDeNaissance(Date dateDeNaissance) {
// 		        this.dateDeNaissance = dateDeNaissance;
// 	        }
// 	        public Address getAddress() {
// 		        return address;
// 	        }
// 	        public void setAddress(Address address) {
// 		        this.address = address;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Maire [id=" + id + ", nom=" + nom + ", prenom=" + prenom + ", civilite=" + civilite + ", dateDeNaissance=" + dateDeNaissance + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa.model;
//      import java.io.Serializable;
//      import javax.persistence.CascadeType;
//      import javax.persistence.Column;
//      import javax.persistence.Entity;
//      import javax.persistence.Id;
//      import javax.persistence.ManyToOne;
//      import javax.persistence.OneToMany;
//      import javax.persistence.OneToOne;
//      @Entity
//      public class Commune implements Serializable {
// 	        @Id@Column(length = 8)
// 	        private String codePostal;
// 	        @Column(length = 80)
// 	        private String nom;
// 	        @OneToOne(cascade = CascadeType.PERSIST, mappedBy = "commune")
// 	        private Maire maire;
// 	        @ManyToOne
// 	        private Departement departement;
// 	        public Commune() {
// 	        }
// 	        public Commune(String nom, String codePostal) {
// 		        this.nom = nom;
// 		        this.codePostal = codePostal;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public String getCodePostal() {
// 		        return codePostal;
// 	        }
// 	        public void setCodePostal(String codePostal) {
// 		        this.codePostal = codePostal;
// 	        }
// 	        public Maire getMaire() {
// 		        return maire;
// 	        }
// 	        public void setMaire(Maire maire) {
// 		        this.maire = maire;
// 	        }
// 	        public Departement getDepartement() {
// 		        return departement;
// 	        }
// 	        public void setDepartement(Departement departement) {
// 	        	this.departement = departement;
//          }
// 	        public String getCodeDepartement() {
// 		        return codePostal.substring(0, 2);
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Commune [nom=" + nom + ", codePostal=" + codePostal + ", maire=" + maire + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa.model;
//      import java.io.Serializable;
//      import javax.persistence.Column;
//      import javax.persistence.Embeddable;
//      import javax.persistence.ManyToOne;
//      @Embeddable
//      public class Address implements Serializable {
// 	        @Column(length = 80)
// 	        private String libelle;
// 	        @ManyToOne
// 	        private Commune commune;
// 	        public Address() {
// 	        }
// 	        public Address(String libelle, Commune commune) {
// 		        this.libelle = libelle;
// 		        this.commune = commune;
// 	        }
// 	        public String getLibelle() {
// 		        return libelle;
// 	        }
// 	        public void setLibelle(String libelle) {
// 		        this.libelle = libelle;
// 	        }
// 	        public Commune getCommune() {
// 		        return commune;
// 	        }
// 	        public void setCommune(Commune commune) {
// 		        this.commune = commune;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Address [libelle=" + libelle + ", commune=" + commune + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import java.util.List;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Commune;
//      import org.vitu.jpa.model.Departement;
//      import org.vitu.jpa.model.Maire;
//      public class FunWithCommunes {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        Commune commune = entityManager.find(Commune.class, "01007");
// 		        System.out.println(commune);
// 		        Maire maire = commune.getMaire();
// 		        Departement departement = commune.getDepartement();
// 		        List<Commune> communes = departement.getCommunes();
// 		        System.out.println("Commune = " + commune);
// 		        System.out.println("Maire = " + maire);
// 		        System.out.println("# Commune = " + communes.size());
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import java.util.Date;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Maire;
//      import org.vitu.jpa.model.util.Civilite;
//      public class FunWithMaire {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        Date date = new Date(1952, 8, 4);
// 		        Maire maire = new Maire("Chirac", "Jacques", Civilite.M, date);
// 		        entityManager.getTransaction().begin();
// 		        entityManager.persist(maire);
// 		        entityManager.getTransaction().commit();
// 		        System.out.println("Maire = " + maire);
// 		        date.setMonth(7);
// 		        System.out.println("Maire = " + maire);
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import java.util.Date;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Address;
//      import org.vitu.jpa.model.Commune;
//      import org.vitu.jpa.model.Maire;
//      import org.vitu.jpa.model.util.Civilite;
//      public class PlayWithAddress {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        Date date = new Date(1952, 8, 4);
// 		        Maire maire = new Maire("Chirac", "Jacques", Civilite.M, date);
// 		        Commune ambronay = entityManager.find(Commune.class, "01007");
// 		        Address address =  new Address("7 boulevard des capucines", ambronay);
// 		        maire.setAddress(address);
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import java.io.BufferedReader;
//      import java.io.IOException;
//      import java.nio.file.Files;
//      import java.nio.file.Path;
//      import java.text.DateFormat;
//      import java.text.ParseException;
//      import java.text.SimpleDateFormat;
//      import java.util.Date;
//      import java.util.HashMap;
//      import java.util.Map;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Commune;
//      import org.vitu.jpa.model.Departement;
//      import org.vitu.jpa.model.Maire;
//      import org.vitu.jpa.model.util.Civilite;
//      public class PlayWithMaire {
// 	        public static void main(String... args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        Map<String, Commune> communes = readCommunes("base-commune/maires-25-04-2014.csv");
// 		        Map<String, Maire> maires = readMaires("base-commune/maires-25-04-2014.csv");
// 		        Map<String, Departement> departements = readDepartements("base-commune/departement.csv");
// 		        for(Commune commune : communes.values()) {
// 			        Maire maire = maires.get(commune.getCodePostal());
// 			        commune.setMaire(maire);
// 			        String codeDepartement = commune.getCodeDepartement();
// 			        Departement departement = departements.get(codeDepartement);
// 			        departement.addCommune(commune);
// 		        }
// 		        entityManager.getTransaction().begin();
// 		        communes.values().forEach(entityManager::persist);
// 		        departements.values().forEach(entityManager::persist);
// 		        entityManager.getTransaction().commit();
// 		        System.out.println("Persisted " + communes.size() + " communes.");
// 		        System.out.println("Persisted " + maires.size() + " maires.");
// 		        System.out.println("Persisted " + departements.size() + " départements.");
// 	        }
// 	        private static Map<String, Commune> readCommunes(String fileName) {
// 		        Map<String, Commune> communes = new HashMap<>();
// 		        Path path = Path.of(fileName);
// 		        try(BufferedReader reader = Files.newBufferedReader(path);) {
// 			        String line = reader.readLine();
// 			        line = reader.readLine();
// 			        while (line != null) {
// 				        String[] split = line.split(";");
// 				        String codePostal = readCodePostal(line);
//                      int population = Integer.parseInt(split[4]);
//                      Commune commune = new Commune(nom, codePostal, population);
// 				        String nom = split[3];
// 				        Commune commune = new Commune(nom, codePostal);
// 				        Commune previousCommune = communes.put(codePostal, commune);
// 				        if (previousCommune != null) {
// 					        System.out.println("Doublon = " + previousCommune);
// 				        }
// 				        line = reader.readLine();
// 			        }
// 		        } catch(IOException e) {
// 			        e.printStackTrace();
// 		        }
// 		        return communes;
// 	        }
// 	        private static Map<String, Maire> readMaires(String fileName) {
// 		        Map<String, Maire> maires = new HashMap<>();
// 		        Path path = Path.of(fileName);
// 		        try(BufferedReader reader = Files.newBufferedReader(path);) {
// 			        String line = reader.readLine();
// 			        line = reader.readLine();
// 			        while (line != null) {
// 				        String[] split = line.split(";");
// 				        String codePostal = readCodePostal(line);
// 				        String nom = split[5];
// 				        String prenom = split[6];
// 				        Civilite civilite = Civilite.of(split[7]);
// 		                Format dateFormat = new SimpleDateFormat("dd/MM/yyyy");
// 				        Date dateDeNaissance = dateFormat.parse(split[8]);
// 				        Maire maire = new Maire(nom, prenom, civilite, dateDeNaissance);
// 				        Maire previousMaire = maires.put(codePostal, maire);
// 				        if (previousMaire != null) {
// 					        System.out.println("Doublon = " + previousMaire);
// 				        }
// 				        line = reader.readLine();
// 			        }
// 		        } catch(IOException | ParseException e) {
// 			        e.printStackTrace();
// 		        }
// 		        return maires;
// 	        }
// 	        private static Map<String, Departement> readDepartements(String fileName) {
// 		        Map<String, Departement> departements = new HashMap<>();
// 		        Path path = Path.of(fileName);
// 		        try(BufferedReader reader = Files.newBufferedReader(path);) {
// 			        String line = reader.readLine();
// 			        line = reader.readLine();
// 			        while (line != null) {
// 				        String[] split = line.split(";");
// 				        String codeDepartement = readCodeDepartement(line);
// 				        String nom = split[1];
// 				        Departement departement = new Departement(codeDepartement, nom);
// 				        departements.put(codeDepartement, departement);
// 				        line = reader.readLine();
// 			        }
// 		        } catch (IOException e) {
// 			        e.printStackTrace();
// 		        }
// 		        return departements;
// 	        }
// 	        private static String readCodePostal(String line) {
// 		        String[] split = line.split(";");
// 		        String codeDepartement = split[0];
// 		        if (codeDepartement.length() == 1) {
// 			        codeDepartement = "0" + codeDepartement;
//              }
// 		        String codeInsee = split[2];
// 		        if (codeInsee.length() == 1) {
// 			        codeInsee = "00" + codeInsee;
// 		        } else if (codeInsee.length() == 2) {
// 			        codeInsee = "0" + codeInsee;
// 		        }
// 		        String codePostal = codeDepartement + codeInsee;
// 		        return codePostal;
// 	        }
// 	        private static String readCodeDepartement(String line) {
// 		        String[] split = line.split(";");
// 		        String codeDepartement = split[0];
// 		        if (codeDepartement.length() == 1) {
// 			        codeDepartement = "0" + codeDepartement;
// 		        }
// 		        return codeDepartement;
// 	        }
//      }
// -----------
// - Note pour le cours précédent : La liste des communes est une liste. Concernant le mapping de l'API Collection, que devons nous utiliser comme type de mapping pour des relations 1:p en JPA.
//      --> De manière générale il vaut mieux utiliser des Set que des List. En effet, une relation 1:p dans une base de données à plus la structure de Set qu'une structure de List.
//          En effet, lorsque nous effectuons une requête sur une base de données, nous ne pouvons pas prédire l'ordre dans lequel les éléments vont être retournés.
//          Ceci est typiquement le comportement d'un Set et non d'une List dans laquelle les éléments sont ordonnés.
//      --> Aussi, dans une relation 1:p, nous ne pouvons pas avoir de doublons dans cette relation, ce qui correspond aussi au comportement d'un Set.
// - Modification dans PlayWithCommunes : Dans la classe Commune, nous ne prenions pas en compte le champs 'population'.
//      --> Nous pouvons donc ajouter 'private int population;' dans notre classe, l'ajouter au constructeur non-vide, à la méthode toString() et générer ses getters & setters.
//      --> Dans PlayWithMaires : Dans la méthode readCommunes, nous pouvons ajouter un int 'population' en parsant la colonne 5 de notre fichier de données, et l'ajouter au constructeur (voir ci-dessus).
//          A savoir que nous sommes obligés de le parser vers un integer car un fichier .csv ne contient que des chaînes de caractères.
// - Maintenant, nous pouvons nous créer un backup de notre base de données :
//      - Nous ajoutons d'abord un nouveau répertoire 'backup' à notre projet.
//      - Nous ouvrons une console dans ce répertoire puis nous pouvons exécuter : 'mysqldump -u jpa-user -p db_jpa --add-drop-table > base-commune.sql'.
//          Une erreur de droit peut se produire, mais ce n'est pas grave car le fichier .sql se créé quand même.
//          --> Ainsi, nous avons un backup de notre base de données, très rapidement, moins d'une seconde, et cela nous évite de réexécuter tout le code java pour remplir la base de données.
//      - Ainsi, si nous dropons nos tables dans MySQLWorkbench, nous pouvons exécuter dans une console locale à son dossier : 'mysql -u jpa-user -p db_jpa < base-commune.sql'.
//          --> De ce fait, notre base de données sera reconstruite et repeuplée de la même manière qu'avant de l'avoir droppée, et ce de manière rapide.
// - Enfin, pour finir sur cette partie, nous devons remettre la relation @OneToOne entre Maire et Commune comme elle l'était auparavant :
//      --> Dans la classe Commune : '@OneToOne(cascade = CascadeType.PERSIST)' sur le champs maire.
//      --> Dans la classe Maire : '@OneToOne(cascade = CascadeType.PERSIST, mappedBy = "maire")' sur le champs commune.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Stream 5 sur JPA/Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// - Nous allons maintenant voir l'héritage en commençant par créer un nouveau projet :
//      --> New > Project > Maven Project > Create a simple project > Next > Group id : org.vitu, Artifact id : jpa-heritage.
//      --> Maintenant nous pouvons recopier notre pom.xml comme celui du projet précédent.
//      --> Nous pouvons créer une première classe 'PlayWithInheritance', dans laquelle nous collons notre EntityManagerFactory et notre EntityManager, emprunté à la classe PlayWithMaire.
//      --> Nous copions et collons le dossier META-INF, contenant le fichier persistence.xml aussi dans notre nouveau projet, dans le dossier src/main/ressources.
// - Maintenant nous pouvons créer une classe 'User', dans un package 'model'.
//      - Nous en faisons un bean, en utilisant un champs 'nom', un champs 'age', ainsi qu'un champs 'id', qui ne fait pas partie du bean, et qui aura une '@GeneratedValue'.
//      - Cette classe va être étendue par une classe que nous allons construire de la même manière 'Customer'.
//      - Puisque 'Customer' étends 'User', cela signifie que 'Customer' possède la clef primaire de 'User', ainsi que les Getter et Setter qui vont avec.
//      - De plus, 'Customer' hérite aussi de l'implémentation de 'Serializable', puisque 'User' implémente elle-même 'Serializable'.
//      - A présent nous pouvons ajouter la méthode toString(), ainsi que les getter et setter dans cette nouvelle classe, et le constructeur vide.
//          Pour ce qui est du constructeur utilisant les fields, nous devons ajouter 'name, age' dans les parenthèses du super() pour que les champs hérités de la classe 'User' soient présents.
//          --> De cette manière nous pourrons voir de quelle manière JPA va mapper l'héritage.
//      - De retour dans notre classe 'PlayWithInheritance' : nous créons un nouvel User ainsi qu'un nouveau Customer et nous les persistons avec l'EntityManager pour voir comment ils seront mappés.
//          Nous pouvons constater qu'il nous a créé automatiquement une table User, qui contient une colonne DTYPE donnant le type User ou Customer.
//          La table comporte 5 colonnes, contenant tous les champs de la classe User, ainsi que le champs de la classe Customer.
//              CREATE TABLE `user` (
//                  `DTYPE` varchar(31) NOT NULL,
//                  `id` int NOT NULL AUTO_INCREMENT,
//                  `age` int NOT NULL,
//                  `nom` varchar(40) DEFAULT NULL,
//                  `ref_cust` varchar(10) DEFAULT NULL,
//                  PRIMARY KEY (`id`)
//              ) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
//          --> Nous pouvons voir aussi qu'Hibernate nous à mis la clef primaire tout seule en 'AUTO_INCREMENT', ce qui est une fausse bonne idée, donc qu'il faut éviter.
//          --> Nous sommes donc dans un type de mapping 'SingleTable', le type de mapping choisi par défaut par Hibernate.
//      - Maintenant nous pouvons ajouter le getter et le setter de la clef primaire 'id' de User dans sa classe. Et l'ajouter à la méthode toString() de la classe Customer.
//          --> A présent, une fois le code lancé, nous obtenons la requête de création de table suivante :
//              CREATE TABLE `user` (
//                  `DTYPE` varchar(31) NOT NULL,
//                  `id` int NOT NULL,
//                  `age` int NOT NULL,
//                  `nom` varchar(40) DEFAULT NULL,
//                  `ref_cust` varchar(10) DEFAULT NULL,
//                  PRIMARY KEY (`id`)
//              ) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
//          --> Nous n'avons plus la colonne de clef primaire qui est auto-incrémentable.
//      - Pourquoi nous à t'il créé une colonne DTYPE ?
//          --> Cette colonne apparaît systématiquement dès l'instant que nous avons plusieurs types d'entités qui sont présentent dans la même table.
// - A présent, dans une autre classe 'FunWithInheritance', nous rappatrions notre EntityManager, et nous lui appliquons la méthode find() pour qu'il nous trouve un User.
//      A savoir que la méthode find() n'est pas nécessairement effectuée au sein d'une transaction puisque ce n'est qu'une opération de lecture.
//      - Nous changeons la méthode de 'create' à 'validate' dans notre fichier persistence.xml, puis nous pouvons lancer.
//          --> Nous constatons malheureusement que si nous recherchons un User avec pour clef primaire 2, il nous retourne un Customer et non un User.
//      - Nous ajoutons le nom des colonnes en passant un paramètre name à chaque entité, et ajoutons une strategy d'inheritance à notre classe User.
//          --> Le second inconvéniant du SingleTable est le suivant, comme toutes les entités JPA vont vivre dans la même table, nous allons avoir des champs dont les valeurs vont être nulles.
//              Par exemple, le champs 'ref_cust' pour un objet de type User sera forcément null, puisqu'un User ne possède pas ce champs.
//              En effet, si nous ajoutons le paramètre JPA 'nullable = false' à ce champs et que nous réexécutons ce code, nous aurons une SQLException à cause de cette valeur nulle.
//              Nous pouvons le constater si nous dupliquons notre transaction en passant un objet dans chacune, dans MySQL, nous n'aurons qu'une ligne d'écrite.
//      --> Donc si nous choisissons ce type de mapping, nous aurons de nombreuses contraintes d'intégrité.
// - Dans le cours, nous avons vu que nous avons une notion importante qui est la performance :
//      - Le nombre de requêtes exécutées lorsque nous effectuons une insertion, une mise à jour, un effacement, donc les opérations CRUD (Create, Retrieve, Update, Delete) classiques.
//          Nous avons aussi la performance liée à l'exécution de requêtes polymorphiques, car JPA fait des requêtes de ce type.
//          Nous avons enfin les problèmes de performances liés ou non au fait d'effectuer des jointures avec des listes.
//      - Supposons que nous avons une nouvelle classe dans le package 'model' appelée 'Users' qui contiens un Set<User> ainsi qu'une clef primaire, mappée @OneToMany(mappedBy = "users").
//          Nous ajoutons le getter et setter de la clef primaire (qui est le même code que pour la classe User).
//          --> Pour le getter de notre Set, nous devons faire une 'copie défensive', en créant un nouveau HashSet<User> à chaque fois.
//          Nous avons aussi besoin de créer une méthode addUser, qui va retourner une boolean puisque la méthode .add() de HashSet<>() nous retourne un boolean.
//          Enfin, nous pouvons ajouter la méthode toString() ainsi que l'implémentation de 'Serializable' pour que notre @Entity soit réellement une entité JPA.
//          Nous devons aussi ajouter un champs Users dans notre classe User, portant l'annotation '@ManyToOne', qui va référencer notre mappedBy.
//          Pour compléter ceci, il nous faut modifier la méthode addUser en gérant la relation inverse.
//              --> Nous créons un boolean 'added' retournant this.users.add(user) (ce qui était retourné précédemment).
//              --> Nous ajoutons une condition disant que si added est false, car dans notre cas, le add() peut échouer.
//      - Pour nous faciliter la vie, nous ajoutons une seconde unité de persistence dans notre fichier persistence.xml, afin d'en avoir une en mode create et l'autre en mode validate.
// - Nous allons à présent changer le mapping en modifiant l'annotation '@Inheritance' à la stratégie 'TABLE_PER_CLASS' qui va nous mettre chaque entité JPA dans une table différente.
//      --> A savoir qu'il faut aussi que la stratégie de l'annotation @GeneratedValue doit être sur 'SEQUENCE'.
//      --> A présent nous n'avons plus aucune cellule null dans nos tables (sauf si nous en insérons nous-même).
//      - Cela fonctionne, et ce qui est bien c'est que nous pouvons maintenant paramétrer la colonne Ref_Cust à non-nullable dans la classe Customer.
//          --> Ainsi, dans notre create statement de la table Customer, le champs ref_cust est à pour contrainte d'intégration 'NOT NULL' au lieu du 'DEFAULT NULL' qui est en place par défaut.
//      - Toutefois, lorsque nous effectuons nos requêtes de persistence de type validate dans 'FunWithInheritance', pour trouver un Customer, nous avons deux requêtes d'effectuées.
//          Une première sur la table User pour trouver l'id puisque l'id est rattaché à la classe User par héritage, et une seconde sur la table Customer pour trouver le Customer.
//          Ceci est représenté par des 'union' dans la partie 'from' des requêtes SQL, et peut être coûteux si nous avons des unions avec de nombreuses tables.
//      --> Donc le mapping TABLE_PER_CLASS se passe bien lorsqu'il s'agit de requêtes de types CRUD sur des classes sans héritage.
//          Toutefois cela peut être vite coûteux lorsque nous avons des requêtes polymorphiques ou lorsque nous avons des relations 1:p.
// - Le dernier cas de figure que nous allons voir et le type de mapping 'JOINED' pour la classe User, car c'est celle dont héritent les classes Customer et Users.
//      - Si nous exécutons la création des entités et donc des tables en exécutant 'PlayWithInheritance', nous pouvons observer les requêtes de création des trois tables appartenant aux trois entités.
//          --> Hibernate nous créé une table User avec la clef primaire et les champs de User à l'intérieur.
//          --> Il nous créé également une table Customer avec la même clef primaire et avec uniquement les champs de Customer.
//          --> Donc chaque table ne contient que les champs qui appartiennent à la classe Java ou entité JPA correspondantes.
//          En effet, dans le TABLE_PER_CLASS, nous avions aussi l'âge et le nom du User dans la table Customer, alors que maintenant nous n'avons que l'id et le ref_cust.
//          Donc pour aller chercher les champs de type User de notre Customer, il nous faut faire une jointure vers la table User.
//              --> Donc ici, pour la table Customer, 'id' est à la fois une clef primaire, ainsi qu'une clef étrangère qui référence le User qui possède cet id.
//      - Maintenant que se passe t'il si nous effectuons des requêtes de lecture, en exécutant 'FunWithInheritance' ?
//          --> A présent nous n'avons plus d'unions, Hibernate récupère les champs de la table User, puis effectue une jointure sur Customer, puis sur Users.
//              Nous n'avons donc plus d'union car toutes les entités, que ce soit des User ou des Customer, sont référencées dans la table User.
//              En utilisant un 'left outer join', donc avec une jointure, Hibernate va aller chercher les informations nécessaires, mais ceci en une seule requête.
//          --> A savoir que visiblement, nous n'avons pas de colonne D_TYPE en effectuant ce type de mapping.
//      --> L'avantage de ce type de mapping est que l'intégralité des entités sont référencées dans une seule table (comme dans SINGLE_TABLE).
//      --> A la différence de SINGLE_TABLE, nous avons la possibilité de maintenir les contraintes d'intégrité dans notre modèle JPA (avec la clause nullable).
//      --> L'inconvéniant va être sur les requêtes de type CRUD, en effet, nous avons autant de requêtes qui sont exécutées que nous avons d'étages dans notre héritage.
// - Question : Si nous recherchons un élément avec .find() et la même clef primaire, trouvons-nous toujours le même élément ?
//      --> C'est le problème des colonnes auto-incrémentables de MySQL, c'est plutôt déconseillé car cela veux dire que d'une table à l'autre, nous pouvons avoir les mêmes valeurs de clefs primaires.
//          Donc si nous sommes confrontés à une situation où nous souhaitons fusionner les tables, nous seront confrontés au fait que des valeurs de clefs primaires seront les mêmes.
//      --> Il vaut mieux avoir des clefs primaires qui sont uniques à l'échelle de la base de données.
// - Concernant le mapping de type JOINED, nous allons vérifier la différence entre Hibernate et EclipseLink.
//      - D'abord, nous devons ajouter les nouvelles dépendances dans le pom.xml pour EclipseLink, mais en fait elles étaient déjà en place.
//      - Pour ceci, nous devons créer une nouvelle unité de persistence en copiant une de celles que nous avons déjà dans le fichier persistence.xml.
//          Nous y retirons les anciennes propriétés propres à Hibernate, et ajoutons les nouvelles associées à EclipseLink.
//          Aussi, certaines propriétés utilisent des fichiers dans leurs champs 'value' rangées dans un dossier 'sql', donc nous pouvons créer ce dossier à la racine de notre projet.
//      - EclipseLink n'a pas de rêgle de découverte des entités par défaut donc il faut les lui préciser en utilisant des balises <class> contenant le chemin complet des classes dans notre projet.
//          Nous pouvons constater une fois que les tables sont créées que nous avons la même contrainte de clef étrangère que pour Hibernate dans le mapping 'JOINED'.
//      --> Donc la majeure différence dans notre cas entre Hibernate et EclipseLink est que ce dernier créé une colonne 'D_TYPE' alors que Hibernate ne le fait pas.
//      --> Il y a beaucoup d'autres différences entre ces deux provider de JPA.
//      --> Ce pourquoi nous devons systématiquement conserver le même provider de JPA pour un même projet, nous ne pouvons pas le créer avec Hibernate et l'utiliser avec EclipseLink par exemple.
// - Concernant à présent le mapping de type MAPPEDSUPERCLASS : nous avons un champs 'id' qui est commun à nos classes, nous pourrions donc améliorer notre projet.
//      - Commençons par nous créer une nouvelle classe dans le package 'model' que nous appelerons 'AbstractPersistentObject'.
//          Dans celle-ci nous ajoutons notre champs 'id', avec les mêmes annotations que dans la classe 'User'.
//          Nous lui ajoutons aussi son getter et son setter, et précisons que cette classe implémente 'Serializable'.
//      - A présent dans la classe 'User', nous pouvons retirer le champs 'id', son getter et son setter, en précisant que la classe étends 'AbstractPersistentObject'.
//          Par conséquent, il n'est plus nécessaire d'implémenter 'Serializable' vu que cette interface est héritée par la classe maîtresse.
//          Ainsi nous pouvons remplacer l'appel à 'id' dans la méthode toString() par la méthode getId() qui est héritée de la classe 'AbstractPersistentObject'.
//      - Nous pouvons aussi effectuer la même chose dans les classes 'Users' et 'Customer'.
//          --> Il nous manque une dernière chose, nous devons retirer les annotations entités des classes 'User' et 'Users' car Hibernate va nous en demander les clefs primaires que nous venons de retirer.
//          --> Aussi, nous devons transmettre l'annotation '@Inheritance' de la classe 'User' à la classe 'AbstractPersistentObject', vu que c'est cette dernière classe qui va dicter la stratégie de mapping.
//      --> Cela fonctionne, toutefois, nous sommes confrontés à un problème : la table AbstractPersistentObject porte tous les objets, alors que nous voulons qu'elle ne porte que les clefs primaires.
//      - Pour cela nous ajoutons l'annotation '@MappedSuperclass' et en retirer l'annotation '@Inheritance'.
//          --> Ainsi, tous les champs et les propriétés de cette classe sont persistentes et seront prises en compte dans toutes les entités JPA qui étendent cette classe.
//          --> Par contre, ce n'est pas une entité, donc nous ne pouvons pas faire de listes de ces objets là, ni de tables de hashage, ni effectuer de requêtes dessus.
//          --> Donc, nous devons remettre l'annotation 'Inheritance' à notre classe User.
//          --> Aussi, nous devons par précaution, ajouter le mot clef 'abstract' lorsque nous déclarons la classe utilisée en tant que MappedSuperclass.
//              Nous la déclarons abstraites, car en toute logique, nous n'allons pas créer d'instances de cette classe, puisqu'elle n'est utilisée que pour mapper les classes qui l'étendent.
//              --> Donc, pour interdire la création d'instances d'une certaine classe, nous devons la mettre abstraite.
//      - Lorsque nous utilisons ce genre de classe, en général, ce n'est pas uniquement pour y mettre des clefs primaires, mais en général d'autres objets.
//          - Nous allons par exemple ajouter deux champs de type Date : 'creationDate' et 'lastModificationDate', ce qui est en général utilisé dans ce type de contexte (en utilisant java.util.Date).
//              --> Attention, il faut absolument mettre l'annotation @Temporal, surtout avec EclipseLink, qui, dans le cas contraire, ne fera pas le mapping.
//              Nous y ajoutons aussi les getters et les setters pour ces deux nouveaux champs et regénérons la méthode toString() complétée de ces deux champs.
//          - De plus, nous pouvons regénérer la méthode toString() de la classe 'User' en y ajoutant la méthode toString() héritée de sa super classe en appelant : super.toString().
//              Nous regénérons de la même manière la méthode toString() de la classe 'Customer'.
//      --> Ainsi, nous avons créé un objet abstrait avec l'annotation '@MappedSuperclass', car ainsi nous pouvons y mettre beaucoup d'informations.
//          Ceci nous permet de monitorer un petit peu la vie de nos entités JPA dans notre application.
//          C'est pourquoi nous y stockons la clef primaire, mais aussi la date à laquelle chaque objet a été créé, et la date de dernière modification de ces derniers.
//          --> Toutefois, ce que nous ne voulons pas, c'est d'avoir à gérer nous-même ces dates de créations.
//          --> Ce que nous souhaitons, c'est d'automatiquement créer la clef primaire et les deux champs dates à chaque création d'un nouvel objet issu d'une entité JPA.
//              --> Ceci peut être fait en annotant '@OnPersist' et '@PreUpdate' une méthode pour créer deux dates lors de la persistance d'un objet, et modifier une date lors d'un update.
//                  A savoir qu'il existe ce type d'annotations pour chacune des opérations CRUD.
//                  Ce sont des annotations qui nous permettent d'exécuter du code selon la phase du cycle de vie d'une entité JPA.
// -----------
//      <?xml version="1.0" encoding="UTF-8" ?>
//      <persistence
// 	        xmlns="http://xmlns.jcp.org/xml/ns/persistence"
// 	        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
// 	        xsi:schemaLocation=
// 		        "http://xmlns.jcp.org/xml/ns/persistence
// 		        http://xmlns.jcp.org/xml/ns/persistence/persistence_2_2.xsd"
// 	        version="2.2">
// 	        <persistence-unit name="tp-jpa-create" transaction-type="RESOURCE_LOCAL">
// 		        <provider>org.hibernate.jpa.HibernatePersistenceProvider</provider>
// 		        <properties>
// 			        <property name="javax.persistence.jdbc.driver"
// 					          value="com.mysql.cj.jdbc.Driver"/>
// 			        <property name="javax.persistence.jdbc.url"
// 					          value="jdbc:mysql://localhost:3306/db_jpa"/>
// 			        <property name="javax.persistence.jdbc.user"
// 					          value="jpa-user"/>
// 			        <property name="javax.persistence.jdbc.password"
// 					          value="user"/>
// 			        <!-- validate | update | create | create-drop -->
// 			        <property name="hibernate.hbm2ddl.auto"
// 					          value="create" />
// 			        <!-- https://www.youtube.com/watch?v=FjmuClV40A4 -->
// 			        <property name="hibernate.show_sql" value="false" />
// 			        <property name="hibernate.format_sql" value="false" />
// 			        <property name="hibernate.use_sql_comments" value="false" />
// 		        </properties>
// 	        </persistence-unit>
//  	    <persistence-unit name="tp-jpa-validate" transaction-type="RESOURCE_LOCAL">
// 		        <provider>org.hibernate.jpa.HibernatePersistenceProvider</provider>
// 		        <properties>
// 			        <property name="javax.persistence.jdbc.driver"
// 					          value="com.mysql.cj.jdbc.Driver"/>
// 			        <property name="javax.persistence.jdbc.url"
// 					          value="jdbc:mysql://localhost:3306/db_jpa"/>
// 			        <property name="javax.persistence.jdbc.user"
// 					          value="jpa-user"/>
// 			        <property name="javax.persistence.jdbc.password"
// 					          value="user"/>
// 			        <!-- validate | update | create | create-drop -->
// 			        <property name="hibernate.hbm2ddl.auto"
// 					          value="validate" />
// 			        <!-- https://www.youtube.com/watch?v=FjmuClV40A4 -->
// 			        <property name="hibernate.show_sql" value="false" />
// 			        <property name="hibernate.format_sql" value="false" />
// 			        <property name="hibernate.use_sql_comments" value="false" />
// 		        </properties>
// 	        </persistence-unit>
// 	        <persistence-unit name="tp-jpa-eclipselink-create" transaction-type="RESOURCE_LOCAL">
// 		        <provider>org.eclipse.persistence.jpa.PersistenceProvider</provider>
// 		        <class>org.vitu.jpa.model.Customer</class>
// 		        <class>org.vitu.jpa.model.User</class>
// 		        <class>org.vitu.jpa.model.Users</class>
// 		        <properties>
// 			        <property name="javax.persistence.jdbc.driver"
// 					          value="com.mysql.cj.jdbc.Driver"/>
// 			        <property name="javax.persistence.jdbc.url"
// 					          value="jdbc:mysql://localhost:3306/db_jpa"/>
// 			        <property name="javax.persistence.jdbc.user"
// 					          value="jpa-user"/>
// 			        <property name="javax.persistence.jdbc.password"
// 					          value="user"/>
// 			        <!-- create-tables | create-or-extend-tables | drop-and-create-tables | none -->
// 			        <property name="eclipselink.ddl-generation"
// 					          value="create-or-extend-tables"/>
// 			        <property name="eclipselink.create-ddl-jdbc-file-name"
// 					          value="sql/create-schema.sql"/>
// 			        <property name="eclipselink.drop-ddl-jdbc-file-name"
// 					          value="sql/drom-schema.sql"/>
// 			        <!-- database | file | both -->
// 			        <property name="eclipselink.ddl-generation.output-mode"
// 					          value="both"/>
// 			        <property name="eclipselink.target-database"
// 					          value="MySQL"/>
// 		        </properties>
//      	</persistence-unit>
//      </persistence>
// -----------
//      package org.vitu.jpa;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import org.vitu.jpa.model.Customer;
//      import org.vitu.jpa.model.User;
//      import org.vitu.jpa.model.Users;
//      public class PlayWithInheritance {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("tp-jpa-create");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        User bigFella = new User("BigFella", 70);
// 		        Customer moussa = new Customer("Moussa", 35, "M35");
// 		        entityManager.getTransaction().begin();
// 		        entityManager.persist(moussa);
// 		        entityManager.getTransaction().commit();
// 		        entityManager.getTransaction().begin();
// 		        entityManager.persist(bigFella);
// 		        entityManager.getTransaction().commit();
// 		        entityManager.getTransaction().begin();
// 		        Users users = new Users();
// 		        users.addUser(moussa);
// 		        users.addUser(bigFella);
// 		        entityManager.persist(users);
// 		        entityManager.getTransaction().commit();
// 		        System.out.println("Moussa = " + moussa);
// 		        System.out.println("BigFella = " + bigFella);
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import org.vitu.jpa.model.User;
//      import org.vitu.jpa.model.Users;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      public class FunWithInheritance {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("tp-jpa-validate");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        User user1 = entityManager.find(User.class, 1);
// 		        System.out.println("User = " + user1);
// 		        User user2 = entityManager.find(User.class, 2);
// 		        System.out.println("User = " + user2);
// 		        Users users = entityManager.find(Users.class, 1);
// 		        System.out.println("Users = " + users);
// 	        }
//      }
// -----------
//      package org.vitu.jpa.model;
//      import java.io.Serializable;
//      import java.util.Date;
//      import javax.persistence.GeneratedValue;
//      import javax.persistence.GenerationType;
//      import javax.persistence.Id;
//      import javax.persistence.MappedSuperclass;
//      import javax.persistence.PrePersist;
//      import javax.persistence.PreUpdate;
//      import javax.persistence.Temporal;
//      import javax.persistence.TemporalType;
//      @MappedSuperclass
//      public abstract class AbstractPersistentObject implements Serializable {
// 	        @Id @GeneratedValue(strategy = GenerationType.SEQUENCE)
// 	        private int id;
// 	        @Temporal(TemporalType.TIMESTAMP)
// 	        private Date creationDate;
// 	        @Temporal(TemporalType.TIMESTAMP)
// 	        private Date lastModificationDate;
// 	        @PrePersist
// 	        private void prePersist() {
// 		        this.creationDate = new Date();
// 		        this.lastModificationDate = this.creationDate;
// 	        }
// 	        @PreUpdate
// 	        private void preUpdate() {
// 		        this.lastModificationDate = new Date();
// 	        }
// 	        public int getId() {
// 		        return id;
// 	        }
// 	        public void setId(int id) {
// 		        this.id = id;
// 	        }
// 	        public Date getCreationDate() {
// 		        return creationDate;
// 	        }
// 	        public void setCreationDate(Date creationDate) {
// 		        this.creationDate = creationDate;
// 	        }
// 	        public Date getLastModificationDate() {
// 		        return lastModificationDate;
// 	        }
// 	        public void setLastModificationDate(Date lastModificationDate) {
// 		        this.lastModificationDate = lastModificationDate;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "AbstractPersistentObject [id=" + id + ", creationDate=" + creationDate + ", lastModificationDate=" + lastModificationDate + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa.model;
//      import javax.persistence.Column;
//      import javax.persistence.Entity;
//      import javax.persistence.Inheritance;
//      import javax.persistence.InheritanceType;
//      import javax.persistence.ManyToOne;
//      @Entity(name = "User")
//      @Inheritance(strategy = InheritanceType.JOINED)
//      public class User extends AbstractPersistentObject {
// 	        @Column(length = 40)
// 	        private String nom;
// 	        private int age;
// 	        @ManyToOne
// 	        private Users users;
// 	        public User() {
// 	        }
// 	        public User(String nom, int age) {
// 		        this.nom = nom;
// 		        this.age = age;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public int getAge() {
// 		        return age;
// 	        }
// 	        public void setAge(int age) {
// 		        this.age = age;
// 	        }
// 	        public Users getUsers() {
// 		        return users;
// 	        }
// 	        public void setUsers(Users users) {
// 		        this.users = users;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "User [nom=" + nom + ", age=" + age + ", toString()=" + super.toString() + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa.model;
//      import javax.persistence.Column;
//      import javax.persistence.Entity;
//      import javax.persistence.Inheritance;
//      import javax.persistence.InheritanceType;
//      @Entity(name = "Customer")
//      public class Customer extends User {
// 	        @Column(name = "ref_cust", length = 10, nullable = false)
// 	        private String refCustomer;
// 	        public Customer() {
// 	        }
// 	        public Customer(String name, int age, String refCustomer) {
// 		        super(name, age);
// 		        this.refCustomer = refCustomer;
// 	        }
// 	        public String getRefCustomer() {
// 		        return refCustomer;
// 	        }
// 	        public void setRefCustomer(String refCustomer) {
// 		        this.refCustomer = refCustomer;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Customer [refCustomer=" + refCustomer + ", toString()=" + super.toString() + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa.model;
//      import java.util.HashSet;
//      import java.util.Set;
//      import javax.persistence.Entity;
//      import javax.persistence.OneToMany;
//      @Entity
//      public class Users extends AbstractPersistentObject {
// 	        @OneToMany(mappedBy = "users")
// 	        private Set<User> users = new HashSet<>();
// 	        public Set<User> getUsers() {
// 		        return new HashSet<User>();
// 	        }
// 	        public boolean addUser(User user) {
// 		        boolean added = this.users.add(user);
// 		        if (added) {
// 			        user.setUsers(this);
// 		        }
// 		        return added;
// 	        }
// 	        @Override
// 	        public String toString() {
// 	        	return "Users [users=" + users + ", toString()=" + super.toString() + "]";
// 	        }
//      }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live Stream 6 sur JPA/Hibernate ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// - Concernant l'utilisation des transactions, nous pouvons expérimenter au travers de la classe 'FunWithInheritance'.
//      - Si nous utilisons la méthode find(), donc une méthode de lecture, en dehors d'une transactions, cela fonctionne.
//          --> Toutefois, si nous souhaitons effectuer une opération d'écriture (création, modification ou suppression), cela ne fonctionne pas, nous devons le faire au sein d'une transaction.
//      - Si nous utilisons une transaction, nous pouvons toutefois être confronté à un problème.
//          - Par exemple, si nous créons un second EntityManager, nous pouvons récupérer le User avec .find() en utilisant l'entityManager1.
//              Toutefois, si nous modifions son âge au sein d'une transaction et persistons vers la base de données avec l'entityManager2, l'âge ne sera pas modifié.
//              Ceci s'explique par le fait que l'instance d'utilisateur récupérer par le premier EntityManager, n'est pas précisée comme la même que celle persistée par le second EntityManager.
//          --> Il nous faut donc le réattacher à notre entityManager2 pour que celui-ci soit bien pris en compte lorsqu'il est persisté en utilisant la méthode '.merge(user1)'.
//      --> Nous allons voir que quand nous allons gérer ces EntityManager dans un univers managé au travers de Java EE, ceci sera beaucoup plus simple.
// - Nous allons à présent voir le cas ou une entité peut être modifiée pendant que nous y accédons, et par conséquent la notion de refresh.
//      - Pour ce faire nous allons commencer par créer une nouvelle classe 'PlayWithRefresh'.
//          Nous y ajoutons deux EntityManager ainsi que notre EntityManagerFactory.
//      - Ensuite, nous créons deux instances de User 'user1' & 'user2', qui sont récupérés avec la méthode .find() et avec le même EntityManager.
//          Ainsi, nous pouvons ensuite imprimer le résultat de 'user1 == user2' pour vérifier que c'est bien le même objet qui a été récupéré.
//          --> Dans un premier temps, c'est bien le cas, et c'est normal, car nous utilisons le même EntityManager pour les deux opérations sur le même objet.
//      - Par la suite, nous récupérons les deux instances avec deux EntityManager différents.
//          --> Etant donné que chaque entité JPA est attaché a son EntityManager, effectivement le résultat est que les deux objets retournés ne sont pas égaux.
//              Ici, c'est comme si nous simulions deux utilisateurs, chacun dans leurs threads respectifs qui font une requête en même temps sur le même objet en base de données.
//              --> Chacun aura une instance de cet objet qui est différente.
//      - Maintenant nous allons, au sein d'une transaction, effectuer une modification de l'âge de user1 qui appartient à entityManager1 et cette modification se faisant par entityManager1.
//          --> Les deux âges seront différents car entityManager2 aura toujours l'acienne version du User, version pour laquelle l'âge n'a pas encore été modifié.
//      - A présent nous allons aussi imprimer le résultat de user2, créé par l'entityManager2. Cette instance se situe dans une autre zone de la mémoire de la JVM.
//          Cette instance n'a donc pas été modifiée, puisque c'est l'entityManager1 qui l'a modifiée.
//          --> Donc user2 est bien différent de user1, car ils sont assignés à deux EntityManager différents.
//      - Maintenant, nous allons, avec l'entityManager2, modifier l'âge de user2. Donc chacune des instances du même User aura son âge modifié avec une différente valeur et un différent EntityManager.
//          --> Donc lorsque user1 est mis à jour, user2 ne le voit pas, l'âge du User dans la base de données est mis à 25.
//          --> Lorsque user2 est mis à jour, user1 ne le voit pas, et l'âge du User dans la base de données est mis à 40.
//          En fait, nous avons deux objets qui sont physiquement différents dans la mémoire, si nous en modifions un, l'autre n'en sera pas notifié.
//      - En revanche, si après notre changement d'âge de user1, nous effectuons la méthode .refresh(user2) sur notre entityManager2, user2 en sera notifié.
//          De même, lorsque nous aurons mis à jour user2, nous pourrons utiliser la même méthode en prenant user1 en paramètre sur notre entityManager1.
//          --> Le .refresh() retourne chercher la valeur souhaitée en base de données, ce qui nous assure d'avoir la dernière valeur à jour, lorsque nous appelons cette méthode.
//      - Maintenant, il faut savoir que tout allait bien car chaque EntityManager tenait une entité qui était toujours reliée à la base d'une manière ou d'une autre.
//          Si nous décidons de commenter les refresh(userX) de chacun des EntityManager et que nous effectuons un detach(user2).
//          --> A ce moment-là, nous ne pouvons plus rafraichir de toute façon ce User, car nous aurons une exception. En effet, nous ne pouvons pas rafraichir une entité qui n'est pas managée.
//          - Par contre, nous pouvons, avant de mettre à jour user2, et en dehors de la transaction, effectuer un merge de ce user2 sur notre entityManager2.
//              --> Ici, le merge à également fait un refresh() de cet entityManager2 automatiquement.
//          --> Donc un detach(entity) suivi d'un merge(entity) fait à peu près la même chose qu'un refresh(entity). Donc nous pouvons faire un refresh(entity) sur un objet qui n'est pas détaché aussi.
// - Au sujet des requêtes, nous allons fermer notre projet jpa-heritage et rouvrir le projet play-with-jpa.
//      - Nous allons commencer par rincer la base de données, puis dans notre dossier 'backup', nous allons clic droit sur le fichier base-commune.sql > Show in local terminal > Terminal.
//          --> Puis nous pouvons effectuer notre commande : 'mysql -u jpa-user -p db_jpa < base-commune.sql' pour reremplir la base de données.
//          Enfin, puisque nous n'effectuerons plus de création sur la base de données, nous pouvons nous mettre en 'validate' dans notre persistence.xml.
//          A présent nous pouvons nous créer une nouvelle classe 'PlayWithNativeQueries'.
//      - Nous avons vu que nous avons deux manières d'éxécuter des requêtes :
//          - Tout d'abord des requêtes dîtes 'natives', donc des requêtes SQL, qui sont indispensables car bien souvent lorsque nous travaillons avec des bases de données, les requêtes SQL sont présentes.
//              Dans ce type de requêtes, nous requêtons des tables, des lignes et des colonnes, avec des jointures si besoin.
//          - L'autre manière est d'utiliser JPQL.
//              Ici, nous effectuons des requêtes vers des noms d'entités JPA, et des champs dans ces entités.
//          --> Donc la nature de ce qui est requêté est très différent entre SQL et JPQL.
//          --> L'avantage de JPQL est que quelque soit le format de la base de données, les entités ne bougent pas, donc les requêtes n'auront pas à être modifiées pour obtenir le résultat souhaité.
//      - Nous allons commencer par créer une requête SQL très simple : 'select count(*) from Commune'.
//          Il nous faut créer comme d'habitude un EntityManagerFactory, ainsi qu'un EntityManager.
//          Puis, nous avons deux manière de créer notre requête, une méthode '.createNativeQuery()' pour les requêtes SQL et une méthode '.createQuery()' pour les requêtes JPQL.
//          --> Puisque c'est une requête native, nous allons créer un nouvel objet de type 'Query' contenant cette première méthode prenant en paramètre notre requête SQL.
//          - Pour obtenir le résultat, nous pourrions utiliser la méthode '.getResultList()' qui est complexe car elle nous retourne une List<> d'objets, et il faut les caster dans les bonnes classes.
//              Or, puisque nous savons que nous n'aurons qu'une ligne (et une colonne) de résultats de cette requête, nous pouvons utiliser la méthode '.getSingleResult()'.
//              Toutefois, nous allons créer un objet de type 'Class' et récupérer la classe de ce singleResult en utilisant la méthode 'getClass()'.
//              --> La classe retournée est la suivante : 'Class = class java.lang.Long'.
//              Donc nous pouvons adapter notre résultat et le caster dans un objet de type Long.
//              --> Ceci est donc le premier problème des requêtes natives. Il nous faut connaître à l'avance le type du résultat retourné.
//                  De plus, ce type retourné peut varier entre Hibernate et EclipseLink, pour une même requête, et donc un même résultat.
//          - En réalisant une seconde requête, retournant le nombre de communes, ainsi la population maximale d'une commune, nous avons toujours un seul résultat, sur une seule ligne.
//              Toutefois, cette fois-ci nous avons deux objets. En vérifiant la classe de l'objet retourné nous obtenons : Class = class [Ljava.lang.Object;. Ceci est un tableau d'objets.
//              Nous pouvons à présent caster le résultat dans un tableau d'objets, puis imprimer chaque classe des deux éléments de ce tableau.
//              --> Nous obtenons : d'abord un Long, comme précédemment, puis un Integer, et non un int, qui lui est de type primitif. En effet, les types primitifs n'étendent pas 'Object'.
//      - Maintenant nous allons créer une requête SQL nous permettant de récupérer des choses sur plusieurs lignes : 'select nom, population from Commune where population > 250000'.
//          A présent nous pouvons retourner notre résultat à l'aide de la méthode .getResultList() qui nous retourne une List non typée (ce qui est assez dangereux comme manoeuvre).
//          Il s'avère qu'il s'agit d'une List de tableaux d'objets, donc nous devons rechercher la classe des deux objets dedans avant de pouvoir les caster : String et Integer.
//          Maintenant nous pouvons les caster dans des objets de type String et de type int pour chacune des lignes de notre List de résultats en utilisant une boucle for each.
//      --> Nous avons à présent vu les quatre types de résultats de requêtes natives : une ligne, une ligne avec plusieurs colonnes, plusieurs lignes, et plusieurs lignes avec plusieurs colonnes.
// - Maintenant nous allons voir les requêtes de JPQL, en dupliquant notre classe et en la renommant 'PlayWithJPQLQueries'.
//      - Nous allons ainsi essayer de réecrire ces requêtes SQL en JPQL. Pour ce faire, nous utiliserons donc à présent la méthode '.createQuery()'.
//          Aussi, nous devons ajouter une annotation '@Table(name = "Commune")'.
//      - Lorsque nous effectuons la seconde requête, il nous faut aussi nommer dans la requête la Commune par 'c' par exemple, et appeler le champs population 'c.population' à la différence du SQL.
//          --> Il faut donc bien penser à définir des variables dans les requêtes JPQL.
//      - Pour la dernière requête, il ne nous suffit donc qu'à déclarer la variable associé à l'entité Commune, ainsi qu'à l'appeler sur les champs noms et population.
// - A présent nous allons récupérer cette troisième requête et en faire une requête paramétrée.
//      - Tout d'abord dans l'univers Natif : 'select nom, population from Commune where population > ?1'.
//          Si nous poursuivons le reste du code comme il était préparé pour la troisième requête, tout compile, toutefois, il y a une erreur d'exécution car nous n'avons pas déclaré notre variable '?1'.
//          Nous pouvons le fixer avec la méthode 'setParameter(indexParamètre, valeur)' exécutée sur l'objet query contenant ce paramètre.
//          --> Tout fonctionne bien, nous avons bien nos 8 Communes en résultat.
//      - Pour l'univers JPQL, nous utilisons exactement la même requête, qui ne s'exécute toujours pas si nous ne déclarons pas la valeur de notre variable.
//          Donc nous pouvons aussi utiliser la méthode 'setParameters()' sur notre objet query.
//      - En JPQL nous pouvons aussi déclarer des variables en utilisant des noms comme ceci : 'select c.nom, c.population from Commune c where c.population > :pop_min'.
//          Il nous suffit simplement dans la méthode 'setParameter(index, valeur)' de remplacer l'index par le nom de la variable, ici : 'setParameter(pop_min, 200_000)'.
//      - Cette requête nous allons essayer de la stocker quelque part, car elle peut nous servir, en effet, nous pourrons en faire une requête nommée.
//          --> Une requête nommée est quelque chose qui est proposé par JPA et qui fonctionne à la fois pour JPA ainsi que pour les requêtes natives.
//          Pour ce faire, nous allons simplement ajouter cette requête dans la classe Commune, vu que cette requête concerne les communes.
//          Il nous suffit d'ajouter une annotation '@NamedQueries({})' qui peut contenir autant d'annotation '@NamedQuery(name = "...", query = "...")' que nous le voulons.
//      - A présent il nous suffit de créer notre objet de type Query en appelant la méthode '.createNamedQuery()' sur notre EntityManager.
//          Puisqu'elle contient une variable, il nous faut tout de même la définir avec la méthode '.setParameter()'.
//          Enfin, nous pouvons effectuer le même traitement que pour query03.
//      - Quel est l'intérêt de faire des namedQuery plutôt que des query normales ?
//          --> Si nous insérons une erreur dans la syntaxe d'une requête normale, le code situé avant l'exécution de cette requête va quand même s'exécuter avant de lancer l'exception.
//          --> Toutefois, si nous mettons cette erreur dans notre requête nommée JPQL (et pas les requêtes nommées SQL), l'exception sera jetée AVANT l'exécution du code, à la compilation d'Hibernate.
//              Effectivement, les requêtes nommées en SQL ne peuvent pas être analysées par Hibernate directement, elles sont envoyées vers la base de données.
//              Donc, si il y a des erreurs de syntaxe, c'est le serveur de base de données qui va jeter les exceptions qui en découlent.
//                  --> Ainsi, ceci nous évite d'exécuter une partie du code lorsqu'il y a une erreur, ce qui est une bonne chose et une sécurité supplémentaire.
// - Nous allons à présent écrire une requête pour retrouver le nom de la commune la plus peuplée de la table Commune.
//      - Pour ce faire, nous allons faire une requête incluse, donc, tout comme en SQL, en JPQL, nous pouvons inclure une requête dans une requête.
//          Comme nous savons que nous allons récupérer une Commune, nous pouvons caster le SingleResult directement dans un objet Commune.
//      - Maintenant si nous voulons le nombre de Communes qui possède moins de 1000 habitants.
//      - Enfin, nous allons voir pour lister la totalité des population des départements dans une nouvelle List. Ceci se fait en utilisant la jointure @ManyToOne.
// - Dans une dernière étape, nous allons créer une nouvelle classe d'objets 'Statistics', qui vont avoir un nomDepartement, population, et une populationMoyenne.
//      - Ainsi, nous allons pouvoir encapsuler le résultat d'une nouvelle requête à l'intérieur d'un objet de ce type.
//          Toutefois, comme nous n'en avons pas fait un objet JPA, dans la requête, nous devons appeler le chemin complet de la classe Statistics ; 'org.vitu.jpa.query'.
//      --> Maintenant, grâce à la méthode toString() de cette classe, les statistiques de chaque département peuvent-être imprimées.
//          Cet objet Statistics nous permet d'éviter d'avoir à faire des cast vers des List<Object[]> ou ce genre de choses, ce qui nous rends la vie plus facile.
//          --> Ainsi, c'est la méthode la plus simple pour mettre un résultat un peu complexe dans un objet de transport pour faciliter l'analyse de cet objet résultat.
// -----------
//      package org.vitu.jpa;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import org.eclipse.persistence.internal.sessions.cdi.EntityListenerInjectionManagerImpl;
//      import org.vitu.jpa.model.User;
//      public class PlayWithRefresh {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("tp-jpa-validate");
// 		        EntityManager entityManager1 = entityManagerFactory.createEntityManager();
// 		        EntityManager entityManager2 = entityManagerFactory.createEntityManager();
// 		        System.out.println("EM 1 = " + entityManager1);
// 		        System.out.println("EM 2 = " + entityManager2);
// 		        User user1 = entityManager1.find(User.class, 1);
// 		        User user2 = entityManager2.find(User.class, 1);
// 		        System.out.println("uA = u2 ? " + (user1 == user2));
// 		        System.out.println("u1 = " + user1);
// 		        System.out.println("u2 = " + user2);
// 		        entityManager2.detach(user2);
// 		        entityManager1.getTransaction().begin();
// 		        System.out.println("U1 à 25");
// 		        user1.setAge(25);
// 		        entityManager1.getTransaction().commit();
//              // entityManager2.refresh(user2);
// 		        System.out.println("u1 = " + user1);
// 		        System.out.println("u2 = " + user2);
// 		        entityManager2.merge(user2);
// 		        entityManager2.getTransaction().begin();
// 		        System.out.println("U2 à 40");
// 		        user2.setAge(40);
// 		        entityManager2.getTransaction().commit();
//              // entityManager1.refresh(user1);
// 		        System.out.println("u1 = " + user1);
// 		        System.out.println("u2 = " + user2);
// 	        }
//      }
// -----------
//      package org.vitu.jpa.query;
//      public class Statistics {
// 	        private String nomDepartement;
// 	        private long population;
// 	        private double populationMoyenne;
// 	        public Statistics(String nomDepartement, long population, double populationMoyenne) {
// 		        this.nomDepartement = nomDepartement;
// 		        this.population = population;
// 		        this.populationMoyenne = populationMoyenne;
// 	        }
// 	        public String getNomDepartement() {
// 		        return nomDepartement;
// 	        }
// 	        public void setNomDepartement(String nomDepartement) {
// 		        this.nomDepartement = nomDepartement;
// 	        }
// 	        public long getPopulation() {
// 		        return population;
// 	        }
// 	        public void setPopulation(long population) {
// 		        this.population = population;
// 	        }
// 	        public double getPopulationMoyenne() {
// 		        return populationMoyenne;
// 	        }
// 	        public void setPopulationMoyenne(double populationMoyenne) {
// 		        this.populationMoyenne = populationMoyenne;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Statistics [nomDepartement=" + nomDepartement + ", population=" + population + ", populationMoyenne="
// 				        + populationMoyenne + "]";
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import java.util.List;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import javax.persistence.Query;
//      public class PlayWithNativeQueries {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        String sql00 = "select count(*) from Commune";
// 		        Query query00 = entityManager.createNativeQuery(sql00);
// 		        Object singleResult00 = query00.getSingleResult();
// 		        Long count00 = (Long)query00.getSingleResult();
// 		        System.out.println("Count = " + count00);
// 		        String sql01 = "select count(*), max(population) count from Commune";
// 		        Query query01 = entityManager.createNativeQuery(sql01);
// 		        Object[] result01 = (Object[])query01.getSingleResult();
// 		        Long count01 = (Long)result01[0];
// 		        Integer max01 = (Integer)result01[1];
// 		        System.out.println("Class = " + result01[0].getClass());
// 		        System.out.println("Class = " + result01[1].getClass());
// 		        System.out.println("Count = " + count01);
// 		        System.out.println("Max = " + max01);
// 		        String sql02 = "select nom, population from Commune where population > 250000";
// 		        Query query02 = entityManager.createNativeQuery(sql02);
// 		        List result02 = query02.getResultList();
// 		        Object object = result02.get(0);
// 		        System.out.println("# resultats : " + result02.size());
// 		        System.out.println("Class = " + object.getClass());
// 		        for (Object[] line : (List<Object[]>)result02) {
//      //			System.out.println("0 : " + line[0].getClass());
//      //			System.out.println("1 : " + line[1].getClass());
// 			        String nom = (String)line[0];
// 			        int population = (int)line[1];
// 			        System.out.println("Nom : " + nom + " - " + population + " habitants.");
// 		        }
// 		        String sql03 = "select nom, population from Commune where population > ?1";
// 		        Query query03 = entityManager.createNativeQuery(sql03);
// 		        query03.setParameter(1, 250000);
// 		        List result03 = query03.getResultList();
// 		        System.out.println("# resultats : " + result03.size());
// 		        for (Object[] line : (List<Object[]>)result03) {
//      //			System.out.println("0 : " + line[0].getClass());
//      //			System.out.println("1 : " + line[1].getClass());
// 			        String nom = (String)line[0];
// 			        int population = (int)line[1];
// 			        System.out.println("Nom : " + nom + " - " + population + " habitants.");
// 		        }
// 		        String sql04 = "select d.nom, sum(c.population) from Departement d join Commune c on d.codeDepartement = c.departement_codeDepartement group by d.nom";
// 		        Query query04 = entityManager.createNativeQuery(sql04);
// 		        List<Object[]> resultList = query04.getResultList();
// 		        resultList.forEach(tab -> System.out.println(tab[0] + " -> " + tab[1]));
//      //		int count = (int)query00.getSingleResult();
//      //		Class class1 = singleResult00.getClass();
//      //		System.out.println("Class = " + class1);
// 	        }
//      }
// -----------
//      package org.vitu.jpa;
//      import java.util.List;
//      import javax.persistence.EntityManager;
//      import javax.persistence.EntityManagerFactory;
//      import javax.persistence.Persistence;
//      import javax.persistence.Query;
//      import org.vitu.jpa.model.Commune;
//      public class PlayWithJPQLQueries {
// 	        public static void main(String[] args) {
// 		        EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("play-with-jpa");
// 		        EntityManager entityManager = entityManagerFactory.createEntityManager();
// 		        String jpql00 = "select count(*) from Commune";
// 		        Query query00 = entityManager.createNativeQuery(jpql00);
// 		        long count00 = (long)query00.getSingleResult();
// 		        System.out.println("Count = " + count00);
// 		        String jpql01 = "select count(*), max(c.population) from Commune c";
// 		        Query query01 = entityManager.createQuery(jpql01);
// 		        Object[] result01 = (Object[])query01.getSingleResult();
// 		        long count01 = (long)result01[0];
// 		        int max01 = (int)result01[1];
// 		        System.out.println("Class = " + result01[0].getClass());
// 		        System.out.println("Class = " + result01[1].getClass());
// 		        System.out.println("Count = " + count01);
// 		        System.out.println("Max = " + max01);
// 		        String jpql02 = "select c.nom, c.population from Commune c where c.population > 250000";
// 		        Query query02 = entityManager.createQuery(jpql02);
// 		        List result02 = query02.getResultList();
// 		        Object object = result02.get(0);
// 		        System.out.println("# resultats : " + result02.size());
// 		        System.out.println("Class = " + object.getClass());
// 		        for (Object[] line : (List<Object[]>)result02) {
//      //			System.out.println("0 : " + line[0].getClass());
//      //			System.out.println("1 : " + line[1].getClass());
// 			        String nom = (String)line[0];
// 			        int population = (int)line[1];
// 			        System.out.println("Nom : " + nom + " - " + population + " habitants.");
// 		        }
// 		        String jpql03 = "select c.nom, c.population from Commune c where c.population > ?1";
// 		        Query query03 = entityManager.createQuery(jpql03);
// 		        query03.setParameter(1,200_000);
// 		        List result03 = query03.getResultList();
// 		        System.out.println("# resultats : " + result03.size());
// 		        for (Object[] line : (List<Object[]>)result03) {
//      //			System.out.println("0 : " + line[0].getClass());
//      //			System.out.println("1 : " + line[1].getClass());
// 			        String nom = (String)line[0];
// 			        int population = (int)line[1];
// 			        System.out.println("Nom : " + nom + " - " + population + " habitants.");
// 		        }
// 		        String jpql04 = "select c.nom, c.population from Commune c where c.population > :pop_min";
// 		        Query query04 = entityManager.createQuery(jpql04);
// 		        query04.setParameter("pop_min",250_000);
// 		        List result04 = query04.getResultList();
// 		        System.out.println("# resultats : " + result04.size());
// 		        for (Object[] line : (List<Object[]>)result04) {
// 			        String nom = (String)line[0];
// 			        int population = (int)line[1];
// 			        System.out.println("Nom : " + nom + " - " + population + " habitants.");
// 		        }
// 		        Query query05 = entityManager.createNamedQuery("Commune.byPopulationMin");
// 		        query05.setParameter("pop_min",230_000);
// 		        List result05 = query05.getResultList();
// 		        System.out.println("# resultats : " + result05.size());
// 		        for (Object[] line : (List<Object[]>)result05) {
// 			        String nom = (String)line[0];
// 			        int population = (int)line[1];
// 			        System.out.println("Nom : " + nom + " - " + population + " habitants.");
// 		        }
// 		        // Commune la plus peuplée
// 		        String jpql06 = "select c from Commune c where c.population = (select max(c.population) from Commune c)";
// 		        Query query06 = entityManager.createQuery(jpql06);
// 		        Commune commune06 = (Commune)query06.getSingleResult();
// 		        System.out.println("Commune la plus peuplée = " + commune06);
// 		        // Nombre de Communes qui ont moins de 1000 habitants
// 		        String jpql07 = "select count(c) from Commune c where c.population < 1000";
// 		        Query query07 = entityManager.createQuery(jpql07);
// 		        long count07 = (long)query07.getSingleResult();
// 		        System.out.println("# communes de moins de 1000 habitants = " + count07);
// 		        // Table nom du département : population du département
// 		        String jpql08 = "select d.nom, sum(c.population) from Departement d, in(d.communes) c group by d.nom";
// 		        Query query08 = entityManager.createQuery(jpql08);
// 		        List<Object[]> result08 = query08.getResultList();
// 		        System.out.println("result08 = " + result08.size());
// 		        result08.forEach(tab -> System.out.println(tab[0] + " - " + tab[1]));
// 		        String jpql09 = "select new org.vitu.jpa.query.Statistics(d.nom, sum(c.population), avg(c.population)) from Departement d, in(d.communes) c group by d.nom";
// 		        Query query09 = entityManager.createQuery(jpql09);
// 		        query09.getResultStream().forEach(System.out::println);
//      //		int count = (int)query00.getSingleResult();
//      //		Class class1 = singleResult00.getClass();
//      //		System.out.println("Class = " + class1);
// 	        }
//      }
// -----------
VOIR CRITERIA API

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Septième partie : Java EE /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cette partie du parcours traite du services REST et de Java EE :
// - Services REST avec JAVA EE,
// - Java EE par la pratique.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : Service REST avec Java EE //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans ce module, nous allons découvrir comment créer un service REST avec Java EE.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à Java EE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'est ce que Java EE (Enterprise Edition) ?
// Nous avons commencé par voir Java SE (Standard Edition), qui est un compilateur, une machine virtuelle, ainsi que le JDK.
// Le JDK est en fait l'ensemble des classes de la librairie Runtime qui permettent de programmer des applications.
// --> Java EE est un peu le pendant de Java SE, mais avec toutes les librairies qui manquent pour faire de vraies applications d'entreprise.
// IL y a essentiellement deux types de librairies :
// - Les librairies qui permettent de gérer le web, avec le protocole HTTP, les IHM web et le service de données au travers des web services.
// - Les services qui nous permettent d'accéder aux bases de données, notamment la gestion des transactions et l'accès au mapping d'objets relationnels avec JPA.
// --> Java EE peut être vu comme un ensemble d'API qui sont une surcouche de Java SE.
// Du point de vue de la licence, nous sommes toujours dans l'open-source et libre de droit.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Historique des versions de Java EE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java SE - 1995 / 1996 : Première version de Java.
// Java 2 - 1998 : Première version de Java pour les grosses applications.
// Java J2SE - 1999 : Première version de Java EE (pas encore de mappin objets relationnels).
// J2EE 1.2 - 1999.
// J2EE 1.3 - 2001.
// J2EE 1.4 - 2003.
// Java EE 5 - 2006 : Première version qui s'appelle vraiment Java EE.
// Java EE 6 - 2009.
// Java EE 7 - 2013.
// Java EE 8 - 2017.
// Jakarta EE 8 - 2019 : Oracle confie la gouvernance de Java EE à Eclipse, ce pourquoi, Java EE deviens Jakarta EE.
// A chaque version qui sort, le nombre de spécifications augemente, mais tout le code utilisé pour les plus anciennes versions reste compatible, bien que certaines fonctionnalités soient dépréciées.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Historique des versions de Java EE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'est ce que Java EE techniquement ? C'est un jeu de spécifications. Donc des documents .pdf.
// Dans la version 8 de Java EE, il y a environ une vingtaine de spécifications.
// Chacune de ces spécification est précisée dans un document que nous appelons un JSR : Java Specification Request.
// Chaque JSR à un numéro, et correspond à une spécification particulière de Java EE.
// Chaque JSR est associée à un groupe d'experts 'EG'. Ceux-ci ont pour mission de rédiger la spécification et de la maintenir dans le temps.
// Ce EG est aussi en charge de préparer une 'RI' : Reference Implementation. C'est celle-ci qui va éclairer toutes les zones d'ombre de la spécification.
// Java EE est lui-même spécifié par une JSR particulière, donc Java EE est une spécification qui spécifie quelles spécifications le compose.
// Java EE est également associé à une RI : GlassFish, qui est open-source et libre de droit, disponible sur GitHub.
// Tout est disponible sur 'www.jcp.org' : Java Comunity Process.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java EE Web Profile et Full Profile ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A partir de 2009, donc de Java EE 6 fournir une implémentation de Java EE devient quelque chose de très compliqué. Donc Java EE, se met à définir deux profils :
//      - Web Profile : qui va regrouper uniquement les composants qui s'intéressent spécifiquement au web, dans lesquels nous retrouvons :
//          - Servlet.
//          - JSF.
//          - JSP.
//          - ...
//              --> Les plus célèbres sont Tomcat et Jetty.
//      - Full Profile : dans lequel nous retrouvons l'intégralité des composants qui forment un serveur Java EE.
// Donc à partir de Java EE 6, nous avons des serveurs d'application qui implémentent le Web Profile, sans implémenter le Full Profile.
// Evidemment, une application qui implémente le Full Profile, mécaniquement implémente le Web Profile, mais l'inverse n'est pas vrai.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Serveurs d'Application Compatibles Java EE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous récapitulons, nous avons Java EE et ses ensembles de spécifications, implémenté par un serveur d'application qui se nomme 'Glassfish'.
// Mais en fait des serveurs d'application il y en a plus d'une vingtaine qui vont implémenter différentes versions de Java EE (grosso modo de Java EE 6 à Java EE 8).
// Nous avons par exemple :
//      - Oracle qui commercialise un serveur qui s'appelle 'Weblogic' (qui n'est pas open-source ni gratuit).
//      - IBM à également son serveur d'application qui s'appelle 'Websphere', dont la version 'Liberty profile' qui elle est gratuite et open-source.
//      - RedHat qui a été rachété par IBM, et possède aussi un serveur d'application qui s'appelle 'JBoss EAP', la version 'WebFly' est elle aussi gratuite et open-source.
//      - Payara qui est un 'fork' de Glassfish.
//      - TomEE qui est une version open-source et libre de droit qui est commercialisée par 'Tomitribe'.
// Donc en fait, ces spécifications Java EE ont créé tout un écosystème de serveurs d'application qui permettent de servir des données, des pages web, ou encore de gérer des données dans des pages.
// Et cela à différentes échelles, et évidemment à différents prix.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Architecture de Java EE ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment sont organisés tous ces composants, tous ces organes de Java EE, dont nous avons parlé, qui sont au nombre de plus d'une vingtaine ?
// Nous allons voir cela en détail, bien que nous n'allons pas voir tous les composants car il y en a de nombreux avec lesquels nous n'intéragissons que rarement voire jamais.
//  --> Tout d'abord nous avons trois composants de base, qui nous permettent d'intéragir avec des données en base de données :
//      - Nous allons partir de la base de données. Le premier composant nous l'avons déjà vu, il s'agit de 'JPA' qui gère la partie mapping objets relationnels.
//      - Le second composant se nomme 'JTA' (Java Transaction API). Nous avons vu que dans JPA nous devons gérer les transactions à la main.
//          Lorsque nous sommes dans un serveur Java EE, les transactions sont gérées par le serveur, nous n'avons pas besoin de les gérer à la main, ce qui nous en décharge en évitant des bugs.
//      - Au même niveau que ces deux composants, nous avons 'JMS' (Java Messaging Service) qui permet de faire de la messagerie que nous ne verrons pas en détail.
//          --> Ces trois composants nous permettent d'intéragir avec des bases de données relationnelles mais pas seulement car JMS peut intéragir avec n'importe quel type de base de données.
//  --> Au dessus de ces trois modules, nous avons un module historique, qui fait partie des premiers modules qui ont été intégrés dans Java EE :
//      - EJB : Enterprise Java Bean. Ce sont des composants qui ont mauvaise réputation. Ils sont toujours là, pour des raisons historiques et de compatibilité ascendantes.
//          Ils ont été entièrement refaits à partir de Java EE 5, et maintenant, faire des EJB est beaucoup plus simple que dans les versions antérieures de Java EE.
//      - CDI : Context Dependency Injection, qui a rendu plus ou moins obsolète les EJB, car il rends à peu près les mêmes services que ceux rendus par les EJB.
//          Aujourd'hui, lorsque nous construisons des applications Java EE, nous avons plus tendance à utiliser CDI que les EJB.
//          --> C'est tout de même bon de savoir que les EJB sont là, ainsi que de comprendre quels sont les services qu'ils rendent et comment ils fonctionnent, car nous les trouvons encore beaucoup.
// --> Au dessus de cela, nous trouvons les services du Web, ceux-ci sont basés sur une API fondamentale de Java EE :
//      - Servlet : qui existait même avant que Java EE n'existe.
// --> Au dessus de Servlet, nous avons plusieurs API qui sont construites :
//      - JSP : Java Server Page, qui est une technologie de page dynamique, qui aussi est très ancienne et est arrivée quasiment en même temps que l'API Servlet.
//      - JSF : Java Server Faces, qui n'est pas aussi ancienne mais qui l'est quand même. Elle est un peu une amélioration de JSP car elle permet de construire des pages à partir de composants.
//          Elle peut faire cela avec de la validation côté client etc.
//      - EL : Expression Language, qui est une espèce de langage qui peut être utilisé à la fois dans les pages JSP et dans les éléments JSF, pour pouvoir manipuler les beans etc.
//      - Jax-WS & Jax-RS : Ces deux éléments là permettent de servir des données sur le web.
//          --> JSF et JSP permettent de servir des pages web, donc des données dans une présentation particulière, qui à la fin est du JavaScript ou du HTML, donc, des pages dans un navigateur.
//          --> Jax-WS & Jax-RS ne vont servir que les données à proprement parler.
//              - Jax-WS implémente SOAP qui est une technologie pas tout à fait récente non plus.
//              - Jax-RS impléménte REST dont l'implémentation est plus récente, que nous allons voir en détail.
// --> Donc voila, à très gros grain les différents organes qui sont disponibles à l'intérieur de cette spécification Java EE.
// Maintenant, comment allons-nous nous en servir pour construire des applications. Ceci va dépendre de l'application que nous voulons construire.
// Par exemple, si l'application que nous voulons faire consiste à servir des données sous format .json nous allons probablement utiliser REST, donc JAX-RS, Servlet (pas JSP, JSF ou EL), CDI et JPA & JTA.
// Tout ceci pourra fonctionner dans un serveur d'application, un Glassfish, un Weblogic, un Websphere, ou n'importe lequel de ces serveurs qui implémentent la spécification Java EE.
// Une des forces de Java EE, est que si nous programmons à partir de la spécification, après nous pouvons déployer le code que nous avons écrit dans le serveur d'application de son choix.
// BASE DE DONNEES
//  |   |   |
// JPA JTA JMS
//  -- | --
// EJB  CDI
//  |    |
// Servlet
//  | - | - | - | --------- |
// JSP JSF  EL JAX-WS   JAX-RS
//              |           |
//             SOAP        REST

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java EE et Microprofile ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Depuis quelques temps, nous parlons de plus en plus des 'MicroServices', notamment les architectures à base de MicroServices.
// Quand ces derniers ont commencé à prendre vraiment de l'importance, il y a une spécification alternative à Java EE qui a fait son apparition et qui s'appelle 'Microprofile'.
// Celle-ci est hébergée sur la fondation Eclipse : microprofile.io.
// Que retrouvons nous dans MicroProfile ? Nous retrouvons essentiellement ce qui va servir à faire des microservices (service de données au format .json).
// JSON : JSON-B (binding) & JSON-P (processing).
// JAX-RS.
// CDI.
// A ces spécificités qui proviennent de Java EE, MicroProfile va en ajouter une demi-douzaine d'autres qui vont ensemble former la spécification MicroProfile.
// Nous avons également des serveurs qui sont spécifiés MicroProfile :
//  - Payara.
//  - Helidon.
//  - Websphere, Liberty.
//  - WildFly (JBoss).
// Cette spécification MicroProfile est très intéressante car c'est une espèce de sous-spécification de Java EE, beaucoup plus légère et petite.
// Elle a un mode de gouvernance qui ressemble à Java EE, mais qui est différent et permet notamment de releaser des versions sur un rythme beaucoup plus soutenu que Java EE, et qui est open-source.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Différences entre Java EE et Spring ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Spring est en fait un concurrent de Java EE. Donc c'est un ensemble de composants Java, dont certaines sont des implémentations de JSR implémentées par Java EE.
// Nous pouvons faire du Spring dans un serveur d'application Java EE.
// Derrière Spring, il y a une société qui se nomme 'Pivotal'.
// Spring est open-source et libre de droit dans une certaine mesure.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java EE et HTTP ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Traitement d'une Requête HTTP Statique ou Dynamique ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avant de rentrer un peu plus dans les détails de l'API Servlet, nous allons commencer par regarder ce qu'il se passe lorsqu'une url arrive sur un serveur et est analysée par ce dernier.
// Nous allons prendre un exemple simple, nous avons une url : 'http://www.data.gouv.fr/stats/datasets/maires/liste'.
// Que se passe t'il lorsque nous avons une url comme celle-ci, que nous la mettons dans notre navigateur, nous appuyons sur 'entrée', donc nous demandons au navigateur de nous 'servir' quelque chose.
// Il se passe plusieurs chose :
// - La première chose qui est analysée c'est évidemment : 'http://www.data.gouv.fr'.
//      Dans cette partie nous avons plusieurs éléments à l'intérieur, dont nottament la partie : 'gouv.fr'. C'est le nom de domaine.
//      Ce nom de domaine est résolu sur un premier serveur qui est un serveur de nom, un DNS 'Domain Name Server'.
//      Ce serveur de nom est en général géré par des fournisseurs d'accès internet, ou des géants du web, tels que google.
//      Il n'est en tout cas pas géré par les personnes qui gèrent le nom de domaine gouv.fr, donc l'administration publique française.
//      --> Ce DNS va nous dire que 'gouv.fr' est géré par une certaine adresse IP, et il va envoyer cette requête sur cette adresse IP.
// - Sur cette adresse IP, il y a un serveur web qui écoute, cela peut être un serveur Apache, NGinx, IIS (Internet Information Server).
//      Le port sur lequel il écoutes est bien sûr le port 80. C'est le port par défaut du protocole HTTP.
//      Le serveur web, lui va s'intéresser à la partie préfixe de cet url : 'www.data'.
//      Un serveur web est quelque chose qui est capable de gérer des hôtes virtuels, et ceux-ci peuvent-être 'www.data', 'data', 'www', en somme, l'intégralité du préfixe de l'url.
//      --> Donc 'www.data' n'est à priori pas géré par le DNS, mais il est géré en local, par le serveur qui gère le domaine 'gouv.fr'.
//      --> Donc, ce serveur web, en fonction de l'hôte virtuel sur lequel nous effectuons notre requête va pouvoir décider :
//          - De traîter cette requête en local.
//          - De la rediriger vers un autre serveur de l'infrastructure web des personnes qui gèrent 'gouv.fr'.
// - Après, nous allons nous intéresser à la partie, purement ressource, donc qui se trouvent, à droite du '/' qui suit le nom de domaine : 'stats/datasets/maires/liste'.
//      Ceci va nous aiguiller soit :
//          - Vers des répertoires. Donc cela peut être un chemin vers des ressources purement statiques.
//              Donc ici, il n'y a pas d'intelligence, pas de code, mais un chemin vers une image ou un fichier qui va être directement pris par le serveur web, et servi au navigateur.
//          - Vers des applications web. Une application web c'est un ensemble ce code qui peut être écrit avec différentes technologies : Java, .NET, C#, PHP, JavaScript...
//              Cela se comporte comme une application : cela va prendre des requêtes, et ça va prendre des décisions par rapport à la réponse qu'il faut apporter à ces requêtes.
//              Par exemple, cela peut décider d'aller rechercher une ressource statique sur un système de fichiers, donc une page HTML typiquement.
//              Donc prendre cette page HTML et la servir en réponse à cette requête.
//              Si cette liste est un document .csv, cela peut prendre ce document .csv, et le servir au navigateur qui a fait cette requête.
//              --> Une application web, est quelque chose dans laquelle il y a de l'intelligence, du code qui s'exécute, et donc qui peut prendre des décisions par rapport au type de requête qui est fait.
//              Ici, par exemple, il peut y avoir une application sous 'stats', et qui, selon les autres ressources, va utiliser d'autres applications web.
//              --> Dans la technologie Java, une application web est en général, un projet Java avec en dépendances, des sous-projets éventuels.
//      --> Nous allons nous intéresser à la partie application web, car l'API Servlet, vit à l'intérieur de cette notion d'application web.
// - Donc notre élément 'stats', si il pointe vers une application web, il ne sera plus géré par le serveur web (Apache par exemple), car même si il le pourrait, ce n'est pas vraiment sa fonction.
//      Il va être géré par un autre type de serveur qui sait bien faire cela, typiquement nous pourrions l'appeler 'serveur Java', mais cela pourrait être un Tomcat, Jetty, Glassfish...
//      Notre serveur Java, gère l'application '/stats', mais il peut aussi en gérér d'autres, par exemple '/auth', '/edt', ...
//          --> Donc cette racine '/stats' est gérée par le serveur Java, et en fonction de cela, le serveur va faire un aiguillage, en disant que '/stats' équivaut à telle ou telle application web.
//              Ainsi, il va router le reste de l'url vers l'application web pour décider qui va répondre à cette url.
// - A l'intérieur de cette application web, nous commençons à avoir des ressources qui peuvent être de deux types :
//      - Statiques : typiquement, une page HTML. Si nous avons une page 'index.html' (ou une image, un fichier .js, un fichier .css, ...), qui vit dans notre serveur, ce fichier .html, est une ressource statique.
//          Une ressource statique est une ressource qui existe indépendamment du fait qu'il y ait des requêtes qui soient faites dessus.
//      - Dynamiques : c'est une ressource qui est calculée, donc c'est une ressource qui ne pré-existe pas à la requête.
//          La requête arrive, et cela va déclencher l'exécution du code Java qui va faire une requête en base de données par exemple et en retourner le résultats.
//      --> La différence entre ces deux types de ressources est qu'en statique, la ressource existe qu'elle soit requêtée ou non, et en dynamique, la ressource est calculée en fonction de la requête.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Générer du Contenu Dynamique avec des Servlets ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ce qu'il faut comprendre, c'est que du point de vue du navigateur du client, que le contenu soit statique ou dynamique, il n'y a pas de différence.
// En Java, comment allons-nous dire à notre serveur Java que le contenu dynamique souhaité doit être géré par tel ou tel code Java ?
//      --> Pour cela, nous utilisons l'API 'Servlet'.
// Une Servlet est une classe Java particulière, que nous allons configurer d'une certaine façon, que nous allons déclarer auprès de notre serveur Java.
// Ainsi, ce dernier saura que lorsqu'il reçoit une requête définie par une URI particulière, c'est telle ou telle Servlet, donc cette classe Java particulière qu'il va falloir invoquer.
// Cette classe Java, nous allons voir sa forme, nous allons voir un exemple, et voir comment elle est faite par la suite.
// Toutefois, elle à une caractéristique que nous allons immédiatement voir :
//      --> Elle ne possède pas de méthode 'main(...)'.
// Jusqu'à présent, tout le code que nous avons exécuté en Java avait une méthode main(...), et c'est l'exécution de cette dernière qui effectuait le travail dont nous avions besoin.
// --> Lorsque nous utilisons des applications serveurs comme celle-ci, nous ne programmons plus de méthode main(...).
//      C'est donc le serveur Java qui va, ou non, déclencher l'exécution de nos Servlets.
// Mais où se trouve la méthode main(...), car dans toute application Java, nous avons forcément une méthode main(...) ?
//      --> Celle-ci se trouve dans le serveur Java. Elle va effectuer tout un tas de choses pour découvrir les Servlets que nous avons déclaré auprès de notre serveur Java associés a des url.
// Dans ce contexte là, nous pouvons voir qu'une Servlet agit comme une 'callback' sur une requête HTTP, donc sur une url particulière.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire une Première Servlet ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons écrire une première Servlet très simple pour voir comment la classe de Servlet est structurée et comment elle fonctionne :
//      @WebServlet("/hello_world")
//      public class HelloWorldServlet extends HttpServlet {
//          protected void doGet(
//              HttpServletRequest req,
//              HttpServletResponse resp
//          ) throws ... {
//              req...
//              PrintWriter pw = resp.getWriter();
//              pw.print("Hello World")
//          }
//      }
// Il faut penser à étendre la classe HttpServlet, ainsi que d'écrire l'annotation '@WebServlet("url")' pour que le serveur Java sacha que cette classe est une Servlet.
// Ensuite nous pouvons y insérer des méthodes qui n'ont pas besoin d'être 'private' mais 'protected'.
//  - La méthode doGet() est invoquée sur une requête http de type 'get' sur l'url de l'annotation.
//      Elle va être invoquée par le serveur Java, car c'est lui qui écoutes la requête http sur le port 80 du Serveur web.
//      Celui-cu va capter cette url, et sait que c'est cette Servlet en particulier qu'il faut aller chercher.
// - Cette méthode prends deux paramètres et jette une certaine quantité d'exceptions.
//      Le serveur Java va nous construire une instance pour chacun de ces objets pour pouvoir nous les fournir.
//      --> Donc nous sommes vraiment dans le cadre d'un callback.
// - L'objet 'req', avec tout un jeu de méthodes, nous donne accès à toutes les caractéristiques de la requête (header http, paramètres, forme de la requête, url complète...).
// - Que faut-il retourner ? C'est en manipulant l'objet 'resp' que nous allons pouvoir écrire dans le navigateur du client.
//      Avec la méthode getWriter(), nous pouvons créer un objet de type PrintWriter (l'objet de Java I/O).
//      Sur cet objet, nous avons tout un tas de méthodes que nous pouvons utiliser, comme la méthode print.
// - La nous pouvons aussi écrire du HTML plus complexe que 'Hello World', nous pouvons aussi aller lire un fichier html sur le disque et le transférer dans notre PrintWriter.
//      Nous pouvons aussi faire des requêtes en base de données pour chercher des éléments textuels et les envoyer vers la page du navigateur.
// --> Le PrintWriter est en fait le point d'entrée de l'application Java, donc nous pouvons faire à peu près ce que nous voulons à partir de là.
// Si jamais nous avons d'autres méthodes http que nous voulons supporter, nous avons également des méthodes qui prennent exactement les mêmes paramètres :
//      --> doPost(...).
//      --> doPut(...).
//      --> doHead(...).
//      --> doDelete(...).
//      --> doOtions(...).
//      --> doTrace(...).

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Rediriger une Requête d'une Servlet vers une Autre ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une Servlet peut rediriger la requête et la ressource vers une autre ressource locale à ce serveur, qui peut être une autre Servlet, ou une page HTML ou JSP.
// C'est une technique assez intéressante et qui est beaucoup utilisée.
// Par exemple une Servlet va récupérer des données en base de données, puis les retransférer à une page HTML de type template, qui sera enrichie par ces données.
// Pour faire ce genre de chose, il nous faut un 'RequestDispatcher' : RequestDispatcher rq = req.getRequestDispatcher("template.jsp");.
// Cet objet possède une méthode forward, à laquelle nous pouvons passer la requête et la réponse : rq.forward(req, resp);.
// En faisant ce genre de choses, nous pouvons transmettre la requête et la réponse à une page JSP qui va recevoir les données et les mettre en forme.
// Supposons que dans ce code, nous avons créé un bean User, récupéré en base de données, et nous souhaiterions le passer en paramètre à la page 'template.jsp'.
// Sur l'objet 'req', nous avons une méthode 'setAttribute()' qui en interne est géré avec une table de hashage qui va nous permettre de passer le bean User en tant qu'attribut à notre requête.
// --> req.setAttribute("user", User);.
// --> getAttribute().

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire l'URL de requête vers une Servlet //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il nous reste un dernier point à voir, c'est à dire, à quelle url est-ce que nous allons pouvoir invoquer cette Servlet ?
// L'annotation '@WebServlet("/hello_world")', est en réalité locale à l'application web sur laquelle nous travaillons.
// Supposons que nous soyons en train de travailler sur un projet global Eclipse et que nous ayons saisi cette Servlet.
//  - Déjà, nous avons un serveur web local qui s'est lancé, donc c'est sur 'http://localhost:8080/' qu'il faut se connecter.
//  - Ensuite, par défaut, c'est le nom de l'application Eclipse qui est ajouté en suffixe.
//  - Enfin, nous avons l'url global.
//      --> http://localhost:8080/projet_eclipse/hello_world.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser les cookies pour créer des sessions en HTTP //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il y a une caractéristique du protocole HTTP qui est très importante et qui est assez dimmensionnante pour le design de l'API Servlet.
// --> Le protocole HTTP est 'déconnecté'.
// Cela veut dire qu'un navigateur envoies une requête vers un serveur, ce dernier va construire une réponse, le navigateur va recevoir la réponse.
// A cet instant, la connection entre le navigateur et le serveur est coupée. Si le navigateur refait une requête vers le serveur, il ne se passera plus rien car le serveur à 'oublié' la première requête.
// La conséquence de cela est que nous n'avons pas de notion de 'Session'. Une session est un ensemble de requêtes dans lequel le serveur se souvient que c'est le même navigateur et le même client.
// Comment s'y prendre pour créer cette notion de session, alors que le protocole HTTP fonctionne en mode déconnecté ?
// --> Pour cela, nous avons la notion de 'cookie', attachée au protocole HTTP, et permet de créer la notion de session sur ce protocole déconnecté, ne sachant gérer la notion de session.
// Qu'est-ce qu'un cookie ?
// --> C'est un petit fichier (quelques ko de taille maximum) au format .txt. Dans ce fichier nous avons un certain nombre d'informations.
//      - C'est un fichier versionné.
//      - Il a une date de péremption.
//      - Il a le domaine qui a émis ce cookie. Donc un identifiant qui permet de savoir à qui ce cookie appartiens.
//      - Informations optionnelles dont en général un numéro d'ID qui correspond à un ID utilisateur.
// Que se passe t-il si nous effectuons une requête sur un site web ?
// Dans sa réponse, le serveur va nous envoyer la page HTML, ainsi qu'un certains nombres de cookies, qui vont être enregistrés par notre navigateur sur notre file system.
// Ainsi, quand nous referons une requête sur le même serveur, le navigateur va regarder tous les cookies de tous les sites web requétés.
// De cette manière, il va sélectionner les cookies appartenant au même nom de domaine que pour la première requête.
// Donc, il va pouvoir envoyer les cookies qu'il possède, en même temps que la requête, au navigateur web.
// Puisque dans notre cookie, il y a l'ID utilisateur (passé en paramètre optionnel), le serveur saura générer la page qui prendra en compte le fait que ce n'est pas la première visite du client.
// --> Ce mécanisme de cookies est défini au niveau HTTP. Il est donc indépendant des navigateurs, ainsi que du type et du langage du serveur de l'hôte.
// Evidemment, si nous changeons de navigateur, étant donné que les cookies sont enregistrés localement à un navigateur, nous allons perdre les informations de visite que nous avions sur le précédemment.
// C'est ce mécanisme là qui nous permet de tracer absolument tout ce que nous faisons sur internet.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser les cookies pour créer des sessions en HTTP //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Au niveau de l'API Servlet, tout passe par les deux objets 'req' & 'resp'.
// Il y a une première façon qui est très simple de gérer le mode connecté dans l'API Servlet, et qui consiste à demander un objet 'Session' avec la méthode 'getSession()'.
//      --> HttpSession session = req.getSession();.
// Cet objet HttpSession va être le même pour un même ensemble de requête fait par un navigateur donné et un utilisateur donné.
// Donc si nous avons un navigateur qui fait trois requêtes successives, nous allons avoir trois appels d'une de nos servlet différents avec à chaque fois un objet req différent.
// Si sur cet objet req nous effectuons la méthode getSession(), le serveur Java nous retournera un objet HttpSession identique pour les trois requêtes, ou tout du moins une copie de l'objet précédent.
// Comme cet objet HttpSession est le même, ou comme c'est une copie de l'objet HttpSession précédent, nous allons pouvoir nous en servir pour enregistrer des informations dans une première requête.
// Et ainsi, les récupérer dans la requête suivante. Pour cela nous avons deux méthodes :
//      - session.setAttribute("id", 12L);. Ici nous passons une clef primaire de 12 sur la clef d'attribut 'id', qui est passée en tant que chaîne de caractères.
//      - session.getAttribute("id");. Si setAttribute() a été appelé pour cette clef d'attribut précédemment, il va nous retourner 12, et ainsi nous saurons quoi faire.
//          Si jamais, cela n'a pas été fait, il va nous retourner 'null', et dans ce cas là aussi, nous saurons comment agir en conséquence.
// Ces deux méthodes fonctionnent de la même manière que celles du même nom appliquées à l'objet req que nous avons vu précédemment pour faire passer des objets d'une requête vers une template par exemple.
// Ainsi, nous pouvons passer un objet d'une requête à une autre, ce qui est très pratique.
// Nous avons une deuxième façon de faire, qui consiste à gérer les cookies de façon explicite.
//      --> Dans l'API Servlet, nous avons une classe cookie, donc nous pouvons créer nos cookies à la main également : Cookie cookie = new Cookie();.
//          Ainsi nous pouvons faire des set() et des get(), car c'est juste un bean un peu particulier, avec de propriétés de dates de péremptions, de domaine, de caractère optionnel etc.
// Pour ajouter un cookie à une réponse, nous avons une méthode addCookie() à laquelle nous passons nos cookies en paramètre :
//      --> resp.addCookie(cookie);.
// Pour récupérer mes cookies, nous avons une méthode getCookies() sur l'objet req :
//      --> req.getCookies();.
// - Donc nous pouvons gérer les choses de manière implicite avec l'objet HttpSession, auquel cas, c'est le serveur Java et l'implémentation de l'API Servlet qui va créer le cookie.
//      Par la suite il gèrera ce cookie entre le serveur et le navigateur pour nous permettre de récupérer un objet HttpSession identique d'une requête à l'autre.
//      Sur cet objet HttpSession nous allons pouvoir ajouter des attributs, qui ne sont pas du tout stockés dans des cookies, mais par le serveur Java, localement dans des serveurs.
// - Si nous voulons, nous pouvons aussi gérer nos cookies à la main, avec une classe cookie, en les ajoutant à la réponse, et les récupérant avec une requête.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Echanger des données avec Java EE /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Echanger des données XML avec SOAP ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons déjà vu une notion assez fondamentale sur le fonctionnement des Servlet, qui est celle de la production de données, séparée avec la notion de présentation des données (HTML notamment).
// Cette séparation entre description des données et description de la présentation des données, elle n'est pas du tout faite en HTML.
// Dans HTML, nous avons un joyeux mélange entre les données et la présentation des données. HTML est un très vieux standards, un des premiers standards du web, qui ne contient pas cette séparation.
// A partir de 1998 et 1999, il s'est avéré que cette notion de séparation est devenue assez fondamentale. A ce moment-là, le XML apparaît pour les données, ainsi que SOAP.
// SOAP (Simple Object Access Protocol), qui est un protocole d'accès à des données.
// SOAP permet de faire des requêtes sur des serveurs, et de récupérer des données en tant que réponse à ces requêtes, et c'est construit sur XML.
// SOAP devient une norme du W3C en 2003, et qui vit jusqu'en 2009, à partir de quand il n'évolue plus, mais est un incontournable tellement il a été utilisé.
//      --> L'idée de SOAP est de dire que nous allons tout construire sur le XML, tout en étant indépendant du langage que nous utilisons, ainsi qu'indépendant du protocole (HTTP, SMTP, TCP, UDP).
//          Donc pour SOAP, toutes les requêtes HTTP passent en POST (et non en PUT, en GET, etc.),
//              --> Donc l'intégralité des informations de la requête doit passer dans le XML.
// L'un des inconvéniants de SOAP est que c'est très 'verbeux', donc pour faire une requête simple, nous avons besoin de beaucoup de données, car le xml ajoute des métadonnées notamment.
// C'est pourquoi SOAP a été un peu laissé de côté et que nous utilisons plutôt REST.
// Dans la pratique, le protocole le plus utilisé pour faire du SOAP est le protocole HTTP. Alors que SOAP sait aussi utiliser d'autres protocoles.
// REST par contre ne sert que pour le protocole HTTP.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Echanger des données avec REST ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le deuxième type de web service qui existe sont les services REST (REpresentational State Transfer). Elle vient de la thèse de Roy Fielding.
// REST et SOAP s'appuyent sur les mêmes idées :
//      - Les données sont transférées au format XML. Aujourd'hui toutefois, nous lui préférons le format JSON.
//      - La seconde idée est l'indépendance du langage, tant du côté client que du côté serveur.
// Là où les choses sont différentes sont au niveau du protocole, REST s'appuyent uniquement sur le protocole HTTP.
// REST s'appuye aussi sur la notion d'URI et d'URL.
// Par exemple, si nous effectuons un GET (une méthode HTTP) sur une URI qui va s'appeler par exemple 'commune/12', nous sommes sensés récupérer un document XML qui va nous décrire la commune 12.
// L'URI (ou URN) correspond également aussi à une URL qui va être une clef primaire, permettant de localiser une donnée sur internet.
// Derrière cette idée de REST, il y a l'idée de l'internet des objets des années 2000, qui nous permet de dire qu'internet permet d'exposer et de partager des objets qui ont des clefs primaires.
// REST définit en fait une sémantique pour les différentes méthodes HTTP.
// L'API Servlet sait s'en servir, mais le plus pratique est JAX-RS et n'utilise pas de Servlet.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Faire un service REST /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire un premier service REST ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment pouvons-nous faire pour créer un service REST avec JAX-RS ? En fait nous avons besoin de deux classes :
//      - Une première classe qui va nous permettre de configurer une application REST à l'intérieur d'une application web.
//          Elle peut-être nommée comme nous le souhaitons, mais elle doit étendre 'Application' de javax.ws.rs (javax, web services, rest service).
//              --> @ApplicationPathh("rest").
//                  public class RestService extends Application {}.
//          Nous n'avons rien besoin de mettre dans cette classe, nous avons seulement besoin de la créer.
//          Toutefois, il faut l'annoter avec une annotation JAX-RS '@ApplicationPath("...")'.
//          A celle-ci nous passons une chaîne de caractères qui va être utilisée comme racine des URI et des URL de notre service REST.
//          --> Donc à l'intérieur de notre application web, nous pouvons avoir plusieurs familles de services REST, qui vont tous vivre sous une URI particulières.
//          Dans cette classe particulière qui étends 'Application', nous pouvons mettre des éléments de configuration.
//      - La seconde classe va implémenter notre service REST particulièrement :
//              --> @Path("hello_world")
//                  public class HelloWorldRS {
//                      @GET
//                      public String helloWorld(){
//                          return "Hello World";
//                      }
//                  }
//          Cette classe n'étends pas d'autres classes, mais nous devons l'annoter avec l'annotation JAX-RS '@Path()' et en lui passant en paramètres une autre URI.
//          --> Cela signifie que l'intégralité des méthodes que nous allons mettre dans cette classe vont être appelées sous l'URI '/rest/hello_world'.
//          La méthode ne prends pas de paramètres et ne jette pas d'exception, et retourne une chaîne de caractères car nous l'avons décidé.
//          Celle-ci pourrait également être annotée par '@Path("...")' si nous voulions l'appeler sur une URI encore plus spécifique.
//          --> Nous lui mettons l'annotation '@GET'.
// L'ensemble de ces deux classes forment un service REST. Donc créer un service REST est beaucoup plus simple que de créer une Servlet.
// Une fois que nous avons écrit tout cela, nous pouvons ouvrir notre navigateur et effectuer la requête : 'http://localhost:8080/tp-javaee/rest/helllo-world'.
// Donc en réalité : JAX-RS fourni une Servlet, qui va charger ces classes, les invoquer en fonction des URL, pour transférer notre chaîne de caractères vers le navigateur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémenter un service REST GET ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous voudrions à présent créer un service REST qui nous permet de gérer notre base de données des communes.
// Dedans, nous allons avoir du CREATE, RETRIEVE, UPDATE et DELETE, donc des requêtes CRUD classiques.
// Dans un premier temps nous voudrions implémenter la requête suivante sur l'URI se terminant par '/commune/12'.
// Nous en récupèrerons un document XML ou JSON contenant la commune 12. Comment allons-nous nous y prendre ?
// --> Nous avons vu que dans notre service REST, nous pouvions annoter des méthodes avec des annotations JAX-RS particulières, pour que JAX-RS les appelle sur les requêtes HTTP corespondantes.
// Nous allons devoir récupérer la clef primaire située dans l'URI sous format chaîne de caractères, et la convertir en long pour l'envoyer vers la base de données en tant qu'id de commune.
//      @Path("commune")
//      public class CommuneRS {
//          @GET
//          @Path("{id}")
//          public Commune findById(@PathParam("id") long id) {
//              Commune c = ...;
//              return c;
//          }
//      }
// Maintenant, comment allons-nous pouvoir cabler la requête de l'URI sur cette méthode ?
//      - Tout d'abord, c'est une requête HTTP de type GET, donc nous allons devoir mettre l'annotation '@GET'.
//      - De plus, l'URI n'est pas juste '/commune', ce que nous avons dans notre annotation '@Path', nous avons aussi le '/12', donc nous devons le préciser à JAX-RS.
//          Pour ce faire, nous pouvons utiliser de nouveau l'annotation '@Path("...")'. Or, cette partie de l'URI est une variable. Donc nous allons l'écrire entre acollades.
//          Nous l'appelons 'id', mais il n'a rien a voir avec notre 'long id'. Nous devons préciser avec l'annotation '@PathParam("id")'.
// --> Ainsi, nous précisons qu'une partie de l'URI est une variable, et l'appelons dans le code pour trouver la commune souhaitée.
// --> JAX-RS va faire son tour de magie pour pouvoir retourner un fichier XML ou JSON paramétré pour cet objet Commune.
// Nous allons voir par la suite que nous pouvons fixer le type de document retourné (XML ou JSON), aussi que nous pouvons particulariser ce fichier et comment nous pouvons configurer cela par la suite.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fixer le format de retour d'un service REST avec @Produces ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Première chose, comment fixer le type de données retourné par notre méthode entre le XML ou le JSON.
// Cela fonctionne encore par annotation, nous utilisons '@Produces(MediaType.TEXT_XML)' ou '@Produces(MediaType.APPLICATION_JSON)' que nous annotons sur notre méthode.
// Ainsi, cela va définir si nous allons voir du XML ou du JSON dans notre navigateur. Ceci est la façon canonique de fixer le type de retour d'une méthode invoquer par JAX-RS.
// Cela dit, nous n'avons pas tout à fait terminer de customiser la façon dont la méthode va retourner des informations au navigateur.
// Le navigateur va s'attendre à avoir une réponse sous forme HTTP, or dans l'entête HTTP d'une réponse, nous avons un code de retour qui nous indique ce qu'il s'est passé du côté du serveur.
// La bonne manière, si aucune commune n'est trouvée est de retrouver une erreur 404 (si c'est une NullPointerException, ce sera une erreur 500 qui sera retournée par le serveur).
// Ce que nous souhaitons c'est de retourner une erreur 404 pour indiquer que cette commune n'a pas été trouvée.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Fixer le retour d'un service REST avec l'objet Response ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Supposons que nous voulons effectuer notre méthode findById() que nous avons créé précédemment.
// - Si la commune existe, à ce moment-là nous la voulons au format XML, grâce à l'annotation '@Produces(MediaType.TEXT_XML)'.
// - Si elle n'existe pas, alors, nous voulons une erreur 404.
// Pour faire cela, il nous faut abandonner l'idée de retourner un objet Commune. Il faut gérer l'erreur de la Commune absente à l'intérieur de notre méthode.
// --> Pour cela, nous avons un objet JAX-RS, 'Response' et qui va nous permettre de faire cela.
// Cet objet Response n'a rien à voir avec l'objet HttpServletResponse de l'API Servlet. C'est un objet différent qui va nous permettre de spécifier ce que nous voulons retourner au navigateur.
//      @Path("commune")
//      public class CommuneRS {
//          @GET
//          @Path("{id}")
//          @Produces(MediaType.TEXT_XML)
//          public Response findById(@PathParam("id") long id) {
//              Commune c = ...;
//              if (c == null) {
//                  return Response.status(404).build();
//              } else {
//              return Response.ok(c).build();
//          }
//      }
// En utilisant la méthode factory '.status()' de l'objet Response auquel nous passons le code de retour que recevra notre navigateur.
// Si la commune a été trouvée, nous pouvons utiliser la méthode factory '.ok()' en lui passant notre objet Commune qui sera retournée au navigateur au format XML comme nous l'avons précisé.
// A noter que nous avons changé le type de la méthode à 'Response', ce pourquoi nous devons retourner dans un cas comme dans l'autre un objet de type Response.
// Aussi, nous utilisons la technique builder, ce qui signifie que nous pouvons ajouter d'autres méthodes à notre méthode ok() ou status().
// Et ceci tant que nous terminons par la méthode 'build()' pour créer l'objet Response.
// Les status du protocole HTTP sont nombreux, ci-après quelques uns :
//      - 200 : Statut Ok avec diverses variantes. Les choses se sont bien passées.
//      - 300 : Statuts de redirection (le résultat de requête n'est plus disponible à cette URI donc il faut aller voir ailleurs).
//      - 400 : Erreurs Web (voir 404 et 418).
//      - 500 : Erreurs serveur (retourné très souvent par les NullPointerException).

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer une donnée avec un service REST POST ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous venons de voir la méthode GET pour faire des retrieves, nous allons voir maintenant la méthode POST pour faire de la création.
// Pour cela, nous avons besoin de nous équiper d'un formulaire HTML :
//      <form method="POST"
//            action="rs/command">
//          <input type="text"
//                 name="codePostal"/>
//          <input type="text"
//                 name="commune"/>
//          ...
//          <input type="submit"
//                 value="ok"/>
//      </form>
// Attention, il faut bien mettre une URI dans notre attribut 'action' de notre balise 'form'. En effet, ainsi ce n'est pas un chemin absolu, mais relatif.
// Ceci nous permet de pouvoir utiliser notre formulaire n'importe où, alors que si nous commençons cet attribut par un '/', nous aurons une erreur 404, car ce chemin absolu n'existe pas.
// Dans ce cas là, il nous faudrait utiliser le chemin absolu et donc l'URL complet, ce qui nous priverait de pouvoir utiliser notre formulaire n'importe où.
// --> Comment allons-nous pouvoir créer une méthode dans notre service REST, qui va accepter le contenu de ce formulaire.
// Tout d'abord, nous avons besoin d'une annotation de type '@POST'.
// Ensuite, étant donné que nous envoyons nos informations sous forme de formulaire, nous devons préciser à JAX-RS que les données se trouvent encodées dans la requête HTTP sous forme d'un formulaire.
// Pour cela, nous devons ajouter l'annotation '@Consumes(MediaType.APPLICATION_FORM_URLENCODED)'. Attention, cette annotation est celle de javax.ws.rs que nous devons utiliser.
// Nous pouvons ensuite créer notre méthode :
//      @Path("commune")
//      public class CommuneRS {
//          @POST
//          @Consumes(MediaType.APPLICATION_FORM_URLENCODED)
//          public Response create(
//              @FormParam("codePostal")String codePostal,
//              @FormParam("commune")String name
//          ) {
//              Commune c = ...;
//              return Response.status(201).build();
//          }
//      }
// Nous pouvons retourner un statut de réponse HTTP de type 201 car c'est celui qui convient pour informer que l'objet désiré a bien été créé en base de données.
// Nous n'avons pas tout à fait terminé car nous n'avons pas indifqué comment les paramètres de notre formulaire correspondent aux champs de notre méthode.
// Pour cela, nous pouvons utiliser l'annotation '@FormParam()' avec en paramètre le nom de l'attribut 'name' du champs du formulaire HTML auquel il appartient.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mettre à jour ou créer une donnée avec un service REST PUT ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu le GET pour faire du retrieve, nous avons vu le POST pour faire de la création à partir de données provenant d'un formulaire, nous allons maintenant voir le PUT.
// Le PUT a une sémantique particulière, il peut faire soit de la sémantique, soit de la mise à jour.
// --> Pour faire de la mise à jour, il va falloir dire que nous effectuons un PUT d'un certain type de données sur une clef primaire déjà existante.
// Cela peut être un PUT sur 'commune/75000' : et quelque part dans la requête HTTP il va falloir dire que le nom de cette commune est Paris.
// Nous pourrions l'indiquer à partir d'un formulaire, comme vu précédemment, mais ici nous allons le faire avec une technique différente.
// --> Il faut remarquer que l'URI fournie lors d'un PUT, est la même URI que pour un GET. C'est une convention qu'il faut suivre.
// Maintenant, comment allons nous écrire notre PUT ? Nous allons l'écrire avec le client HTTP fourni par JAX-RS.
// En fait JAX-RS est un serveur de service REST, dans celui-ci nous pouvons avoir besoin de faire des requêtes vers d'autres services REST, soit pour récupérer des informations, soit pour en récupérer.
// Donc, à l'intérieur de JAX-RS, nous avons cette double fonctionnalité, d'être à la fois client et serveur.
// Ainsi, ce client nous allons l'utiliser pour effectuer notre requête de type PUT.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire un client pour créer une requête PUT en JSON ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le code client que nous allons écrire, nous allons l'écrire dans une méthode main(...).
// Nous pourrions aussi très bien l'écrire dans un service REST, auquel cas il serait exécuté sur invocation de ce service REST.
// Mais ici, puisque nous allons l'utiliser pour invoquer notre service REST directement, il sera plus simple de l'écrire dans une méthode main.
// Le premier élément dont nous avons besoin c'est l'élément Client que nous pouvons créer à partir de l'élément 'ClietBuilder', auquel nous devons passer plusieurs informations.
// Tout d'abord, nous allons devoir lui passer l'URL à laquelle il doit s'adresser, nous pouvons construire un objet de type 'WebTarget', à partir de notre objet de type 'Client'.
//      Client client = ClientBuilder.newClient();
//      WebTarget target = client.target("http://localhost:8080/projetJava/applicationREST");
// Il nous manque toutefois la partie URI de l'URL pour aller jusqu'à 'commune', et nous allons pouvoir compléter cela par la suite.
// Nous pouvons le faire en construisant un autre objet de type 'WebTarget', à partir de l'objet créé précédemment, et donc d'ajouter en suffixe l'URI à l'URL de l'objet déjà existant :
//      WebTarget communeUpdate = target.target("commune/75000");
// Maintenant, nous savons déjà que nous allons avoir besoin d'une méthode à l'intérieur de notre service REST qui va répondre à cette URI 'commune/{id}'.
// A partir de cet objet 'communeUpdate', nous allons pouvoir créer un autre objet intermédiaire qui va nous permettre de créer des requêtes prenant du JSON en paramètres :
//      Invocation.Builder builder = communeUpdate.request(MediaType.APPLICATION_JSON);
// Ce nouvel objet 'builder', va nous permettre de construire des requêtes qui vont transporter leurs données au format JSON.
// Nous allons voir besoin de créer un objet spécial JAX-RS qui va nous permettre de transporter des objets HTTP.
// Ces objets HTTP sont des objets encodés dans des formats spéciaux (XML ou JSON) encapsulé dans une requête HTTP.
// JAX-RS modélise cela avec une classe qui se nomme 'Entity<>' et qui est paramétrée par le type d'objet que cet Entity HTTP va transporter :
//      Entity<Commune> entity = Entity.entity(paris, ...);
// Pour envoyer la requête, à présent il nous suffit de faire :*
//      builder.put(entity);
// --> Donc ce code nous permet par API, d'envoyer une requête qui porte une commune encodée dans du JSON, vers notre service REST disponible à l'URI 'commune/{id}'.
// Maintenant, nous allons écrire le service REST qui va permettre de répondre à cette requête, de récupérer les champs de la commune au format JSON et de mettre à jour la commune en base de données.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecrire un service REST PUT pour mettre à jour une donnée JSON /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Derrière cela, notre méthode PUT va être assez simple à implémenter. Nous allons préciser avec l'annotation '@PUT' que nous répondons à la méthode HTTP 'PUT'.
// Nous allons lui dire que nous consommons du JSON avec l'annotation '@Consumes()', ainsi que l'annotation '@Path()' pour lui préciser l'URI à laquelle cette méthode réponds.
//      @Path("commune")
//      public class CommuneRS {
//          @PUT
//          @Consumes(MediaType.APPLICATION_JSON)
//          @Path("{codePostal}")
//          public Response update(
//              @PathParam("codePostal")
//              String codePostal,
//              Commune commune
//          ) {
//              Commune c = ...;
//              c.setName(commune.getName());
//              return Response.status(201).build();
//          }
//      }
// Donc voici le code du PUT qui mélange à la fois des données qui viennent du 'Path' et des données qui viennent de JSON, faisant partie de la requête HTTP et venant au travers de cette dernière.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Effacer une donnée avec un service REST DELETE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La dernière des opérations CRUD qu'il nous reste à voir est l'opération DELETE, qui fonctionne à peu près de la même façon que l'opération GET.
// Si nous effectuons un DELETE sur commune/12, ce qui va permettre d'effacer la commune dont la clef primaire est 12 :
//      @Path("commune")
//      public class CommuneRS {
//          @DELETE
//          @Path("{id}")
//          public Response delete (
//              @PathParam("id") long id
//          ) {
//              ...
//              return Response.status(201).build();
//          }
//      }
// L'opération DELETE et l'opération GET sont les plus simple à écrire car il n'y a qu'un seul paramètre a prendre en compte (ici le paramètre clef primaire 'id').
// Nous n'avons en effet pas de mise à jour, ni de paramètres à récupérer dans un formulaire ou dans un document JSON.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur le passage de paramètres à un service REST //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu différentes façon pour transférer des paramètres entre une requête et une méthode JAX-RS.
// Ici, nous avons repris une méthode update qui réponds à la méthode HTTP qui se nomme PUT, par ailleurs, nous appelons des 'verbes' dans le jargon JAX-RS.
// Cette méthode prends un paramètre de '@Path', qu'elle injecte en tant que paramètre de la requête sous forme d'un id.
// Elle prends également une Commune qui est stockée dans l'entité HTTP de cette requête, qui peut être sous forme XML ou sous forme JSON en tant que paramètre de l'annotation '@Consumes()' .
// Nous avons vu également un autre type de paramètre lorsque nous utilisons des formulaires, qui est l'annotation '@FormParam'.
// Pour l'instant nous en sommes à '@FormParam' et '@PathParam', plus la possibilité de récupérer l'entité HTTP qui fait partie de la requête au format XML ou JSON.
//      @Consumes(...)
//      @PUT @Path("{id}")
//      public Response update(
//          @PathParam("id") long id,
//          Commune commune,
//          @QueryParam("cp") String codePostal,
//          @HeaderParam("Accept-language") String langue
//      )
// Nous pouvons également passer des paramètres directement sur l'URL, ce qui n'est pas très courant lorsque nous utilisons du REST, mais qui est tout de même possible.
//      --> commune?id=12&cp=75000
// Nous pouvons les récupérer sous forme de '@QueryParam'. Ce n'est pas forcément le plus utilisé.
// Le plus utilisé est le '@HeaderParam', qui va nous permettre de récupérer des informations situées dans l'en-tête HTTP.
// Ce paramètre de l'en-tête HTTP est en fait fixé par le navigateur, celui-ci envoies en tant que paramètre de la requête, dans l'en-tête HTTP les langues dans lesquelles il est configuré.
// Grâce à ce 'Header', au niveau de notre service REST, nous savons si le navigateur de notre client, est configuré en français, en anglais, italien, etc.
// Nous avons également la possibilité d'aller chercher les paramètres dans les cookies avec l'annotation '@CookieParam'.
// Aussi, nous avons une dernière façon de faire, qui est une utilité HTTP assez rarement utilisée qui est '@MatrixParam'.
// Nous avons une dernière annotation qui se nomme '@Context', qui nous permet de récupérer des objets du contexte, et que nous verrons plus en détail par la suite.
// Donc voila toutes les manières que nous avons pour récupérer des paramètres à partir de la requête HTTP qui nous parviens :
//      - @PathParam.
//      - @FormParam.
//      - @QueryParam.
//      - @HeaderParam.
//      - @CookieParam.
//      - @MatrixParam.
//      - @Context.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Accéder au contexte d'un service REST /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La dernière façon de passer des paramètres à notre service REST est d'utiliser l'annotation '@Context'.
// Cette annotation permet d'aller chercher des objets qui sont situés dans le contexte du service REST que nous avons.
// Nous avons plusieurs objets de contexte standard qui sont définis dans JAX-RS :
//          - UriInfo : qui contient en fait des informations sur l'URI qui a servi à faire une requête sur ce service REST.
//          - Request : différent de HttpServletRequest, mais qui ont la même implémentation, et qui ainsi peut nous permettre de gérer des sessions dans JAX-RS.
//          - HttpHeaders : permet d'accéder directement aux Headers HTTP de la requête, sachant que nous pouvons aussi injecter des attributs particuliers des Headers HTTP avec l'annotation '@HeaderParam'.
//          - Configuration : qui permet de récupérer des éléments de configuration du service REST et de l'application REST dans laquelle nous nous trouvons.
// --> Cette annotation @Context peut être apposée soit sur un champs de notre service REST, UriInfo par exemple.
//      Ainsi, lorque nous nous trouverons dans la méthode REST dans laquelle nous sommes appelés, ce champs sera peuplé automatiquement par JAX-RS, par injection de dépendances.
// --> Mais nous pouvons également l'utiliser sur des paramètres de la requête.
//      @Path("commune")
//      public class CommuneRS {
//          @Context
//          UriInfo uriInfo;
//          @GET @Path("{id}")
//          public Response getById(
//              @PathParam("id") long id,
//              @Context HttpHeaders headers
//          ) {
//              ...
//          }
//      }
// Toutefois, il faut faire attention à la manière dont nous l'utilisons, car les choses ne se passent pas forcément de le même façon.
// UriInfo, Request et HttpHeaders sont des éléments qui sont propres à chaque requête, ils vont varier d'une requête à une autre.
// Comme ils sont variables, il est probablement plus logique de les passer en tant que paramètres de méthodes (deuxième solution).
// La Configuration, elle, est fixe pour une application, donc c'est naturel de la mettre en tant que champs.
//      --> La différence entre 'Request' et 'HttpServletRequest' est que le premier est un objet JAX-RS, alors que le second est un objet de l'API Servlet.
//          Il se trouve que l'implémentation est la même, donc si nous injectons HttpServletRequest cela va fonctionner aussi.
//          Nous pouvons tout de même avoir la session au travers des cookies avec HttpServletRequest, ce qui pourrait être intéressant.
//          Sauf que les services REST sont par nature 'Stateless', donc ils ne sont pas censés gérer un état du côté du serveur.
//              --> Il ne faut donc jamais utiliser de session dans un service REST.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur les opérations REST de base /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons donc vu 4 méthodes associées à 4 opérations CRUD :
//      - GET : qui prends des requêtes de type 'commune/12'.
//      - POST : qui prends des ressources de type URI 'commune' et qui va probablement passer ses données sous forme d'entités HTTP ou de paramètres de formulaire.
//      - PUT : qui prends par convention le même type d'URI que le GET. Si nous effectuons un PUT, puis un GET sur la même URI, nous sommes sensés récupérer l'entité créée ou mise à jour dans le PUT.
//      - DELETE : qui fait également un effacement sur le même type d'URI que le GET et le PUT.
// Parmi ces opérations, il y en a qui, si elles sont répétées, vont donner le même résultat, avec le GET, le PUT, ainsi que le DELETE.
// Avec le POST toutefois, le même objet sera créé plusieurs fois, avec les mêmes champs, mais avec différentes clefs primaires.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java EE et XML ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Conversion d'objets en documents XML avec JAXB ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu que JAX-RS a cette capacité à convertir des objets de notre modèle (Commune ou Departement), directement dans du XML ou du JSON.
// Nous l'avons vu dans deux contextes, soit nous avons une méthode JAX-RS qui retourne directement un objet Commune et donc la conversion va se daire automatiquement.
// Soit nous passons cet objet Commune en paramètre du builder de Response, et à ce moment-là c'est cet objet Response, donc toujours JAX-RS qui va convertir cet objet Commune sous forme de XML ou de JSON.
// Comment est-ce que cela fonctionne ? Il y a deux API :
//      --> JAX-B : XML.
//      --> JSON-B : XML.
// Ces deux API fonctionnent en posant des annotations sur les classes de notre méthode.
//      @XmlAccessorType(XmlAccessType.FIELD)
//      @XmlType(propOrder = {"name", "communes"})
//      @XmlRootElement(name = "dept")
//      public class Departement {
//          @XmlAttribute(name = "code-postal")
//          private String codePostal;
//          @XmlElement(name = "name")
//          private String name;
//          @XmlElementWrapper(name = "communes")
//          private List<Commune> communes;
//      }
// Il ne faut pas oublier d'ajouter l'annotation '@XmlAccessorType()', sinon, nous aurons des erreurs si nous mettons d'autres annotations JAX-B.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maturité de vos services //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Modèle de maturité de Richardson //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tout ce que nous avons vu sur les services REST, notamment ce qui nous permet de structurer les services REST, avec des méthodes GET, PUT, POST et DELETE réponds au 'Modèle de Maturité de Richardson'.
//      --> Richardson Maturity Model - Martin Fowler.
// Ce modèle définit 4 niveaux :
//      - Niveau 0 - 'Marécage REST' : éléments web qui échangent du XML ou du JSON, sans structure ni norme, standard ou convention sur la façon dont nous pouvons accéder aux requêtes.
//          Ni sur la manière dont les serveurs doivent répondre selon ce que nous avons fait.
//      - Niveau 1 : définit des entités et des clefs primaires qui sont en fait associées à des URI.
//      - Niveau 2 : standard, ou convention pour créer des services REST reposant sur l'utilisation des méthodes HTTP GET / POST / PUT (PATCH) / DELETE.
//      - Niveau 3 : surensemble du niveau 2, qui est différent de par les éléments qu'il retourne, notamment de la métadata, ainsi que les opérations supplémentaires qui peuvent être effectuées.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Persistances des données //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Persister des données en Java EE avec JPA et des EJB //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Il y a des éléments dont nous n'avons pas du tout discuté jusqu'à présent, c'est la partie persistence dans Java EE.
// Le code JDBC ou JPA doit être écrit d'une certaine façon puisque nous sommes dans Java EE.
// Nous reprenons le squelette de notre service REST et de notre méthode create() qui est censée répondre à un POST HTTP.
// Celle-ci reçoit une Commune en paramètre par le biais de l'entité HTTP qui est écrite en XML ou en JSON. Nous recevons donc une commune qui n'a jamais vu la base de données.
// Nous souhaiterions faire un EntityManager.persist(), passer cet objet Commune en paramètre, et le faire dans le cadre d'une transaction.
// Comment pouvons-nous récupérer cet EntityManager et comment pouvons-nous récupérer cette transaction ?
//      --> En fait, dans le contexte de Java EE, nous pouvons faire tout cela de manière automatique.
//          Nous avons deux solutions pour le faire :
//              - La solution historique qui passe par les EJB (Enterprise Java Bean).
//              - La solution plus récente qui passe par CDI, l'injecteur de dépendances de Java EE.
// Nous allons le faire par les deux méthodes :
//      public class CommuneRS {
//          @EJB private communeEJB;
//          public Response create(
//              Commune commune
//          ) {
//              communeEJB.persist(commune);
//          }
//      }
// Ici, toutes les opérations de persistance sont portées par ce 'Enterprise Java Bean', ou EJB.
//      --> Qu'est ce que c'est que cette classe EJB ?
//          Il s'agit simplement d'une classe normale, annotée par l'annotation '@Stateless'.
//      --> Quel est l'intérêt de cette classe EJB dans le contexte de Java EE ? Il y en a plusieurs :
//          Toutes les méthodes de cet EJB vont être transactionnelles, elles vont donc être appelées dans le contexte d'une transaction.
//      @Stateless
//      public class CommuneEJB {
//          @PersistenceContext(unitName = "jpa")
//          EntityManager em;
//          void persist(Commune c){
//              em.persist(c);
//          }
//      }
//      --> Comment les choses se passent-elles ? Qui va créer cette classe CommuneRS ? Cela se passe exactement comme l'instance de Servlet, qui créé l'instance de Servlet ?
//          C'est le contenair Java EE (Glassfish, JBoss, Tomcat...). Donc le serveur Java EE instancies les classes, donc c'est lui qui exécute les méthodes.
//          Nulle part dans notre code, nous créons une instance de cette classe, et il en va de même pour les instances de Servlet.
//          Lorsqu'il instancie la classe, il va chercher les champs de cette classe par Reflexion et va regarder les annotation qui sont apposées sur ces champs.
//          Lorsqu'il voit une annotation '@EJB', il comprends que ce champs, c'est à lui, contenair de l'instancier.
//          Donc il va aller chercher la classe CommuneEJB, va la trouver, l'instancier, et copier l'instance dans le champs où il a été appelé.
//              --> Nous appelons ça une injection de la valeur du champs dans le champs appelé.
//          Il va faire de même pour la classe CommuneEJB en appelant l'EntityManager.
// Les EJB sont toutefois en cours d'obsolescence, car ils font beaucoup de choses, dont de très nombreuses ne sont plus utilisées, ce pourquoi nous préférons la méthode suivante en général.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Persister des données en Java EE avec JPA et CDI //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment les choses vont-elles se passer en utilisant CDI ?
//      public class CommuneRS {
//          @Inject
//          CommuneService communeService;
//          public Response create(
//              Commune commune
//          ) {
//              communeService.persist(commune);
//          }
//      }
// L'annotation '@Inject' est une annotation CDI (Context Dependency Injection), elle va dire à JAX-RS que quand nous initialisons cette classe, qu'il doit nous mettre une instance de l'objet annoté.
// Ainsi, JAX-RS va passer la main à CDI, qui va chercher une classe qui se nomme CommuneService, il va l'instancier en scannant ses champs.
// Il verra ainsi qu'il à une annotation '@PersistenceContext()', et va chercher l'unité de persistence associée dans le fichier persistence.xml.
// Ainsi, il pourra mettre créer l'EntityManager, et faire fonctionner le code de la classe en question, puis l'injecter dans la classe appelante.
// La différence entre EJB et CDI est que les méthodes dans CDI ne sont pas transactionnelles par défaut.
// Nous pouvons l'indiquer en ajoutant l'annotation '@Transactional' sur la méthode, ou directement sur la classe, ce qui voudra dire que l'ensemble des méthodes de cette classe sont transactionnelles.
//      public class CommuneService {
//          @PersistenceContext(unitName = "jpa")
//          EntityManager em;
//          @Transactional
//          void persist(Commune c) {
//              em.persist(c);
//          }
//      }
// Nous pouvons ainsi voir que du point de vue de la syntaxe, gérer la persistance avec un EJB ou avec CDI, revient sensiblement au même.
// Pourquoi est-ce que CDI est préféré ? Cela vient du fait que CDI propose plus d'options pour avoir un contrôle sur ce qui va effectivement être injecté dans notre objet annoté '@Inject'.
// Ainsi que sur ce qui va être injecté dans notre EntityManager.
// Si nous voulons par exemple, écrire des tests sur notre service REST, et donc dans le contexte de ces tests, s'adresser à des bases de données de test plutôt que de production.
// Dans ce cas là nous n'allons pas injecter directement le '@PersistenceContext()' de cette manière là, mais d'une façon différente.
// Dans le contexte du test, ce sera automatiquement un EntityManager sur une base de données de test.
// Et dans le contexte de production, ce sera automatiquement la bonne base de données dont l'EntityManager sera injecté.
// CDI permet de faire ce genre de choses de façon très simple, alors que les EJB n'offrent pas ce genre de service.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Configurer JPA et CDI en Java EE //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour faire fonctionner CDI et JPA tel que nous l'avons vu, nous avons besoin de modifier un petit peu la configuration que nous avions vu sur la partie JPA.
// Nous avions besoin de créer le fichier MET-INF/persistence.xml.
// Pour faire fonctionner CDI, nous avons besoin d'ajouter un autre fichier : META-INF/beans.xml, qui peut si besoin, uniquement contenir <beans />.
// En revanche, dans le persistence.xml, nous avons besoin de changer des choses :
//      <persistence-unit name="jpa"
//                        transaction-type="JTA">
//          <provider>...</provider>
//          <jta-data-source>jdbc/MySQLDS</jta-data-source>
// Nous devons ainsi modifier la valeur de l'attribut 'transaction-type' à 'JTA'.
//      --> Ceci signifie que les transactions vont être gérées automatiquement par le contenair Java EE et que nous n'avons plus le droit de les gérer à la main.
// De plus, nous devons ajouter après la balise provider, la balise '<jta-data-source>' que JPA utilisera pour se connecter à notre base de données.
// Donc tous les éléments que nous avions mis dans '<properties>' avec l'URL, le driver, le nom de la base de données, de l'utilisateur et le mot de passe peut être retiré car il n'en a plus besoin.
// En fait, c'est parce que le serveur de base de données (Glassfish, Weblogic, Websphere, Jboss...) va pouvoir être configuré pour qu'il connaisse la base de données.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Services asynchrones //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Architecture des appels asynchrones et réactifs ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir à présent une autre façon d'invoquer les services REST qui va avoir un impact sur la manière dont nous programmons ces services REST. La notion de service 'Asynchrone'.
// Que se passe t'il lorsqu'un client envoies une requête HTTP sur une serveur web. Ce dernier va passer un certain temps pour préparer la réponse, puis va la retourner au client.
// Il y a une convention qui dit que pour ce serveur HTTP, une requête HTTP recquiert un thread pour s'exécuter. Un serveur normal peut gérer quelques centaines de threads.
// Donc nous avons dans notre boucle de requête un thread de bloqué. Supposons à présent que cela dure quelques secondes. Le client, de son côté ne voit rien arriver tant que la réponse n'est pas prête.
// Si la création de la réponse prends vraiment beaucoup trop de temps, le clint au bout d'un certain temps va recevoir un 'TimeOut' qui va casser la connection.
// Nous avons donc deux problèmes ici :
//      - Premièrement, nous bloquons un thread côté serveur.
//      - Secondement, si le serveur prends trop de temps, le client part en erreur avec un timeout affiché par le navigateur.
// --> Pour gérer ce problème, nous allons faire les choses de manière asynchrone.
// En asynchrone, comment cela va t-il se passer ?
//      --> Le client envoies une requête HTTP d'une certaine forme, avec une information informant que c'est une requête asynchrone.
//          Le serveur, sachant que la tâche qu'il va exécuter est longue, donc il va se dire que cette requête là est gérée en asynchrone.
//          Donc, dès qu'il a reçu la requête, le serveur va envoyer une information au client, qui est une espèce de 'aknowledge'.
//          Ceci permet d'expliquer au client que la requête a bien été reçue et est en cours de traitement, et que cela va prendre un peu de temps.
//          Cela permet de libérer le client, en effet, dès qu'il à reçu ça, le client pourra faire quelque chose.
//          Au bout d'un moment, lorsque la réponse est prête, elle va être envoyée au client, et ce dernier va pouvoir réagir à cette réponse.
// Nous avons deux manières de faire les choses :
//      - Soit le client envoies un 'CallBack' dans la requête HTTP.
//      - Soit le serveur retourne un objet particulier qui va permettre de faire de la 'Programmation Réactive'.
// Nous avons une API pour implémenter ce besoin en Java : API 'CompletionStage'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un service REST asynchrone /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent la première de ces définitions que est le fait de faire un service REST asynchrone qui fonctionne par CallBack vis a vis du client.
// Cette méthode est historiquement la plus ancienne des deux méthodes, et bien qu'elle ait été beaucoup utilisée il y a quelque temps, aujourd'hui elle l'est de moins en moins.
// Ici, nous avons appelé notre classe 'AsyncRestService', avec une méthode process qui prends un paramètre 'message' sous l'url 'process/{messages}' et injectant ce message avec un '@PathParam' :
//      @Path("async")
//      public class AsyncRestService {
//          @Resource
//          ManagedExecutorService es;
//          @GET
//          @Path("process/{message}")
//          public void process(
//              @PathParam("message") String message,
//              @Suspended AsyncResponse response
//          ) {
//              Runnable task = () ->
//                  ...
//                  response.resume(...);
//                  es.submit(task);
//          }
//      }
// La seule chose différente d'un service REST tel que nous l'avons vu jusqu'à présent est que notre méthode 'process()' ne retourne rien.
// --> Elle ne retourne rien, car elle va fournir sa réponse au travers du callback que va lui envoyer JAX-RS.
// Ce callback est de type 'AsyncResponse', et nous allons l'annoter avec l'annotation '@Suspended'. C'est cette annotation qui va nous permettre de faire de l'asynchrone.
// Cette méthode va donc faire un traitement long. Nous allons donc l'encapsuler dans une tâche de type 'Runnable' que nous allons implémenter avec une Lambda Expression.
// Lorsque nous aurons terminé notre traitement, il ne nous manquera plus qu'a appeler la méthode 'resume()' de cet objet ce type Response.
// Cette méthode prenant des paramètres, ceux-ci étant probablement construits sur la formation d'une réponse à partir de ce message.
// Nous allons à présent traiter ce message, c'est un traitement qui est long, et nous allons le passer en paramètre de la méthode 'resume()' de notre objet de type Response.
// Et c'est c'est appel à la méthode 'resume()' qui va informer le client de la réponse que nous avons formé.
// Le fait que nous encapsulons tout cela dans une Lambda Expression ne prends pas de temps, la création de cet objet 'task' est instantannée.
// Ce qui va prendre du temps est l'exécution de l'objet 'task', c'est l'appel de la méthode 'run()' du Runnable.
// Cette tâche, pour l'exécuter, nous avons besoin de la confier à un 'ExecutorService' et c'est tout.
// Le fait de confier cette tâche à un ExecutorService ne prends pas de temps non plus.
// --> Cette tâche va être exécutée dans un des threads de l'ExecutorService, et donc le thread qui exécute la méthode 'process()' sera débloqué, contrairement à si c'était un service synchrone.
// Ainsi, nous allons pouvoir rendre la main immédiatement, et JAX-RS va pouvoir envoyer une réponse au navigateur du client en lui disant que la tâche est lancée.
// --> Ainsi, le client saura que le serveur n'est pas en timeout.
// La question se pose maintenant à propos de l'ExecutorService, car lorsque nous sommes dans un environnement Java EE, nous n'avons pas le droit de créer nos propres threads !
// Ceci est inscrit dans le standart Java EE : 'IL EST INTERDIT DE CREER SES PROPRES THREADS' !
// --> Donc, cet ExecutorService, il va falloir que nous nous le fassions 'injecter' en tant que 'Ressource', avec l'annotation '@Resource'.
// Cette resource, tous les serveurs d'application peuvent nous la fournir, et elle sera de type 'ManagedExecutorService', donc un ExecutorService particulier, propre à Java EE.
// Celui-ci va être envoyé en injection de dépendance, et nous allons pouvoir l'utiliser dans la méthode 'process()'.
// Nous allons à présent voir comment nous devons écrire le code du client qui va permettre d'utiliser ce service asynchrone REST.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un client REST asynchrone //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le client fonctionne de la même façon que le client synchrone normal. Nous commençons par le créer à partir de notre 'ClientBuilder'.
// Puis nous le cablons sur une cible particulière au travers de l'objet de type 'WebTarget', puis, nous pouvons compléter cette cible avec un 'path'.
//      Client client = ClientBuilder.newClient();
//      WebTarget t = client.target("http://...");
//      WebTarget path = t.path("process/{message}");
//      WebTarget target = path.resolveTemplace("message", "hello");
//      AsyncInvoker ai = target.request().async();
//      InvocationCallback<String> callback = new InvocationCallback<>(){
//          public void completed(String s) {
//              System.out.println("Hello World!");
//          }
//          public void failed(Throwable t) {
//              ...
//          }
//      }
// Ici, nous avons choisi de nous créer un path 'process/{message}', qui nous permet de créer des espèces de templates de path qui correspondent à des templates de path côté serveur (voir ci-dessus).
// La différence est qu'après nous allons avoir besoin d'appeler une méthode 'resolveTemplate()' dans laquelle nous précisons la chaîne de caractères du message requis pour cette template, ici 'hello'.
// C'est à ce stade là que les choses vont se compliquer un peu.
// --> Nous avons besoin de dire au client JAX-RS que nous voulons faire une réponse asynchrone et nous avons besoin de construire cet objet callback que nous passerons comme paramètre de notre requête.
// Sur notre objet 'target', nous allons passer la méthode 'request()', comme avant, mais en lui précisant que c'est une méthode asynchrone en le suffixant de la méthode 'async()'.
// Ceci va nous retourner un objet de type 'AsyncInvoker' qui est en fait l'invoqueur asynchrone de cette requête, et qui va nous permettre de passer notre callback.
// Le second objet dont nous avons besoin est de type 'InvocationCallback<String>', le type d'attribut doit correspondre au type que nous passons en paramètre de notre méthode 'resume()' côté serveur.
// Ce callback va être créé en appelant 'newInvocationCallback', dans ce callback nous avons deux méthodes à implémenter :
//      - Une première qui se nomme 'public void completed(String s)' qui prends en paramètre le type de l'InvocationCallback, et donc au type d'objet passé à la méthode 'resume()' de notre serveur.
//          Avec cette chaîne de caractères nous pouvons faire des choses dans la méthode. Pour le moment un System.out.println().
//      - La seconde méthode 'public void failed(Throwable t)' qui va nous permettre de gérer les erreurs côté serveur.
//          Ainsi, nous pouvons remonter l'information d'une éventuelle erreur côté serveur, directement au client.
// --> Ceci représente l'intégralité de notre 'InvocationCallback'.
// Donc InvocationCallback n'est pas très compliqué. Il a deux méthodes, dont une qui va être invoquée dans le cas de la réussite de la requête, et l'autre dans le cas d'un échec.
// --> Maintenant, ce callback, il va falloir que nous l'envoyions à notre service REST. Pour cela, nous allons utiliser notre 'AsyncInvoker'.
//      Nous pouvons lui appliquer la méthode 'get()', en lui passant comme paramètre l'objet de type InvocationCallback.
// Ceci va nous retourner un objet de type 'Future', sur lequel nous allons éventuellement pouvoir gérer du timeout si nous en avons besoin.
// Le callback que nous passons va nous permettre de créer cet objet AsyncResponse qui se trouve du côté serveur.
// L'objet que nous passons à l'AsyncResponse va être passé en paramètre de la méthode 'completed()', du côté du client.
// Attention, le client ne connaît pas l'objet AsyncResponse, mais seulement son InvocationCallback, donc cet objet AsyncResponse est un objet JAX-RS, créé par JAX-RS, et inutilisable du côté du client.
// --> Si nous résumons, le code que nous appelons à partir de l'objet 'WebTarget', qui est le même objet que dans le cas du client synchrone, c'est 'target.request().async().get()'.
//      Pourquoi, parce que nous appelons une méthode GET, et lui passons le callback au serveur qui à son annotation '@GET'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ecriture d'un client et d'un serveur REST réactif /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment les choses fonctionnent-elles avec l'API 'CompletableFuture' ou 'ComputionStage', qui sont en fait une seule et même API.
//      @Path("async")
//      public class AsyncRestService {
//          @Resource
//          ManagedExecutorService es;
//          @GET
//          @Path("process/{message}")
//          public CompletableFuture process(
//              @PathParam("message") String message
//          ) {
//              Supplier<String> task = () -> ...;
//              CompletableFuture<String> cf = CompletableFuture.supplyAsync(task, es);
//              return cf;
//          }
//      }
// Du côté du serveur, d'abord, les choses sont un petit peu plus simple. Essentiellement, nous avons la même structure de classe et la même structure du service REST, avec les mêmes annotations.
//      --> La seule différence est que la méthode 'process()' qui exécute ce traitement long n'a pas besoin de prendre un objet technique particulier qui va lui être fourni par JAX-RS.
//          Elle prends juste cet objet 'message', qui est le paramètre qui arrive du client, et avec lequel nous allons faire notre traitement.
//          Cette méthode va avoir besoin de produire un résultat à partir de ce message.
//      --> Pour produire un message, dans le JDK Java 8, nous avons une Lambda Expression particulière, qui est de type 'Supplier'.
//          Donc, déjà, plutôt que de modéliser notre tâche dans un 'Runnable', nous allons la modéliser dans ce Supplier.
//          Elle ne prends pas de paramètres et retourne un résultat construit à partir du message que nous avons passé en paramètre de la méthode 'process()'.
//          Le fait de produire ce résultat, ce n'est qu'une Lambda Expression, donc cela ne prends absolument pas de temps.
//      --> C'est l'invocation de la méthode 'get()' de ce Supplier qui éventuellement va prendre du temps.
//          A partir de ce Supplier, nous allons créer une tâche asynchrone avec l'API 'CompletableFuture', en utilisant la méthode factory 'supplyAsync()'.
//          Nous lui passons en paramètre, la tâche 'task', ainsi que l'ExecutorService que nous avons injecté en tant que '@Resource' dans notre classe.
//              --> L'invocation de la méthode 'supplyAsync(...)' va nous retourner un objet de type 'CompletableFuture', et c'est cet objet que nous allons retourner.
//              --> Cela signifie que notre méthode 'process()' qui retournait void dans le cas asynchrone avec callback, retourne à présent un 'CompletableFuture'.
// Ainsi, à présent, côté serveur, nous avons à présent un pattern beaucoup plus simple.
//      Client client = ClientBuilder.newClient();
//      WebTarget t = client.target("http://...");
//      WebTarget path = t.path("process/{message}");
//      WebTarget target = path.resolveTemplate("message", "hello");
//      CompletableFuture<String> cf = target.request().rx().get(String.class);
// Le pattern côté client est également beaucoup plus simple.
//      --> Nous commençons par créer notre 'Client', notre 'WebTarget' et notre 'path' que nous résolvons car nous avons fait un template, ce qui ne changes pas.
//          Sur cet objet 'WebTarget', nous allons avoir le même genre de pattern :
//          --> Nous appelons la méthode 'request()' pour construire la requête, dans le cas précédent, nous appelions aussi la méthode 'async()' pour préciser que cette méthode était une méthode asynchrone.
//          --> Dans le cas réactif, nous appelons la méthode 'rx()' à la place de la méthode 'async()' qui informe JAX-RS que la requête que nous souhaitons est une requête réactive.
//          La différence entre 'asynchrone' et 'réactive' est un petit peu subtile. Dans un premier temps nous allons supposer que c'est la même chose, et que la différence est purement technique.
//          Ensuite nous lui passons la méthode 'get()' à laquelle nous passons comme paramètre 'String.class'.
//          Ce paramètre doit correspondre à la classe du 'Supplier<>' que nous avons passé côté serveur donc 'Supplier<String>'.
//          --> Ce que nous sommes en train de dire est que cette requête doit nous retourner une chaîne de caractères.
//              Celle-ci est produite par la 'task' côté serveur, qui est par conséquent un 'Supplier<String>'.
//              Cette chaîne de caractères fixe également, le type du 'CompletableFuture' que nous avons côté serveur.
//              Si nous ne passons pas de paramètre à la méthode get(), ce qui est possible, dans ce cas nous récupèrerons un objet de type Response
//              Cet objet de type Response, nous pourrons interroger pour toutes les informations qu'il contient.
//          Ceci va nous retourner un objet de type 'CompletableFurure<String>', et ce, de manière immédiate.
//          Nous pouvons comparer ce pattern avec le pattern précédent qui était 'target.request().async().get(callback)'.
//          --> Maintenant, qu'allons-nous pouvoir faire avec ce 'CompletableFuture' ?
//              Celui-ci fonctionne comme le 'Future' de 'Java.util.concurrent', en effet, 'CompletableFuture' étends la classe 'Future'.
//              Donc le get() ne nous rendra la main que lorsque le Supplier aura terminé son travail, donc il est bloquant, et ce n'est pas ce que nous voulons.
// --> Donc, à présent nous allons voir quelles sont les fonctionnalités que CompletableFuture ajoute à Future pour réagir, quand l'objet qui doit être créé par le Supplier va être disponible.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation des CompletableFuture /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer des chaînes de traitement réactifs avec CompletableFuture ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Que pouvons-nous faire avec cet objet 'CompletableFuture' ?
// Cet objet 'ComletableFuture' est une classe implémentant l'interface 'CompletableStage' qui est une extension de l'interface 'Future'.
// Donc par conséquent, 'CompletableFuture' est un 'Future', donc à un moment dans le futur, il va encapsuler un résultat.
// Sur un 'Future', nous pouvons faire la méthode 'get()', contenant éventuellement un timeout, la méthode 'isDone()', ou la méthode 'cancel()'.
// Donc nous pouvons tester si le résultat est là, le récupérer, et annuler la tâche qui est en train de s'exécuter dans un autre thread sur lequel ce 'Future' est connecté.
// La classe 'CompletableFuture', apporte de nouvelles fonctionnalités. Supposons que nous avons un objet de type CompletableFuture 'cf', donc, qui à un moment dans le futur, va encapsuler un résultat.
// Dans le cadre de notre exemple, ce résultat est une chaîne de caractères fournie par notre Supplier. Cela pourrait bien sûr être n'importe quel type d'objet.
// Sur cet objet CompletableFuture, nous pouvons appeler un certain nombre de méthodes, et nous allons en voir 3 :
//      - cf.thenAccept(Consumer), à savoir que 'accept()' est le nom de la méthode abstraite de l'interface fonctionnelle Consumer, donc 'thenAccept()' prends un Consumer en paramètres.
//          Par exemple : cf.thenAccept(s -> System.out.println(s));.
//          Donc, comme un Consumer retourne void, 'thenAccept()' va nous retourner un CompletableFuture<void>, avec lequel nous ne pouvons pas faire grand chose.
//          Ainsi, lorsque notre chaîne de caractères va arriver dans notre CompletableFuture, la méthode 'thenAccept()' va être activée et non invoquée (car elle à déjà été invoquée).
//          A ce moment, le consumer passé en paramètre va être invoqué par l'API.
//      - cf.thenApply(Function), à savoir que 'apply()' est le nom de la méthode abstraite de l'interface fonctionnelle Function, donc thenApply() prends une Function en paramètre.
//          Cette Function, à la différence du Consumer, elle, peut produire un résultat. Donc ce 'thenApply()' va nous retourner un autre CompletableFuture.
//          Nous pouvons ainsi retourner un CompletableFuture<String>, mais aussi un CompletableFuture<...> contenant un autre type de données, selon la Function passée en paramètre.
//      - cf.theRun(Runnable), à savoir que 'run()' est le nom de la méthode abstraite de l'interface fonctionnelle Runnable, donc 'thenRun()' prends un Runnable en paramètre.
//          Ce Runnable ne prends pas de paramètres, et il ne retourne rien, donc cette méthode nous retourne aussi un CompletableFuture<void>.
// Ainsi, en effectuant ces différentes méthodes, nous pouvons chaîner les appels à nos CompletableFuture.
// --> L'avantage, est que tous nos CompletableFuture sont vides, tant qu'ils n'ont pas encapsulé de résultat, donc si nous les chaînons, ils sont toujours vides.
//      Ainsi, étant donnés que ces CompletableFuture sont construits par des Lambda Expressions, ces dernières ne seron invoquées par l'API au moment où les données sont produites et encapsulées.
//      Donc nous sommes en train de créer une chaîne de CompletableFuture : cf1 --> cf2 --> cf3 --> cf4 --> ... --> cfx.
//      La création de cette chaîne est instantanée, nous recevons des CompletableFuture qui au début sont vides.
//      --> Lorsque le premier va recevoir les données, à ce moment-là il va activer toutes les Lambda Expressions jusqu'au bout, et donc jusqu'à produire des résultats.
// Avec cela, nous pouvons utiliser des Consumer pour par exemple mettre à jour des IHM, utiliser des Function pour transformer les résultats.
// Nous pouvons aussi ajouter des Runnable pour créer des callback pour réagir lorsque les données seront prêtes.
// --> Ceci est la première utilisation de cette API 'CompletableFuture', d'être capable de créer des chaînes de traitements d'un CompletableFuture à un autre.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer des chaînages avancés de tâches par combinaison de CompletableFuture ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans un premier temps, nous avons créé une chaîne de traitement unidirectionnelle : cf1 --> cf2 --> cf3 --> cf4.
// De la même manière, nous pouvons créer une chaîne de traitement bidirectionnelle :
// cf1 --> cf2 : cf1.thenApply(f1);.
// cf1 --> cf3 : cf1.thenApply(f2);.
// Nous pouvons également créer des graphes comme suit :
// cf1 --> cf3 : cf1.runAfterBoth(cf2, Runnable);, ceci nous permet de combiner deux CompletableFuture en un seul.
// cf2 --> cf3 : cf1.thenAcceptBoth(cf2, BiConsumer<T, U>);, ceci nous permet de combiner deux CompletableFuture d'objets de type différents en un seul.
//     --> cf1.thenCombine(cf2, BiFunction<T, U, R>);, nous permet de combiner deux CompletableFuture d'objets de type différents en un CompletableFuture d'un troisième type.
// Ainsi, avec ce genre de système, nous pouvons réellement créer toutes les situations que nous souhaitons.
// Nous pouvons par exemple avoir un CompletableFuture qui va déclencher tout un tas de tâches différentes, chacune en créant d'autres, pour se réunir en une seule et construire un résultat unique.
// Nous pouvons donc faire des traitements asynchrones ainsi que des traitements en parallèles, puisque ces tâches vont pouvoir s'exécuter dans différents threads.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Contrôler les threads d'exécution dans l'API CompletableFuture ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu que CompletableFuture étends Future, et que ce dernier est utilisé en programmation concurrente pour récupérer des données produites dans un thread dans un autre thread.
// Ainsi, un CompletableFuture permet donc de jouer aussi avec les threads.
// Pour l'instant, dans tout ce que nous avons écris, nous n'avons pas précisé quel ExecutorService était utilisé pour les exécuter.
// --> Par défaut, toutes ces méthodes s'exécutent dans le même thread.
// Nous avons une deuxième version de chacune de ces méthode :
// - cf.thenApplyAsync();.
// - cf.thenAcceptAsync();.
// - cf.runAfterBothAsync();. ...
// En utilisant n'importe laquelle de ces méthodes (en ajoutant le mot 'async' en suffixe), nous avons la possibilité d'exécuter la Lambda Expression dans un autre thread.
// Si nous ne passons pas d'ExecutorService en paramètre à une de ces méthodes, dans ce cas là, la Lambda Expression va s'exécuter dans un autre thread d'un ExecutorService particulier.
// Cet ExecutorService particulier est défini au niveau de la JVM qui s'appelle le 'FORGEANDCALL'.
// Chacune de ces méthodes Async existe en deux versions, dont une qui prends un ExecutorService en paramètre, ainsi, la Lambda Expression sera exécutée dans un thread de cet ExecutorService.
// Donc chacune de ces méthodes existent en trois versions :
// - thenApply();.
// - thenApplyAsync();, qui prends juste une tâche et non l'ExecutorService.
// - thenApplyAsync();, qui prends une tâche et un ExecutorService dans lequel cette tâche va devoir s'exécuter.
// Nous pouvons ainsi contrôler les tâches qu'exécutent chacun des threads si nous ne mettons qu'un seul thread par ExecutorService, ce qui est tout a fait possible.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérer les exception avec l'API CompletableFuture //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment pouvons-nous gérer les errers avec les CompletableFuture ?
// Ce point est très important car, lorsque nous créons des tâches longues, c'est que ces tâches sont probablement des I/O, des requêtes sur d'autres services, donc des choses qui peuvent échouer.
// Supposons que dans le schéma suivant, une erreur soit jetée dans le cf21 :
// cf1 --> cf21 -->          --> cf3 --> cf5
//  |                                   |
// cf22                                cf4
// L'exception va être passée aux CompletableFuture suivants et ainsi de suite jusqu'au CompletableFuture final.
// Ainsi, ce CompletableFuture final ne pourra pas résoudre sa tâche à lui, et nous ne pourrons pas faire récupérer le résultat qu'il encapsule.
// Comment pouvons-nous faire pour rattraper cette erreur ?
// --> Nous allons insérer des CompletableFuture particuliers qui vont pouvoir capter, non-seulement le résultat d'une tâche, mais également l'éventuelle exception qui a été générée par cette tâche.
//      Ils vont pouvoir faire un choix : transmettre cette exception, ou bien faire du rattrapage sur l'erreur, par exemple en mettant une valeur par défaut à la place du résultat souhaité à l'origine.
//      Nous pouvons aussi choisir par exemple de ne rien afficher, si par exemple nous avons besoin d'afficher une carte avec la météo, c'est ok si la météo sur un point de la carte ne s'affiche pas.
// Pour créer cet objet, nous avons plusieurs façon de le faire :
// - Nous pouvons appeler 'cf21.exceptionaly(Function<Throwable, ...>)', qui prends une Function prenant en attribut un Throwable, et ce que nous voulons en second paramètre.
//      Cette fonction, si elle ne génère pas d'erreur, va passer à cf3 comme si c'était un CompletableFuture normal.
// - Nous pouvons appeler 'cf21.handle(BiFunction<T, Throwable, ...>)', cette BiFunction va systématiquement être appelée sur le résultat de cf21.
// - Nous pouvons appeler 'cf21.whenComplete(BiConsumer<T, Throwable>)'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur JAX-RS et son intégration dans Java EE //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Effectuons un petit bilan sur ce que nous avons vu sur ces services REST :
// - Il y a un enjeu à transférer des données en HTTP indépendamment du fait que ces données sont présentées dans des IHM ou envoyées vers des serveurs pour des traitements.
//      Il existe deux technologies pour effectuer ce genre de choses :
//          - SOAP, qu'on appelle aussi web services.
//          - REST, qui est aussi un web service, même si web service fait plutôt référence à SOAP qu'à REST.
//      Ces deux méthodes sont indépendantes du langage, et construites sur du XML, même si aujourd'hui REST évoly vers l'utilisation du JSON.
//      SOAP n'est pas construit sur HTTP, ce qui apporte de la lourdeur dans son fonctionnement ainsi que des problèmes, alors que REST est construit sur HTTP.
// - Nous avons vu ce que nous pouvons faire avec l'API Servlet, qui est en fait l'implémentation du protocole HTTP dans Java EE.
// - Nous avons aussi passé pas mal de temps à voir JAX-RS qui permet de créer des services REST.
// - Nous avons vu trois types de services REST :
//      - Classiques.
//      - Asynchrones.
//      - Réactive.
//          --> Le type réactif est le plus utilisé de nos jours.
// - Nous avons vu l'intégration avec Java EE avec JPA et avec deux technologies concurrentes EJB et CDI.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java EE par la pratique ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ce module est une mise en pratique de service REST avec Java EE à l'aide de sessions de live coding.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live coding ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live coding part 1 ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Rappel à propos de l'installation d'Eclipse et du JDK :
//      - Le téléchargement d'Eclipse se fait sur 'eclipse.org' > Download Packages > Eclipse IDE for Enterprise Java Developpers > 32bits ou 64bits en fonction de l'OS.
//      - Pour savoir sur quelle version de Java nous nous trouvons : CommandPrompt > java -version --> Donne la version du JDK ainsi que 32bits ou 64bits.
//      - Pour télécharger un jdk : 'adoptopenjdk.net' > Choose version > Choose a JVM (OpenJ9, nouvelle JVM développée par IBM, puis par Eclipse), choisir plutôt HotSpot (développée par Oracle).
// -----------
// Si nous voulons lancer une version d'Eclipse avec une version spécifique de Java :
//      - Dans le fichier 'eclipse.ini' se trouvant dans le dossier d'installation d'Eclipse, trouver '--launcher.appedVmargs'.
//      - Sauter une ligne > Ajouter '-vm' > Sauter une ligne > Ajouter le chemin complet du dossier de l'exécutable 'javaw.exe', par exemple : 'D:\jav\jdk-13\bin\javaw.exe'.
//      --> A chaque ouverture de l'Eclipse dont le fichier 'eclipse.ini' a été modifié, le JDK utilisé par cet Eclipse sera celui dont le chemin est spécifié dans le fichier.
// -----------
// Rappel sur le path, à mettre dans un batch :
//      - Créer un .bat avec les 4 lignes suivantes, indiquant le chemin du dossier racine du JDK souhaité
//              echo Setting Java 16
//              @echo off
//              set JAVA_HOME=C:\Users\Emile\Desktop\JAVA\Java\OpenJDK16U-jdk_x64_windows_hotspot_16.0.2_7\jdk-16.0.2+7
//              set PATH=%JAVA_HOME%\bin;%PATH%
//      --> Maintenant, pour changer de machine virtuelle, il suffit d'ouvrir une console, naviguer dans le dossier du .bat, puis taper le nom .du bat et entrée.
//      --> Pour vérifier la version de Java actuelle du PATH, il suffit de taper dans une console 'java -version'.
//      - Pour connaître la version de Java utilisée par Eclipse : Window > Preferences > 'JRE' > Installed JRE.
// -----------
// Téléchargement et configuration de GlassFish :
//      - Aller sur : 'https://projects.eclipse.org/projects/ee4j.glassfish' > Downloads > Dernière version 'Full Profile'.
//      - GlassFish ne s'installe pas mais se dézippe simplement dans un répertoire, pour cela, il faut éviter d'avoir des espaces dans le chemin du répertoire en question.
//      - Attention ! Le bon fichier 'asadmin' ne se trouve pas dans le dossier 'racine/bin', mais dans le dossier 'racine/glassfish/bin'.
//      - Dans une console, naviguer dans ce dossier et taper : 'asadmin start-domain' :
//              Waiting for domain1 to start ........................
//              Waiting finished after 23?703 ms.
//              Successfully started the domain : domain1
//              domain  Location: C:\Users\Emile\Desktop\JAVA\Java\glassfish7\glassfish\domains\domain1
//              Log File: C:\Users\Emile\Desktop\JAVA\Java\glassfish7\glassfish\domains\domain1\logs\server.log
//              Admin Port: 4?848
//              Command start-domain executed successfully.
//      - Pour arrêter GlassFish : 'asadmin stop-domain'.
//              Waiting for the domain to stop .
//              Waiting finished after 86 ms.
//              Command stop-domain executed successfully.
//      - En démarrant GlassFish, cela nous créé un domaine par défaut, qui va contenir toute la configuration, les servlets, toutes les applications dynamiques du web que nous allons faire.
//      - Sur notre navigateur, nous pouvons à présent nous connecter à l'IHM d'administration de GlassFish : 'localhost:4848'.
// -----------
// Connection de GlassFish à Eclipse :
//      - Pour ce faire, nous avons besoin de télécharger deux plugins :
//          --> Le premier, nous devons récupérer sur internet : 'https://www.eclipse.org/projects/archives.php' > télécharger l'archive 'Sapphire' et la dézipper deux fois dans notre dossier Java.
//              Puis dans notre Eclipse > Help > Install New Software... > Add... > Archive > Sélectionner le .zip de la dernière version dans les dossiers > Cocher tout > Next > Finish > Restart Eclipse.
//          --> Le second se trouve sur la page GlassFish Tools de la fondation Eclipse : 'https://projects.eclipse.org/projects/webtools.glassfish-tools/downloads'.
//              Il nous suffit de copier le lien du repository 'https://download.eclipse.org/glassfish-tools/1.0.1/repository/'.
//              Le lien étant lui aussi déprécié, il faut retourner sur les archives Eclipse pour pouvoir récupérer le double zip de GlassFish Tools, et faire la même procédure que pour le premier plugin.
//      - Maintenant nous devons configurer Eclipse pour qu'il sâche où se trouve GlassFish sur notre disque dur :
//          Window > Preferences > Filtrer sur 'Server' > Server > Runtime Environment > Add... > GlassFish > Next > Sélectionner le dossier de GlassFish et le dossier du JDK > Finish.
//          Apply and Close > A présent, Eclipse sait où se trouve GlassFish.
//      - A présent, si il n'est pas présent, nous pouvons ajouter l'onglet 'Servers' sur l'environnement du bas en le sélectionnant dans : Window > Show View > Other...
//          Maintenant sur le nouvel onglet : New Server > Sélectionner GlassFish > Next > Next (car nous n'avons pas de projets qui y sont liés) > Finish.
//          A présent, si notre serveur Glassfisf est démarré (étape précédente avec la commande 'asadmin start-domain'), le serveur à une légende 'Started' dans l'onglet 'Servers'.
//          --> Maintenant, notre serveur est listé dans l'onglet 'Server', et en nous servant du bouton rouge 'Stop' et du bouton vert 'Start', nous pouvons lancer ou stopper notre serveur depuis Eclipse.
// -----------
// Création d'un projet 'Web Dynamic' :
//      - Dans la vue 'Project Explorer' d'Eclipse, nous avons une option 'Create a Dynamic Web project'.
//          Nous pouvons aussi faire : File > New > Dynamic Web Project.
//          Enfin, nous pouvons aussi faire : File > New > Project > Dans le dossier Web sélectionner 'Dynamic Web Project'.
//              --> Une fois le projet sélectionner, il faut rentrer son nom, ici 'java-ee', puis sélectionner un 'Target Runtime' puisque c'est un projet de type 'Dynamic Web'.
//                  GlassFish 5 est automatiquement pré-sélectionné. La partie 'Dynamic web module version' équivaut à la version de l'API 'Servlet', nous conservons la version 4.0 > Next > Next > Finish.
//          --> Si à ce moment-là nous avons un erreur de type 'Cannot install project facet Java 1.8. Some version of this project facet is already installed.', c'est un problème courant.
//              En effet, si nous essayons de déployer notre projet dans le GlassFish en faisant un clic droit sur le serveur > Add and Remove..., il nous dit qu'il n'y a aucune ressource d'accessible.
//              Cela s'explique car notre projet est invisible a GlassFish car notre projet utilise une version postérieure à Java 8.
//          Pour voir ce qu'il se passe, nous pouvons faire : Clic droit sur le projet > Properties > Java Build Path. Nous pouvons vérifier que nous avons bien un JDK 1.8.
//          Aussi, dans l'onglet 'Java Facets', nous pouvons voir dans la liste déroulante 'Configuration' que 'Default Configuration for GlassFish 5' est bien présent.
//          Toutefois, 'Dynamic Web Module', 'JAX-RS' ne sont pas cochés dans la Liste des 'Project Facets'.
//              --> Notre projet n'est pas correctement configuré ! Nous pouvons donc supprimer ce projet : Clic droit sur le projet > Delete.
//          Nous pouvons retourner dans : Window > Preferences > Filtre : 'JRE' > Java > InstalledJREs > Sélectionner Java 1.8 et supprimer les autres JDK > Apply and Close.
//          Maintenant, dans la même fenêtre, sélectionner la catégorie : 'Compiler' > JDK Compliance > Compiler Compliance Level : 1.8.
//      - Une fois que nous pouvons créer un projet Web Dynamic, et qu'il contient tous les Java Facets nécessaires, nous pouvons l'ajouter à notre serveur.
//          Clic droit sur le serveur dans l'onglet 'Server' > Add and Remove... > Ajouter le projet Java > Finish.
//              --> Ici, le problème était que Eclipse 2023 nécessite un JDK 11 au minimum, donc impossible de le lancer avec un JDK 8. Il faut donc installer un Eclipse antérieur (2017 par exemple).
//      - A présent, lorsque nous ouvrons notre projet, nous avons les onglets auxquels nous nous attendons pour un projet Java EE : 'Deployment Descriptor', 'JAX-WS', 'Java Resources' et le 'Web Content'.
//          De plus, si nous faisons un clic droit sur notre projet et allons dans les propriétés de ce dernier, dans la partie 'Project Facets', nous avons bien nos modules de cochés.
//          Nous avons bien 'Dynamic Web Module', 'GlassFish Web Extensions', 'Java', et dans l'onglet 'Runtimes', nous avons bien 'GlassFish 5' de sélectionné.
// -----------
// Maintenant nous avons un projet web sur lequel nous pouvons travailler.
//      - Tout d'abord, nous allons créer un fichier index.html : clic droit sur le dossier 'Web Content' > New > HTML file > 'index.html' > Finish.
//          Nous lui ajoutons un title et un <h1> dans le <body>, puis nous pouvons sauvegarder et démarrer notre serveur GlassFish.
//          --> Enfin, pour s'assurer que tout fonctionne, nous nous rendons sur : 'http://localhost:8080/play-with-java-ee/index.html', et notre <h1> s'affiche. Donc tout fonctionne.
//          --> Lorsque nous effectuons des modifications, puis les sauvegardons sur des fichiers de notre application web, nous devons cliquer sur le bouton 'Publish to the Server'.
//              Celui-ci se trouve prêt du bouton 'Stop' dans la fenêtre serveur et va synchroniser le serveur. Il ne nous restera plus qu'à rafraichir la page pour que notre nouveau contenu s'y affiche.
//      - A présent nous créons un fichier index.jsp : clic droit sur le dossier 'Web Content' > New > JSP file > 'index.jsp' > Finish.
//          Celui-ci fonctionne de la même manière que notre fichier index.html donc nous pouvons à présent y accéder via : 'http://localhost:8080/play-with-java-ee/index.jsp'.
//          Maintenant si nous ajoutons dans le '<body>' le code suivant : '<p><%= new java.util.Date() %>', nous aurons la date qui s'affichera de manière dynamique.
//          --> Le code Java que nous avons écris est exécuté à chaque requête qui est lancée, donc à chaque fois que nous rechargeons la page.
//      --> Une requête statique est une requête qui va chercher une ressource qui existe indépendamment de cette requête.
//      --> Une requête dynamique est une requête qui va chercher une ressource qui est indépendante à cette requête, telle que la date et l'heure, qui seront différentes.
// -----------
// A présent, nous allons construire une Servlet. Une 'Servlet' est une classe particulière qui étends une classe de l'API Servlet 'HTTPServlet'.
// Cette classe va avoir des méthodes spécifiques qui vont être invoquées par le serveur Java sur des méthodes HTTP particulières.
//      - Pour créer de nouvelles Servlet, nous avons dans l'IHM, un bouton bleu contenant un 'S' avec un '+', en le cliquant, nous pouvons sélectionner 'Servlet'.
//          Sinon pour créer notre Servlet, nous créons simplement une nouvelle classe, en précisant qu'elle étends 'HttpServlet'.
//          HttpServlet est une classe et non une interface car c'est assez ancien et c'est pour des raisons de compatibilités ascendantes.
//      - Dans HttpServlet, nous avons tout un tas de méthodes que nous pouvons voir avec 'Ctrl + O' : 'doGet()', 'doHead()', 'doPost()', 'doPut()', 'doDelete()', 'doOptions()', 'doTrace()'.
//          Ces méthodes là sont les méthodes invoquées par le serveur Java sur la méthode HTTP corespondante.
//          Ainsi, si nous ne codons rien dans cette classe, GlassFish va envoyer une requête et appeler par exemple la méthode 'doGet()' de notre classe, et donc de sa 'SuperClass'.
//          Et par conséquent, elle ne va rien faire. Si nous voulons faire un 'doGet()', il faut que nous surchargeons cette méthode.
//          Alt + Shift + s > 'Override / Implement Methods' > Sélectionner les méthodes que nous souhaitons surcharger > Automatiquement, les méthodes '@Override' vont s'ajouter dans notre classe.
//              --> Nous pouvons enlever le 'super', puis le code que nous allons écrire dans ces méthodes surchargées va être celui qui s'exécutera lorsque nous exécuterons une requête.
//      - Pour l'instant ces requêtes existent mais ne sont connectées à aucune URL, donc pour cela nous devons ajouter l'annotation '@WebServlet'.
//          A celle-ci, nous pouvons passer l'URL souhaité comme valeur de l'attribut 'urlPatterns', nous pouvons par exemple lui donner comme valeur '/hello-world'.
//              --> A présent, si nous accédons à l'URL 'localhost:8080/play-with-java-ee/hello-world', rien ne s'affiche car nous n'avons rien codé, mais nous n'avons pas d'erreur 404.
//      - Comment faire pour écrire quelque chose sur le navigateur du client ? Par exemple pour écrire un message 'Hello World!'.
//          Notre méthode doGet() prends deux objets en paramètres 'HttpServletRequest' et 'HttpServletResponse'. En utilisant ce dernier nous pourrons aboutir à ce que nous souhaitons.
//          Pour ce faire, nous pouvons utiliser la méthode 'getWriter()' sur notre objet 'HttpServletResponse', et la méthode 'print()' sur ce dernier.
//          Avec ce Writer, qui provient de l'API Java I/O, nous pouvons écrire du texte, ainsi que du HTML, contenant des objets Java, comme une 'new Date()' par exemple.
//              --> En fait la classe que nous sommes en train d'écrire est un callback.
//      - Nous pouvons aussi très bien appeler la méthode 'doPost()' à partir de la méthode 'doGet()'. Toutefois, il faut faire attention que les deux méthodes surchargent les servlet avec '@Override'.
//          Si nous mettons 'doGat()' au lieu de 'doGet()' et que nous ne surchargeons plus, nous aurons une erreur 405 : 'La méthode HTTP GET n'est pas supportée par cette URL'.
//          La présence du triangle vert à gauche indique que la méthode sur cette ligne est bien une surcharge.
//      - Supposons à présent que dans notre requête de la méthode 'doPost()', nous créons un bean Commune prenant deux String comme champs, le code postal et le nom de la Commune.
//          Cette commune, nous souhaiterions l'afficher dans une page JSP. Dans le dossier WebContent > Clic droit > New > JSP file > commune.jsp.
//          Dans deux paragraphes '<p>', nous plaçons 'commune.getNom()' et 'commune.getCodePostal()'. Nous voudrions ainsi passer la commune que nous avons dans notre Servlet, à notre page JSP.
//          Nous allons ainsi prendre la requête gérée par cette Servlet, et la transmettre vers une autre ressource de notre web application : une autre Servlet par exemple, ou une page JSP.
//          Pour ce faire, nous avons besoin d'un objet particulier qui est un 'RequestDispatcher', que nous pouvons créer à partir de l'objet 'req', en lui passant le String du nom du fichier JSP.
//          Ensuite, nous pouvons appliquer la méthode '.forward(req, resp)' à notre nouvel objet, ce qui signifie qu'à présent, la requête est gérée par notre ressource 'commune.jsp'.
//              --> Attention, nous ne pouvons pas forwarder vers une ressource extérieure à notre web application, uniquement une ressource interne.
//          Le problème est que notre fichier JSP ne reconnaît pas l'objet 'commune', il nous faut donc le lui passer, avec la méthode 'setAttribute()' sur l'objet 'req'.
//          Ce faisant, nous lui passons en paramètre une clef, que nous pourrons appeler à partir de la ressource à laquelle nous passons la requête.
//          En second paramètre, nous lui passons l'objet auquel sera assigné la clef que nous lui avons fourni. Ici ce sera donc l'objet 'commune'.
//              --> Ceci équivaut à une table de hashage dans la requête.
//          Il faut savoir que l'objet requête que nous recevons dans la Servlet, et celui que nous passons à notre page JSP est physiquement le même.
//          Ainsi, dans notre code JSP, nous pouvons préciser du code Java, et donc créer un objet de type Commune, en le castant, et en important la classe Commune.
//          --> Si nous effectuons un bilan, nous créons un objet de type 'Commune' de toutes pièces dans notre Servlet, et nous l'attachons en tant qu'attribut à la requête.
//              Nous créons cet objet technique, le RequestDispatcher qui va nous permettre de forwarder notre requête vers une page JSP qui sait afficher un objet de type 'Commune'.
//              Enfin, nous appelons la méthode forward de ce RequestDipsatcher, en lui passant l'objet 'req' que nous avons, et l'objet 'resp' que le serveur web nous a confié.
//              Après, c'est notre page JSP qui gère la requête, celle-ci va récupérer l'objet de type 'Commune' sur l'attribut de la requête, et va pouvoir en afficher ses champs.
//          --> Ainsi, c'est de cette manière que nous procédons en application web : d'un côté nous avons des Servlets qui crééent des objets Java, et de l'autre nous avons des pages qui affichent ces objets.
//              A savoir que nous utilisons ici du JSP, mais nous pourrions aussi utiliser du JSF, qui est un peu plus complexe, mais réponds aux mêmes besoin que le JSP.
//      - A présent imaginons que nous voulons récupérer la Commune dont le code postal est entré dans l'URL comme ceci : 'localhost:8080/play-with-java-ee/commune?cp=75000'.
//          Dans notre Servlet, nous avons une méthode qui s'appelle 'getParameter()' qui nous retourne une chaîne de caractères, que nous pouvons appeler 'codePostal'.
//          A cette méthode nous passons en paramètre "cp", que nous avons signalé dans l'URL.
//          Nous pouvons passer ce 'codePostal', à la place du code postal qui était sous forme de chaîne de caractères, lors de la création de l'objet de type 'Commune'.
//          Ainsi, lorsque nous modifions le code postal recherché dans l'URL, c'est ce dernier qui s'affiche sur la page.
//          --> Donc nous pouvons passer des paramètres à notre Servlet, puis les récupérer avec la méthode 'getParameter()', et ce code postal devient ainsi un paramètre de la requête.
// -----------
// Maintenant nous allons créer un service REST :
//      - Tout d'abord, dans notre projet, nous allons créer un package 'rest' dans notre package 'org.vitu'.
//          Dans ce dernier, nous allons créer une première classe que nous allons appeler 'RestService'. Celle-ci va en réalité juste porter de la configuration.
//          Pour faire du service REST dans l'univers Java EE, nous utilisons l'API JAX-RS, et pour ce faire, nous avons besoin d'un élément technique.
//          Ce dernier est simplement une classe qui étends 'Application', du package 'javax.ws.rs.core'.
//          Enfin, cette classe ne doit rien contenir, nous devons simplement lui ajouter l'annotation '@ApplicationPath("...")', avec comme paramètre un morceau d'URL, par exemple "rest".
//              --> Ici, nous avons créé un serveur REST, un serveur étant un ensemble de services, et que tous ces services vont vivre sous un morceau d'URL : 'rest'.
//                  Donc notre URL sera : 'localhost:8080/play-with-java-ee/rest/servicesX'.
//      - A présent nous allons nous créer une nouvelle classe, qui se nomme 'CommuneRS', que nous allons exposer sous un chemin particulier 'commune', avec l'annotation '@Path'.
//          Ainsi, toutes les méthodes que nous allons créer dans cette classe, seront disponibles pour des requêtes HTTP sous le chemin 'commune'.
//          Pour commencer nous pouvons nous créer un String qui retourne "Hello World!" avec un '@Path("hello-world")', en y apposant aussi l'annotation JAX-RS de la méthode HTTP '@GET'.
//              --> Nous avons à présent un service REST fonctionnel.
//      - Pourquoi utiliser GlassFish, limité à Java 8, et non Tomcat, qui est compatible jusqu'à Java 11 ?
//          --> Entre Java 8 et Java 11, il y a des différences, mais pas par rapport au code que nous avons écrit jusqu'à présent.
//          --> Tomcat utilise le WebProfile et non le FullProfile, donc nous ne pourrons pas faire du JPA, et donc c'est difficile de faire des EJB ou du CDI.
//      - Nous allons maintenant essayer de passer une commune avec un code postal en paramètre, comme nous l'avons fait avec la Servlet.
//          Si à présent, nous créons une seconde méthode sur un autre '@Path', qui retourne une Commune, en prenant en paramètre un String 'codePostal', JAX-RS nous affiche du JSON.
//          Effectivement, nous avons l'objet Commune, avec un code postal égal à une chaîne de caractères vide, et le nom 'Paris'.
//          Pour faire ce que nous voulons, il faut passer à l'annotation '@Path("{code-postal}")' pour que nous puissions ensuite l'injecter dans la méthode comme bon nous semble.
//          Ensuite, nous pouvons appeler ce paramètre en utilisant l'annotation '(@PathParam("code-postal") String codePostal)' en tant que paramètre de notre méthode.
//          Ainsi, nous avons à présent à l'adresse 'http://localhost:8080/play-with-java-ee/rest/commune/89000' une page qui affiche du JSON : '{"codePostal":"89000","nom":"Paris"}' de manière dynamique.
// -----------
//      <!DOCTYPE html>
//      <html>
//          <head>
//              <meta charset="ISO-8859-1">
//              <title>Hello World!</title>
//          </head>
//          <body>
//              <h1>Hello World!</h1>
//          </body>
//      </html>
// -----------
//      <%@ page language="java" contentType="text/html; charset=ISO-8859-1"
//          pageEncoding="ISO-8859-1"%>
//      <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
//      <html>
//          <head>
//              <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
//              <title>Hello jsp World!</title>
//          </head>
//          <body>
//              <h1>Hello jsp World!</h1>
//              <p><%= new java.util.Date() %>
//          </body>
//      </html>
// -----------
//      package org.vitu.model;
//      import java.io.Serializable;
//      public class Commune implements Serializable {
// 	        private String codePostal;
// 	        private String nom;
// 	        public Commune() {
// 	        }
// 	        public Commune(String codePostal, String nom) {
// 		        this.codePostal = codePostal;
// 		        this.nom = nom;
// 	        }
// 	        public String getCodePostal() {
// 		        return codePostal;
// 	        }
// 	        public void setCodePostal(String codePostal) {
// 		        this.codePostal = codePostal;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Commune [codePostal=" + codePostal + ", nom=" + nom + "]";
// 	        }
//      }
// -----------
//      package org.vitu.servlet;
//      import java.io.IOException;
//      import java.io.PrintWriter;
//      import java.util.Date;
//      import javax.servlet.RequestDispatcher;
//      import javax.servlet.ServletException;
//      import javax.servlet.annotation.WebServlet;
//      import javax.servlet.http.HttpServlet;
//      import javax.servlet.http.HttpServletRequest;
//      import javax.servlet.http.HttpServletResponse;
//      import org.vitu.model.Commune;
//      @WebServlet(urlPatterns = "/commune")
//      public class HelloWorldServlet extends HttpServlet {
// 	        @Override
// 	        protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
// 		        doPost(req, resp);
// 	        }
// 	        @Override
// 	        protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
// 		        //		PrintWriter writer = resp.getWriter()
// 		        //		writer.print("Hello world\n");
// 		        //		writer.print("<h2>BIGGER Hello world</h2>\n");
// 		        //		writer.print("<h1>Hello world, it is " + new Date() + "</h1>");
// 		        String codePostal = req.getParameter("cp");
// 		        Commune commune = new Commune(codePostal, "Paris");
// 		        req.setAttribute("commune", commune);
// 		        RequestDispatcher rd = req.getRequestDispatcher("commune.jsp");
// 		        rd.forward(req, resp);
// 	        }
//      }
// -----------
//      <%@ page import="org.vitu.model.Commune" %>
//      <%@ page language="java" contentType="text/html; charset=ISO-8859-1"
//          pageEncoding="ISO-8859-1"%>
//      <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
//      <html>
//          <head>
//              <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
//              <title>JavaEEFirstPage</title>
//          </head>
//          <body>
//              <% Commune commune = (Commune) request.getAttribute("commune"); %>
//              <p>Nom : <%= commune.getNom() %></p>
//              <p>Code postal : <%= commune.getCodePostal() %></p>
//          </body>
//      </html>
// -----------
//      package org.vitu.rest;
//      import javax.ws.rs.ApplicationPath;
//      import javax.ws.rs.core.Application;
//      @ApplicationPath("rest")
//      public class RestService extends Application {
//      }
// -----------
//      package org.vitu.rest;
//      import javax.ws.rs.GET;
//      import javax.ws.rs.Path;
//      import javax.ws.rs.PathParam;
//      import org.vitu.model.Commune;
//      @Path("commune")
//      public class CommuneRS {
// 	        @GET @Path("hello-world")
// 	        public String helloWorld() {
// 		        return "<h1>Hello World!</h1><p>This is a REST website</p>";
// 	        }
// 	        @GET @Path("{code-postal}")
// 	        public Commune commune(@PathParam("code-postal") String codePostal) {
// 		        return new Commune(codePostal, "Paris");
// 	        }
//      }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Live coding part 2 ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tout d'abord, nous allons visiter l'IHM de GlassFish en effectuant une requête dans notre navigateur sur 'localhost:4848'.
//      --> Dans notre projet Eclipse, GlassFish est lancé, et nous avons déployé notre application 'play-with-java-ee' dedans.
//          Comme notre application a été déployé dans GlassFish, par Eclipse, si nous nous connectons sur l'IHM d'administration de GlassFish, nous allons pouvoir voir l'application.
//      --> Dans la barre latérale de gauche de l'IHM, nous avons un noeud 'Applications', dans lequel nous pouvons retrouver toutes les applications se trouvant sur notre serveur GlassFish, donc la notre.
//          Dans cette nouvelle page, nous avons un certain nombre d'informations à l'intérieur, notamment le 'Context Root' qui pour nous est '/play-with-java-ee', donc l'URL de notre application.
//      --> Dans la table 'Module and Components', sur la première ligne, à droite, nous pouvons cliquer sur 'Launch', pour vérifier que les pages web fonctionnent.
// -----------
// A présent nous allons ajouter sur la même application, les classes 'Maire' et 'Departement', ainsi qu'une unité de persistence, de la même manière que lorsque nous travaillions sur JPA.
//      - Tout d'abord, il faut bien noter que toutes les annotations JPA que nous apportons sont importées de GlassFish, d'où l'importance d'avoir bien configuré GlassFish dans un premier temps.
//          En effet, si nous regardons par exemple la classe '@Entity', importée de 'javax.persistence', nous pouvons voir que le .jar nous vient du répertoire d'installation de GlassFish.
//      - Si nous reprenons à présent notre classe 'CommuneRS', nous pourvons créer une nouvelle méthode, sur la même URI que précédemment que nous allons appeler 'helloWorld'.
//          Sur internet, nous préférons retourner des objets de type 'Response', plutôt que des String ou des int pour répondre aux requêtes.
//          Donc nous pouvons utiliser l'objet 'Response', provenant de 'javax.ws.rs.core', sur lequel nous pouvons appliquer la méthode 'ok()', puis 'build()', que nous retournons à notre navigateur.
//      - Aussi, nous pouvons ajouter une condition, retournant un statut de type 'BAD_REQUEST', si nous requêtons un code postal égal à 0 en utilisatn la méthode 'status()' sur l'objet 'Response'.
//          --> Il est important dans le web de respecter les conventions HTTP, ainsi, l'apprentissage des types de réponses HTTP et leur respect dans les applications web est très important.
// -----------
// Maintenant nous allons créer un nouveau service REST qui se nomme 'UserRS'.
//      - Pour ce faire il suffit de créer une nouvelle classe 'UserRS' dans notre package 'rest'. Nous lui apposons le '@Path("user")'.
//          Ensuite nous lui ajoutons une méthode sur le '@Path("{id}")' retournant un objet de type 'Response' que nous nommons 'findById', prenant en paramètre le '@PathParam("id") long id'.
//      - Ensuite, nous pouvons créer une classe java bean 'User' dans les models.
//          Enfin, nous créons de toutes pièces dans cette méthode un nouvel User prenant l'id passé en paramètre du path.
//      - Nous pouvons retourner ce dernier à l'aide des méthode 'ok()', puis 'entity(user)', et enfin 'build()'.
//          --> Ainsi, nous avons transféré un objet de type 'User' à internet sous la forme d'un objet de type 'Response', comme les conventions le souhaitent.
//      - Il est aussi possible de forcer le type de format que nous voulons utiliser pour notre réponse avec l'annotation '@Produces(MediaType.APPLICATION_JSON)'.
//          --> De cette manière, le format de réponse retournée par la requête sur cet URI par la méthode annotée sera obligatoirement JSON.
// -----------
// A présent nous allons voir quelques applications de l'API JAX-B, sur le format XML des bean Java, et leur implémentation dans des pages dynamiques web.
//      - Si nous lui mettons un 'MediaType' de type 'TEXT_XML', la page nous donne une erreur 500, signifiant que nous avons une erreur côté serveur.
//          Pour en savoir plus sur cette erreur, nous pouvons aller chercher dans les logs GlassFish : Clic droit sur le serveur > GlassFish > View Log File.
//              --> A ce moment-là nous pouvons trouver une erreur indiquant que GlassFish ne sait pas convertir notre classe User en XML.
//              Cela signifie que GlassFish a des règles par défaut pour convertir des bean en JSON, mais pas pour convertir des bean en XML.
//              Donc nous allons lui expliquer comment convertir cette classe en XML, avec l'API JAX-B, en ajoutant sur la classe l'annotation '@XmlRootElement'.
//                  --> Maintenant, nous pouvons visualiser le contenu XML de cette classe sur notre URI.
//      - Nous pouvons aussi lui ajouter l'annotation '@XmlAttribute(name = "id")' sur le champs 'id' pour préciser à JAX-B que le champs 'id' est un attribut de la classe.
//          --> Toutefois, en faisant cela, nous avons de nouveau une erreur 500, ceci est dû au fonctionnement de JAX-B, et constitue une erreur classique de JAX-B.
//      - Comment fonctionne JAX-B ?
//          --> Par défaut, JAX-B fait de l'introspection sur les classes pour aller chercher les valeurs des propriétés.
//              Il travaille avec des bean, donc pour identifier les propriétés des beans, il va faire de l'introspection.
//              Il va, par défaut chercher les getters et les setters pour identifier les propriétés d'une classe.
//      - Toutefois, ici, nous avons annoté le champs 'id' de la classe avec '@XmlAttribute', et lorsqu'il cherche les getters et les setters, il va trouver un autre champs 'id'.
//          Ainsi, il se retrouve avec deux champs 'id', d'où l'erreur.
//              --> Il faut donc mettre l'annotation '@XmlAttribute' sur le getter du champs 'id', pour que cela fonctionne.
//      - Si nous souhaitons tout de même annoter les champs de la classe, ce qui est tout de même pratique, nous pouvons le préciser à JAX-B avec l'annotation '@XmlAccessorType(XmlAccessType.FIELD)'.
//          --> A présent, cela fonctionne convenablement, car JAX-B sait qu'il doit chercher les champs et non les getters et les setters, et notre annotation '@XmlAttribute' se trouve bien sur un champs.
//      - Une autre annotation importante est '@XmlType(propOrder = {champs, champs, ..., champs})'. En effet nous savons qu'en XML, l'ordre des sous-éléments au sein d'un élément à son importance.
//          --> Si nous inversons l'order des champs dans cette annotation, cet inversement est bien respecté dans son affichage dans le navigateur.
//      --> C'est donc à l'aide de cet API, JAX-B que nous pouvons expliquer à JAX-RS comment transformer un bean Java en un document XML.
// -----------
// Toujours sur l'utilisation de JAX-B, nous allons voir comment créer des fichiers XML à partir de bean Java.
//      - Nous allons commencer par se créer un package 'org.vitu.main' dans lequel nous allons créer une classe 'Main', avec une méthode 'main(String... args)'.
//          Cette classe 'Main' va être embarquée dans notre application, personne ne va l'appeler dans GlassFish, mais nous pouvons l'appeler dans notre IDE.
//      - Nous pouvons nous créer un objet de type 'JAXBContext', en appeleant la méthode 'newInstance()', et en lui passant une classe en paramètre.
//          A partir de ce dernier nous pouvons nous créer un objet de type 'Marshaller'.
//      - Une fois ce Marshaller créé, nous pouvons lui assigner des paramètres à l'aide de la méthode 'setProperty()', qui prends pour paramètre la propriété souhaitée et sa valeur.
//          Nous lui mettons par exemple 'setProperty("jaxb.encoding", "utf-8")' pour avoir de l'utf-8 sur notre fichier de sortie.
//          Nous mettons aussi 'setProperty("jaxb.formatted.output", true)', afin que le fichier de sortie soit lisible et indenté pour faciliter la lecture par la personne le visionnant.
//      - Enfin, nous allons pouvoir marshaller un fichier XML avec la méthode 'marshal()', qui prends en paramètre un objet de type 'User', et le fichier XML que nous voulons créer.
//          --> En exécutant la méthode main, un fichier XML est créé contenant le bean User avec les bons champs et les valeurs souhaitées.
// -----------
// Pour finir sur l'utilisation de JAX-B, nous pouvons aussi créer un Unmarshaller.
//      - Ceci ce fait aussi à partir de l'objet 'JAXBContext', en utilisant la méthode 'createUnmarshaller()'.
//          A partir de ce dernier, nous pouvons utiliser la méthode 'unmarshal()', en lui passant le fichier XML à unmarshaller, en le castant dans un objet de type 'User'.
//      - Ainsi, nous pouvons lui passer le fichier que nous venons de créer en paramètre puis exécuter la méthode main.
//          --> A présent, le User qui est contenu dans le fichier XML est bien imprimé sur la console.
// --> Pour information, il existe une API JSON-B qui permet d'effectuer la même chose que JAX-B, mais vers des dociments de type JSON.
// -----------
// Nous avons à présent vu la requête GET, qui est la plus simple du protocole HTTP, c'est par ailleurs celle qui est utilisée par défaut par les navigateurs.
// Si nous voulons créer des requêtes POST, PUT et même DELETE, il faut commencer à écrire des clients, ou a utiliser des applications clientes 'à la main'.
// Il existe un outil qui s'appelle POSTMAN, qui permet de créer des requêtes HTTP en fixant la méthode HTTP que nous voulons utiliser.
// Il permet aussi de fixer les paramètres que nous voulons mettre dans le header, les entités en XML, en JSON etc.
// Il faut savoir qu'une requête sur un service REST peut résulter en d'autres requêtes sur d'autres services REST, tant que ceux-ci se trouvent à l'intérieur du premier service REST.
// C'est pourquoi nous devons pour ce faire, utiliser un client, qui pourrait par exemple être POSTMAN.
//          --> Nous allons utiliser l'application 'client' de JAX-RS.
//      - Nous allons commencer par nous créer une nouvelle classe 'PlayWithClient' dans notre package 'main', qui elle aussi possède une méthode main.
//          Dans cette dernière, nous allons créer un objet de type 'Client', provenant du package 'javax.ws.rs.client', à l'aide de la méthode 'newClient()' sur un objet de type 'ClientBuilder'.
//          Nous allons pouvoir dire à ce client de faire des requêtes particulières sur des cibles, donc sur des URL particulières, ces dernières modélisées par des objets de type 'WebTarget'.
//      - Nous pouvons ainsi créer un objet 'host' de type 'WebTarget' en appliquant la méthode 'target()' sur notre objet de type 'Client'.
//          Ce faisant, en lui passant en paramètre l'URL souhaité 'http://localhost:8080/play-with-java-ee/rest'.
//      - Ensuite, en invoquant la méthode 'path()' sur notre objet 'host', nous pouvons ajouter à ce path 'user/{id}' et créer un objet de type 'WebTarget' contenant l'URL complète.
//          --> Pour remplir le paramètre variable 'id', il nous suffit d'appliquer la méthode 'resolveTemplate()', avec pour paramètres 'id', et la valeur que nous souhaitons lui assigner.
//              Nous avons à présent notre URL complet avec la variable remplie.
//      - Pour nous créer un objet de type 'Response', nous devons appliquer les méthodes 'request()', puis 'get()' (le type de requête HTTP souhaité) à la suite sur notre objet 'WebTarget' final.
//          A partir de cet objet de type 'Response', nous pouvons appliquer les méthodes vues précédemment pour en obtenir le statut ou encore l'entité qui résulte de cette requête.
//      - Si nous voulions changer le type de requête HTTP, il nous suffit de remplacer la méthode 'get()' par la méthode 'post()' par exemple sur notre objet de type 'WebTarget'.
//          Toutefois, avec une méthode de type 'post()', équivalent à une requête de type POST, il nous faut lui passer en paramètre un objet de type 'Entity'.
//      - Ainsi, nous pouvons créer un objet de type 'Entity<User>' en appliquant la méthode 'entity()' qui prends deux paramètres.
//          Le premier étant l'objet passé, donc dans notre cas c'est 'user', et dans le second nous pouvons lui préciser le type de media par lequel il sera transmis 'MediaType.APPLICATION_JSON'.
//          --> Ceci signifie que sur notre client, nous allons avoir besoin d'une méthode POST, qui va accepter un bean de type 'User', en tant qu'entité HTTP.
//      - Donc, nous pouvons retourner dans notre classe 'UserRS', et créer une nouvelle méthode, qui sera annotée par l'annotation '@POST'.
//          Nous n'avons pas besoin de lui ajouter une annotation '@Path', étant donné que c'est une méthode HTTP différente, nous n'avons pas besoin d'avoir un '@Path' qui le différencie des autres.
//          Toutefois, nous pouvons ajouter l'annotation '@Consumes(MediaType.APPLICATION_JSON)'. Nous pouvons ainsi passer un objet de type 'User' à notre méthode.
//          Tout comme notre méthode '@GET', elle va retourner un objet de type 'Response' que nous allons pouvoir construire.
//          A cet objet, nous lui appliquons la méthode 'status(Status.CREATED)', vu que les méthodes HTTP POST effectuent des créations, puis nous lui appliquons la méthode 'build()'.
//          --> A noter, que si nous devions ajouter des modifications de la base de données, ce serait dans cette méthode, avant de retourner l'objet de type 'Response'.
//          Enfin, avant de lancer notre requête, nous devons ajouter un nouvel objet de type 'WebTarget' dans la méthode main, car l'URL du POST sera différent de celui du GET, contenant la variable id.
//          --> Comme nous avons des problèmes avec le type fourni, nous ajoutons aussi le format XML à notre méthode 'create()' : '@Consumes({MediaType.APPLICATION_JSON, MediaType.TEXT_XML})'.
//              Effectivement, une même méthode HTTP peut recevoir différents types de formats d'entité, donc cela ne pose pas de problèmes.
//      - Puisque nous avons des problèmes dû à une dépendance manquante : JSONP, nous allons effectuer le POST 'à l'ancienne'.
//          Pour ce faire, nous créons un nouveau fichier HTML dans le dossier 'WebContent', que nous nommons 'user.html'.
//          Dans ce dernier, nous ajoutons un formulaire, ayant pour 'action', 'rest/user', et pour 'method', 'post'.
//          Ensuite, nous créons un tableau, contenant une ligne pour le nom et une ligne pour l'âge, avec un bouton submit.
//      - A présent, nous devons aller dans notre classe 'UserRS', et modifier le paramètre 'MediaType' de l'annotation '@Consumes'. A présent, elle va être de type 'APPLICATION_FORM_URLENCODED'.
//          De plus, la méthode ne prendra plus d'objet de type 'User' en paramètre, mais chacun des champs du formulaire un par un.
//          Ainsi, nous devons mettre en paramètre de la méthode, deux objets annotés par '@FormParam()'. Il nous suffit ensuite de créer un objet de type 'User' avec ces paramètres.
//          Ensuite, nous pouvons ajouter à l'objet de type 'Response' la méthode 'entity(user)', de sortes à bien afficher le nouvel objet User dans la réponse.
//          Enfin, nous pouvons ajouter l'annotation '@Produces(MediaType.TEXT_XML)' sur notre méthode 'create()' pour bien préciser le type de document à fournir en sortie de la méthode.
//      - Ainsi, si nous naviguons sur la page 'http://localhost:8080/play-with-java-ee/user.html', nous pouvons entrer un nom et un âge pour créer un objet de type 'User' via la méthode HTML POST.
//          Lorsque nous appuyons sur 'ok', la page 'http://localhost:8080/play-with-java-ee/rest/user' s'ouvre à présent et affiche le document XML de l'objet de type 'User' qui vient d'être créé.
// --> Nous avons créé une méthode GET, une méthode POST, nous avons joué avec le type d'éléments consommés et le type d'éléments produits, ainsi qu'avec le type de réponses générées.
// -----------
// Maintenant nous allons connecter notre application web à une base de données, et voir comment utiliser JPA et JAX-RS. Nous allons effectuer cela uniquement avec la méthode HTTP GET.
//      - Pour commencer, nous allons copier la classe 'CommuneRS', et la coller au même endroit sous le nom 'CommuneWithJPARS'. Nous travaillerons sur cette dernière classe.
//          Lorsque nous sommes dans un service REST, nous avons deux manières de faire de la persistence, l'une avec le framework EJB, l'autre avec le framework CDI.
//          Ces deux framework, dans un cas comme dans l'autre, vont nous permettre d'utiliser JPA, et donc un EntityManager, pour aller faire nos requêtes en base de données.
//          Il faut toutefois bien comprendre que nous ne sommes plus dans un univers Java SE, nous sommes en Java EE, ce qui signifie que nous ne créons pas nos connections aux bases de données à la main.
//          En Java EE, nous devons expliquer au serveur, comment il peut se connecter à la base de données. C'est donc le serveur d'application qui va se connecter à la base de données.
//          Le serveur d'application va créer une réserve de connection, ouverte en permanence à la base de données, connections qu'il va pouvoir distribuer aux différents services que nous allons créer.
//      - Pour faire cela, il faut indiquer à GlassFish que nous voulons ajouter des connections à une base de données, via l'IHM de GlassFish sur l'URL : 'http://localhost:4848/'.
//          Dans le menu de gauche, nous avons un onglet 'JDBC', qui contient 'JDBC Resources' ainsi que 'JDBC Connection Pools'.
//              --> Il faut commencer par configurer les connection pools, puis ensuite les resources. C'est sur cette liste de ressources que notre application va se connecter et faire des requêtes.
//      - Attention : Par défaut, GlassFish connaît les bases de données 'MySQL', mais il ne possède pas le driver 'MySQL', qui est pourtant indispensable à la configuration. Il faut donc le lui indiquer.
//          - Nous pouvons le récupérer dans le dossier de stockage de Maven : 'User'> .m2 > repository > mysql > mysql-connector-java > 'mysql-connector-java-501044.jar'.
//              Sinon, nous pouvons le récupérer sur 'https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.44/'.
//          - Ensuite, il nous suffit de le coller dans le dossier 'lib' se trouvant dans le dossier GlassFish 'C:\Users\Emile\Desktop\JAVA\java-util\glassfish5\glassfish\lib'.
//          - Maintenant, il nous faut redémarrer GlassFish pour le rafraichir, afin qu'il trouve la nouvelle dépendance.
//              En démarrant, il va découvrir les classes pour se connecter à MySQL, donc le driver JDBC pour MySQL, et c'est ce que nous allons utiliser pour se connecter à notre base de données.
//          - A présent, dans notre IHM, nous pouvons sélectionner 'JDBC Connection Pools' dans le menu 'JDBC'. Ceci nous montre une liste de deux éléments.
//              Ces deux éléments correspondent à deux pools de connections qui sont déjà définies, une vers une base de données qui s'appelle 'Derby', et une autre.
//              --> Ces deux ressources ne sont pas vraiment des connections, ce sont des 'DataSources' qui ne sont pas exactement des connections mais se comportent similairement.
//          - Nous allons créer un nouveau 'Connection Pool', en cliquant sur 'New' :
//              - Pool Name : 'MySQLPool'.
//              - Resource Type : 'javax.sql.DataSource'.
//              - Database Driver Vendor : 'MySql'.
//                  --> Nous pouvons passer à la page suivante en cliquant sur 'Next'.
//                  --> A noter que GlassFish, sait déjà quoi faire si la base de données est une MySQL (ou plusieurs autres types de base de données), mais il faut quand même lui fournir le driver.
//          - Une fois arrivés sur la seconde et dernière page, nous allons garder toute la partie supérieure de la page telle qu'elle est par défaut.
//              --> A présent il nous faut voir parmi les deux cents et quelques options, lesquelles nous voulons garder.
//                  Effectivement, il nous faut configurer 'User', 'Password', 'DatabaseName' et 'URL'. En effectuant des recherches sur la page, nous pouvons retrouver les champs souhaités.
//              - Ensuite, nous pouvons remplir chacun des champs avec les données de notre précédent fichier 'persistence.xml' ou des paramètres de notre base de données.
//                  A noter que l'URL est légèrement différent car il a un préfixe particulier à GlassFish : 'jdbc:mysql://localhost:3306/db_jpa'.
//              - Puis nous pouvons cliquer sur 'Finish' : 'MySQLPool' est ajoutée à la liste des JDBC Connection Pools.
//              - Si nous cliquons sur notre nouvelle pool, nous avons une page sur laquelle nous avons plusieurs boutons, dont un bouton 'Ping'.
//                  Ce dernier va tester pour voir si notre pool réussit à se connecter à notre base de données. Une popup 'Ping Succeeded' apparaît lorsque c'est bon.
//              - Si nous allons dans l'onglet 'Advanced' de notre MySQLPool, nous pouvons voir plus en détail ce qu'il s'y passe, notamment en cas d'erreur.
//      - Seconde partie, il nous faut à présent configurer notre fichier 'persistence.xml' dans notre application Java.
//          - Pour commencer, il nous faut ajouter nos trois '<class>' persistées qui nous proviennent du package 'org.vitu.model', par rapport aux fichiers persistence.xml que nous avons vu précédemment.
//              Celui-ci doit être rangé dans le dossier 'META-INF', déjà existant dans le dossier 'WebContent' de l'arborescence de notre application web.
//              Nous configurons le fichier 'persistence.xml' avec EclipseLink car celui-ci est préinstallé dans GlassFish, ce qui facilite la vie, et nous évite des configurations supplémentaires.
//              Si nous voulions utiliser Hibernate, tout comme nous l'avons fait avec MySQL, il nous faudrais récupérer tous les fichiers .jar d'Hibernate, et les déposer dans le dossier de GlassFish.
//          - Dans le '<persistence-unit>', nous déclarons les classes persistentes, et nous pouvons enlever les propriétés de connections vu qu'elles sont déjà configurées dans l'IHM de GlassFish.
//              Donc, nous pouvons retirer les propriétés Driver, URL, utilisateur et mot de passe. Car ce n'est pas notre application qui va se connecter à la base de données.
//              Effectivement, notre application web va demander l'autorisation de se connecter à GlassFish, qui va dispatcher des connections de sa Connection Pool.
//          - Dans GlassFish, nous avons configuré la connection, mais nous ne l'avons pas exposée en tant que ressource Java EE.
//              Dans l'IHM GlassFish : JDBC > JDBC Resources > New > 'jdbc/MySQLDS' pour MySQL Data Source, puis nous sélectionnons notre pool récemment créée > Ok > Notre nouvelle ressource apparaît.
//              Le nom 'jdbc/MySQLDS', est un nom 'JNDI', ce qui est une des specs Java EE, 'Java Naming Directory Interface'.
//              En fait, c'est un annuaire de toutes les ressources, donc de tout ce qui existe dans un serveur Java EE, et qui est exposée sous forme de paire clef / valeur.
//              Donc, le nom JNDI va être la clef, et la pool de connection sera sa valeur. Ainsi, nous pourrons faire une requête vers cet annuaire avec ce nom pour récupérer notre pool de connection.
//          - Maintenant que notre ressource est exposée dans cet annuaire de ressources, nous allons pouvoir la référencer dans notre fichier persistence.xml.
//              Après l'élément '<provider>', nous pouvons ajouter une balise '<jta-data-source>', et lui donner pour valeur, notre nom JNDI.
//              Ceci permet d'expliquer à notre unité de persistence, comment elle doit se connecter à la base de données.
//          - Les deux '<property>' restantes concernent EclipseLink et ses propriétés de connection à la base de données.
//              La première lui indique de se connecter sans toucher aux tables de la base de données.
//              La seconde lui indique quel type de base de données est concernée par cette unité de persistence pour pouvoir y adapter son langage, ici, c'est donc 'MySQL'.
// -----------
// Maintenant, comment allons-nous pouvoir utiliser la base de données dans notre application ?
//      - De retour dans notre classe 'CommuneRS', nous allons faire quelque chose qui est commun à Spring et à Java EE, qui s'appelle l'injection de dépendances.
//          C'est à dire que nous allons supposer que nous avons une classe, 'CommuneEJB', EJB pour 'Enterprise Java Bean', que nous allons créer.
//          Les EJB sont sensés supporter toutes les opérations de persistence.
//          Donc toutes les opérations avec la base de données. Ces dernières, nous n'allons pas les faire dans notre service REST, nous pourrions, mais ce n'est pas une bonne pratique.
//          Nous allons plutôt les déléguer dans un autre objet, dont la spécialisation va être de mener à bien ces opérations de persistence.
//          Donc nous allons créer une méthode 'findById(codePostal)' sur notre objet de type 'CommuneEJB', qui nous retournera un objet de type 'Commune'.
//          Ce dernier sera renvoyé avec la réponse en tant que paramètre de la méthode 'ok()' sur l'objet de type 'Response' retourné, avant de lui appliquer la méthode 'build()'.
//      - Il nous manque à créer dans notre classe 'CommuneEJB', la méthode 'findById(codePostal)' qui retourne un objet de type 'Commune'.
//          Pour ce faire, il nous faut créer un 'EntityManager', sur lequel nous appelons simplement la méthode 'find()', en lui passant 'Commune.class', ainsi que 'codePostal'.
//          - Si nous exécutons les choses comme cela, ça ne fonctionnera pas, il nous faut dans la classe appelante donc, dans 'CommuneRS', annoter la déclaration de veriable avec l'annotation '@EJB'.
//              Ainsi, ce sera le serveur Java EE qui va créer cette instance d'objet de type 'CommuneEJB'. Ce qui va le créer sera JAX-RS et Java EE.
//                  --> Donc le serveur Java EE va suivre une procédure et regarder les champs un par un, voir si ils ont des annotations.
//                      Donc lorsqu'il voit l'annotation '@EJB', il sait que lorsqu'il créé une instance de 'CommuneRS', il va aussi devoir créer une instance de 'CommuneEJB'.
//                      Pour ce faire, nous devons aussi ajouter l'annotation '@Stateless' sur la classe 'CommuneEJB'.
//          - Enfin, il nous faut aussi ajouter l'annotation '@PersistenceContext(unitName = "jpa-java-ee")' sur l'EntityManager de la classe 'CommuneEJB'.
//              Ainsi, lorsque JAX-RS va trouver aussi cette annotation, vérifier qu'il existe bien une unité de persistence avec ce nom, puis créer un EntityManagerFactory.
//              A partir de ce dernier, il va créer un EntityManager, qu'il va insérer dans le champs de la classe qui a été annotée.
//              Ainsi, lorsque nous allons appeler la méthode utilisant l'EntityManager, ce dernier ne sera pas null.
//                  --> Ce mécanisme qui consiste à instancier soi-même des classes, donc de créer des objets, puis de les ranger dans des champs, s'appele l'INJECTION DE DEPENDANCES.
//      - A présent, nous pouvons republier sur le serveur GlassFish, et nous pouvons essayer de requêter un code postal avec l'URL 'http://locolhost:8080/play-with-java-ee/rest/commune/75000'.
//          --> Toutefois cela ne fonctionne pas, car l'unité de persistence n'est pas reconnue.
//              Effectivement, nous avions laissé '<persistence-unit name="jpa-java-ee" transaction-type="RESOURCE_LOCAL">', or nous ne sommes plus en ressources locales.
//                  --> Il nous faut donc mettre à présent '<persistence-unit name="jpa-java-ee" transaction-type="JTA">'.
//          - Maintenant, nous avons toujours une erreur, car le fichier 'persistence.xml', n'est pas trouvé.
//              Il faut donc le déplacer dans un nouveau dossier 'META-INF' qui se trouve dans le dossier 'src', et donc déplacer notre fichier persistence.xml à l'intérieur de ce dernier.
//          - A présent, nous avons une 'StackOverflow' error, car 'Commune' référence 'Maire' et 'Departement', et que 'Maire' et 'Departement' connaissent leurs commune.
//              De plus, nous demandons du JSON par défaut, alors que nous n'avons rien configuré dans ces classes.
//                  --> Donc nous pouvons indiquer à notre méthode 'findById()' l'annotation '@Produces(MediaType.TEXT_XML)', pour le forcer à produire du XML et plus du JSON.
//                  --> Aussi, nous devons configurer JAXB dans notre classe 'Commune', pour préparer le formattage en XML de cet objet lorsqu'il est requété par notre service REST.
//                          - '@XmlRootElement', sur le nom de la classe, pour indiquer que cette classe représente un document XML.
//                          - '@XmlType(propOrder = {"nom", "population"})', sur le nom de la classe, pour indiquer l'ordre des champs.
//                          - '@XmlAccessorType(XmlAccessType.FIELD)', sur le nom de la classe, pour préciser que ce sont les champs et non les getters ou setters qui vont représenter les éléménts du XML.
//                          - '@XmlAttribute(name = "code-postal")', sur le champs 'codePostal', pour indiquer que ce champs est un attribut de l'élément XML 'Commune', et non un sous-élément.
//                          - '@XmlElement', sur le champs 'nom', pour indiquer que ce champs est un sous-élément de l'élément 'Commune'.
//                          - '@XmlTransient', sur les champs 'Maire' et 'Departement', pour indiquer qu'il faut ignorer ces deux champs.
//          - Maintenant, cela fonctionne, toutefois, si nous entrons dans la requête HTTP un code postal qui n'existe pas, une page vide s'affiche, nous préfèrerions avoir un message d'erreur HTTP.
//              Pour ce faire, il nous suffit d'ajouter une condition avec commune égal à null dans notre méthode pour envoyer une réponse avec un status not found (erreur 404).
//          --> A présent, nous avons connecté notre service REST à une base de données.
//      --> Les EJB sont très pratiques, car systématiquement, toutes les méthodes de nos EJB sont appelées par défaut dans le contexte d'une transaction, même des CREATE, DELETE...
//          Toutefois, les EJB ont une très mauvaise réputation, il existe des méthodes plus pratiques et moins complexes à débuger.
// -----------
// Comment est-ce que nous préfererions effectuer aujourd'hui ces opérations de persistence ? Nous préfererons les effectuer avec CDI, qui veut dire 'Context and Dependency Injection'.
// CDI est l'injecteur de dépendance par défaut utilisé par Java EE actuellement.
//      - Nous créons un nouvel objet de type 'CommuneService' dans notre classe 'CommuneRS', puis nous créons cette classe dans le package 'org.vitu.cdi'.
//          Dans cette classe, nous mettons exactement la même chose que dans la classe 'CommuneEJB'.
//          Toutefois, nous n'avons pas besoin d'annoter la classe 'CommuneService' en elle-même, comme nous le faisions avec les EJB.
//      - Dans notre classe 'CommuneRS', au lieu d'annoter notre nouvel objet de type 'CommuneService', avec l'annotation '@EJB', nous l'annotons avec l'annotation '@Inject'.
//          De plus nous devons créer un fichier 'beans.xml' de configuration, que nous mettons dans le dossier 'META-INF' de notre web application, contenant uniquement '<beans />'.
//      --> La différence fondamentale entre CDI et les EJB est que CDI n'utilise pas de méthode automatiquement transactionnelles.
//          Donc toutes les méthodes de modifications de données dans la base de données vont devoir être mises nécessairement dans une transaction.
//              --> Pour rendre une méthode transactionnelle, c'est très simple, il nous suffit de l'annoter avec l'annotation '@Transactional' du package 'javax.transaction'.
//              --> Nous pouvons aussi mettre '@Transactional' directement sur la classe, pour que toutes les méthodes de la classe soient transactionnelles.
//      - Pourquoi est-ce que les développeurs préfèrent CDI aux EJB ? Il y a plusieurs raisons à cela.
//          - Déjà, CDI n'a pas la mauvaise réputation qu'ont les EJB.
//          - La seconde chose est qu'avec CDI, nous pouvons faire beaucoup plus de choses qu'avec les EJB.
//              Certaines choses faites par les EJB ne peuvent pas être faites par CDI, mais ce sont des choses très peu utilisées, voire obsolètes.
//          - Notamment, CDI sait faire des providers, qui est une classe qui peut construire d'autres classes.
//              Nous pouvons en voir l'exemple en créant un package 'org.vitu.cdi.provider', et en y créant une classe 'EntityManagerProvider', que nous annotons par '@Stateless' pour en faire un EJB.
//              Ceci nous est utile car ainsi, nous pouvons avoir l'injection de dépendance pour créer le '@PersistenceContext'.
//              Nous pouvons ajouter l'annotation '@Produces' provenant du package 'javax.enterprise.inject.Produces', ainsi le champs annoté, ici l'EntityManager, devient un champs producteur CDI.
//                  --> A présent, nous pouvons simplement remplacer dans notre classe 'CommuneService' l'annotation '@PersistenceProvider' par '@Inject'sur l'EntityManager.
//                      Ainsi, CDI va chercher les providers qu'il connaît, et il va pouvoir invoquer celui que nous avons créé dans la classe 'EntityManagerProvider'.
// -----------
// Dernière chose à propos des web services. Attention, ceux-ci n'utilisent pas le protocole HTTP.
//      - Nous allons créer tout d'abord un package 'org.vitu.ws', dans lequel nous allons créer la classe 'CommuneWebService'.
//          Nous pouvons l'annoter de l'annotation '@WebService', provenant du package 'javax.jws.WebService'.
//      - Nous allons y faire le même genre de chose que dans notre classe 'CommuneRS', c'est à dire que nous allons injecter un '@EJB' de type CommuneEJB.
//          Aussi, nous allons y créer une méthode retournant une Commune, se nommant 'findById(String codePostal)', retournant le résultat de 'communeEJB.findById(codePostal)'.
//          Enfin, nous pouvons annoter cette méthode, de l'annotation '@WebMethod', provenant de 'javax.jws.WebMethod'.
//      - Maintenant nous pouvons redéployer. Or, comme les web services sont construits sur des posts, et ne sont pas construits sur le protocole HTTP.
//          Pour le voir, nous pouvons aller dans l'IHM de GlassFish > Applications > play-with-java-ee > CommuneWebService, View Endpoint > Tester > http://.
//          Sur la page qui s'ouvre, nous avons les méthodes de notre web service, donc pour nous, seulement 'findById()', à laquelle nous pouvons passer notre String codePostal et lancer la requête.
//          Celui-ci va nous retourner un document XML nous montrant la requête, et le XML retourné par cette requête, donc la commune correspondant au code postal passé en paramètre.
//      - Nous pouvons aussi nous créer une seconde méthode, additionnant deux int, en l'annotant avec '@WebMethod'.
//          Le problème est que ceci est très gourmand en mémoire, car les XML sont assez lourds.
//          Par exemple ici, pour retourner un entier, qui fait à peu près 4 octets (2 octets par caractère), nous utilisons un XML de 350 caractères, soit 700 octets.
// -----------
//      <?xml version="1.0" encoding="UTF-8" ?>
//      <persistence
// 	        xmlns="http://xmlns.jcp.org/xml/ns/persistence"
// 	        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
// 	        xsi:schemaLocation=
// 		        "http://xmlns.jcp.org/xml/ns/persistence
// 		        http://xmlns.jcp.org/xml/ns/persistence/persistence_2_2.xsd"
// 	        version="2.2">
// 	        <persistence-unit name="jpa-java-ee" transaction-type="JTA">
// 		        <provider>org.eclipse.persistence.jpa.PersistenceProvider</provider>
// 		        <jta-data-source>jdbc/MySQLDS</jta-data-source>
// 		        <class>org.vitu.model.Maire</class>
// 		        <class>org.vitu.model.Departement</class>
// 		        <class>org.vitu.model.Commune</class>
// 		        <properties>
// 			        <!-- validate | update | create | create-drop | none -->
// 			        <property name="eclipselink.ddl-generation"
// 					        value="none" />
// 			        <property name="eclipselink.target-database" value="MySQL" />
// 		        </properties>
// 	        </persistence-unit>
//      </persistence>
// -----------
//      <beans />
// -----------
//      <?xml version="1.0" encoding="UTF-8"?>
//      <!DOCTYPE glassfish-web-app PUBLIC "-//GlassFish.org//DTD GlassFish Application Server 3.1 Servlet 3.0//EN" "http://glassfish.org/dtds/glassfish-web-app_3_0-1.dtd">
//      <glassfish-web-app>
//          <context-root>/play-with-java-ee</context-root>
//      </glassfish-web-app>
// -----------
//      package org.vitu.model.temp;
//      import javax.xml.bind.annotation.XmlAccessType;
//      import javax.xml.bind.annotation.XmlAccessorType;
//      import javax.xml.bind.annotation.XmlAttribute;
//      import javax.xml.bind.annotation.XmlRootElement;
//      import javax.xml.bind.annotation.XmlType;
//      @XmlRootElement
//      @XmlAccessorType(XmlAccessType.FIELD)
//      @XmlType(propOrder = {"age", "nom"})
//      public class User {
// 	        @XmlAttribute(name = "id")
// 	        private long id;
// 	        private String nom;
// 	        private int age;
// 	        public User() {
// 		        super();
// 	        }
// 	        public User(long id, String nom, int age) {
// 		        this.id = id;
// 		        this.nom = nom;
// 		        this.age = age;
// 	        }
// 	        // @XmlAttribute(name = "id")
// 	        public long getId() {
// 		        return id;
// 	        }
// 	        public void setId(long id) {
// 		        this.id = id;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public int getAge() {
// 		        return age;
// 	        }
// 	        public void setAge(int age) {
// 		        this.age = age;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "User [id=" + id + ", nom=" + nom + ", age=" + age + "]";
// 	        }
//      }
// -----------
//      package org.vitu.model;
//      import java.io.Serializable;
//      import java.util.Date;
//      import javax.persistence.CascadeType;
//      import javax.persistence.Column;
//      import javax.persistence.Entity;
//      import javax.persistence.GeneratedValue;
//      import javax.persistence.GenerationType;
//      import javax.persistence.Id;
//      import javax.persistence.OneToOne;
//      import javax.persistence.Temporal;
//      import javax.persistence.TemporalType;
//      @Entity(name = "maire")
//      public class Maire implements Serializable {
// 	        @Id @GeneratedValue(strategy = GenerationType.SEQUENCE)
// 	        private int id;
// 	        @Column(nullable = false, length = 80)
// 	        private String nom;
// 	        @Column(length = 80)
// 	        private String prenom;
//      //	@Column(length = 5)
//      //	@Enumerated(EnumType.STRING)
//      //	private Civilite civilite;
// 	        @OneToOne(cascade = CascadeType.PERSIST, mappedBy = "maire")
// 	        private Commune commune;
// 	        @Temporal(TemporalType.DATE)
// 	        private Date dateDeNaissance;
// 	        public Maire() {
// 	        }
// 	        public Maire(int id, String nom, String prenom,
// 			        // Civilite civilite,
// 			        Commune commune, Date dateDeNaissance) {
// 		        this.id = id;
// 		        this.nom = nom;
// 		        this.prenom = prenom;
// 		        // this.civilite = civilite;
// 		        this.commune = commune;
// 		        this.dateDeNaissance = dateDeNaissance;
// 	        }
// 	        public int getId() {
// 		        return id;
// 	        }
// 	        public void setId(int id) {
// 		        this.id = id;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public String getPrenom() {
// 		        return prenom;
//          }
// 	        public void setPrenom(String prenom) {
// 		        this.prenom = prenom;
// 	        }
//      //	public Civilite getCivilite() {
//      //		return civilite;
//      //	}
//      //	public void setCivilite(Civilite civilite) {
//      //		this.civilite = civilite;
//      //	}
// 	        public Commune getCommune() {
// 		        return commune;
// 	        }
// 	        public void setCommune(Commune commune) {
// 		        this.commune = commune;
// 	        }
// 	        public Date getDateDeNaissance() {
// 		        return dateDeNaissance;
// 	        }
// 	        public void setDateDeNaissance(Date dateDeNaissance) {
// 		        this.dateDeNaissance = dateDeNaissance;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Maire [id=" + id + ", nom=" + nom + ", prenom=" + prenom + ", commune=" + commune + ", dateDeNaissance="
// 				        + dateDeNaissance + "]";
// 	        }
//      }
// -----------
//      package org.vitu.model;
//      import java.io.Serializable;
//      import java.util.ArrayList;
//      import java.util.List;
//      import javax.persistence.Column;
//      import javax.persistence.Entity;
//      import javax.persistence.Id;
//      import javax.persistence.OneToMany;
//      @Entity
//      public class Departement implements Serializable {
// 	        @Id @Column(length = 4)
// 	        private String codeDepartement;
// 	        @Column(length = 40, nullable = false)
// 	        private String nom;
// 	        @OneToMany(mappedBy = "departement")
// 	        private List<Commune> communes = new ArrayList<>();
// 	        public Departement() {
// 	        }
// 	        public Departement(String codeDepartement, String nom, List<Commune> communes) {
// 		        this.codeDepartement = codeDepartement;
// 		        this.nom = nom;
// 	        }
// 	        public String getCodeDepartement() {
// 		        return codeDepartement;
// 	        }
// 	        public void setCodeDepartement(String codeDepartement) {
// 		        this.codeDepartement = codeDepartement;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public void addCommune(Commune commune) {
// 		        this.communes.add(commune);
// 		        commune.setDepartement(this);
// 	        }
// 	        public List<Commune> getCommunes() {
// 		        return new ArrayList<>(this.communes);
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Departement [codeDepartement=" + codeDepartement + ", nom=" + nom + "]";
// 	        }
//      }
// -----------
//      package org.vitu.model;
//      import java.io.Serializable;
//      import javax.persistence.CascadeType;
//      import javax.persistence.Column;
//      import javax.persistence.Entity;
//      import javax.persistence.Id;
//      import javax.persistence.ManyToOne;
//      import javax.persistence.NamedQueries;
//      import javax.persistence.NamedQuery;
//      import javax.persistence.OneToOne;
//      import javax.persistence.Table;
//      import javax.xml.bind.annotation.XmlAccessType;
//      import javax.xml.bind.annotation.XmlAccessorType;
//      import javax.xml.bind.annotation.XmlAttribute;
//      import javax.xml.bind.annotation.XmlElement;
//      import javax.xml.bind.annotation.XmlRootElement;
//      import javax.xml.bind.annotation.XmlTransient;
//      import javax.xml.bind.annotation.XmlType;
//      @NamedQueries({
// 	        @NamedQuery(
// 		        name = "Commune.byPopulationMin",
// 		        query = "select c.nom, c.population from Commune c where c.population > :pop_min"
// 	        )
//      })
//      @Entity(name = "Commune")
//      @Table(name = "commune")
//      @XmlRootElement
//      @XmlType(propOrder = {"nom", "population"})
//      @XmlAccessorType(XmlAccessType.FIELD)
//      public class Commune implements Serializable {
// 	        @Id @Column(length = 8)
// 	        @XmlAttribute(name = "code-postal")
// 	        private String codePostal;
// 	        @Column(length = 80)
// 	        @XmlElement
// 	        private String nom;
// 	        @OneToOne(cascade = CascadeType.PERSIST)
// 	        @XmlTransient
// 	        private Maire maire;
// 	        @ManyToOne()
// 	        @XmlTransient
// 	        private Departement departement;
// 	        private int population;
// 	        public Commune() {
// 	        }
// 	        public Commune(String codePostal, String nom, int population) {
// 		        this.codePostal = codePostal;
// 		        this.nom = nom;
// 		        this.population = population;
// 	        }
// 	        public String getCodePostal() {
// 		        return codePostal;
// 	        }
// 	        public void setCodePostal(String codePostal) {
// 		        this.codePostal = codePostal;
// 	        }
// 	        public String getNom() {
// 		        return nom;
// 	        }
// 	        public void setNom(String nom) {
// 		        this.nom = nom;
// 	        }
// 	        public Maire getMaire() {
// 		        return maire;
// 	        }
// 	        public void setMaire(Maire maire) {
// 		        this.maire = maire;
// 	        }
// 	        public Departement getDepartement() {
// 		        return departement;
// 	        }
// 	        public void setDepartement(Departement departement) {
// 		        this.departement = departement;
// 	        }
// 	        public int getPopulation() {
// 		        return population;
// 	        }
// 	        public void setPopulation(int population) {
// 		        this.population = population;
// 	        }
// 	        @Override
// 	        public String toString() {
// 		        return "Commune [codePostal=" + codePostal + ", nom=" + nom + ", maire=" + maire + ", departement="
// 				        + departement + ", population=" + population + "]";
// 	        }
//      }
// -----------
//      package org.vitu.ejb;
//      import javax.ejb.Stateless;
//      import javax.persistence.EntityManager;
//      import javax.persistence.PersistenceContext;
//      import org.vitu.model.Commune;
//      @Stateless
//      public class CommuneEJB {
// 	        @PersistenceContext(unitName = "jpa-java-ee")
// 	        private EntityManager em;
// 	        public Commune findById(String codePostal) {
// 		        return em.find(Commune.class, codePostal);
// 	        }
//      }
// -----------
//      package org.vitu.main;
//      import javax.ws.rs.client.Client;
//      import javax.ws.rs.client.ClientBuilder;
//      import javax.ws.rs.client.Entity;
//      import javax.ws.rs.client.WebTarget;
//      import javax.ws.rs.core.MediaType;
//      import javax.ws.rs.core.Response;
//      import org.vitu.model.temp.User;
//      public class PlayWithClient {
// 	        public static void main(String[] args) {
// 		        Client client = ClientBuilder.newClient();
// 		        WebTarget host = client.target("http://localhost:8080/rest");
//      //		WebTarget userGetPath = host.path("user/{id}");
// 		        WebTarget userPostPath = host.path("user");
//      //		WebTarget requestGetTarget = userGetPath.resolveTemplate("id", 150);
// 		        User user = new User(14, "Edinson", 47);
// 		        Entity<User> entity = Entity.entity(user, MediaType.APPLICATION_JSON);
//      //		Response response = requestGetTarget.request().get();
// 		        Response response = userPostPath.request().post(entity);
// 		        int status = response.getStatus();
// 		        // Object entity = response.getEntity();
// 		        System.out.println("Status = " + status);
// 		        System.out.println("Entity = " + entity);
// 	        }
//      }
// -----------
//      package org.vitu.main;
//      import java.io.File;
//      import javax.xml.bind.JAXBContext;
//      import javax.xml.bind.JAXBException;
//      import javax.xml.bind.Unmarshaller;
//      import org.vitu.model.temp.User;
//      public class Main {
// 	        public static void main(String... args) throws JAXBException {
//      //		User user = new User(12, "Kylian", 19);
// 		        JAXBContext jaxbContext = JAXBContext.newInstance(User.class);
//      //		Marshaller marshaller = jaxbContext.createMarshaller();
//      //		marshaller.setProperty("jaxb.encoding", "utf-8");
//      //		marshaller.setProperty("jaxb.formatted.output", true);
//      //		marshaller.marshal(user, new File("xml/user.xml"));
// 		        Unmarshaller unmarshaller = jaxbContext.createUnmarshaller();
// 		        User newUser = (User) unmarshaller.unmarshal(new File("xml/user.xml"));
// 		        System.out.println("user = " + newUser);
// 		        System.out.println("terminé");
// 	        }
//      }
// -----------
//      package org.vitu.rest;
//      import javax.ws.rs.ApplicationPath;
//      import javax.ws.rs.core.Application;
//      @ApplicationPath("rest")
//      public class RestService extends Application {
//      }
// -----------
//      package org.vitu.rest;
//      import javax.ws.rs.Consumes;
//      import javax.ws.rs.FormParam;
//      import javax.ws.rs.GET;
//      import javax.ws.rs.POST;
//      import javax.ws.rs.Path;
//      import javax.ws.rs.PathParam;
//      import javax.ws.rs.Produces;
//      import javax.ws.rs.core.MediaType;
//      import javax.ws.rs.core.Response;
//      import javax.ws.rs.core.Response.Status;
//      import org.vitu.model.temp.User;
//      @Path("user")
//      public class UserRS {
// 	        @GET @Path("{id}")
// 	        @Produces(MediaType.TEXT_XML)
// 	        public Response findByid(@PathParam("id") long id) {
// 		        User user = new User(id, "Ngolo", 28);
// 		        return Response.ok().entity(user).build();
// 	        }
// 	        @POST @Consumes(MediaType.APPLICATION_FORM_URLENCODED)
// 	        @Produces(MediaType.TEXT_XML)
// 	        public Response create(
// 			        @FormParam("name") String name,
// 			        @FormParam("age") int age
// 			        ) {
// 		        User user = new User(1L, name, age);
// 		        return Response
// 				        .status(Status.CREATED)
// 				        .entity(user)
// 				    .build();
// 	        }
//      }
// -----------
//      package org.vitu.rest;
//      import javax.ejb.EJB;
//      import javax.inject.Inject;
//      import javax.ws.rs.GET;
//      import javax.ws.rs.Path;
//      import javax.ws.rs.PathParam;
//      import javax.ws.rs.Produces;
//      import javax.ws.rs.core.MediaType;
//      import javax.ws.rs.core.Response;
//      import javax.ws.rs.core.Response.Status;
//      import org.vitu.cdi.CommuneService;
//      import org.vitu.ejb.CommuneEJB;
//      import org.vitu.model.Commune;
//      @Path("commune")
//      public class CommuneRS {
//      //	@EJB
//      //	private CommuneEJB communeEJB;
// 	        @Inject
// 	        private CommuneService communeService;
// 	        @GET @Path("hello-world")
// 	        public String helloWorld() {
// 		        return "<h1>Hello World!</h1><p>This is a REST website</p>";
// 	        }
//      //	@GET @Path("{code-postal}")
//      //	public Commune commune(@PathParam("code-postal") String codePostal) {
//      //		return new Commune(codePostal, "Paris");
//      //	}
//      //	@GET @Path("{code-postal}")
//      //	public Response helloWorld(
//      //			@PathParam("code-postal") String codePostal) {
//      //
//      //		if (codePostal.equals("0")) {
//      //			return Response.status(Status.BAD_REQUEST).build();
//      //		}
//      //		return Response.ok("Code postal = " + codePostal).build();
//      //	}
// 	        @GET @Path("{code-postal}")
// 	        @Produces(MediaType.TEXT_XML)
// 	        public Response findById(
// 			        @PathParam("code-postal") String codePostal) {
// 		        Commune commune = communeService.findById(codePostal);
// 		        if (commune == null) {
// 			        return Response.status(Status.NOT_FOUND).build();
// 		        } else {
// 			        return Response
// 					        .ok(commune)
// 					        .build();
// 		        }
// 	        }
//      }
// -----------
//      package org.vitu.cdi;
//      import javax.inject.Inject;
//      import javax.persistence.EntityManager;
//      import javax.persistence.PersistenceContext;
//      import org.vitu.model.Commune;
//      public class CommuneService {
//      //	@Inject
// 	        @PersistenceContext(unitName = "jpa-java-ee")
// 	        private EntityManager em;
// 	        public Commune findById(String codePostal) {
// 		        return em.find(Commune.class, codePostal);
// 	        }
//      }
// -----------
//      package org.vitu.ws;
//      import javax.ejb.EJB;
//      import javax.jws.WebMethod;
//      import javax.jws.WebService;
//      import org.vitu.ejb.CommuneEJB;
//      import org.vitu.model.Commune;
//      @WebService
//      public class CommuneWebService {
// 	        @EJB
// 	        private CommuneEJB communeEJB;
// 	        @WebMethod
// 	        public Commune findById(String codePostal) {
// 		        return communeEJB.findById(codePostal);
// 	        }
// 	        @WebMethod
// 	        public int add(int x, int y) {
// 		        return x + y;
// 	        }
//      }
// -----------
//      package org.vitu.rest;
//      import javax.ws.rs.GET;
//      import javax.ws.rs.Path;
//      import javax.ws.rs.PathParam;
//      import javax.ws.rs.core.Response;
//      import javax.ws.rs.core.Response.Status;
//      @Path("communewithjpars")
//      public class CommuneWithJPARS {
// 	        @GET @Path("hello-world")
// 	        public String helloWorld() {
// 		        return "<h1>Hello World!</h1><p>This is a REST website</p>";
// 	        }
// 	        @GET @Path("{code-postal}")
// 	        public Response findById(
// 			        @PathParam("code-postal") String codePostal) {
// 		        if (codePostal.equals("0")) {
// 			        return Response.status(Status.BAD_REQUEST).build();
// 		        }
// 		        return Response.ok("Code postal = " + codePostal).build();
// 	        }
//      }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Huitième partie : Principes SOLID et Design Pattern ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cette partie du parcours traite de concepts d’architecture liés aux principes SOLID et des Design Patterns essentiels.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Principes SOLID et Design Patterns ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans ce module, nous allons découvrir les 5 principes de conception SOLID lié à la Programmation Orientée Objet.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Principes SOLID et Design Patterns ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Principes SOLID et Design Patterns ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans ce cours, nous allons discuter de design d'applications, ce qui va nous amener à discuter de trois choses :
//      - Les principes SOLID, ce sont des manières d'écrire du code, qui respecte un certain nombre de principes.
//      - Les design patterns, sont un ensemble de modèles de code, que nous allons pouvoir utiliser, nous inspirer pour écrire du code.
//          Si nous les implémentons correctement, ces design patterns peuvent et doivent si possible respecter les principes SOLID.
//      - L'architecture logicielle, ou qu'est ce qui fait que l'organisation d'un certain nombre de classes dans une application écrite en programmation objet, respecte une architecture correcte.
//          Qu'est-ce qui définis une architecture correcte, quelle qualité doit-elle avoir. Que pouvons-nous attendre d'une architecture correcte ?

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qualités d'une architecture logicielle ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avant de commencer, quelques mots sur, ce qui fait qu'une architecture logicielle est correcte ou non.
//      - Elle doit permettre de tester l'application, et ce, de manière automatique.
//          Donc d'essayer de faire fonctionner cette application, dans un environnement qui n'est pas exactement l'environnement de production.
//          Un environnement qui va essayer de reproduire à peu près l'environnement de production, avec des données, qui ne sont pas non plus celles de production, mais qui sont censées en être proche.
//          Surtout, si les tests sont en échec, si des bugs sont détectés, à ce moment-là, nous n'avons pas d'impact sur la manière dont la vraie application fonctionne en production.
//              --> L'objectif de tester une application est de détecter les défauts du code que nous avons écrit, avant que ce code ne soit utilisé en production, et qu'il ne puisse y créer de domages.
//      - Elle doit permettre à l'application d'évoluer. Une application ne vis pas dans un univers figé, ce n'est pas quelque chose qui est abouti.
//          Une application logicielle est quelque chose qui vit en permanence, qui doit être modifiée en permanence, pour corriger des bugs ou pour l'évolution des besoins des utilisateurs.
//      - Les choix techniques peuvent-y être revus et / ou modifiés. Nous pouvons prendre pour exemple une application qui fonctionne avec une base de données MySQL.
//          Pour un certain nombre de raisons, nous souhaitons remplacer MySQL par SQLServer.
//          Le choix technique MySQL à eu un impact sur l'architecture et que les modifications qu'il faut faire dans l'application rend SQLServer impossible ou trop coûteux.
//          Cela veux dire que l'architecture logicielle a été mal pensées dès le début.
//              --> Une bonne architecture, est une architecture qui isole les choix techniques, de manière à pouvoir les faire évoluer avec le temps.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Responsabilités d'une classe //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La première chose dont nous allons parler est la notion de responsabilité, que ce soit pour un bloc de code, une classe, un module... Ici, nous parlerons pour une classe.
// Nous avons une classe 'Employee' et qui modélise dans une application simplement l'employé d'une entreprise.
// Dans cette classe, nous avons un certain nombre de champs qui modélisent l'état de cette personne (nom, âge, adresse), et nous avons également des méthodes utilitaires.
// La programmation objet nous dit que l'avantage d'avoir des objets est que nous pouvons rajouter des méthodes sur ces objets, qui vont permettre d'enrichir les fonctionnalités de certains objets.
// Ici, nous avons une méthode qui exporte vers la base de données 'saveToDB()', une méthode qui permet d'exporter au format XML 'saveToXML()', et une méthode 'pay()' qui permet de payer les employés.
// --> La question est ainsi : Quel peut-être le coût d'entretien de cette classe ? Quel est le coût du développement et de la livraison d'une modification de cette classe dans l'application.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Livraison des modifictions d'une classe ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La modification a été effectuée, elle a été comitted, pushed, et elle se trouve dans un repository Git. Quelles sont les étapes jusqu'à la livraison finale ?
//      - Récupérer le code, avec une opération de type fetch, pull, avec des merge etc. ce qui peut déjà ne pas être une opération évidente, mais elle peut être automatisée.
//      - Compiler la nouvelle version du code, ce qui peut aussi être automatisé.
//      - Lancer des tests unitaires, notamment sur les classes métiers, qui sont plutôt critiques, pouvant porter des règles métiers, mais ceci peut aussi être automatiser.
//      - Packager notre application, ranger les classes dans des .jar, les .jar dans des modules, ces derniers éventuellement dans d'autres structures plus larges, ce qui peut aussi être automatisé.
// --> A ce stade, nous avons une application, que nous pouvons considérer comme fonctionnelle, toutefois, nous avons aussi une autre phase.
//      - Q / A, phase de contrôle qualité, qui va valider le fait que cette application correspond bien a ce que nous attendons d'elle, cette partie-là n'est toutefois pas automatisable.
//      - Une fois que la validation des contrôles a été effectuée, nous pouvons enfin passer à la phase de livraison à proprement parler. Cette partie-là peut, ou non être automatisée.
// Ainsi, dans tout ce processus, nous avons deux phases, qui recquièrent une intervention humaine, qui sont coûteuses et qui prennent du temps.
// Dans l'univers Java, nous avons l'outil 'Jenkins', fonctionnant de paire avec soit 'Maven', soit 'Gradle', qui permettent de gérer les phases automatisables d'une livraison.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour quelles raisons une classe change t'elle /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous retournons sur notre classe 'Employee' et que nous nous posons la question : Qui contrôle les modifications de cette classe ?
// Cela revient a se poser la question : Qui va demander des modifications dans cette classe, dans ces méthodes ?
//      - Si nous regardons les gens susceptibles de demander des modifications dans la méthode 'saveToDB()' ?
//          --> Il s'agira probablement des gens de la base de données, les 'DBA', ou DataBase Administrators.
//              Si par exemple, les paramètres d'authentification de la base de données, ou le schéma de cette dernière à changé.
//      - Si nous regardons les gens susceptibles de demander des modifications dans la méthode 'saveToXML()' ?
//          --> Des personnes qui s'intéressent au web. Par exemple, le format des documents XML peut changer, ou la manière de publier les documents XMl au travers des services REST ou SOAP.
//      - Si nous regardons les gens susceptibles de demander des modifications dans la méthode 'pay()' ?
//          --> Ce seront notamment les personnes des ressources humaines.
// --> Donc ici, nous avons trois types d'acteurs qui sont susceptibles de venir nous voir pour créer des modifications.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour quelles raisons une classe change t'elle /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La première question que nous pouvons nous poser est : à quelle vitesse est-ce que cette classe 'Employee' va t-elle changer ?
//      --> Cela sera la vitesse la plus courte de demande d'évolution des trois fréquences de demandes d'évolution des trois groupes précédents respectifs.
// Quel est le coût de ces évolutions ?
//      --> Ce sera le coup des différentes phases que nous avons vu, de la compilation à la livraison.
// Comment pouvons-nous faire des économies sur ce coût ?
//      --> Soit nous regroupons ces livraisons, par exemple une livraison mensuelle.
//          Cela peut nous permettre de prévoir le coût des livraisons sur l'année.
//          Par contre, un bug ne pourra être réparé qu'à la livraison suivante, donc potentiellement un mois plus tard.
//      --> Soit de tout automatiser, ce qui rends la livraison d'un correctif automatique et à moindre coût.
// Ainsi, le frein principal seront les étapes manuelles.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Impact de la mise à jour d'une classe /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Au delà du coût de la livraison d'une application, nous avons aussi l'impact sur les utilisateurs d'une application.
// Cet impact peut être négatif, et peut engendrer des régressions, et donc des bugs supplémentaires, donc des vrais problèmes dans la façon dont nous allons pouvoir travailler au quotidien.
// Lorsqu'il y a une livraison de la classe 'Employee', il y a un impact sur l'ensemble des personnes qui utilisent cette classe, donc sur les mêmes personnes qui commandites ces mises à jour.
// --> Le soucis, est que lorsqu'un seul service lié à la classe demande une évolution, c'est l'intégralité des services liés à cette classe qui vont être impactés.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Responsabilité d'une classe ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Que faut-il corriger dans cette organisation pour essayer de sortir de cette situation, situation dans laquelle nous ne souhaitons pas nous retrouver ?
// --> Il faut essayer de réduire le nombre de personnes qui ont un impact sur les modifications de cette classe.
//      Idéalement, que ce nombre soit de 0, pour que nous n'ayons plus aucune raison de changer cette classe.
// Nous ne pouvons pas réellement tomber à 0, mais à 1. Pour cela nous n'allons autoriser qu'un seul type de modification dans la classe 'Employee'.
// Cette modification sera de rajouter des fonctionnalités à l'intérieur de cette classe.
// Pour ce faire, nous allons définir la notion de 'Responsabilité', d'un bloc de code, d'une classe, d'un module.
// Ainsi, nous allons dire que le nombre de responsabilités d'une classe est le nombre d'acteurs qui peuvent demander des modifications dans cette classe.
// Ici, nous avons trois acteurs, donc trois repsonsabilités, plus une pour un acteur éventuel extérieur, comme par exemple, quelqu'un qui souhaiterais créer une méthode 'saveToJSON()'.
// Donc nous avons quatre responsabilités, soit trois de trop. Si nous arrivons à n'en avoir qu'un, nous allons grandement simplifier l'entretien de cette classe.
// Nous pourrons également simplifier la façon dont les modifications vont pouvoir être livrées aux acteurs qui en ont besoin.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Single Responsibility Principle ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le point que nous venons de voir, est un des points fondamentaux de la programmation orientée objet.
// C'est ce que nous appelons le 'Principe S', le premier des 5 principes 'SOLID', et qui signifie 'Single Responsibility Principle'.
// Ce principe nous dit que nous ne devons avoir qu'une seule raison de modifier un bloc de code, une classe, un module, etc.
// Nous allons voir comment modifier la classe 'Employee' pour qu'elle n'ait plus qu'une seule responsabilité.
// Attention, toutefois, elle aura toujours ses trois méthodes. Le nombre de fonctionnalités et le nombre de responsabilités sont deux choses différentes.
// Nous allons voir que nous pouvons diminuer le nombre de responsabilités, tout en conservant un nombre de fonctionnalités égales.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Diminuer les responsabilités en utilisant la délégation ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment allons-nous nous y prendre pour retirer la responsabilité de 'saveToDB()' de la classe 'Employee' ?
// Ce que nous voulons retirer de la classe 'Employee' est le code technique pour se connecter à la base de donnée et de faire de la lecture / écriture en base de données.
// Nous voulons le retirer de cette méthode là, mais ce code à tout de même besoin de s'exécuter quelque part.
// Dans un premier temps nous allons supposer que nous allons nous créer un objet que nous allons appeler dbService et qui va effectuer une méthode 'saveToDB()' de notre 'Employee'.
// Ceci est ce que nous nommons de la délégation, donc nous déléguons une tâche à un objet tiers.
// Evidemment cet objet de type 'DBService' doit être un champs de notre classe 'Employee'.
// Si nous regardons en terme de dépendances comment les choses se passent :
//      --> Employee à une dépendance pour DBService car elle porte un champs DBService, donc Employee dépends de DBService à la compilation.
//      Toutefois, nous avons retiré la responsabilité de 'Employee' à 'saveToDB()', car cette méthode est désormais portée par la classe 'DBService'.
//      --> Par contre, si nous modifions 'DBService', 'Employee' sera également impactée car cette dernière à une dépendance envers la première.
//          --> Il nous faudrait donc inverser cette dépendance, et faire en sortes que ce soit 'DBService' qui dépends de 'Employee'.
// -----------
// public class Employee {
//     DBService dbService;
//     saveToDB(...) {
//         dbService.saveToDB(this);
//     }
// }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Inverser une dépendance à l'aide d'une interface //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour inverser cette dépendance, nous allons utiliser quelque chose de très classique en programmation orientée objet.
// Nous allons plutôt dire que 'Employee' dépends de 'DBService', mais nous ne considèrerons plus 'DBService' en tant que classe, mais en tant qu'interface.
// Donc de cette manière, 'Employee' dépends toujours de 'DBService'. Par contre, 'DBService' à besoin d'une implémentation, donc d'une classe supplémentaire 'MySQLDBService' qui implémente 'DBService'.
// Maintenant, quelle est la dépendance entre 'DBService' et 'MySQLDBService' ?
//      --> A la compilation, l'implémentation dépends de l'interface, ce qui nous donne : Employee --> DBService <-- MySQLDBService.
// Ainsi, nous pouvons packager 'Employee + DBService' dans un module, et 'MySQLDBService' dans un second module.
// De cette manière, si nous devons relivrer le second module, le premier n'en sera pas impacté, et donc, les autres acteurs, n'en seront pas impactés non plus.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dependency Inversion Principle ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons vu le premier principe S pour 'Single Repsonsibility Principle', des principes SOLID.
// Nous venons de voir le dernier principe, D pour 'Dependency Inversion Principle'.
// Ce principe dit que ce sont les détails d'implémentation qui doivent dépendre des notions de haut niveau.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Précautions pour appliquer l'inversion de dépendance //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous ne sommes pas encore tout à fait au bout de l'application du principe D.
//      --> Il nous faut voir comment nous allons le mettre en oeuvre sur cette classe 'Employee'.
// Ce que nous pourrions faire, serait d'écrire :
//      DBService dbService = DBService.getInstance(...);
// Nous avons le droit d'utiliser des méthodes factory sur des interfaces, et nous pourrions aussi appeler 'newInstance(...)'.
// Ceci pourrait être la déclaration du champs 'DBService', donc d'avoir un initialisateur de ce champs.
// Cette façon de faire a éventuellement un intérêt, que 'DBService', n'étant qu'un service pour se connecter à la base de données, nous pourrions utiliser le pattern 'Singleton'.
// Ce pattern 'Singleton' impose que le champs ne peut avoir qu'une seule instance à l'échelle de notre application, ce qui peut éviter les doublons.
// Donc si nous utilisons cette méthode factory, nous pourrons l'utiliser pour contrôler qu'il n'y ait qu'une seule instance construite de ce service.
// L'intérêt du 'Singleton', est aussi de limiter le nombre d'objets de notre application.
//      --> Pourquoi est-ce que cette méthode n'est pas bonne ?
// Il faut aller regarder l'implémentation de cette méthode factory 'getInstance()', quelque part à l'intérieur de celle-ci, nous aurons forcément 'new MySQLDBService'.
// Et donc à l'intérieur de l'interface, nous aurons une référence sur la classe d'implémentation, ce qui va créer une 'Dépendance Circulaire' entre l'interface et la classe d'implémentation.
// Donc cette façon de faire n'est pas bonne !

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation du principe d'inversion de dépendance //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous voulons conserver les directions de mes dépendances à la compilation, les détails d'implémentation vers les règles de haut niveau, nous n'avons pas le choix.
//      --> Pour récupérer l'instance de 'DBService', il va falloir que nous déclarions que notre classe 'Employee' dépends d'une instance de 'DBService'.
//              public Employee(DBService service) {
//                  this.dbService = service;
//              }
// Donc, dans la déclaration même de cette classe 'Employee', nous encodons le fait qu'un 'Employee' pour fonctionner, à besoin d'une instance de 'DBService'.
//      --> Ceci est ce que nous appelons une 'Injection de dépendance'.
// Ainsi, nous déclarons au niveau du constructeur, que pour fonctionner, 'Employee' a besoin d'une implémentation de 'DBService'.
//      --> De cette manière, 'Employee' ne dépends que de l'interface 'DBService'.
//      --> De plus, nous n'avons plus de méthode factory qui créé des dépendances circulaires entre l'interface et la classe d'implémentation.
// Maintenant, quelque part, il va quand même falloir que nous ayons : 'DBService service = new MySQLDBService();' qui créé la dépendance retour entre l'implémentation et l'interface.
// La question à présent va être : Où est-ce que nous pouvons mettre cette ligne de code ?
//      --> Celle-ci se trouve dans la méthode 'main' car c'est elle qui va instancier 'service', qui va instancier 'Employee', en lui passant l'instance de 'DBService' en paramètre du constructeur.
// De cette manière là, notre application aura découpé toutes ces dépendances, les détails d'implémentation dépendront des règles de haut niveau et notre application sera assemblée par la méthode 'main'.
// Ainsi, le module de la méthode 'main' sera le seul module qui connaît tous les détails d'implémentation à l'échelle de cette application.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisation des modules de l'application /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous reprenons les dépendances de notre application et la structure que cette dernière va avoir :
// Employee --> DBService (interface)
//          --> Web (interface)
//          --> Pay (interface)
// Seront dans un premier module, mais qui contient un dépendance circulaire, ce qui n'est pas l'idéal.
// En effet, car les interfaces ont besoin d'un 'Employee' pour fonctionner, et 'Employee' porte les méthodes appelant les interfaces.
// Les trois interfaces ont chacune un module 'techniques' indépendants qui en dépendent.
// Toutefois, cette manière d'organiser les choses applique bien le 'Single Responsibility Principle'.
// Enfin, un dernier module, contient la méthode 'main' qui permet d'assembler les différents composants de notre application.
// Celle-ci va instancier nos 'Employee', elle va aussi instancier les différentes implémentations de nos interfaces.
// Enfin, elle va construire les instances d'employés en leur injectant les instances de ces interfaces.
// Le module 'main' dans cette organisation est donc le module de plus bas niveau que nous puissions avoir, et c'est toujours de cette manière que cela se passe.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Méthodes métier de la classe Employee /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous pouvons tout de même avoir une critique sur cette organisation : à l'intérieur de notre module de plus haut niveau ('Employee' et ses trois interfaces), nous avons des dépendances circulaires.
// La classe 'Employee' dépends de 'DBService', et 'DBService', prenant un 'Employee' en paramètre, dépends de la classe 'Employee'.
// Les dépendances circulaires sont des choses à éviter le plus possible, car elles peuvent provoquer beaucoup d'erreurs.
// --> Le vrai problème est que ces méthodes 'saveToDB()', 'saveToXML()' et 'pay()' n'ont rien à faire dans la classe 'Employee'.
// --> La classe 'Employee' devrait juste être là pour transporter un état.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Relation d'héritage entre Integer et Float ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les conséquences de cette première partie sur les principes S et D, nous ont permis de donner un rôle aux interfaces dans la programmation orientée objet.
// Maintenant, nous allons parler d'héritage, notion qui n'est pas naturelle est pour laquelle nous allons devoir adopter les bons principes pour pouvoir l'utiliser à bon escient.
// Nous allons prendre un premier exemple, qui est la relation entre les nombres entiers et les nombres réels.
// En mathématiques, nous savons qu'un nombre entier est un nombre réel, ce qui implique que l'ensemble des nombres entiers est inclus dans l'ensemble des nombres réels.
// Cette relation est souvent interprétée comme une relation d'héritage.
// --> Les entiers en Java sont des 'int', un type primitif, donc qui n'étends rien, et 'Integer', et son wrapper.
// Comment un 'int' est-il encodé en interne par le langage Java ?
// --> En Java, un 'int' est encodé sur 32 bits.
// Comment est-ce que ces bits sont utilisés ?
// --> Les entiers, en informatique sont encodés dans ce que nous appelons le 'complément à deux'.
//      Par exemple si nous prenons 1 : 0b 0001.
//      Ou encore 0 : Ob OOOO.
//      Donc tous les entiers positifs sont encodés de cette manière, en prenant simplement leur image en binaire.
//      Pour les entiers négatifs, nous effectuons un complément à 1 (remplacer les 0 par des 1 et vice-versa), puis nous ajoutons 1 : 0b 1111.
// Si nous regardons comment les 'float' de type primitifs ('Float' étant le type Wrapper) sont encodés, c'est aussi sur 32 bits.
// Sur ces 32 bits, les 23 premiers bits vont être la mantisse de ce nombre flottant, les 8 bits suivant sont utilisés pour l'exposant (en base deux), le dernier bit pour le signe de ce nombre flottant.
// Quel est le rapport entre la façon d'encoder des 'int' et celle d'encoder des 'float' ?
//      --> Il n'y en a aucun !
//      --> Est-il raisonnable de créer un lien d'héritage entre un 'float' et un 'int' ?

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Relation d'héritage entre Float et Complex ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons regarder une seconde relation, également avec une relation d'héritage supposé dans les nombres.
// Nous pouvons dire qu'un nombre réel est un nombre complexe, dans ce cas, est-ce que c'est la même chose en terme d'héritage.
// Dans le premier exemple, nous avons vu que l'implémentation de l'entier et l'implémentation du nombre à virgule flottante les rendaient incompatibles.
// Entre réels et complexes, la relation est un petit peu différente, car un complexe est construit sur une partie réelle et une partie imaginaire. Donc nous n'avons pas ce problème d'encodage différent.
// Nous allons donc supposer que nous avons une classe qui s'appelle 'Float', qui d'ailleurs existe dans le JDK, et nous avons aussi une classe qui se nomme 'Complex', qui elle n'existe pas dans le JDK.
// Si nous considérons qu'un nombre réel 'est' un nombre complexe, cela signifie que note classe 'Float' doit étendre la classe 'Complex'.
// Comment se définit la classe 'Complex' ? Et bien nous avons besoin de définir la partie réelle et la partie imaginaire.
// Donc nous aurions un premier champs de type 'Float' que nous appelerons 're' pour représenter la partie réelle, et un second champs de type 'Float' également que nous appelerons 'im'.
// Le problème est que dans cette classe 'Complex', nous avons besoin d'un constructeur auquel nous devrons donc fournir deux éléments de type 'Float'.
//      --> Ce faisant, nous créons une relation bi-directionnelle entre 'Float' et 'Complex', car 'Float' dépends de 'Complex', puisqu'il l'étends, et 'Complex' a besoin de 'Float' dans son constructeur.
//          Ainsi, si nous compilons ce code, il va compiler, mais si nous essayons de l'exécuter, il ne s'exécuteras pas, il fera une boucle infinie, et donc une 'StackOverflowException'.
//      --> Ici, nous sommes dans une situation d'héritage ou le mot 'est' ne correspond pas à un héritage, ici car elle créée une relation bi-directionnelle.
//          Cette fois-ci, nous n'avons pas une différence en terme d'encodage, mais en terme de relation entre les classes.
//      public class Float extends Complex {
//          ...
//      }
//      public class Complex {
//          Float re;
//          Float im;
//          Complex (Float re, Float im) {
//              ...
//          }
//      }
// Nous allons voir un dernier exemple dans lequel cette relation 'est' qui semble 'naturelle', en fait ne se translate pas correctement dans le code.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Relation d'héritage entre Square et Rectangle /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Troisième et dernier exemple que nous allons voir, un classique, la relation entre une classe 'Square' et une classe 'Rectangle' représentant tous deux l'aspect géométrique.
// La classe 'Square' aura une propriété 'size' de type 'int', et la classe 'Rectangle' aura deux propriétés 'width' et 'height', toutes deux de type 'int'.
// Maintenant, si nous disons que 'Square' hérite de 'Rectangle', nous pouvons voir qu'il y a une espèce de mismatch qui se créé entre les deux.
// En effet, d'un côté nous avons une propriété, et nous en avons deux de l'autre. Comment allons-nous pouvoir associer ces deux classes l'une à l'autre ?
// Une manière de régler ce problème de mismatch serait de dire que nous allons supprimer le champs 'size'.
// Et dans un second temps que le setter 'setSize()' va en fait appeler le setter 'setWidth()' et 'setHeight()' avec les valeurs de 'size' en tant que paramètre de ces deux setters.
// Mais attention, ce n'est pas la seule chose que fait l'héritage. En effet, si 'Square' étends 'Rectangle', cela veut dire que 'Square' a aussi une méthode 'setWidth()' et une méthode 'setHeight()'.
// Ainsi, il faut que dans la classe 'Square', nous devons surcharger ces méthodes, ainsi, lorsque nous modifions la hauteur, la largeur est aussi modifiée, et réciproquement.
// Nous pouvons voir qu'il y a un petit peu de complexité qui arrive dans la classe 'Square'.
// En effet, si 'setWidth()' appelle 'setSize()', il faut qu'il appelle aussi 'setHeight()', mais celui de la classe 'Rectangle', pas la surcharge dans la classe 'Square'.
// Ici, nous voyons que la complexité ne vient pas du fait qu'un carré est un rectangle, mais des règles de la programmation orientée objet, de la surcharge des méthodes, et de l'héritage en programmation.
// Toutefois, les problèmes ne se trouvent pas uniquement là. Nous avons aussi des problèmes au niveau du comportement de notre classe 'Rectangle'.
// En effet, si celle-ci possède une méthode 'getArea()', cela ne pose pas de problèmes car 'getSize()', va bien renvoyer à 'getHeight()' et 'getWidth()'.
// Par contre, si nous supposons que nous avons aussi une optimisation de cette méthode, avec un champs 'area', qui prends la valeur de la surface.
// Mais ce champs ne retourne la surface qu'à partir de la seconde fois, car la première fois, elle doit être calculée, à l'aide de la méthode 'getArea()'.
// De plus, lorsqu'un rectangle voit un de ses côtés augmentés d'un certain pourcentage, sa surface augmente du même pourcentage. La méthode 'setWidth()' intégre cette rêgle en plus.
// Comment cela va t-il se translatter dans la classe 'Square' ? Et bien cela ne fonctionnera plus du tout.
// Donc les modifications que nous avons faîtes dans la classe 'Rectangle' correspondant à des propriétés géométriques de ce dernier, ne s'applique pas au carré et seront erronées dans ce cas là.
// En fait, avec le comportement sur 'size' et le comportement sur 'area', nous pouvons montrer que ces deux classes ont des comportements qui sont différents.
//      --> Ainsi, un carré 'est' bien un rectangle, mais un carré ne se 'comporte' pas comme un rectangle.
// Ceci est un point extrèmement important de l'héritage : l'héritage est une relation du type 'est' mais aussi du type 'se comporte comme'.
// En fait, dans cette classe rectangle, nous avons une notion d'invariance'. Cela signifie que lorsque nous modifions une propriété d'un objet, les autres propriétés en restent inchangé.
// Comment pouvons-nous repérer dans du code, que nous sommes en train de créer des relations d'héritage entre des classes qui ne se comportent pas de la même manière ?
// Et bien il faut faire comme nous venons de le faire, en rajoutant du code dans la classe fille, pour s'assurer que cela ne pose pas de problèmes à la classe mère, et qu'il n'y a pas d'incohérence.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Liskov Substitution Principle /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous effectuons un petit bilan sur ce que nous venons de voir :
//      - Un entier 'est' un réel : ne veux pas dire que Integer peut étendre Float, notamment à cause de l'encodage.
//      - Un entier 'est' un complexe : ne signifie pas que Float peut étendre Complex, notamment à cause de la relation bi-directionnelle.
//      - Un carré  'est' un rectangle : ne signifie pas que leurs comportements soient similaires.
// --> La bonne façon de voir l'héritage, est de se poser la question du comportement.
// Si A 'se comporte' comme B, alors, A 'étends' B.
//      --> Ceci est le 'principe de Liskov', ou 'LSP', Liskov Subsitution Principle.
//          'Si A se comporte comme B, donc A éténds B, si toutes les instances de B de notre application peuvent être remplacées par des instances de A et que celle-ci fonctionne toujours'.
// Ce principe de Liskov est le principe 'L' des principes 'SOLID'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Etude de cas : modéliser avec des interfaces //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons voir à présent un exemple qui se sort des exemples classiques, ou académiques, tels que ceux que nous avons vu précédemment.
// Ainsi, nous allons supposer que nous travaillons avec une entreprise qui veux créer une application qui permet de gérer ses salariés. Nous créons par conséquent la classe 'Employee'.
// Nous nous rendons compte qu'il y a deux types de salariés, ceux qui sont en CDI, et ceux qui sont en CDD. Les processus métiers et les règles juridiques différent selon le type de contrat du salarié.
// Il s'avère que même les données qi sont rattachées à un salarié qui est en CDI diffère de celles d'un salarié qui se trouve en CDD. Typiquement, la date de fin de contrat n'existe que pour un CDD.
// De plus, il y a un certain nombre de processus métier qui sont rattachés à ces salariés, tels que des processus liés à la base de données, et d'autres qui sont liés aux versements des salaires.
// Nous avons vu précédemment que ces processus métier sont gérés par différentes équipes de l'entreprise et donc qu'il fallait essayer de les départager.
// Nous allons essayer de voir à présent comment nous pouvons appliquer les principes 'S', 'L' et 'D' pour nous permettre de structurer notre application.
// La structure des classes et interfaces, et le découpage de notre application en modules va s'appuyer sur le respect de ces principes.
// --> Comment allons-nous nous y prendre ?
//      - Déjà, le principe 'S', nous indique que les règles sont différentes pour les CDD et les CDI, donc les raisons de modifier ces règles différentes et indépendantes.
//          --> Il nous faut donc séparer ce qu'il se passe pour les CDI de ce qu'il se passe pour les CDD.
//          --> Donc un module qui va gérer les CDI, et un second module qui va gérer les CDI, avec chacun sa classe maîtresse.
//      - Le principe 'L' nous dit que dans notre application, nous avons un certain nombre de processus métier qui gèrent les employés en CDI et en CDD.
//          L'exécution de ces processus métiers, le déclenchement de ces processus métier ne doivent pas dépendre du fait qu'un employé soit en CDI ou en CDD.
//          Par exemple, si nous devons aller lire un employé dans la base de données, la commande qui nous permet d'aller lire cet employé ne dépends pas du fair que celui-ci soit en CDI ou en CDD.
//          Ce qui va dépendre du fait que l'employé soit en CDI ou en CDD se sont les détails d'implémentation, détails qui ne doivent pas apparaître dans le code primaire.
//          --> Cela nous impose, mécaniquement, d'avoir une structure, au dessus de CDI et de CDD qui va être la structure manipulée par l'application, cette structure, nous l'appelerons 'Employee'.
//      - Cette structure ne dépends pas de CDI et de CDD, ce sont ces deriers qui dépendent d'elle.
//          --> Ceci, nous est imposé par le principe 'D', d'inversion des dépendances : les détails d'implémentation dépendent des notions de haut niveau.
//      - Il nous reste une question que nous pouvons nous poser au sujet de cette structure 'Employee' : est-ce qu'il s'agit d'une interface, ou d'une classe abstraite ?
//          --> Que nous utilisions un cas comme l'autre, la dépendance se fera toujours dans le sens de l'implémentation vers le haut niveau, donc cela n'a pas d'importance.
//          --> La convention est d'utiliser une interface. En effet, c'est l'interface qui modélise vraiment ce que doit faire une classe.
//              Effectivement, une classe abstraite contient déjà des détails d'implémentation, et nous pourrions être tentés dans l'évolution de l'application, de faire hériter aux classes concrètes.
//                  --> Seules les interfaces permettent de modéliser ce que doivent faire les classes.
//              Nous allons voir que les classes abstraites ont aussi un rôle à jouer dans ce schéma là, mais ce rôle sera différent.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisation d'une factory /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Application
//      |
// Employee (interface)
//      |
//   ------
//   |    |
// CDI   CDD
//---------------
// Voici le schéma auquel nous parvenons. Nous avons deux classes concrètes 'CDI' et 'CDD' qui implémentent l'interface 'Employee'.
// Notre application va consommer cette interface pour appeler les différentes règles métiers qui y sont relatives.
// Nous pouvons séparer en deux modules l'interface et son implémentation, de sortes à ce que ce soit bien les détail d'implémentation qui dépendent des règles de haut niveau, et non pas l'inverse.
// La première question que nous pouvons nous poser est : Comment s'y prendre pour créer des 'Employee' ? En effet, dans notre application, nous allons devoir créer les 'Employee' avant de les gérer.
//      --> Pour créer les 'Employee', nous allons utiliser un pattern particulier qui se nomme le pattern 'Factory'. Par exemple pour nous ce sera 'EmployeeFactory'.
//          Cette factory va avoir deux méthodes 'createCDI()' et 'createCDD()', qui vont chacune prendre un certain nombre de paramètres.
// Cette structure 'EmployeeFactory', doit-elle être une classe ou une interface ? Où devons-nous la ranger par rapport à l'application et aux implémentations ? Regardons les deux cas.
// --> Si c'est une classe et que nous nous intéressons à l'implémentation de 'createCDI()', nous allons avoir une implémentation qui va être 'return new CDI()'.
//      --> Ainsi, nous avons une relation de dépendance d'EmployeeFactory vers CDI.
//      Dans cette structure, c'est l'application qui va appeler 'createCDI()'.
//      Ainsi, si 'EmployeeFactory' est une classe, l'application va dépendre de la factory, et cette dernière va dépendre des détails d'implémentation, tout comme l'application, et ce de façon transitive.
//          --> Donc, 'EmployeeFactory' ne peut pas être une classe.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation de la factory //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si il ne s'agit pas d'une classe, c'est qu'il s'agit d'une interface, et nous devrons donc créer une implémentation de cette interface.
// Il faut déjà préciser que les deux méthode 'createCDD()' et 'createCDI()' retournent un 'Employee', et non l'inverse, sinon, l'interface 'EmployeeFactory' dépendra des détails d'implémentation.
// Donc à présent, notre application dépends de notre interface, ce qui est bien car une interface est sensée vivre en isolation. Mais il va falloir tout de même que nous implémentions cette interface.
//      --> Pour l'implémenter nous allons créer une interface 'EmployeeFactoryImpl', et qui va produire des implémentations pour ces deux méthodes 'createCDD()' et 'createCDI()'.
// Par contre, cette implémentation de notre factory 'EmployeeFactoryImpl' va dépendre de 'CDI' et de 'CDD'. Il va falloir à un moment utiliser des 'new' pour créer les instances d'employés.
// Ainsi, nous avons maintenant 'Application', 'Employee' et 'EmployeeFactory' dans un module dit de 'haut niveau', et 'EmployeeFactoryImpl', 'CDI' et 'CDD' dans un second module en dépendance du premier.
// De cette manière, nous ontinuons à appliquer le principe 'D' correctement.
// Nous pouvons même isoler 'EmployeeFactoryImpl' de 'CDD' et 'CDI' de manière à isoler la factory des objets manipulés.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisation de l'application à l"exécution ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Techniquement, au niveau du code, comment allons pouvoir écrire et assembler ces classes ?
// Pour créer nos objets dans l'application, nous allons continuer d'appliquer le principe d'inversion de dépendances, donc :
//      public Application(EmployeeFactory){...}
// Ainsi, 'Application', va copier 'EmployeeFactory' dans un champs privé, ainsi, dans toutes les méthodes où nous aurons besoin de créer des 'Employee', nous allons référencer cette instance.
// A quel moment est-ce que 'Application' va recevoir cela ? Et bien ce sera lors de l'instanciation dans la méthode 'Main'.
//      --> Dans la méthode 'Main', nous allons créer les objets du module 'Application', créer une instance de 'EmployeeFactory'. Ainsi dans la méthode 'Main' nous aurons 'new EmployeeFactoryImpl'.
//          Cette instance de 'EmployeeFactory', nous pourrons la passer en paramètre de la construction des objets de notre module 'Application'.
// Ainsi, à la compilation, 'Application', ne dépendra que des interfaces, c'est à l'exécution que les interfaces vont être implémentées à partir de la méthode 'Main'.
//      --> Le module 'Main' est le seul module qui a l'intéralité des modules de notre application en dépendances, que ce soit les modules de haut niveau, ou les détails d'implémentation.
//          Ainsi, le détail d'implémentation le plus fin de l'ensemble de notre application, c'est le module 'Main', car c'est le module qui a l'intégralité des détails d'implémentation en dépendance.
// Ce principe, d'injecter les dépendances par le constructeur, est une façon d'appliquer le principe d'inversion de dépendance.
// Les framework 'CDI' et 'Spring', nous permettent de gérer cette injection de dépendance automatiquement avec des annotations.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ajout d'une implémentation pour Employee //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cette structure respecte les différents principes, et nous avons vu que nous pouvons construire notre application en effectuant de l'injection de dépendances, avec un framework ou par le constructeur.
// Imaginons qu'au bout d'un certain temps, nous avons une demande business qui arrive en nous indiquant qu'il n'y a pas que des gens en CDI ou en CDD, mais aussi des indépendants sous contrat.
// Ainsi, il faudrait que nous rajoutions une classe d'implémentation sous 'Employee' à côté de 'CDI' et de 'CDD'.
//      --> Notre structure accepte facilement ce fenre de chose, c'est même assez facile de rajouter une classe d'implémentation.
// Le seul soucis, est que nous avons besoin de rajouter du code, dans 'EmployeeFactory' du type 'createContractor()'.
// Ceci est embètant car par conséquent nous devons ajouter du code aussi dans notre module de haut-niveau.
//      --> Comment pouvons-nous éviter de rajouter du code dans l'interface factory lorsque nous rajoutons des implémentations de notre interface ?
//      --> Autrement dit, comment pouvons-nous casser cette ultime dépendance ?
// Nous n'avons pas le choix, nous devons passer de trois à une méthode qui va prendre un paramètre qui variera pour créer des CDI, des CDD ou des Contractor.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pattern Abstract Factory //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ainsi, le code de notre méthode 'create' va devenir celui-ci :
//      - Nous allons lui passer un premier paramètre qui va nous permettre de reconnaître le type de contrat, et donc le type d'objet 'CDD', 'CDI' ou 'Contractor'.
//      - Puis, nous allons lui passer les paramètres de 'Employee' comme le nom, l'âge etc.
// Par conséquent, nous passons d'un modèle, où nous avons autant de méthodes factory que nous avons de classes d'implémentation, à un modèle où nous n'avons plus qu'une seule méthode prenant un paramètre.
// Ce paramètre permettant de reconnaître la classe à implémenter.
// L'implémentation elle, n'est pas dans l'interface, elle est toujours dans la classe d'implémentation de la factory.
//      --> Donc, du point de vue des dépendances, nous n'avons rien changé, cette méthode nous permet de rajouter des implémentations à la demande sans avoir besoin de faire évoluer l'interface factory.
// Le pattern que nous avons ici, d'utiliser une interface en tant que factory, avec une classe d'implémentation de cette factory est un design pattern.
//      --> Ce design pattern s'appelle 'Abstract Factory', car la factory que nous avons est abstraite, puisque c'est une interface, et elle doit être implémentée pour pouvoir fonctionner à l'exécution.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation de la factory avec un switch ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Regardons à présent de plus près le code de cette méthode 'create()'.
// Cette méthode retourne un objet de type 'Employee', elle prends en paramètre un String que nous appelerons 'label', ainsi que tous les autres paramètres permettant de construire un 'Employee'.
// A l'intérieur de cette méthode, nous allons avoir une structure avec un switch, nous aurions aussi pu le faire avec un if / else.
// Il faudra aussi penser au cas où le label fourni en paramètre de la méthode 'create()' ne correspond à aucune implémentation.
//      Employee create(String label, ...){
//          switch(label) {
//              case "CDD" : return new CDD(...);
//              case "CDI" : return new CDI(...);
//              ...
//          }
//      };
// Nous avons à présent une structure de code que nous allons devoir faire varier en fonction du fait que nous allons ajouter ou retirer des implémentations de notre interface 'Employee'.
// Si nous avons d'autres méthodes que 'create()' comme 'pay()' ou 'addToDB()', nous retrouverons dans chacune de ces méthodes cette structure de 'switch'.
//      --> Cette structure de switch est quelque chose de très dangereux dans une application.
// En effet, cette structure de switch à tendance a être reproduite dans l'application, et nous nous retrouvons avec pleins de switch dans notre application.
// Si les choses sont bien maîtrisées, nous ne retrouverons ces switch que dans les parties détails d'implémentation, et pas dans la partie application.
// C'est un problème exactement pour la même raison que pour le design de notre interface factory.
//      --> En effet, quand nous voulons rajouter une implémentation, nous devons mettre ce switch à jour.
// Comment allons-nous pouvoir éviter de mettre des switch dans notre application.
//      --> Nous allons appliquer un autre pattern qui est le pattern 'Strategy'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Identification des éléments du pattern Strategy ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le pattern 'Strategy' que nous allons voir à présent est un pattern extrèmement important car il est vraiment utilisé partout dans les applications d'informatique de gestion.
// Partout, nous allons faire des switch, ou des if / else sur un certain nombre de critères pour appliquer certains traitements à des données.
// Le pattern 'Strategy' permet de transformer donc quelque chose qui à une structure de switch en une autre structure beaucoup plus simple et qui permet surtout d'avoir ces branches de code.
//      --> La première chose qu'il faut comprendre est : qu'est-ce que c'est que cette strategie ?
//              --> La stratégie est le traitement que nous appliquons en fonction d'un certain critère.
// Ici, le traitement que nous appliquons est simple, c'est soit 'new CDI()', soit 'new CDD()', soit 'new Contractor()'.
// La stratégie est donc ici, chaque branche de notre switch, ou alors, chaque branche de notre if / else.
//              --> Une stratégie est donc une branche de code.
//      --> Quels critères nous permet de décider quelle stratégie va être appliquée ?
//              --> Dans notre situation, le critère va être le 'label'.
//      --> Quel sera le modèle de stratégie ?
//              --> Ce sont les entrées et les sorties. Par exemple si nous mettions cela dans une méthode, qu'est-ce qu'elle prendrait en paramètre, et qu'est-ce qu'elle retournerait ?
// Une fois que nous avons bien identifié ces trois éléments, nous allons pouvoir mettre en oeuvre notre stratégie.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création des classes du pattern Strategy //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment fonctionne ce pattern ? Il fonctionne en deux temps.
// Tout d'abord, ce que nous pouvons détecter est que ce 'label' nous définit un type d'employé, qui peut être 'CDI', 'CDD' ou 'Contractor'.
// Nous allons donc créer une classe abstraite que nous allons appeler 'AbstractEmployeeType'. Celle-ci va porter une méthode abstraite qui va encoder chacune de nos stratégies.
//      AbstractEmployeeType {
//          abstract Employee create(...);
//      }
// Et c'est tout ce que nous allons faire au niveau de cette classe abstraite, à savoir que les paramètres de sa méthode 'create()' seront les mêmes que ceux qui lui des méthodes du switch.
// Ensuite, cette classe abstraite, nous allons l'étendre, par autant de classes concrètes que nous avons de stratégies dans notre switch.
//      CDDType {
//          Employee create(...) {
//              return new CDD(...);
//          }
//      }
// Ceci sera donc la première classe concrète de notre stratégie, nous aurons aussi 'CDIType', ainsi que 'ContractorType'.
//      --> Ainsi, nous avons échangé notre switch avec une classe abstraite qui porte le modèle de notre stratégie, et autant de classes concrètes que de stratégies dans notre switch.
//              --> Ces dernières vont nous fournir les implémentations concrètes des la méthode abstraite que nous avonns défini précédemment.
//              --> Ainis, au lieu de rajouter des branches dans notre switch, nous n'avons plus qu'à ajouter des extensions de notre classe abstraite.
// Maintenant, nous allons voir comment nous pouvons exploiter cette structure de classe pour remplacer la structure de switch.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Open Closed Principle /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Premier détail, le switch à disparu, nous n'avons plus besoin de lui ni d'un if / else.
// A présent il va falloir que nous procédions en deux temps :
//      - Choisir la stratégie que nous voulons appliquer.
//      - Exécuter cette stratégie.
// Nos stratégies se trouvent à présent dans les classes concrètes, donc il nous faut récupérer la bonne instance de classe concrète, mais en fonction de quel critère ? En fonction du 'label'.
// Nous allons faire cela au travers d'une méthode factory, donc nous allons récupérer une instance de 'AbstractEmployeeType' dans une variable que nous allons appeler 'type'.
// Ainsi, nous pouvons passer le critère en paramètre de la méthode factory '.of()'. Celle-ci va décider si nous créons un 'new CDDType', un 'new CDIType', ou un 'newContractorType'.
// Donc à l'intérieur de cette méthdoe factory, nous avons toujours notre switch, mais ce switch là n'applique pas la stratégie, il la choisit seulement en fonction du critère passé.
//      AbstractEmployeeType type = AbstractEmployeeType.of(type);
//      Employee employee = type.create(...);
// Ainsi, nous avons remplacé notre switch par cette structure particulière, certes un peu compliquée, mais qui nous permet de n'avoir que les deux lignes de code ci-dessus dans notre code client.
//      --> Ces deux lignes de code par ailleurs, ne dépendent plus du fait que nous ayons trois implémentations d'employés différentes.
//          Nous appelons ces deux lignes de code, code client au sens ou il vit dans l'implémentation de notre factory abstraite.
//      --> Ici, nous disons une chose très importante, c'est que le code client est fermé à la modification.
//      --> En revanche, le code de notre application est ouvert à l'extension, en effet, nous pouvons en ajouter ou en retirer autant que nous voulons.
// Ceci est un des principe de 'SOLID', c'est le principe 'O', le 'Open-Closed Principle', ou 'OCP'.
// Ce principe nous dit que le code que nous écrivons doit être fermé à la modification.
// Aussi, que si nous voulons augmenter le nombre de fonctionnalités de notre application, nous devons le faire uniquement en étendant la classe abstraite.
//      --> Donc en fournissant des implémentations supplémentaires d'interface.
// Le pattern Strategy est une bonne manière d'appliquer le principe Open-Closed.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémenter le pattern Strategy par composition ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le pattern Strategy à un intérêt majeur, est qu'elle fournit une solution pour implémenter l'Open-Closed Principle.
// La manière classique d'implémenter le pattern Strategy est la suivante :
//      public class CDDType {
//          public Employee {
//              create(String name) {
//                  return new CDD(name);
//              }
//          }
//      }
// Cette manière n'est pas parfaitement satisfaisante car elle nécessite d'avoir une classe abstraite et autant de classes concrètes que nous avons de stratégies dans notre switch originel.
// Cela dit, nous pouvons implémenter ce pattern différemment, en utilisant une autre technique que l'héritage, qui est la composition.
// Si nous regardons cette classe 'CDDType', ce qu'elle nous fournis essentiellement, c'est une stratégie, contenant une méthode.
// Or, il se trouve qu'à partir de Java 8, nous pouvons :
//      - Passer des méthodes en paramètres d'autres méthodes.
//      - Nous pouvons mettre des méthodes dans des champs ou dans des variables.
//      - Des méthodes peuvent retourner elles-même ces méthodes.
// Ces méthodes que nous pouvons emmener à droite à gauche dans notre application sont encodées sous forme de Lambda Expressions.
// En utilisant ces dernières, nous allons pouvoir simplifier l'implémentations du pattern Strategy.
//      --> Notre classe ci-dessus en réalité encode une méthode, que nous allons mettre dans une Lambda Expression.
//          Mais attention, elle encode également un type qui est porté par le type même de cette classe. Ce type, il va également falloir le retenir.
// Comment allons-nous nous y prendre ?
//      public EmployeeType {
//          String label;
//          Function<String, Employee> create;
//          EmployeeType(String label, Function<String, Employee> create) {
//              ...
//          }
//          String type() {
//              return label;
//          }
//          Employee create(String name) {
//              return create.apply(name);
//          }
//      }
// Maintenant nous n'avons plus qu'un seul modèle de classe, concrète cette fois-ci, paramétrée par une Lambda Expression et par un type, sous forme d'une chaîne de caractères.
// Notre Lambda Expression, ici, c'est une fonction parce que la méthode de création des 'Employee' prends une chaîne de caractère en paramètre et retourne un objet de type 'Employee'.
//      --> Nous avions auparavant une structure ayant une classe abstraite et autant de classes concrètes que de nous avons de stratégies différentes.
//      --> Nous avons à présent une structure où nous n'avons plus qu'une seule classe concrète et autant d'instances de cette classe concrète que nous avons de stratégies.
// Il nous reste deux points à voir :
//      - Comment pouvons-nous créer toutes les instances de l'objet 'EmployeeType' dont nous avons besoin ?
//      - Programmer la méthode factory qui va nous permettre de retourner le bon 'EmployeeType' en fonction des 'Employee' que nous voulons créer.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création des objets composés de la Strategy ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Commençons par créer les instances de 'EmployeeType', nous en avons trois :
//      EmployeeType cdd = new EmployeeType("cdd", name -> new CDD(name));
// Nous pouvons faire la même chose pour 'CDI', et de même pour 'Contractor', de cette manière nous allons nous retrouver avec trois instances.
// Une fois que nous avons toutes les instances, comment allons-nous nous y prendre pour créer cette factory ?
// Nous allons commencer par nous créer un champs 'EmployeeType', avec les differents types d'EmployeeType dont nous disposons.
// Ces champs, nous allons les mettre dans une List<EmployeeType> que nous pouvons appeler 'types' en utilisant la méthode 'list.of(cdd, cdi, contractor)'.
// Après, nous allons pouvoir créer la méthode qui nous retourne un 'Employee', qui se nomme 'create()', qui est la méthode factory que nous devons implémenter.
// Cette méthode 'create()', prends un String 'label', permettant de reconnaître quelle instance d'EmployeeType nous allons devoir utiliser.
// Puis elle prendra un second paramètre, qui est le paramètre nécessaire pour construire un employé.
// Dans cette méthode 'create()', il va falloir qu'elle regarde et filtre la liste en fonction du label que nous avons, pour sélectionner dans cette liste, l'instance d'EmployeeType qui possède ce 'label'.
// Une fois qu'elle a cette instance, elle appelle la méthode 'create()' d'EmployeeType, en lui passant 'name' en paramètre.
// Cette opération de filtrage est quelque chose que nous pouvons faire très facilement avec un Stream.
// Nous pouvons filtrer ce Stream en testant l'égalité du label fourni par la méthode 'create()' avec celui d'EmployeeType.
// Ensuite nous pouvons utiliser '.findAny()' pour nous retourner le type souhaité, ceci nous retournant un 'Optional', nous pouvons appeler la méthode '.map()' sur cet optional.
// Ainsi, nous pouvons mapper sur le type d'Employee donné par la liste 'types' sur lequel nous pouvons appeler la méthode 'create()' en lui passant les paramètres de création d'employé.
// Cette méthode '.map()' qui est une méthode d'Optional et non de Stream, va nous retourner un autre optional.
// Si l'optional d'avant n'était pas vide, ce dernier optional va contenir l'instance d'Employee que nous voulons retourner.
// Maintenant, nous pouvons appliquer à ce dernier optional, la méthode 'orElseThrow()', ceci ouvre l'optional pour voir ce qu'il y a dedans, et jette une exception si il n'y a rien.
// Si il n'y a rien, c'est que le label fourni ne correspond à aucune instance que nous avons, si il n'est pas vide, il contiens le retour de la méthode 'create()', donc un Employee.
// Voici donc l'implémentation de notre méthode factory :
//      EmployeeType cdd, cdi, contractor;
//      List<EmployeeType> types = list.of(cdd, cdi, contractor);
//      Employee create(String label, String name) {
//          return types.stream()
//                      .filter(type -> type.label == label)
//                      .findAny()
//                      .map(eType -> eType.create(name))
//                      .orElseThrow();
//      }
// Maintenant, nous avons un pattern qui est beaucoup plus simple, nous n'avons qu'une seule classe. Notre méthode factory, nous pouvons la mettre dans 'EmployeeType' directement.
// Nous n'avons qu'une seule classe, et nous avons une instance de cette classe par stratégie.
// Ainsi, si nous avons besoin d'ajouter une stratégie, tout ce que nous avons à faire et de rajouter une instance d'EmployeeType, en appelant son constructeur, et avec la bonne Lambda Expression.
// De plus, notre méthode factory ne fait que lire la List<EmployeeType>, nous n'aurons donc jamais besoin de la modifier, elle restera toujours la même.
// La seule chose qui peut y changer est le prédicat que nous avons dans la méthode 'filter()' qui dépends de la manière dont nous avons sélectionné notre stratégie.
// La seconde chose qui peut y changer est le traitement qu'il faut effectuer pour créer l'objet que nous souhaitons créer ou d'une façon générale pour appliquer la stratégie que nous souhaitons appliquer.
//      --> Tout ceci est encodé dans ce pattern, construit sur l'API Stream.
// Donc voila comment nous pouvons implémenter un pattern Strategy :
//      --> Soit avec une classe abstraite et des classes concrètes.
//      --> En utilisant de la composition, c'est à dire avec une classe unique que nous pouvons instancier en passant des Lambda Expressions.
//          Ces dernières, vers lesquelles nous allons déléguer les différentes opérations de notre stratégie.
//              --> Donc dans cette seconde manière d'écrire les choses, les stratégies sont encodées directement dans les Lambda Expressions.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Design Patterns et Gang of Four (Gof) /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avant d'aller plus loin, faisons une petite pause pour reparler de cette notion de 'Design Pattern'.
// En fait 'Design Pattern' est une expression qui désigne deux choses :
//      - C'est un modèle de code, une espèce de recette que nous pouvons utiliser lorsque nous développons des applications.
//      - C'est un livre qui a été écrit en 1994 avant même la première version de Java (1995), écrit pour le C++. C'est un livre des 'Design Patterns', et c'est même le livre fondamental à ce propos.
// Le 'GoF', soit le 'Gang of Four', désigne ce livre, par ses 4 auteurs.
// Dans ce livre, nous avons 23 patterns qui sont décrits. Ce qui est peu car avec ces 23 patterns, nous pouvons résoudre 99% des problèmes de la programmation orientée objet.
// Ces 23 patterns se regroupent dans trois catégories :
//      - Patterns de construction, donc qui s'intéressent à la construction des objets, comme les patterns 'Factory', 'AbstractFactory', ainsi que les pattern 'Singleton', 'Builder' et 'Prototype'.
//      - Patterns structurels (7).
//      - Patterns behaviorals (11) : par exemple 'TemplateMethod' qui a trois extensions, 'Strategy', 'State', 'ChainOfCommand', nous avons aussi le pattern 'Iterator', ou encore 'Visitor'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pattern Singleton /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant que nous savons ce qu'est un pattern, nous pouvons voir le pattern 'Singleton', à quoi il sert, quand est-ce que nous pouvons l'utiliser, et comment l'implémenter.
// Ce pattern nous dit qu'une classe qui suit ce pattern ne peut avoir qu'une seule instance.
//      --> Ceci veux dire qu'il faut que nous protégions cette classe contre les instanciations qui pourraient créer plusieurs instances de cette classe.
// Quel est l'intérêt de n'avoir qu'une seule instance pour une classe ?
//      --> C'est d'économiser la mémoire et en moindre partie le CPU.
// Effectivement, un objet consomme de la mémoire, donc si nous n'avons pas besoin d'avoir plusieurs instances d'un même objet, il vaut mieux n'en avoir qu'une seule.
// Ceci consomme aussi du CPU car plus nous créons d'instances d'objet, pllus nous avons de chances de créer de la pression sur le 'GarbageCollector'.
// En effet, dans une JVM, les objets qui ne sont plus utilisés sont gérées par le 'GarbageColector', qui, de temps en temps va examiner la mémoire à la recherche de ces objets, et qui va les jeter.
// Le fonctionnement de ce 'GarbageCollector' n'est pas gratuit, et plus nous diminuons la pression sur ce 'GarbageCollector', mieux notre application fonctionnera.
// Pour quelles classes ce pattern fonctionne t'il bien ?
//      --> Cela fonctionne particulièrement bien pour les classes de service.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Première implémentation du Pattern Singleton //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment implémenter une classe 'Singleton' ?
// Supposons que nous avons une class de service, la première chose que nous devons faire est contrôler qui peux construire cette classe.
// Pour cela, il faut interdire à tout le reste de notre application de pouvoir instancier cette classe.
// Pour pouvoir faire cela il y a une mécanisme très simple. Il suffit de dire que le constructeur vide de cette classe est privé.
// Ainsi, plus personne ne peut étendre cette classe, car les super classes ne pourront pas appeler ce constructeur là, donc le compilateur jettera une erreur.
// Deuxièmement, le code extérieur à cette classe, ne peut pas construire cette classe.
// Maintenant que nous avons fermé la porte à tout le monde, il va falloir que nous l'entrouvions. En effet, il va falloir trouver un moyen de construire une instance de cette classe.
// Nous ne pouvons construire d'instance de cette classe que de l'intérieur de cette classe puisque son constructeur est privé.
// Comment allons-nous pouvoir rendre cette instance disponible ?
//      --> Etant donné que nous avons besoin de cette instance disponible au travers de la classe, avant que quelqu'un ait une référence sur cette instance, il faut que ce soit avec un accesseur statique.
// Nous pouvons ainsi créer une méthode créant une instance de 'MySQLDBService', et nous pouvons la récupérer avec une méthode que nous appelons généralement 'getInstance()' car c'est un 'Singleton'.
// Et cela est suffisant. Bien sûr, nous pouvons mettre toutes les autres méthodes d'instances que nous voulons, et qui seront accessibles au travers de cet objet 'service'.
// Dans cet exemple-ci, cela pourrait être des méthodes 'save()', 'update()', 'retrieve()', et toutes les autres opérations classiques que nous pouvons effectuer sur une base de données.
// Ceci est la méthode la plus simple possible d'implémenter le pattern 'Singleton' en Java. Ce n'est toutefois pas la manière préférée des développeurs.
// En effet, nous avons une instanciation de notre objet 'service' qui n'est pas contrôlée lorsque nous écrivons 'new MySQLDBService()'.
//      --> Ce que nous aimerions serait d'avoir une instanciation 'LAZY'. Cela signifie que nous aimerions que cet objet 'service' ne soit instancié que lorsque nous appelons 'getInstance()'.
// Si la classe est extrèmement simple comme ici, et qu'elle n'a pas d'autres champs statiques, ni d'autres méthodes statiques, c'est ce qui va se passer.
// En effet, cet initialisateur statique sera invoqué sur un appel à 'getInstance()' et juste avant que 'getInstance()' soit effectivement appelé.
// Mais si jamais nous avons une classe un peu plus compliquée avec d'autres membres, d'autres membres statiques ou des références ou que cette classe est référencée par autre chose.
// A ce moment-là, il sera possible que nous payons le prix de cette instance alors qu'en fait nous n'allons pas appeler 'getInstance()'.
// Pourquoi est-ce que c'est embêtant ? Parce que nous sommes en train de créer un objet, alors qu'il est possible que nous n'en ayons jamais besoin.
//      public class MySQLDBService {
//          private MySQLDBService(){
//              ...
//          }
//          static MySQLDBService service = new MySQLDBService;
//          static MySQLDBService getInstance() {
//              return service;
//          }
//          ...
//      }
// Nous avons une autre façon d'implémenter le pattern 'Singleton' qui est la façon canonique et recommandée et que nous allons voir à présent.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation du Pattern Singleton avec une énumération //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La façon canonique et recommandée de créer des 'Singleton' en Java, est aussi extrèmement simple, c'est d'utiliser une Enumération.
// L'énumération est un mécanisme qui a été introduit en Java 5 , et il a tous les avantages que nous souhaiterions avoir lorsque nous voulons créer des 'Singleton' en Java.
// L'énumaration 'MySQLDBService' n'a qu'une seule instance qui s'appelle 'INSTANCE'.
// Le fait qu'il soit impossible d'instancier d'autres valeurs énumérées pour cette énumération, il est garanti, non pas par notre code, mais par la JVM elle-même.
// Une énumération est juste un artifice de compilation, c'est ce que nous appelons un sucre syntaxique, car en fait au niveau de la compilation, derrière, nous avons une vraie classe.
// Dans cette dernière, il peut y avoir un constructeur qui est privé, donc nous pouvons écrire ce constructeur et y passer des paramètres en construction de cette instance qui s'appelle 'INSTANCE'.
// Nous pouvons aussi y avoir des méthodes statiques, ou des méthodes d'instances dans laquelle nous pouvons surcharger 'toString()' notamment, etc.
// En plus, l'instanciation de cet objet 'INSTANCE' est 'Thread-Safe'.
//      public enum MySQLDBService {
//          INSTANCE:
//      }

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pattern Builder pour la création d'objets complexes ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Continuons à étudier ces Patterns dits de 'Construction', en étudiant à présent le pattern 'Builder'. Celui-ci est également très important et très utilisé dans les applications.
// Le pattern 'Builder' fait partie de la collection des patterns pour construire des objets.
// Nous avons déjà vu les pattern 'Singleton', 'Factory' et 'AbstractFactory', et maintenant nous allons voir le 'Builder'.
// Ce pattern sert à construire des objets COMPLEXES. Ces objets complexes peuvent poser deux types de problèmes :
// Ils peuvent avoir un nombre de champs très important (plusieurs dizaines par exemple).
//      --> Ceci peut poser des problèmes de validation, car nous pouvons nous retrouver avec des règles de validation sur certains champs, voire sur plusieurs champs.
//      --> Cela peut aussi poser des problèmes de complétude, en effet, nous pouvons nous retrouver avec des objets dont les champs sont manquants.
// Qu'avons-nous à disposition jusqu'à présent pour construire des objets ?
//      - Le constructeur, si nous utilisons un constructeur, nous allons être obligés de créer un constructeur qui va prendre l'ensemble des valeurs de champs nécessaires pour construire cet objet.
//          --> Ceci peut conduire facilement à des erreurs et a des bugs lorsque nous avons de nombreux champs.
//          --> Même si nous n'avons pas beaucoup de paramètres mais que nous avons de la validation à faire, cela va rester très compliqué d'utiliser un constructeur.
//              En effet, dès l'instant que nous codons 'new ...', nous créons notre objet, ainsi, ainsi nous devons écrivons nos règles de validation à l'intérieur de notre constructeur.
//              A partir de ce moment-là, comment pouvons-nous faire pour empêcher la création de cet objet, sachant que nous sommes déjà en train d'exécuter la création de cet objet.
//                  --> Sachant que nous sommes déjà en train d'exécuter la création de cet objet, tout ce que nous pouvons faire est d'empêcher la finalisation de la construction de l'objet.
//                  --> Ceci ne peut donc se faire que par un seul mécanisme, qui est le fait de jeter une exception. Or un constructeur qui jette une exception n'est jamais une bonne idée.
//              Le dernier élément est la complétude, que se passe t'il si nous avons des champs manquants ?
//                  --> Soit nous pouvons prévoir les champs qui sont manquants, et nous allons nous retrouver avec tout un tas de constructeurs.
//                  --> Soit nous n'avons qu'un seul constructeur que nous allons pouvoir appeler avec des valeurs null.
//      - Le pattern factory est une alternative au constructeur.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'objets complexes avec une factory //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'en est-il donc du pattern de la classe 'Factory' ?
//      --> Si nous avons 60 paramètres, nous serons dans le même état, et nous allons avoir des appels de méthodes qui vont être bloqués.
//          De toutes manières, il faut se dire qu'une méthode bien designée prends quelques paramètres, de 1 à 3 maximum.
// Ainsi, si nous avons réellement 60 paramètres à passer, ni le constructeur, ni la factory ne seront des bons pattern.
// Toutefois, avec le pattern 'Factory', la validation se passe un petit peu mieux car la 'Factory', peut commencer par lire les règles que nous lui avons donner, puis y appliquer les règles de validation.
// Ainis, si des règles de validation sont en échec, la 'Factory' peut choisir de retourner un objet null ou un objet dégradé, ou un message d'erreur, et éventuellement de jeter une exception.
// La 'Factory' peut effectuer tout cela avant d'avoir appelé le constructeur de l'objet, c'est donc une espèce de couche de protection avant l'appel du constructeur.
// Celle-ci nous permet d'agir et de lancer la création de l'objet que lorsque nous sommes sûrs que cela va réussir et aussi qu'elle va créer un objet valide.
// Si nous avons des champs manquants, nous tombons exactement dans la même problèmatique que pour le constructeur.
//      --> Soit nous allons nous retrouver avec plein de méthodes factory qui vont prendre des combinatoires de paramètres qui vont être horribles à gérer.
//      --> Soit nous allons nous retrouver avec une méthode que nous allons appeler avec des paramètres null et ceci est fortement déconseillé à cause de NullPointerException.
// Donc, la 'Factory' est pas mal pour faire de la validation, mais dès l'instant que nous avons des objets complexes avec beaucoup de champs, ce n'est pas non-plus un patter très adapté.
//          --> C'est la raison pour laquelle, les 4 membres du 'GoF' ont inventé le pattern 'Builder' que nous allons voir à présent.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Création d'un objet complexe avec un Builder //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment pouvons-nous utiliser le pattern 'Builder' et en quoi est-ce qu'il va pouvoir nous aider ?
// Nous allons d'abord voir comment l'utiliser, puis, dans un second temps, comment l'implémenter.
// Supposons que nous avons une classe 'Contrat'. Le pattern 'Buillder' nous dit que pour pouvoir instancier des objets de type 'Contrat', nous devons renvoyer les paramètres du contrat.
// Nous devons ainsi les renvoyer à un objet intermédiaire qui est précisémment ce 'Builder'. Le type de cet objet intermédiaire dans ce pattern est 'Contrat.Builder', cet objet sera donc notre 'Builder'.
// Nous pouvons l'instancier avec : 'new Contrat.Builder();'.
//      --> Cet objet 'Builder' va exposer tout un tas de méthodes, en fait, autant de méthodes que nous avons de champs dans la classe 'Contrat' avec un pattern comme suit :
//      builder.withStartDate(...)
//              .withEndDate(...)
//              .withAmount(...)
//              .with...(...)
//              .build();
// Ainsi, à chaque fois que nous voulons ajouter des éléments, donc des nouveaux champs dans notre contrat, nous avons une méthode qui correspond au nom de ce champs et qui est préfixé par 'with'.
// Ceci va nous retourner un objet de type 'Contrat', qui va être créé par cette méthode '.build()', avec l'intégralité des informations que nous avons données ici.
// Nous pouvons voir que par rapport au cas où nous nous trouvions précédemment, nous sommes dans une situation qui est nettement meilleure.
// En effet, ici, nous ne sommes pas à créer une méthode unique qui va prendre 20, 30, 60 paramètres. Nous sommes en train de créer autant de méthodes que nous avons de paramètres.
// De plus, chacune de ces méthodes porte le nom du paramètre, donc nous n'avons aucune raison de nous tromper.
//      --> Ainsi, le pattern 'Builder' règle le problème du grand nombre de paramètres nécessaire pour construirre un objet de type 'Contrat'.
//      --> Cela règle également le problème des paramètres manquants.
//          En effet, si par exemple nous ne connaissons pas notre date de fin de contrat car elle n'est pas encore fixée, et bien nous n'appelons pas cette méthode.
//          Ainsi, le champs 'endDate' ne sera pas initialisé au niveau de notre objet de type 'Contrat'.
//      --> Enfin, cela règle aussi le problème de la validation des paramètres.
//          Effectivement, la méthode '.build()' est en fait une méthode factory, c'est même LA méthode factory du pattern 'Builder'.
//          Si nous avons des règles de validation à appliquer, elles le seront forcément avant l'appel à la méthode '.build()', donc, avant la construction de l'objet complexe.
// Donc ce pattern permet de gérer le problème du grand nombre de paramètres, le problème des paramètres manquants, et le prolblème de la validation des paramètres.
//      --> Maintenant, nous allons voir comment implémenter ce pattern 'Builder'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation du Builder /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment allons-nous pouvoir implémenter le pattern 'Builder' ?
// Dans notre classe 'Contrat', nous avons en fait une classe interne 'Builder' qui est statique et aussi publique car nous avons besoin de l'appeler de l'extérieur de la classe 'Contrat'.
// A l'intérieur de cet objet 'Builder', nous devons avoir des champs qui correspondent aux champs qui sont déclarés dans la classe 'Contrat'.
//      --> Donc si nous avons 50 champs dans la classe 'Contrat', nous aurons au moins autant de champs dans sa sous-classe 'Builder'. Cet objet 'Builder', n'est donc pas forcément simple à générer.
//      --> A l'intérieur de notre classe 'Builder', nous aurons le même nombre de méthode 'with'.
//          Ces méthodes 'with', vont stocker le champs ciblé, non pas dans la classe 'Contrat', car nous n'avons pas encore d'instance de 'Contrat', mais dans un champs de 'Builder'.
// Ainsi, nous pouvons chaîner les appels à la méthode 'with', c'est une manière d'écrire du code qui s'appelle 'fluent'.
// Ceci fonctionne si chaque méthode 'with' retourne l'objet 'Builder' que nous avions initialement. Ces métodes vont recopier les champs dans des champs internes à 'Builder'.
//      --> La dernière méthode est la méthode 'build()'. Sa responsabilité est d'instancier l'objet de type 'Contrat'.
//          Ainsi, nous n'avons pas besoin d'un constructeur ultra-complexe dans notre classe 'Contrat'.
//          Nous pouvons juste avoir un constructeur vide, puis appeler tous les setters de 'Contrat' avec tous les champs qui ont été instanciés.
//          Si nous avons des champs manquants, nous pouvons tracer le fait que certains champs ont été instanciés, et d'autres non, nous pouvons gérer des valeurs par défaut.
//          Pour tracer si un champs a été instancié, nous pouvons setter dans la méthode 'with', un flag de type boolean indiquant que le champs a bien été instancié.
//          A l'intérieur de notre 'Builder', nous aurons, if boolean = true then nous pouvons appeler le setter correspondant du 'Contrat'.
// Ainsi, la méthode 'build()' nous retournera un objet de type 'Contrat', et même si cet objet est complexe a construire, la complexité sera masquée dans l'API.
// Elle sera ainsi masquée dans notre méthode 'build()' et ne trainera pas dans notre code 'métier', dans laquelle nous appelons simplement 'build()'.
// Les règles de validation seront eux aussi présents dans la méthode 'build()'.
//      public class Contrat {
//          // Champs
//          static Builder {
//              // Champs
//              Builder withStartDate(Date d) {
//                  this.startDate = d;
//                  return this;
//              }
//              ...
//              Contrat build() {
//                  return Contrat;
//              }
//          }
//      }
// --> Voila comment nous pouvons implémenter le pattern 'Builder' avec une façon 'fluent' d'appeler ces méthodes.
// --> Cette façon de faire est très utile car chaque paramètre qui est positionné est immédiatement nommé ce qui limite énormément les risques de bug au niveau de la création des objets.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Interface Segregation Principle ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Examinons un cas d'utilisation qui pourrait, de manière simplifiée, être extrait d'une application.
//      interface VATService {
//          int getVat(String countryCode);
//          int getVAT_2(CountryCode code);
//          CountryCode getCountriCode(String countryCode);
//      }
//      class InvoiceProcess {
//          VATService service;
//          InvoiceProcess(VATService s) {
//              this.service = s;
//          }
//          int computeVAT(int amount) {
//              return service.getVAT("FR") = amount;
//          }
//      }
// Nous avons une interface qui modélise un service de TVA. Ce service de TVA reçoit des codes qui sont censés représenter des pays, par exemple 'FR' dans une chaîne de caractères.
// Cette interface nous retourne le taux de TVA en vigueur dans ce pays, ici, dans notre exemple, ce serait 20,6.
// A côté de cela, nous avons un processus de facturation qui dépends du service de TVA qui applique bien le principe de 'Dependency Inversion', il déclare donc une dépendance vers l'interface.
// A l'intérieur, nous avons une méthode métiers qui va calculer la TVA en fonction d'un certain montant en appelant la méthode 'getVAT()' de notre interface.
// Tout se passe bien jusqu'à ce que les gens qui gèrent le service de TVA se disent qu'en fait cet objet 'countryCode' modélisé par une chaîne de caractères, est incomplet.
// En effet, il faudrait y ajouter des informations supplémentaires, donc nous allons créer une autre méthode 'getVAT_2()' qui va prendre un objet de type 'CountryCode' à la place et qui retournera un int.
// Ce faisant, nous recompilons notre classe 'InvoiceProcess', car évidemment, lorsque nous modifions une interface, c'est le seul moment où nous devons recompiler l'intégralité de notre application.
// Effectivement, tout le monde dépends des interfaces, que ce soit les détails d'implémentation ou le code client.
// De plus, ils rajoutent également une méthode utilitaire qui permet à partir de la chaîne de caractère 'countryCode', de construire un objet de type 'CountryCode'.
// Malheureusement, le développeur qui a réécri l'interface à fait une erreur et à mis un 'i' à la place d'un 'y' dans 'CountriCode', et cela à malgré tout passé le contrôle qualité.
//      --> Déjà, c'est embêtant car nous devons recompiler 'InvoiceProcess', alors que les deux méthodes ajoutées dans l'interface ne sont pas appelées dans celle-ci.
//      --> De plus, nous avons un bug dans l'interface fournie.
// Donc cette interface en v2 va être corrigée en une v3, car nous n'aimons pas les fautes d'orthographe dans les noms de méthode.
// Ceci implique que pour la seconde fois, nous devons aussi recompiler la classe 'InvoiceProcess', pour la correction d'un bug dans une méthode que nous n'utilisons pas.
//      --> Ceci nous coûte du temps, de l'argent, et ne nous apporte absolument rien.
// Il se trouve que ce faisant, il y a un principe qui a été violé, qui est le principe 'I', et s'appelle 'Interface Segregation Principle'.
//      --> Il nous dit que nous ne devons pas dépendre d'une interface qui possède des méthodes dont nous n'avons pas besoin.
// Nos deux méthodes ajoutées à l'interface nous sont inutiles dans la classe 'InvoiceProcess', et donc ce n'est pas dans 'VATService' qu'elles doivent être ajoutées.
// Nous aurions dû les ajouter sur une autre interface que 'VATService', ainsi, nous n'aurions pas eu besoin de recompiler 'InvoiceProcess' en ajoutant cette interface.
// De plus, du côté de l'implémentation, l'implémentation de 'VATService' qui va maintenant implémenter ces deux méthodes supplémentaires avait juste besoin d'implémenter deux interfaces au lieu d'une.
//      --> Du point de vue de l'implémentation, cela ne changeait rien, du point de vue du code client, ça aurait simplifié les choses.
// Le principe d'Interface Segregation nous dit que nous dépendons d'interfaces, et dans ces interfaces, nous avons le nombre minimum de méthodes dont nous avons besoin pour fonctionner.
//      --> Autrement dit, nous ne devons pas dépendre d'interfaces qui possèdent des méthodes dont nous n'avons pas besoin.
//      --> Il faut que nous réduisions la taille de ces interfaces vraiment au minimum de ses besoins.
// C'est le dernier principe des principes 'SOLID', et peut-être l'un des plus délicats à mettre en oeuvre, car il touche vraiment au design de l'intérieur des interfaces.
// Mais c'est un principe très important en programmation orientée objet.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur les principes SOLID /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// A présent que nous avons vu ces 5 principes 'SOLID', nous allons pouvoir faire un bilan :
//      - S : 'Single Responsibility Principle' :
//          Il nous dit que nous ne devons avoir qu'une seule raison de modifier un bloc de code, une méthode, une classe, ou un module.
//          Une raison de modifier ce bloc de code, ce doit être une raison métier, exprimée par une personne du métier.
//      - O : 'Open-Closed Principle' :
//          Il nous dit que si nous voulons faire évoluer les fonctionnalités de notre application, la seule chose qu'il faut faire est d'étendre certaines classes bien choisies de notre application.
//          Une façon d'implémenter ce principe était d'utiliser le pattern 'Strategy', un des patterns du 'GoF'. Nous avons vu deux manières d'implémenter ce pattern 'Strategy' :
//              - La façon canonique, telle qu'elle est expliquée dans le 'Gof', qui consiste à avoir une classe abstraite, et des classes concrètes.
//              - Une façon qui fonctionne avec de la composition, avec une classe concrète unique, qui possède un nombre d'instances bien déterminé.
//                  Ces instances déléguant les stratégies à des Lambda Expressions modélisées dans cette classe.
//      - L : 'Liskov Substitution Principle' :
//          Il nous explique ce qu'est l'héritage en programmation orientée objet.
//          Si l'instance d'une classe B peut être utilisée à la place de l'instance d'une classe A sans que le processus qui utilise ces instances ne voit de différence, cela veut dire que B étends A.
//          Ceci définis ce qu'est la relation d'héritage, comme nous l'avons vu, ce n'est pas une relation de type 'est' ou 'is a', mais plutôt une relation 'se comporte comme'.
//          La relation d'héritage parle du comportement plutôt que de la nature des objets.
//      - I : 'Interface Segregation Principle' :
//          Quand un service, une classe ou un processus a une dépendance vis-à-vis d'une interface, les méthodes de celle-ci doivent être minimales par rapport aux méthodes dont le client a besoin.
//          Un client qui dépendrait d'une interface, mais que ne dépendrait pas de toutes les méthodes de cette dernière s'expose à des problèmes lorsque ces méthodes non-utilisées devront évoluer.
//              --> Effectivement, si tel était le cas, il devrait se reconstruire, et payer le coût de cette reconstruction de manière inutile.
//      - D : 'Dependency Inversion Principle' :
//          Il nous dit que lorsque nous voulons inverser la dépendance entre deux modules dans une application, il nous suffit d'insérer une interface entre les deux.
//          Ce faisant, les dépendances à la compilation, vont toutes les deux pointer vers cette interface.
//              --> Mettre des interfaces permet de protéger du code client contre les modification des implémentations.
//              --> D'une façon générale, les dépendances au niveau du code doivent toujours aller des détails d'implémentation vers les règles de haut niveau.
// Cet acronyme 'SOLID' a été créé par un auteur qui a assemblé ces principes, qui s'appelle 'Bob Martin', surnommé 'Uncle Bob'. C'est lui qui a assemblé ces 5 principes et qui à créé l'acronyme 'SOLID'.
// Lui-même dit que ce n'est pas lui qui l'a créé, mais une autre personne qui est tout aussi connue en programmation orientée objet, 'Kent Beck'.
// Kent Beck est la personne qui a inventé 'Extreme Programming', ou encore le 'Test-Driven Development', et qui a programmé la premmière version d'un framework de test en Java, 'JUnit'.
// Il se trouve que Bob Martin a également énnoncé le principe 'S' dans les années 90, les principes 'SOLID' datant, eux, du début des années 2000.
// Le principe 'O', a été ennoncé par 'Bertrand Meyer', qui écrit aussi des livres en programmation orientée objet, et créé le langage 'Eiffel'.
// Le principe 'L' a été ennoncé par 'Barbara Liskov', les principes 'I' et 'D' n'ont pas d'auteur connu.
// Dans l'industrie logicielle, Kent Beck et Bob Martin ont fait partie des 17 personnes qui ont écrit en 2001 le 'Manifest Agile', puis se sont fait les chantres du 'Clean Coding'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pattern Visitor ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Un cours sur les 'Design Patterns' ne seraient pas complets si nous ne parlions pas du pattern 'Visitor', ce que nous allons faire maintenant.
// Pourquoi ce pattern est-il si important, probablement car c'est le pattern le plus compliqué à comprendre et à mettre en oeuvre techniquement sur des hiérarchies d'objets.
// Donc, si nous sommes capables de bien comprendre le pattern 'Visitor', à priori, nous serons capables de comprendre l'intégralité des patterns du 'GoF', donc les 22 autres patterns.
// A quoi sert ce pattern 'Visitor' ?
//      --> Il procède toujours de la même intention : séparer les traitements du modèle objet.
// Le modèle objet, ce sont ces classes qui modélisent le business que notre application est censée gérer, que notre système d'information est censé gérer.
// Les traitements, ce sont les processus métier, les procédures métier qui vont agir sur ces objets. Par exemple, créer un contrat, créer un compte bancaire, ou créer un voyage sont des traitements.
// Pourquoi est-ce que nous aurions envie de séparer ces deux éléments, pour une raison que nous avons déjà vu.
//      --> En effet, les traitements sont des choses qui bougent plus vite, qui sont modifiés sur une échelle de temps plus courte que le modèle objet en lui-même.
//          En séparant les deux choses, nous pourrons livrer les traitements indépendamment du modèle objet, et donc de pouvoir faire des économies sur les livraisons de l'application dans sa globalité.
//      --> Le pattern 'Visitor' permet précisemment de séparer la partie traitement de la partie modèle objet pour les hiérarchies d'objets complexes.
// Par exemple, supposons que notre modèle objet a à sa racine un objet 'Company', qui contient un certain nombre de 'Department', référençant un certain nombre de 'Project', contenant des 'Employee'.
//      Company -- 1/n --> Department -- 1/n --> Project -- 1/n --> Employee.
// Cette hiérarchie à plusieurs caractéristiques, elle est modélisée par plusieurs interfaces (une pour chaque), et chaque interface peut avoir plusieurs implémentations (CDI, CDD, Contractor...).
// Tout cela fait que notre hiérarchie est assez complexe, donc nous pouvons avoir un nombre de classes et d'interfaces assez important, ainsi qu'une complexité dans les relations entre ces entités.
//      --> Le pattern 'Visitor', apporte une solution au fait que sur cette hiérarchie, nous avons besoin d'ajouter des fonctionnalités.
// De quels type de fonctionnalités pouvons-nous avoir besoin ? Nous pouvons avoir par exemple besoin de compter tous les 'Employee' ou tous les 'Employee' d'un certain type.
// Des fonctionnalités qui vont dans tous les cas nous imposer de visiter l'intégralité de cette hiérarchie.
// Et sur chaque élément de cette hiérarchie, avoir envie d'effectuer certaines actions, qui pourront éventuellement être validées par le type d'élément que nous sommes en train de visiter.
// Si par exemple nous voulons compter tous les projets informatiques dans la 'Company', nous allons visiter toute la hiérarchie.
// Et a chaque fois que nous rencontrerons un objet dont l'implémentation est 'projet informatique', là, nous déclencherons un certain type d'action.
// En terme de design, une erreur serait de se dire que chaque interface va modéliser les opérations que nous pouvons faire dessus.
// Par exemple, les 'Projects' référencent des 'Employee', donc la moyenne des salaires des 'Employee' va être calculée par l'objet 'Project'.
// Si nous faisons ça, cela signifie que nous ne séparons pas les traitements du modèle objet.
// Ainsi, à chaque fois que nous aurons un nouveau traitement à implémenter sur cette hiérarchie, il va falloir relivrer le modèle objet, ce qui sera compliqué et coûteux.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Design du Pattern Visitor /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment allons-nous nous y prendre ? Nous allons créer ce que nous appelons un 'Visitor', celui-ci est représenté par une interface.
// L'interface 'Visitor', est capable de visiter l'intégralité des objets de notre hiérarchie.
//      --> Donc l'interface 'Visitor' doit posséder autant de méthodes qu'il y a d'interface dans cette hiérarchie.
// Ceci tombe bien, car le nombre d'interfaces dans une hiérarchie, même s'il est important, va être petit, face au nombre d'implémentations de cette interface.
// Et, il sera d'autant plus petit par rapport au nombre d'instances de ces interfaces.
//      interface Visitor {
//          void visitCompany(Company c);
//          void visitDepartment(Department d);
//          void visitProject(Project p);
//          void visitEmployee(Employee e);
//      }
// Déjà, nous pouvons voir que par nature, la modification de cette interface va être fonction du rajout, ou du retrait d'interfaces dans notre hiérarchie d'objets.
// Ainsi, si les interfaces de notre hiérarchie sont stables, notre interface 'Visitor' sera stable également.
// Pour l'instant, nous pouvons voir, que notre interface 'Visitor', a un lien à la compilation vers le modèle objet mais le modèle objet, lui, n'a pas de lien à la compilation vers cette interface.
// Malheureusement, c'est quelque chose que nous n'allons pas pouvoir maintenir dans le temps.
//      --> En effet, dans chaque interface de notre hiérarchie, il va falloir que nous ajoutions du code pour prendre en compte le fait que nous utilisions ce pattern 'Visitor'.
//          L'intégralité de ces interfaces vont devoir accepter un 'Visitor', à l'aide d'une méthode particulière, ci-après l'exemple pour l'interface 'Company'.
//      interface Company {
//          void accept(Visitor v);
//          ...
//      }
// Donc, à ce stade-là, les interfaces de notre hiérarchie d'objets ont une dépendance à la compilation vers cette interface 'Visitor'.
//      --> Ainsi, l'interface 'Visitor' doit vivre dans le modèle objet car si nous la mettons dans un autre module, nous créerons une dépendance circulaire entre notre modèle objet et notre 'Visitor'.
//      --> Ceci est la seule intrusion du pattern 'Visitor' dans le modèle objet. Il faut que cette hiérarchie d'objets soit prête a accepter des visiteurs pour que ce pattern fonctionne.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation de la visite d'une hiérarchie d'objets /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment allons-nous faire pour implémenter cette méthode 'accept()', quel contenu devons-nous y mettre. Ce contenu est également dirigé par le pattern 'Visitor', ce qui va nous simplifier la vie.
// Nous allons regarder une implémentation de l'interface 'Department', en l'occurrence, le département des ressources humaines.
// Celui-ci implémente l'interface 'Department', donc nous devons également implémenter cette méthode 'accept()'.
// Cette méthode 'accept()' va être appelée par un mécanisme externe que nous n'avons pas encore vu, avec une instance de 'Visitor' en paramètre.
// Qu'allons-nous faire de cette instance de 'Visitor' ? Nous avons essentiellement deux choses à faire avec :
//      - La première chose, est de transmettre ce 'Visitor' aux autres noeuds connus par 'Department', ici sera transmis au noeud 'Project', et 'Employee'.
//          C'est donc la responsabilité de chaque noeud de la hiérarchie qui reçoit un visiteur de transmettre ce visiteur.
//          Le pattern pour le faire est d'appeler la méthode 'accept()' des noeuds connus avec le visiteur en paramètre.
//      - La seconde chose, est que le visiteur visite l'objet dans lequel nous nous sommes, donc l'objet 'this'.
//          Car en fait, cette méthode 'accept()', permet de transmettre le visiteur, mais ne permet pas d'agir, car dans notre interface, nous n'avons pas de code métier, donc pas de processus métier.
//          Nous avions dit que le visiteur peut compter le nombre de salariés ou faire tout type de statistiques mais pour l'instant nous ne l'avons pas programmé.
//          En fait, nous allons le programmer par 'CallBack', c'est-à-dire que nous recevons un objet, et nous appelons cet objet en retour, en nous passant en tant qu'instance à l'exécution.
//          Donc ici, le 'Visitor' va nous recevoir, ici, en tant qu'instance de 'HRDepartment', et va pouvoir agir sur ce 'Department'.
// --> Ceci est tout ce que nous avons à faire avec ce 'Visitor'.
//      class HRDepartment implements Department {
//          void accept(Visitor v) {
//              // 1- Transmettre le visiteur.
//              this.projects.forEach(p -> p.accept(v));
//              // 2- Le visiteur visite l'objet 'this'.
//              v.visitDepartment(this);
//          }
//          ...
//      }
// Cette méthode 'accept()' est en fait entièrement générique, elle ne dépends que de l'interface 'Visitor', elle ne réalise aucun traitement en tant que tel.
// Elle nous permet juste de transmettre ce visiteur à l'intégralité de la hiérarchie, et d'appeler une méthode callback, qui elle, va faire le traitement.
// Ceci est le coeur du pattern 'Visitor'. Nous visitons la hiérarchie, et nous appelons le visiteur en callback.
//      --> C'est ce que nous appelons le 'Double Dispatch' : nous sommes en train d'appeler la méthode 'accept()' en passant 'Visitor', et cette méthode 'accept()' rappelle le 'Visitor' en callback.
//          Ce 'Double Dispatch' est cet espèce de va et vient entre le 'Visitor' et les objets de la hiérarchie.
// Une fois que nous avons fait ceci, comment pouvons-nous effectuer des traitements ?
//      --> Nous pouvons le faire en implémentant cette interface 'Visitor', et c'est ce que nous allons voir à présent.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation d'un visiteur qui compte ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comment allons-nous implémenter cette interface 'Visitor' ?
//      --> Nous allons l'implémenter en fonction des traitements que nous souhaitons faire.
// Nous pouvons par exemple créer une classe 'CountingVisitor', qui va compter le nombre d'employés de la société.
// Evidemment, il faut que nous implémentions l'intégralité des méthodes 'visit', toutefois, nous pouvons décider qu'elles ne font rien.
// En revanche, comme nous souhaitons compter les employés, nous pouvons créer un champs 'count', initialisé à 0. Puis nous pouvons ajouter un getter pour 'count' pour en récupérer la valeur.
// Si nous voulions uniquement compter les salariés d'un certain type, nous aurions pu tester avec un 'instanceOf()', le type d'employé avant d'éventuellement le compter.
//      class CountingVisitor{
//          void visitCompany(Company c){};
//          void visitDepartment(Department d){};
//          void visitProject(Project p){}
//          long count = 0;
//          void visitEmployee(Employee e) {
//              count++;
//          }
//          ...
//      }
// Comment allons-nous mettre cela en oeuvre ?
//      --> Nous allons le faire dans une méthode 'Main', qui va créer cette structure 'Company', 'Department', 'Project' & 'Employee'.
//          De plus, elle va instancier ce 'CountingVisitor', et à la racine de cette hiérarchie, nous avons donc un objet 'Company' qui est capable d'accepter un 'Visitor'.
//          Donc nous avons juste invoqué la méthode 'accept()' de cette 'Company' avec une instance de ce 'CountingVisitor'.
//          Lorsque la méthode 'accept()' rendra la main, nous allons pouvoir invoquer le getter 'getCount()' sur l'instance de 'CountingVisitor' pour récupérer notre résultat.
// La méthode 'Company' a une méthode 'accept()', qui fait deux choses, elle transmet le 'Visitor' a l'ensemble des 'Department' qui vont transmettre le 'Visitor' aux 'Project' et aux 'Employee'.
// De plus, dans chaque objet visité par cet objet 'CountingVisitor', les méthodes 'visitCompany()', 'visitDepartment()', 'visitProject()' et 'visitEmployee()' vont être appelées.
// Quand ce sera une des trois premières méthodes 'visit', rien ne se fera, en revanche, quand 'visitEmployee()' sera invoquée, là, le compteur sera incrémenté.
//      --> Ceci est un pattern extrèmement puissant car nous avons un code très générique à ajouter aux éléments de notre hierarchie, une interface à rajouter avec notre modèle objet.
//          Mais finalement, cette interface est unique et vit dans le modèle objet, et donc, elle va évoluer en même temps que notre modèle objet évolue.
//          Ceci est dû au fait que cette interface à une relation bidirectionnelle avec les différents objets de mon modèle.
//          En revanche, ces implémentations vivent dans des modules séparés, dans des modules de traitement de données et ont des dépendances vers ces interfaces, donc dépendent du modèle objet.
// Grâce au pattern 'Visitor', nos traitements dépendent du modèle objet, ils peuvent bouger à la vitesse à laquelle ils veulent bouger.
// Etant donné qu'ils sont dans des modules séparés, ils peuvent être livrés séparémment, avec un processus différent, et donc réaliser des économies sur le coût d'entretien de notre application.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur le pattern Visitor //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Effectuons un petit bilan sur le pattern 'Visitor', dans quel cas est-il utile ?
//      --> Il est utile lorsque nous avons une hiérarchie d'objets de type différents, disparates, modélisés par des interfaces et par des classes d'implémentation.
//      --> Il est intéressant lorsque nous avons des traitements à faire sur ces objets. Des traitements dont certains sont connus, mais pas forcément tous.
//          En effet, une fois que l'implémentation de l'interface 'Visitor' est ajoutée au niveau de notre hiérarchie, nous pouvons rajouter des implémentations à la demande.
// Comment pouvons-nous mettre ce pattern en paramètre ?
//      --> Nous avons le 'Double Dispatch', d'abord, nous avons l'interface 'Visitor' à mettre en place, référençant l'intégralité des interfaces de notre hiérarchie avec autant de méthodes 'visit...()'.
//      --> Au niveau des interfaces qui modélisent nos objets, là nous avons besoin d'avoir des méthodes 'accept(Visitor v)'.
//          Ce qui veut dire que chacune des classes de notre hiérarchie va avoir un peu de code technique à ajouter qui va implémenter cette méthode 'accept()'.
// Quelles sont les faiblesses de ce pattern ?
//      --> Ceci est une des petites faiblesses du pattern 'Visitor', il est effectivement un peu 'intrusif' à l'intérieur des classes d'une hiérarchie.
//          En effet, une fois que nous avons un modèle objet, si toutes les classes n'ont pas été prévues pour être visitées, cela devient extrèmement coûteux de réécrire ces classes.
// En conclusion :
//              --> C'est un pattern qui est extrèmement puissant et qui permet d'avoir une séparation très propre entre les traitements d'une part, et le modèle objet d'autre part.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Architecture d'une application ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons comment nous pouvons organiser, à l'échelle d'une application, les modules d'une application, et ce que nous allons mettre dans chacun d'entre eux.
//      --> L'idée importante à retenir depuis le début de cette présentation, est qu'il faut, autant que faire se peut, mettre au centre des applications les éléments qui bougent le moins souvent.
//              --> La pluupart du temps ce sera le modèle objet, qui modèlise vraiment ce que fait une application.
//          Modèle Objet
//              |
//          Traitement métier
//              |
//          - Controler - Presenter : Pour tout ce qui est IHM.
//          - Gateway : Pour tout ce qui est accès réseau.
//              |
//          UX - Web - Mobile
//          DB - REST - SOAP
// Toutes les dépendances vont de l'extérieur vers le modèle objet, toujours de l'implémentation vers les règles de haut-niveau.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation de la partie IHM ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Examinons d'abord ce qu'il se passe avec les IHM. Supposons que dans notre modèle objet, nous avons un objet bien compliqué, qui est un objet de type 'Contrat'.
// Nous allons nous intéresser à la mise à jour d'un contrat. Donc dans notre processus métier, nous avons un processus à ce nom.
// Ainsi, nous avons une frontière entre notre entité d'une part, et notre traitement métier d'une autre part.
// Maintenant, quelles sont les étapes de la mise à jour de ce contrat ?
//      - Il faut d'abord présenter ce contrat à l'utilisateur avec un 'Presenter'.
//      - Ensuite il faut l'envoyer sur une 'View' qui va permettre à l'utilisateur d'intérragir avec les données qui lui sont présentées.
//      - Cette vue va repartir vers le processus 'MaJContrat', via un 'Controler'.
// Si nous regardons les dépendances dans ce schéma, nous nous rendons compte que la mise à jour du contrat, présente une dépendance vers 'Contrat'.
// Les autres flèches formant une boucle représentent non pas des dépendances, mais ce que nous appelons le 'Flow of Control', c'est à dire, le cheminement à l'exécution.
// -----------
// Contrat <--|-- MaJContrat --> Presenter --> View
//            |         |                       |
//            |         <-------- Controler  <--
// -----------
// Mainenant la façon dont nous allons organiser le code va nous permettre de fixer les dépendances à la compilation.
//      --> La nous ne parlons plus de 'Flow of Control' mais de dépendance entre les différents éléments de code source que nous gérons dans notre application.
// Ainsi, notre 'Presenter' doit dépendre de notre processus métier, donc de 'Contrat'. Cela veut dire que nous devons y introduire une interface.
// Nous l'appelerons 'Output', car elle nous permet de sortir les données de notre processus métier, et de les envoyer vers notre IHM.
// Donc, 'MaJContrat' appelle une méthode de l'interface 'Output'. Notre 'Presenter', lui est dans un module, et il implémente cette interface.
// Ainsi, la frontière entre notre processus métier, et notre 'Presenter', est bien traversée par une dépendance qui va dans le bon sens, tant que 'Output' est dans le module des processus métier.
//      --> Toutefois, le processus métier à besoin de transmettre des données au 'Presenter', ces données venant de l'entité 'Contrat'.
//          Elle va le faire en passant un objet de type 'Contrat', mais qui est en fait un objet de transport, que nous allons appeller 'DTOContrat', 'DTO' voulant dire 'Data Transport Object'.
//          C'est un objet qui est indépendant du projet 'Contrat', qui est créé par le processus métier, et qui est local au module des processus métier.
//          Cet objet va être utilisé à l'interieur de cette interface 'Output'. Donc l'interface 'Output' va prendre l'objet 'DTOContrat' en paramètre.
//      --> Donc, le 'Presenter' va recevoir cet objet de transport, ce qui signifie que le 'Presenter' dépends de cet objet de transport.
// Notre 'Presenter' va transférer ces données à la 'View', et la dépendance entre la 'View' et le 'Presenter' va se faire exactement de la même façon, via une interface.
// La 'View' va ensuite générer des modifications, qu'elle va ensuite transférer à un objet 'Controler' qui vit dans le même module que le 'Presenter'. La 'View' va également dépendre du 'Controler'.
// Qu'est-ce que la 'View' va transférer comme données au 'Controler', de même, un objet de transport contenant ce que la 'View' a généré.
// A savoir que chaque module propose son propre objet de transport, lui évitant ainsi de réinverser les dépendances, et de garder isolé chaque module.
// Le 'Controler' va ensuite passer par une nouvelle interface 'Input', dont 'Presenter' dépends, et qui se trouve dans le module des processus métier.
// Ainsi, le 'Controler' va être une implémentation de l'interface 'Input', de sortes que toutes les dépendances vont des implémentations vers les règles de haut-niveau.
// -----------
// View -------|--> Presenter --|--> Output(I) <-- MaJContrat ---|--> Contrat |
//  |          |                |    DTOContrat         |        |            |
//  |          |                |                       |        |            |
//  -----------|--> Controler --|--> Intput(I) <--------         |            |
//             |                |    DTOContratBis               |            |
// ------------|----------------|--------------------------------|------------|
// Module n+3  |   Module n+2   |            Module n+1          |  Module n  |
// -----------
// Donc voici la manière d'implémenter ce processus avec ce 'Flow of Control', nous gardons les mêmes principes.
// Les frontières sont toutes traversées dans le même sens de sortes que ce soient les détails d'implémentation qui dépendent des règles de haut-niveau.
// Cela implique quelque chose que nous n'avions pas vu avant, qui est de définir comment est-ce que les données vont traverser ces frontières.
// Les objets de transport sont définis de ce côté de la frontière pour encore une fois, ne pas inverser le sens des dépendances.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentation de l'accès à la base de données ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Deuxième point de l'analyse de la manière dont nous pouvons implémenter ces grands principes aux applications réelles, l'intéraction entre le modèle objet et la base de données.
// Si nous sommes sur une application, qui utilise une base de données relationnelle pour stocker son modèle objet, la plupart du temps, nous allons nous retrouver avec un framework de type 'Hibernate'.
// Est-ce que l'utilisation d'Hibernate est intrusive dans un modèle objet, pas nécessairement, car Hibernate est particulièrement bien fait.
// En effet, nous ne dépendons pas des implémentations d'Hibernate, nous ne dépendons que des interfaces, et des annotations proposées par Hibernate.
//      --> Toutefois, nous créons une dépendance entre notre modèle objet et un framework, alors que les framework sont dans le cercle le plus externe de notre hiérarchie.
// Comment pouvons-nous gérer ce genre de chose ? Nous pouvons le voir dans notre 'Flow of Control'.
// -----------
// DB <--> CRUD Contrat --> Contrat
// -----------
// Comment pouvons-nous organiser cela en terme d'architecture, en respectant les patterns que nous avons vu.
// -----------
// Hibernate --> Couche d'adaptation --|--> DataAccess(I) <-- CRUD ---|--> Contrat |
//                                     |--> DTO               Contrat |            |
//  |          |                |                       |        |            |
//  -----------|--> Controler --|--> Intput(I) <--------         |            |
//             |                |    DTOContratBis               |            |
// ------------|----------------|--------------------------------|------------|
// Module n+3  |   Module n+2   |            Module n+1          |  Module n  |
// -----------
// La couche d'adaptation sera un élément d'implémentation de l'interface 'DataAccess' va recevoir les données sous forme de 'DTO', puis les recopier dans des objets Hibernate.
// Ces dernières vont porter les annotations Hibernater et référencer les interfaces Hibernate ou JPA.
// Hibernate définit sa dépendance avec la base de données dans le bon sens aussi, car c'est au moment du 'Runtime' que nous associons la base de données à Hibernate.
//      --> En organisant les choses de cette manière, nous respectons les liens de dépendance entre les modules qui sont des détails d'implémentation ou des framework, et les modules de haut-niveau.
// Il se trouve qu'en général, ce seront les objets de type 'Contrat' qui portent les annotations Hibernate, donc, 9 fois sur 10, dans les applications, ce schéma n'est pas respecté.
// En effet, dans cette situation là, Hibernate est directement en dépendance du modèle objet, ce qui va à l'inverse de ce qui est préconisé lorsque nous appliquons les principes 'SOLID' et les patterns.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bilan sur les Design Patterns et les Principes SOLID //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'avons-nous vu dans cette partie sur les Design Pattern ?
//      --> SOLID :
//              - Ce qui dirige le développement au niveau de l'écriture du code :
//                      --> Principe S : Single Responsibility Principle.
//                      --> Principe O : Open-Closed Principle.
//              - Ce qui dirige aussi l'organisation des applications :
//                      --> Principe L : Liskov Substitution Principle.
//                      --> Principe I : Interface Segregation Principle.
//                      --> Principe D : Dependency Inversion Principle.
//      --> Design Patterns : Nous avons vu sans en parler les deux suivants :
//              - Composite : Lorsqu'une classe référence d'autres classes comme la classe 'Project' est un composite des classes 'Employee'.
//              - Adapter : Lorsque nous voulons convertir des données qui nous arrivent dans un certain format, donc en tant qu'implémentation d'une classe, en données qui vont sortir dans un autre format.
//                  Donc en tant qu'implémentation d'une autre classe, comme ce que nous avons fait avec nos objets de transport.
//              - Visitor.
//              - Strategy.
//              - Builder.
// Ces Design Patterns sont indépendants du langage que nous utilisons, ce qui en fait sa force.
//      --> Le point clef qu'il faut comprendre est que l'application de ces principes permet de minimiser les coûts, notamment d'entretien des applications, ainsi que sur la livraison.
// Il y a une question très simple que nous pouvons nous poser, pour savoir si une application est modulaire ou non :
//      --> Est-ce que nous sommes capables de livrer les modules de cette application indépendamment les uns des autres.
// -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Neuvième partie : Consolidation (OpenClassRoom) ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cette partie du parcours va vous aider à consolider les fondamentaux vus dans les chapitres précédents.
// - Architecture MVC et principes SOLID : Structurer avec l'architecture MVC, appliquer les principes SOLID, résoudre des problèmes de programmation courants à l'aide de design patterns.
// - Maven : Organisation d'un projet Maven.
// - Les tests : Ecrire et affiner des tests unitaires, écrire des tests d'intégration.
// - Le débogage : Identifier des méthodologies, des outils, et le vocabulaire du debug, enquêter sur un bug avec un debugger Java, réparer des bugs avec VisualVM, JConsole, et des techniques de log.
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Écrivez du code Java maintenable avec MVC et SOLID ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans ce module, nous allons découvrir comment créer un service REST avec Java EE.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisez votre code Java à l'aide de l'architecture MVC //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'est-ce qu'un code de bonne qualité ? Quels sont les critères d'une bonne conception objet ?
// C'est pour répondre à ces questions que nous allons faire appel aux principes de conception 'SOLID'.
// Chaque lettre de cet acronyme représente une ligne directrice à suivre pour concevoir notre code.
// Dans ce cours, nous allons voir comment ces principes peuvent être mis en oeuvre au travers de l'architecture MVC 'Modèles-Vue-Controleur'.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les bonnes pratiques de programmation avec les principes SOLID ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si nous avons déjà utilisé un vieux vélo, nous pouvons constater que la mécanique est simple, donc facile à réparer et à maintenir.
// Nous souhaitons suivre la même philosophie lorsque nous concevons nos systèmes logiciels : facile à comprendre et facile à modifier.
//      --> C'est la raison d'être des principes 'SOLID'.
// Cela ne veux pas dire qu'en suivant ces règles, nous nous interdisons de construire des systèmes complexes. Mais nous voulons que chaque partie soit facilement compréhensible.
// Dans l'exemple du vélo, la chaîne à un rôle, ainsi que le cable de frein.
// Dans un système orienté objet, il arrive souvent, si nous ne faisons pas attention, de construire des classes trop compliquées.
// Par exemple, en utilisant trop l'héritage, ou en alourdissant les interfaces.
// En effet, en début de vie, un code va souvent être simple, mais avec le temps, nous ajoutons des fonctionnalités et la conception peut se dégrader.
// Nous avons donc besoin de bonnes pratiques pour éviter cela. C'est ici que les principes SOLID peuvent nous aider.
// Si nous concevons notre code au regard de ces pratiques, nous pouvons savoir quand et pourquoi notre code se dégrade.
// Nous verrons ainsi des exemples de bonnes implémentations, et aussi des contre-exemples typiques qui contreviennent aux principes SOLID.
// Finalement, nous comprendrons pourquoi chaque principe est une bonne idée, et dans quel contexte l'appliquer.
// -----------
//  - Découvrez les pièges des solutions complexes :
//      Voici un récit édifiant, celui des programmes spatiaux américains et soviétiques. Essayez de résoudre ce problème :
//      --> Comment écrire dans un environnement zéro gravité ? Les Américains et les Soviétiques ont chacun apporté une réponse différente.
//              --> Les ingénieurs américains ont planché sur l'élaboration d'un stylo pressurisé.
//              --> Les Soviétiques ont opté pour un crayon.
//      L'excès d'ingénierie est un piège dans lequel vous pourriez tomber.
//      Mais ce n'est pas le seul problème à envisager. Les systèmes logiciels gagnent en complexité au fil du temps.
//      Les utilisateurs veulent – toujours – de nouvelles fonctionnalités, que vous devez bien sûr leur fournir.
//      Et l’ajout de ces fonctionnalités peut, si vous n’y prenez garde, donner lieu à des conceptions inadéquates.
//      Voici comment surviennent les ennuis : la première fonctionnalité est facile à coder. Vous déterminez ce qu'il faut faire, effectuez le travail de conception et écrivez le code.
//      Vient ensuite une autre fonctionnalité qui ressemble beaucoup à la première, bien qu'elle diffère légèrement.
//      Comment mettez-vous en place cette nouvelle fonctionnalité ? Vous avez bien entendu la solution classique du copier-coller.
//      Prenez le code existant, faites-en un copier-coller et modifiez-le légèrement pour l'adapter à sa nouvelle destination. Répétez ensuite le processus pour les fonctionnalités suivantes.
//          --> À terme, ce code devient difficile à maintenir.
//      Vous pouvez aussi ajouter la nouvelle fonctionnalité en rendant un peu plus complexe une classe déjà existante.
//      Étant donné que la classe effectue déjà l'essentiel du travail, qu'entend-on par « un peu plus » ?
//      En réalité, le problème est double : tout d'abord, la solution gagne progressivement en complexité. Le nombre de personnes capables d'en comprendre le fonctionnement risque de diminuer.
//      Ensuite, un changement de mentalité s'opère. L'équipe commence à accepter un travail de moindre qualité, dans l'intérêt de fournir une fonctionnalité.
//      Cela dépasse la simple conception d'une architecture médiocre, dans le sens où il devient acceptable et même inévitable de recourir à une architecture médiocre.
//      Lorsqu’un projet de développement gagne en complexité, que la conception définie initialement n’est, plus respectée, et que cela devient problématique, on parle communément de... dette technique !
//      Comment éviter que vos solutions deviennent difficiles à comprendre et à modifier ?
//      Autrement dit, comment éviter de s'endetter ? La simplicité avant tout ! Une conception simple présente plusieurs avantages.
//      Demandez à n'importe quel mécanicien s'il préfère travailler sur un moteur de deux-chevaux ou sur celui d’un tout nouveau SUV (réponse : la première réponse).
//      Il présente l'avantage d'être plus facile à comprendre. Et plus facile à comprendre, dit plus facile à modifier (et à réparer !).
//      De plus, vous pouvez être davantage certain que la modification s'effectuera sans dommage.
//      Autre avantage, il est plus simple à tester. Si quelque chose est difficile à tester, cela signifie probablement qu'il manque de simplicité.
//      Scinder le test et le code associé, autour de composants plus simples à tester, peut être une solution. Plus facile à dire qu'à faire.
//      Heureusement, vous pouvez tirer profit des connaissances de ceux qui vous ont précédé, et qui ont identifié des méthodes d'intervention efficaces.
//      Les principes de conception SOLID synthétisent toutes ces idées.
//  - Identifiez les principes SOLID
//      Chaque lettre de l'acronyme SOLID représente un mantra à répéter pour concevoir l'architecture de votre système. Au fur et à mesure du cours, nous les analyserons chacun en détail.
//      Nous les mettrons également en pratique en concevant une application simple de jeu de cartes.
//          --> S.O.L.I.D, qu’est-ce que ça peut bien vouloir dire ?
//              - « S » correspond au principe single responsibility (responsabilité unique).
//                  Une classe ne doit faire qu'une seule chose et elle doit bien la faire. Elle ne doit avoir qu'une seule raison de changer.
//              - « O » correspond au principe open/closed (ouvert/fermé).
//                  Une classe doit être ouverte à l'extension, mais fermée à la modification.
//      Hmm… mais encore ? Eh bien, lorsque vous ajoutez un nouveau concept au système (une fonctionnalité), vous ne devriez pas avoir à revenir en amont.
//      Ceci, pour éviter d'effectuer tout un ensemble de modifications sur l’existant pour qu’il puisse supporter le code de la nouvelle fonctionnalité.
//              - « L » correspond au principe de substitution de Liskov.
//                  L'ajout d'un sous-type par héritage ne doit pas rompre le code existant. C'est ce que j'appelle le principe « zéro surprise ».
//                  En d'autres termes, si le système fonctionne et que j'ajoute une nouvelle classe héritée d'une autre, le système doit continuer de fonctionner.
//              - « I » correspond au principe interface segregation (ségrégation des interfaces).
//                  Il s'agit pour l'essentiel du principe de responsabilité unique appliqué aux interfaces.
//              - « D » correspond au principe dependency inversion (inversion des dépendances).
//                  Les classes de haut niveau ne devraient pas avoir à être modifiées lorsqu'une classe de bas niveau est modifiée.
//                  Les classes de haut niveau doivent définir une abstraction à laquelle se conforme la classe de bas niveau.
//      Nous mettrons en œuvre chacun de ces principes en Java. Intéressons-nous tout d'abord à la façon dont ils sont implémentés dans une architecture connue et reconnue :
//          --> L’architecture modèle-vue-contrôleur (MVC). Nous avons choisi de nous appuyer sur la structure MVC, car elle est en phase avec les principes SOLID.
// - En résumé :
//      --> Une conception simple, réfléchie et intentionnelle amène à un code facile à comprendre, modifier et tester.
//      --> L'application des principes SOLID est une ligne directrice pour ce type de conception.
//      --> Les principes SOLID sont les suivants :
//              - S : Responsabilité unique.
//              - O : Principe ouvert/fermé.
//              - L : Substitution de Liskov.
//              - I : Ségrégation des interfaces.
//              - D : Inversion des dépendances.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Structurez une application conforme aux principes SOLID avec l'architecture MVC ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous l'avons compris, SOLID est un ensemble de grands principes de programmation. Voyons comment ils sont mis en oeuvre dans un modèle bien connu : 'Modèle-Vue-Contrôleur' ou 'MVC'.
// L'approche 'MVC' propose d'organiser les classes en fonction de leurs responsabilités. Chaque partie du système, Modèle, Vue ou Contrôleur, a un rôle qui lui est propre.
// Le grand avantage de cette organisation est que nous pouvons facilement modifier le comportement d'une partie sans impacter les autres.
// Essayons de réfléchir au dernier restaurant dans lequel nous sommes allés, nous nous sommes assis sur une table, avons choisi un plat sur la carte, et un serveur est arrivé pour prendre notre commande.
//      --> Nos intéractions avec le système 'Restaurant' s'arrête là.
// Toutefois, en coulisses, le serveur à transmis notre commande en cuisine, et les cuisiniers ont préparé notre plat en suivant une recette.
// Cette organisation suit le pattern 'MVC' :
//      - D'abord, le 'Modèle', c'est la raison d'être du système. Il représente les données qui sont manipulées et qui persistent dans le temps.
//          Dans un système logiciel, le modèle est souvent sauvegardé en base de données.
//              --> Dans notre exemple, c'est le plat, et les ingrédients qui le composent.
//      - Ensuite, la 'Vue', elle présente les informations du 'Modèle' à l'utilisateur, et lui permet d'intéragir avec le système.
//              --> Dans notre exemple, c'est la carte et le serveur.
//      - Tout ceci nous amène au 'Contrôleur', c'est lui qui va réceptionner les demandes et coordonner les étapes de réponse et de traitement du modèle.
//              --> Dans notre exemple, c'est le personnel qui s'affaire en cuisine.
//      --> Les trois entités 'Modèle-Vue-Contrôleur' travaillent ensemble pour que le repas se passse bien.
//          Imaginons que le plat arrive trop cuit, quelle partie du système à mal fonctionné.
//              --> C'est le bon plat, donc les données sont bonnes et conformes à la demande.
//              --> C'est donc en cuisine qu'il y a eu un problème, au niveau du contrôleur.
//                      --> Ainsi, il est inutile de modifier tout le système, il suffit d'agir sur le 'Contrôleur', et la prochaine fois le plat sera meilleur.
//      --> Si nous décidons de nous faire livrer chez nous un plat du restaurant, cette fois-ci, c'est la 'Vue' qui change.
//              --> Nous commandons en ligne, et c'est un livreur qui nous amène notre plat.
//              --> Dans cette situation, le 'Modèle' et le 'Contrôleur' ne changent pas.
// --> Nous allons voir qu'en codant nos applications en suivant cette même architecture, nous allons pouvoir produire du code efficace et maintenable.
// -----------
// Vous venez de découvrir les principes SOLID.
// Pour plonger au cœur du sujet et poser les fondations de notre code, appuyons-nous sur un patron de conception connu et éprouvé, qui applique à merveille les principes SOLID : MVC !
//  - En quoi consiste MVC ?
//      MVC est un motif d'architecture logicielle. Il scinde les responsabilités du système en trois parties distinctes :
//          - Modèle : le modèle contient les informations (données) utilisées par le système.
//          - Vue : la vue est la façon dont ces informations sont affichées pour l’utilisateur.
//          - Contrôleur : le contrôleur veille à ce que les demandes de l'utilisateur soient correctement exécutées, en modifiant les objets du modèle et en mettant à jour la vue.
//      Vous devriez déjà être capable d'identifier un des principes SOLID dans MVC : la responsabilité unique !
//          --> Comment cela fonctionne-t-il en pratique ?
//      Imaginez votre prochain repas dans un restaurant. D'abord, une personne vous accueille à l'entrée et vous demande de patienter jusqu'à ce qu'une table soit disponible.
//      Ensuite, elle vous guide jusqu'à votre siège. Un serveur prend votre commande. Le cuistot prépare la commande en cuisine, le serveur vous l’apporte à votre table.
//      Finalement, quelqu’un s'occupe du nettoyage après votre départ. Pour terminer, le plongeur nettoie tous les ustensiles de cuisine et la vaisselle.
//      Chaque personne a une responsabilité claire dans le déroulement de votre repas. Vous n'avez pas besoin d'interagir avec chaque personne impliquée dans cette organisation.
//      Le plongeur ne sort pas de l'arrière-cuisine pour vous aider à vous installer. Et aucune personne ne doit exécuter à elle seule l’ensemble des tâches.
//          --> Sur la base de cet exemple, voici du code Java contraire aux principes SOLID :
//                  class RestaurantWorker {
//                      public void seatPatrons();
//                      public void takeOrder();
//                      public void cookOrder();
//                      public void deliverOrder();
//                      public void cleanTable();
//                      public void washDishes();
//                  };
//          --> Ce code propose qu’un seul objet  (RestaurantWorker ) effectue tout le travail. Arghh !
//          --> SOLID nous préconise de répartir les responsabilités. Le motif modèle-vue-contrôleur (MVC) décrit cette répartition.
//              Il s'agit de la base de l'architecture de votre système. Chaque classe du système appartient à l'une des trois catégories et a par conséquent un objectif spécifique.
//  - Que contient le modèle (M) ?
//      Les informations d’état (données) sont contenues dans les classes de modèle. Il s'agit des informations affichées, manipulées et qui persistent dans le temps.
//      Si vous deviez programmer le restaurant cité en exemple, certains objets de modèle seraient la commande d'un client, ou le nombre de kilos de pommes de terre disponibles dans la réserve :
//                  class CustomerOrder {
//                      List<MenuItems> selectedItems;
//                      float baseCost;
//                      float tax;
//                  };
//                  class PantryItem {
//                      String name;
//                      float currentInventoryLevel;
//                      float reorderLevel;
//                  };
//      Ou, si vous pensez à notre jeu, le modèle correspondrait aux informations qui racontent notre « histoire ». Combien y a-t-il de joueurs ? Quel joueur détient quelle carte ?
//      Quelles sont les cartes restantes dans le jeu ? L'ensemble de toutes ces informations constitue l'état du jeu.
//  - Que contient la vue (V) ?
//      La vue englobe la présentation et les interactions du modèle avec l'utilisateur. C'est ce qui est le plus susceptible de changer.
//      Il faut vraiment distinguer la façon dont cette partie interagit avec le reste du système. Au restaurant, il s'agirait du menu, mais également du préposé à l'accueil, du personnel de service et de toute personne avec laquelle vous seriez en interaction directe. Si vous deviez élaborer une application, il s'agirait de votre interface utilisateur, ou UI. Vous pourriez concevoir l'une des vues de la façon suivante :
//                  class Greeter {
//                      public void askHowManyPeopleToSeat();
//                      public void reportEstimatedWaitTime();
//                      public void takeCustomersToTable();
//                  }
//      Ce code correspond aux interactions possibles avec l'utilisateur.
//  - Que contient le contrôleur (C) ?
//      Le contrôleur englobe la gestion du flux de l'application. Il est le chef d’orchestre des interactions entre l'utilisateur et le système.
//      L'utilisateur interagit avec la vue, qui interagit ensuite avec le contrôleur.
//      Le contrôleur prend les décisions : il apporte les modifications nécessaires aux objets du modèle, en crée de nouveaux ou supprime ceux qui ne sont plus utiles.
//      Dans l'exemple du restaurant, le contrôleur correspondrait à l'ensemble des règles définies par le propriétaire pour s’occuper d'un client :
//                  class ProcessCustomer {
//                      public void customerGreeted();
//                      public void customerSeated();
//                      public void orderTaken();
//                      public void orderDelivered();
//                      public void patronSatisfactionChecked();
//                      public void billPresented();
//                      public void billPaid();
//                  };
//      Il s'agirait ici du workflow ou du séquencement des étapes du parcours client.
//  - Quels sont les avantages de l'approche MVC ?
//      En suivant cette approche, vous concevez un système dans lequel les responsabilités sont clairement définies. C'est en cela que MVC se conforme au principe S du système SOLID.
//          --> Bon, petit rappel,  que signifie la lettre S ?
//                  --> Single responsibility (responsabilité unique). Nous examinerons chaque responsabilité dans un instant.
//                      Ceci dit, l'idée principale est que les classes du modèle font une chose, alors que celles des vues ou des contrôleurs en font d'autres.
//      Quant aux autres principes, ils sont également appliqués. Par exemple, la vue étant séparée, il est facile d'ajouter de nouveaux éléments d'interface utilisateur.
//      Et ceci, sans avoir à modifier le modèle ou le contrôleur.
//          --> Et de quel principe s'agit-il ici ?
//                  --> Le principe ouvert/fermé ? C'est exact !
//  - En résumé :
//      MVC suit le principe « S » du système SOLID en séparant les responsabilités.
//          - Le modèle contient des informations d'état, les données.
//          - La vue contient les éléments d'interactions avec l'utilisateur.
//          - Le contrôleur veille à ce que l'enchaînement des étapes s'effectue correctement.
// --> Dans le chapitre suivant, nous nous concentrerons sur la création des classes du modèle de notre jeu de cartes.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémenter le modèle de notre application ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'objectif ici est de devenir à l'aise avec MVC, et d'éviter de nous perdre dans les petits détails du code.
// De toutes manières, si nous suivons les principes SOLID, nos classes seront faciles à construire.
// Nous allons coder un jeu de carte, et utiliser MVC et les principes SOLID pour structurer notre code.
//      --> Nous aurons les objets du 'Modèle', comme les joueurs ou les cartes.
//      --> Nous aurons un 'Contrôleur' qui va orchestrer le jeu.
//      --> Et nous aurons la 'Vue' qui sera un simple affichage en console.
// Nous pourrons toutefois changer d'avis, et prendre une interface graphique par exemple, ce qui sera facile à mettre en place car nous aurons bien séparé la 'Vue' du reste de l'application.
// Les règles du jeu seront très simple, l'idée n'est pas de coder une intelligence artificielle, mais de nous concentrer sur la conception.
// Donc voyons les règles :
//      - Les cartes sont mélangées.
//      - Chaque joueur reçoit une carte.
//      - Nous regardons qui à la carte la plus forte.
//      - Nous affichons le nom du gagnant.
//          --> Par la suite, les cartes sont ramassées, et nous rejouons.
// L'enjeu ici, sera d'améliorer notre code, à mesure que nous avançons, et en suivant les principes SOLID.
//      --> Commençons par écrire les classes de 'Modèle' de notre application.
// -----------
// Commençons à coder! Pour appliquer les principes SOLID et l'architecture MVC, nous allons développer ensemble un jeu de cartes dont les règles seront simples.
// Nous créerons un jeu classique de 52 cartes. Nous disposerons d'un nombre paramétrable de joueurs et distribuerons une carte à chaque joueur ; le gagnant sera celui qui aura la plus forte.
// Nous allons coder la base du jeu puis effectuer des modifications au fur et à mesure du cours. Nous modifierons ensuite les règles ainsi que le jeu de cartes.
// Nous ajouterons une GUI (interface utilisateur graphique). Si nous observons les principes SOLID et l'approche MVC, l'impact de nos modifications sera réduit.
// Voyons les exigences de l'application.
//  - Règles du jeu (spécifications fonctionnelles) :
//      - Créer un jeu classique de 52 cartes.
//      - Entrer les noms des joueurs. Limiter le nombre de joueurs à cinq.
//      - Mélanger les cartes.
//      - Distribuer une carte à chaque joueur (face cachée).
//      - Retourner les cartes de tous les joueurs, afin qu'elles soient visibles.
//      - Identifier le joueur ayant la carte dont la valeur est la plus forte : As > Roi > Reine > Valet > 10 > . . . 2.
//  - En cas d'égalité, le choix du gagnant s'effectue en fonction de la couleur :
//      - Trèfle > Pique > Cœur > Carreau
//      - Présenter le nom et la carte du joueur gagnant.
//      - Remettre toutes les cartes dans le jeu.
//      - Recommencer à mélanger les cartes.
//          -->Ce type d'organisation est également appelé un cas d'utilisation. Si vous souhaitez en savoir plus, consultez le cours Appliquez le principe du Domain-Driven Design à votre application.
// -----------
//  - Concevez le modèle :
//      Identifions les principaux éléments que les joueurs verront et avec lesquels ils interagiront.
//      La méthode la plus simple pour trouver des objets de modèle consiste à parcourir les exigences fonctionnelles à la recherche des noms (substantifs).
//      En lisant la description, vous trouvez : un jeu de cartes, des joueurs, des valeurs et des couleurs de carte.
//          --> Comment mettre en lien les joueurs et leur carte ? Un joueur sera en possession d'une carte durant le jeu, n'est-ce pas ?
//              Même si cela n'est pas explicitement mentionné, la carte unique détenue par un joueur est intégrée à une classe Hand (une main, c'est-à-dire l'ensemble des cartes détenues par un joueur).
//              Cela reste conforme au principe de responsabilité unique.
//      Un joueur se définit par son nom et sa main.
//      Si les règles viennent à changer, il est probable que cela concernera le nombre de cartes détenues dans une main ou un détail dans la façon de manipuler les cartes.
//      Vous n’aurez donc pas à modifier le modèle de base d'un joueur si vous modifiez les règles du jeu.
//      Pour en savoir plus sur l'identification des objets de modèle, consultez le cours sur la conception orientée domaine d'OpenClassrooms.
//  - Implémentez le modèle :
//      À présent, vous allez devoir créer des classes Java pour chacun des éléments du modèle. Faisons cela ensemble !
//      J'utiliserai Eclipse comme environnement de développement. Vous pouvez utiliser l'environnement avec lequel vous vous sentez le plus à l'aise. L'environnement Java est toujours le même.
//          - Étape 1 : coder la valeur et la couleur :
//              Nous avons créé :
//                  --> Rank.java  (une énumération de 2 à as, l'as étant la valeur la plus forte).
//                          Comme nous voulons comparer les valeurs entre elles, nous associons chaque énumération à un entier.
//                          Ensuite, nous ajoutons du code pour associer un entier à une valeur de carte et inversement.
//                  --> Suit.java  (une énumération des couleurs, trèfle étant la couleur la plus forte).
//                          Pour cette énumération, nous la construisons de la même manière que la précédente.
//          - Étape 2 : coder une carte :
//              Nous avons créé :
//                  --> PlayingCard.java  (une valeur, une couleur et un flag indiquant si la carte est face visible ou cachée).
//                          Dans cette classe, nous allons utiliser les énumérations que nous venons de créer.
//                          Nous y appelons nos deux énumérations en tant que champs privé, avec un getter, mais pas de setter, car nous ne voulons pas que la valeur d'une carte puisse être changée.
//                          Nous ajoutons aussi un constructeur, ainsi qu'un flag 'faceUp' pour savoir si la carte est retournée ou non, avec une méthode 'flip()' pour modifier la valeur de 'faceUp'.
//          - Étape 3 : créer un jeu :
//              Nous avons créé :
//                  --> Deck.java  (un ensemble de cartes à jouer).
//                          Pour ce faire nous créons une List<PlayingCard>, et à présent il faut créer les 52 cartes, ce que nous devons faire dans le 'Controller'.
//                          Pour ce 'Controller', nous créons une double boucle forEach sur chacune des énumérations, puis nous l'ajoutons à la liste<PlayingCard>, donc l'objet 'Deck'.
//                          Ensuite, nous devons mélanger, donc nous appelons une méthode 'shuffle()', que nous allons créer, en utilisant un objet 'Random' et la méthode 'swap()' de l'objet 'Collection'.
//                          Enfin, nous créons trois dernières petites méthodes, un getter pour l'objet 'cards', une 'removeTopCard()' et une 'returnCardToDek()'.
//                          Ainsi, nous avons toutes nos méthodes pour le jeu de cartes au même endroit, dans notre 'Controller'.
//          - Étape 4 : créer une main et un joueur :
//              Nous avons créé :
//                  --> Hand.java (un ensemble de cartes de jeu détenues par un joueur).
//                          Nous la créons en tant que List<PlayingCard> même si dans un premier temps, un joueur n'a qu'une carte par main.
//                          Nous ajoutons les méthodes pour ajouter, et retirer des cartes de la main, ainsi que le getter.
//                              --> A noter que la 'Hand' ne se préoccupe pas du 'Deck', c'est le 'Controller' qui fera ça.
//                  --> Player.java  (un nom et une main).
//                          Nous créons un champs 'name', appelé par le constructeur avec un 'new Hand()' pour que le joueur ait systématiquement un nom.
//                          Puis nous ajoutons les méthodes pour ajouter, retirer et récupérer des cartes dans la main associée à ce joueur.
// À mesure que nous coderons le jeu, en conformité avec les principes SOLID, nous modifierons tout cela.
// Dans le chapitre suivant, nous allons commencer à travailler sur le contrôleur et l’affichage en ligne de commande.
// -----------
// En résumé :
//  --> Le modèle se compose des éléments avec lesquels vous entrez en interaction. Ces derniers contiennent les informations d'état du système.
//  --> Pour identifier vos objets de modèle, référez-vous aux exigences de votre projet.
//  --> Dans notre application, nous avons défini ce qui suit :
//  --> le modèle se compose d'un joueur, d'une main, d'une carte, d'un jeu, d'une valeur et d'une couleur ;
//  --> un joueur a un nom et une main. Une main se compose d'une carte à jouer. Un jeu se compose de plusieurs cartes à jouer.
//          --> Dans le chapitre suivant, nous nous occuperons de l'enchaînement des événements du jeu.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentez le contrôleur et la vue de votre application //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une erreur classique pourrait être de lancer un café en oubliant de mettre le café. Dans nos applications, par contre, le besoin de séquencer les évènements est bien réel.
//      --> Dans l'approche MVC, c'est le 'Controller' qui a cette responsabilité. Il s'assure que les choses soient réalisées dans le bon ordre.
// Dans notre jeu, nous n'essayons pas de détterminer le gagnant avant que tout les joueurs aient une carte.
// Dans les tâches du 'Controller', nous avons :
//      - S'assurer que chaque joueur ait une carte.
//      - Calculer le gagnant.
// Cette logique de calcul peut aller dans le 'Controller', mais nous n'avons pas d'intérêt à la laisser ici. En effet, le 'Controller', lui, ne fait que séquencer les évènements.
// Quand vient l'heure de calculer le gagnant, il devrait solliciter une autre classe qui, elle, connaît le calcul, la logique métier.
// Ce serait par exemple une classe 'GameEvaluator'. De cette façon, si les règles du jeu changent, nous n'avons pas à toucher au 'Controller', mais seulement le 'GameEvaluator'.
//      --> C'est le 'O' de 'SOLID', 'Open / Closed'.
// Maintenant, il nous reste à concevoir la 'Vue'. Celle-ci est chargée :
//      - D'envoyer les évènements au 'Controller'.
//      - De montrer aux joueurs l'état du jeu.
// Le rôle de la 'Vue' est assez limité. D'abord, il faut saisir les noms des joueurs, ensuite, nous avons besoin que le 'Controller' distribue les cartes, et qu'il indique à la 'Vue' qui est le gagnant.
// Les échanges entre le 'Controller' et la 'Vue' sont a double sens, mais pour être flexible, nous allons faire en sorte que ce soit le 'Controller' qui définisse l'interface qui convient.
// Par exemple, une des méthodes sera de montrer le gagnant, avec une chaîne de caractères passée en paramètre.
// Pour réaliser l'affichage, notre 'Vue' devra implémenter cette interface et cette méthode, ce qui est pratique. En effet, le 'Controller', n'a pas à savoir de quelle manière la 'Vue' affiche le jeu.
// Il fait ainsi seulement appel à l'interface. Pour le moment, nous l'afficherons seulement sur la console.
//      --> La prochaine étape dans la conception de notre application MVC consiste à implémenter notre contrôleur. Entrons maintenant dans le vif du sujet !
// -----------
//  - Concevez le contrôleur :
// Le contrôleur est responsable de l'enchaînement des interactions avec l'utilisateur. Après observation du jeu, l'enchaînement des séquences se révèle être le suivant :
//      - Créer le jeu.
//      - Entrer les noms des joueurs.
//      - Mélanger les cartes.
//      - Distribuer une carte à chaque joueur.
//      - Retourner les cartes.
//      - Déterminer le gagnant.
//      - Afficher le gagnant.
//      - Recommencer le jeu.
// Le contrôleur doit savoir à quelle étape en est le jeu et recevoir une demande valide pour cette étape.
//          --> Comment le contrôleur est-il informé d'une demande  ?
// Une demande, ou commande d'entrée, vient de la vue. Le contrôleur évalue cette entrée.
// Toute entrée non valide est ignorée ou génère une exception de type erreur (vous décidez de la sévérité de l’erreur, et de la façon d'informer l'utilisateur de sa saisie non valide via la vue).
// Nous devons à présent examiner l'enchaînement des étapes ci-dessus et identifier les interactions entre le contrôleur et la vue.
//      - Démarrer le jeu :
//          La première étape consiste à instancier le contrôleur. Le contrôleur instancie les objets essentiels au démarrage du jeu.
//          Il s'agit du jeu de cartes et d'une liste vide de joueurs. Il doit également avoir connaissance de la vue.
//          La vue doit être créée ailleurs et transmise au contrôleur au lieu d'être créée par le contrôleur lui-même.
//          --> Bon, mais pourquoi faire en sorte que la vue soit transmise au contrôleur, plutôt que de le laisser créer la vue lui-même ?
//          Eh bien, si demain, vous deviez créer une version mobile de cette application, les composants UI seraient différents, non ?
//          Vous devriez donc modifier le contrôleur pour les créer. Et cela contreviendrait au numéro 2 des principes SOLID : le principe ouvert/fermé.
//          Nous examinerons cela plus en détail dans la partie 2.
//      - Entrer les noms des joueurs :
//          Après chaque saisie d'un nom par l'utilisateur, le contrôleur ajoute le nom à la liste des joueurs.
//      - Indiquer que la saisie des noms est complète
//          Le contrôleur demande à la vue de présenter l'état du jeu, c'est-à-dire les valeurs des divers objets.
//      - Distribuer les cartes :
//          Le contrôleur mélange les cartes et prend la première carte pour la donner à un joueur. Il demande ensuite à la vue de présenter l'état du jeu.
//          Qui se compose désormais des noms des joueurs et d'une carte, face cachée, pour chaque joueur.
//      - Révéler les cartes :
//          Le contrôleur retourne la carte de chaque joueur, puis calcule le gagnant. Il demande à la vue de présenter l'état du jeu, qui comprend à présent le nom du gagnant !
//          Les mains des joueurs sont ramassées et replacées dans le paquet de cartes.
//      - Rejouer :
//          Le contrôleur retourne à l'étape 3.
// --> Dans notre première implémentation, le contrôleur va effectuer lui-même le « calcul » du gagnant. Si vous avez bien suivi, vous devriez tiquer !
//      Pour violation d'un principe SOLID ! Eh oui, le contrôleur va exécuter plusieurs tâches !
//      Il ne se contente plus de réaliser l’enchaînement des interactions : il joue l’arbitre, en appliquant les règles !
//          --> Hep hep hep ! Prenez note de ce point.
//      Étant donné que nous changerons les règles ultérieurement, nous veillerons à arranger cela à ce moment en plaçant la logique de calcul dans une classe indépendante.
// -----------
// - Implémentez le contrôleur :
//      Le contrôleur doit avoir des méthodes pour chacune des étapes d'interactions avec l'utilisateur.
//      La vue appelle ces méthodes. Après chaque étape, le contrôleur informe la vue du nouvel état du jeu.
//          --> Écrivons ces méthodes ensemble !
//                  public class GameController {
//                      public GameController(View view, Deck deck) {}
//                      public void addPlayer(String playerName) {}
//                      public void startGame() {}
//                      public void flipCards() {}
//                      void evaluateWinner() {}
//                      void displayWinner() {}
//                      void rebuildDeck() {}
//                  };
//      Examinons à présent ce que nous avons écrit :
//          - Démarrer le jeu correspond à la View, au Deck et au GameController, instancié ailleurs (dans Main.java). Le GameController reçoit la vue et le jeu.
//          - Entrer les noms des joueurs correspond à la méthode addPlayer.
//          - Indiquer que la saisie du nom est complète est géré par la méthode startGame (une fois qu'un jeu est lancé, nous n'autorisons pas l'ajout de joueurs).
//          - Distribuer les cartes est également géré par la méthode startGame, car c'est la première chose qui se passe au début du jeu.
//          - Retourner/révéler les cartes est géré par la méthode flipCards. C'est également à ce moment que l'on calcule qui est le gagnant. De plus, la vue est appelée avec le nom du joueur gagnant.
//          - Rejouer (rebuildDeck()) récupère toutes les cartes distribuées, et les remet dans le jeu, puis retourne à l'étape 3.
// -----------
// --> Code :
// Pour implémenter le 'Controller', nous allons commencer par créer le chef d'orchestre de notre jeu, le 'GameController' dans une classe du même nom.
// Nous savons qu'il devra manipuler des objets du modèle ainsi que l'objet 'Vue', donc nous commencerons par lui ajouter une vue simpliste dans une seconde classe située dans la même classe.
// Maintenant revenons à l'implémentation du 'Controller'. Nous avons besoin :
//      - D'un 'Deck'.
//      - D'une liste de joueurs.
//      - D'un joueur qui sera le gagnant.
//      - D'une 'Vue'.
// Nous allons aussi introduire une énumération qui représentera l'état du jeu, ainsi que d'une variable pour contenir cette information.
// Ensuite, nous pouvons coder le constructeur du 'Controller', qui prends en paramètres la 'Vue' et le 'Deck', qui seront créés ailleurs, et il configure le reste des propriétés.
// Passons à présent aux autres méthodes. Nous allons dans un premier temps écrire une méthode 'run', qui va regarder l'état du jeu, et appelle des méthodes de la 'Vue' en conséquences.
// L'idée étant de boucler sur l'état 'AddingPlayers' pour ajouter autant de joueurs que nous le voulons. Maintenant, voyons les autres méthodes.
// La première est de définir les joueurs, puis il faut démarrer le jeu, donc mélanger le paquet, tirer une carte pour chaque joueur, et passer à l'étape suivante du jeu (avec la méthode 'run()').
// L'étape suivante consiste à montrer les cartes, calculer le gagnant, afficher le gagnant, reconstruire le jeu et passer à l'étape suivante en appelant toujours la méthode 'run()'.
// L'algorythme est simple, nous commençons en initialisant les variables, puis nous allons regarder la carte de chaque joueur, et la comparer avec la meilleure carte trouvée jusqu'ici.
// -----------
// - Concevez la vue
//      Rappelez-vous que la vue est à la fois l'interface utilisateur et le générateur d'événements. Le contrôleur appelle exclusivement les méthodes d'affichage de la vue.
//      Par conséquent, vous devriez vous intéresser à ce que le contrôleur demande à la vue d'afficher.
//      Et vous ne voulez pas que la vue accède directement aux informations du modèle (ce serait contraire au principe de la responsabilité unique).
//      Au lieu de montrer un joueur, vous devez seulement montrer le nom d'un joueur. Il s'agit de la seule information devant être affichée à ce stade. Il en va de même pour la carte de jeu.
//      Vous pouvez indiquer la valeur et la couleur à afficher, plutôt que la PlayingCard complète.
//      Faisons cela ensemble :
//              public class View {
//                  public void showPlayerName(int playerIndex, String name);
//                  public void showFaceDownCardForPlayer(int playerIndex, String name);
//                  public void showCardForPlayer(int playerIndex, String Name, String rank, String suit);
//                  public void showWinner (String winnerName);
//              };
//      Examinons ce que nous avons ajouté :
//          - Entrer les noms des joueurs : la vue envoie la chaîne saisie au contrôleur, lequel rappelle la méthode showPlayerName de la vue.
//          - Distribuer les cartes : appelle la méthode showFaceDownCardForPlayer de la vue.
//          - Révéler les cartes : appelle les méthodes showCardForPlayer et showWinner de la vue.
//      MVC recommande que les saisies soient collectées par l'UI, puis envoyées au contrôleur, lequel, en retour, rappelle la vue :
//          --> Vue (appelle) -> contrôleur (appelle) -> Vue.
//      Par exemple, après la saisie d'un nom, la méthode controller.addPlayer(playerNameString) est appelée. Le contrôleur rappelle la vue avec un nouvel appel showPlayerName(playerIndex, name).
//      Cela vous paraît un peu lourd ? Pourquoi la vue ne conserve-t-elle pas simplement les noms des joueurs ?
//      Ici, je ne peux pas hisser mon pavillon SOLID pour vous répondre. :) Les objets du modèle sont responsables de la gestion des données.
//      Les objets Player connaissent déjà le nom qu'ils stockent (c’est leur responsabilité unique). Par conséquent, ils peuvent tout aussi bien conserver cette donnée en un seul endroit.
// -----------
// --> Code :
// Dans cette partie, nous allons coder le squelette de la 'Vue', c'est-à-dire les méthodes que le 'Controller' va appeler.
// Les premiers appels que nous allons corriger sont ceux de la méthode 'run()'. Nous allons devoir demander à la 'Vue' de faire quelque-chose de particulier pour chaque état du jeu.
//      - Pour l'état 'AddingPlayers', nous voulons que la 'Vue' affiche la saisie du 'PlayerName', soit 'promptForPlayerName()'.
//      - Quand les cartes sont distribuées 'CardsDealt', nous voulons retourner les cartes 'promptForFlip()'.
//      - Finalement, après avoir montré le gagnant 'WinnerRevealed', nous voulons proposer une nouvelle partie 'promptForNewGame()'.
// Nous pouvons ajouter dans un premier temps ces méthodes sans leurs implémentations.
// A présent, nous allons ajouter des méthodes spécifiques pour chaque action que le 'Controller' va traiter.
//      - La premimère action est l'ajout d'un joueur, dans ce cas, nous allons devoir afficher le nom du joueur créé 'showPlayerName()'.
//      - Quand le jeu aura débuté, nous voudrons que la 'Vue' affiche tous les joueurs avec leur face cachée 'showFaceDownCardForPlayer()'.
//      - Quand les cartes seront distribuées, il faudra montrer la carte de chaque joueur 'showCardForPlayer()'.
//      - Une fois que le gagnant aura été déterminé, il faudra afficher son nom 'showWinner()'.
// Pour finir, nous pouvons extraire l'ensemble de cette classe 'View' et l'ajouter à une classe 'View' se situant dans un package spécifique à la 'Vue', afin de la séparer du 'Controller'.
// -----------
//  - Implémentez la vue :
//      Notre implémentation est simple. La vue présente seulement les noms des joueurs, les cartes distribuées et les résultats dans la console.
//      Cependant, comme nous avons isolé cette fonctionnalité, nous pourrions facilement remplacer le mécanisme avec une implémentation GUI.
//          --> Faisons cela ensemble.
//                  // Implementation en ligne de commande simple.
//                  // La vue n'a pas besoin de garder une liste des joueurs.
//                  // Cette méthode sera appellée par GameController à chaque fois qu'il faudra afficher le nom d'un joueur.
//                  public void showPlayerName(int playerIndex, String name) {
//                      System.out.println("[" + playerIndex + "][" + name + "]");
//                  }
// -----------
// --> Code :
// L'implémentation de la 'Vue' est très basique, nous appelons simplement des System.out.println() pour afficher l'information que le 'Controller' aura passé.
// Effectivement, c'est le mieux, car la 'Vue', n'a pas besoin de savoir ce qu'il se passe en coulisses.
//      - Le corps de 'setController()', lui, va simplement définir l'instance de notre 'Controller'.
//      - Les informations qu'envoient les utilisateurs sont saisies au clavier, donc nous fournissons à notre classe un simple objet de type 'Scanner', qui fera la lecture.
//      - Pour 'promptForPlayerName()', nous affichons un message, et demandons au scanner de récupérer une chaîne de caractères, l'indication de fin de saisie sera une chaîne de caractères vide.
//      - Pour 'promptForFlip()', 'promptForNewGame()' et 'showWinner()', nous appelons System.out.println() avec la chaîne de caractères fournie par le 'Controller'.
// Voila, nous avons maintenant une implémentation très simple de notre 'Vue' en ligne de console.
// -----------
//      --> Examinons le code. Nous disposons à présent d'une interface utilisateur simple qui affiche les informations que nous transmet le contrôleur.
//          Nous devons cependant retourner au contrôleur et appeler ces méthodes là où c'est nécessaire.
//          Et nous devons relier tous les éléments ensemble dans une classe de jeu qui aura une méthode principale appelante.
// -----------
// --> Code :
// Maintenant, nous allons assembler toutes les pièces du puzzle 'MVC', commençons par créer la classe 'Games' qui aura la méthode 'main'.
// Nous aurons besoin d'une instance de 'GameController', en sachant que son constructeur prends en paramètres un 'Deck' et une 'View'.
// Par la suite, nous n'avons plus qu'à appeler la méthode 'run()' sur notre nouvel objet de type 'GameController'.
// -----------
//  - En résumé :
//      --> Le contrôleur a pour mission de réaliser l’enchaînement des étapes d'un cas d'utilisation et de valider les événements envoyés par la vue.
//      --> La vue est responsable de la présentation des informations du modèle et doit collecter les saisies effectuées par l'utilisateur.
//      --> Les responsabilités du contrôleur sont définies en examinant le workflow de l'application. Les responsabilités de la vue sont définies par ce que le contrôleur doit présenter à l'utilisateur.
//      --> Nous disposons à présent d'une application opérationnelle fidèle à l'approche MVC !
//              --> Dans la partie suivante, nous commencerons à appliquer les principes de conception SOLID un par un, pour rendre notre application plus robuste.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Evaluation ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Compétences évaluées :
// - Quel est l'avantage d'utiliser l'approche MVC ?
//      --> Chaque couche (modèle, vue, contrôleur) respecte le principe de responsabilité unique.
// - Quelles informations doivent être incluses dans le modèle ?
//      --> Dé, joueur, modérateur, score du joueur.
// - Dans l’approche modèle-vue-contrôleur, lesquels des extraits de code suivants incombe au modèle ?
//      class StopWatch {
//          int elapsedSeconds;
//          int getElapsedSeconds() {
//              return elapsedSeconds
//          }
//          void beginTiming()  {
//              elapsedSeconds = 0;
//          }
//      };
// - Dans modèle-vue-contrôleur, lequel des extraits de code suivants appartient au contrôleur ?
//      class PossibleController {
//          View view;
//          Model someModelElement;
//          void processEvent(Event e) {
//              someModelElement.setNewValue();
//              view.update(someModelElement.getValue();
//          }
//      };
// - Dans modèle-vue-contrôleur, lequel des extraits de code suivants appartient à la vue ?
//      class PossibleView {
//          TextBox text;
//          ListBox playerList;
//          void handleUserKeypress(Event e) {
//              text.setText(e.getKeyValue());
//          }
//          void addNewPlayer(String player) {
//              playerList.append(player);
//          }
//      };
// - Laquelle des séquences suivantes présente une interaction MVC typique ?
//      --> L'utilisateur (interagit avec) la vue
//          La vue (interagit avec) le contrôleur
//          Le contrôleur (interagit avec) le modèle
//          Le contrôleur (interagit avec) la vue
// - Parmi les principes SOLID suivants, lequel est suivi par MVC ?
//      --> Les objets de vue peuvent facilement être modifiés, sans aucune modification pour le contrôleur (ouvert/fermé).
// - L'extrait de code suivant représente une partie d'un objet du modèle dans un système. Lequel des autres extraits de code pourrait faire partie de cette classe ?
//      public int roll () {
//          faceUpPips = Random.getNextInt(0, numberOfSides) + 1;
//          return faceUpPips;
//      }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Appliquez les principes SOLID dans votre code Java ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// « S » pour Single Responsibility, le principe de la responsabilité unique /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lorsque nous développons, nous devons absolument éviter la situation dans laquelle une classe fait plusieurs choses à la fois.
// Le 'S' de S.O.L.I.D. nous dit qu'une classe ne doit avoir qu'une seule raison de changer, et donc, n'avoir qu'une et une seule responsabilité.
// De cette manière, nos classes ont plus de chances de rester petites, facilement modifiables et testables.
// IL y a des signes qui montrent qu'une classe porte trop de responsabilités :
//      - Allonger la signature d'une méthode pour ajouter des traitements.
//      - Modifier souvent une classe pour des raisons différentes.
// --> Quand nous créons une classe, nous devrions choisir un nom de classe précis et explicite, en énonçant simplement que cette classe réalise telle action.
//      Au moment d'ajouter une nouvelle fonctionnalité, nous pourrons nous demander si le nom de la classe correspond toujours, donc si nous restons dans une responsabilité unique avec le principe 'S'.
// -----------
// L'une des tâches de mon fils à la maison est de vider le lave-vaisselle. Force est de constater que cela n'inclut pas de ranger les verres dans les placards, seulement les assiettes...
// Il est très, très fort pour mettre en application le principe de la responsabilité unique.
// En d'autres termes, une classe ne doit faire qu'une seule chose, et la faire bien. Pour le dire encore autrement, une classe ne doit avoir qu'une seule raison de changer.
// -----------
//  - Pourquoi utiliser le principe de la responsabilité unique ?
//      Vous voulez comprendre ce qui se passe dans une classe et rendre cela compréhensible aussi par le reste du monde : restreindre au maximum les responsabilités de la classe permet d'y parvenir.
//      Tout d'abord, cela vous permet d'accéder plus facilement au code qui vous intéresse : une idée = un endroit d'implémentation.
//      Dans notre partie de cartes, nous savons que tout ce qui est associé à une carte de jeu se retrouvera dans la classe PlayingCard.
//      Ensuite, les tests unitaires se rédigent beaucoup plus facilement.
//      Les tests de PlayingCard nécessiteraient seulement la validation des quelques éléments dont PlayingCard a la responsabilité (valeur, couleur et face visible).
//      Pour finir, il est facile de donner un nom à la classe, puisque les tâches de la classe sont évidentes et restreintes.
//          --> L’utilisation d’un nom complexe pour une classe est un très bon signe indiquant qu'une classe enfreint le principe de responsabilité unique.
//              Si les responsabilités sont trop nombreuses, il devient difficile de lui trouver un nom.
//              Si vous êtes tenté de donner "gestionnaire" ou "utilitaire" comme nom à votre classe, c'est sûrement que vous faites fausse route.
//      Résumons notre méthode :
//          - Examiner les exigences pour déterminer ce que le code doit faire.
//          - Scinder le code en responsabilités MVC.
//          - Pour chaque responsabilité, veiller à ce qu'elle soit placée dans la classe appropriée.
//          - Si une classe regroupe trop de responsabilités, créer de nouvelles classes pour isoler les responsabilités les unes des autres.
// -----------
//  - Appliquez le principe à votre code :
//      - Il s'agit d'un principe facile à enfreindre. Cela se produit lorsque vous devez ajouter une nouvelle fonctionnalité à un système.
//          Chaque brique de la fonctionnalité doit aller quelque part, n'est-ce pas ? Il peut paraître judicieux d'intégrer les nouvelles briques à des classes existantes.
//          Mais alors, la classe devra réaliser plus qu’une seule tâche...
//      - Examinons notre jeu de cartes. L'une des premières classes que nous avons implémentées est PlayingCard.
//          Elle est assez simple : une valeur, une couleur et un flag indiquant si la carte est face visible ou cachée.
//          Cette implémentation pourrait être utilisée dans de nombreux jeux de cartes différents (le poker, par exemple !). Comme dans la vraie vie !
//          Vous n'avez pas besoin d'un nouveau paquet de cartes pour chacun de vos jeux.
//      --> Nous souhaitons maintenant ajouter l'étape de calcul du gagnant d'une main, c'est-à-dire déterminer quel joueur a la meilleure carte.
//          Une des approches possibles consisterait à ajouter une méthode « isBetterThan(PlayingCard other) » à la classe PlayingCard...
//          Les PlayingCards se connaissent entre elles, donc il serait simple d'ajouter cette implémentation (moyennement satisfaisante) :
//                      // mauvaise implémentation
//                      // logique spécifique au jeu inclu dans le modèle
//                      class PlayingCard {
//                          Rank rank;
//                          Suit suit;
//                          boolean faceUp;
//                          public bool isBetterThan(PlayingCard other) {
//                              // l'évaluation du rang et de la suite se fait ici
//                          }
//                      }
//      - Cependant, la classe disposerait ici d'une nouvelle raison de changer. Vous voyez de quoi il s'agit ?
//          Si les règles changent, que par exemple on décide que le cœur est la couleur la plus forte, nous devons modifier PlayingCard.
//          Et si les règles changent à nouveau, nous modifierons à nouveau cette classe.
//          Comme vu plus haut, dans la réalité, vous n'avez pas besoin de paquets de cartes différents selon le jeu auquel vous jouez. Le même principe doit s'appliquer à notre application.
//              --> Et donc dans le code ci-dessus, la classe a plus d'une responsabilité.
//      - Le calcul du gagnant doit être réalisé ailleurs. Pour l'instant, ce code est intégré au contrôleur.
//          Il enfreint le principe de responsabilité unique. Le fait de calculer le gagnant ne modifie pas le flux des interactions (la mission du contrôleur).
//          Voyez-vous un moyen d'implémenter le calcul du gagnant, tout en respectant le principe de la responsabilité unique ?
// - Faites l'expérience vous-même !
//      Laissez-moi vous présenter la classe GameEvaluator.
//      Elle dispose d'une méthode permettant d'identifier le joueur qui a la meilleure carte, elle ne fait que cela et ce sera sa seule raison de changer !
//          --> Faisons cela ensemble :
// -----------
// --> Code :
// Nous avons écrit le code qui calcule le gagnant dans le 'Controller'. Donc nous ne respectons pas le principe de responsabilité unique.
// Ce que nous allons faire est ainsi, de créer une classe dédiée à la logique du calcul 'GameEvaluator'.
// Dans celle-ci, nous pouvons créer une méthode et y glisser le code précédemment dans le 'GameController' concernant le calcul du gagnant 'Player evaluateWinner(List<Player> players)'.
// -----------
//                      public class GameEvaluator {
//                          public Player evaluateWinner(List<Player> players);
//                      }
//      En parlant de changement, nous modifierons les règles du jeu dans le prochain chapitre, et découvrirons les avantages du principe ouvert/fermé.
// -----------
//  - En résumé
//      - L'expression responsabilité unique signifie qu'une classe ne doit faire qu'une chose, ou, dit autrement, n'avoir qu'une seule raison de changer.
//      - Ce principe est facile à enfreindre, à mesure que vous ajoutez de nouvelles fonctionnalités au système. Lorsque vous ajoutez une nouvelle fonctionnalité, réfléchissez à ceci :
//          --> Quels changements à venir peuvent avoir des répercussions sur la classe ?
//          --> Qu'est-ce qui pourrait conférer à la classe plusieurs raisons de changer ?
//      - N'oubliez pas : si une classe reproduit un concept de la vraie vie, elle doit uniquement implémenter la responsabilité correspondant à ce concept.
// --> Intéressons-nous à l'ajout de fonctionnalités supplémentaires à notre système, sans modifier ce que nous avons actuellement écrit, en appliquant le principe ouvert/fermé.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// « O » pour le principe ouvert/fermé ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les fonctionnalités que nous codons sont destinées à évoluer, ce que nous avons implémenté aujourd'hui ne répondra sûrement plus aux besoins de demain.
// En effet, nous voulons ajouter des fonctionnalités, mais ne pas casser ce qui fonctionne déjà.
//      --> C'est ici que le deuxième principe S.O.L.I.D., le principe 'O' pour 'Open / Closed' entre en jeu.
// Ce dernier nous préconise de fermer nos classes aux modifications, mais de les ouvrir aux extensions.
// D'une certaine manière, nous verrouillons ce qui est déjà fonctionnel et nous nous concentrons sur les nouveautés, ce qui est moins coûteux.
// Au lieu de modifier une classe, nous allons en ajouter une qui héritera ou implémentera un niveau d'abstraction plus haut.
// -----------
// J’ai travaillé sur un site de petites annonces entre particuliers, ciblant des marchés de niche et permettant d’acheter et de vendre des articles ayant des caractéristiques assez techniques.
// À chaque fois que nous ajoutions une nouvelle famille d’articles, une grosse partie du code devait être modifiée. Approche peu concluante lorsque nous voulions ajouter de nouvelles familles d'articles.
// Je me suis rendue compte que nous pouvions faire appel au principe ouvert/fermé. Une classe devait être ouverte pour l'extension, mais fermée pour la modification.
// Le système devait pouvoir s'ouvrir pour l'extension (nous pouvions ajouter de nouvelles fonctionnalités) et devait rester fermé à la modification.
// En effet l'ancien code n'avait pas nécessairement besoin d'être modifié lorsque nous ajoutions ces nouvelles fonctionnalités.
// En d'autres termes, les nouvelles fonctionnalités ne nécessitaient aucune réécriture du code existant.
// Hola hola, mais comment ? Je pensais que vous deviez modifier le code à chaque nouvelle famille d’articles !
// C'est ce que nous faisions, mais il n'était pas nécessaire de procéder ainsi. J'ai pu isoler l'essentiel de l'ancienne implémentation.
// Ensuite, je me suis concentrée sur les nouvelles données à gérer (les nouvelles familles d’articles). J'ai pu rendre le processus plus générique.
// À partir de là, lorsque nous ajoutions une nouvelle famille d’articles, nous ne modifiions rien (ou presque…) dans le code existant.
// Avec le terme générique, je fais référence à une approche moins spécifique, et par conséquent plus facilement réutilisable.
// -----------
//  - Pourquoi utiliser le principe ouvert/fermé ?
//      Si vous ne modifiez pas le code existant, vous savez que vous ne risquez pas de l’endommager.
//      Toutes les nouvelles fonctionnalités sont contenues dans la ou les classe(s) nouvellement ajoutée(s) et le risque de régressions est moindre.
//      L'aspect le plus complexe de ce principe est de reconnaître quand il peut être appliqué avant de commencer le codage.
//      Voici quelques exemples pour vous aider à reconnaître à quel moment le principe ouvert/fermé peut s’appliquer.
//          - Lorsque vous disposez d'algorithmes qui effectuent un calcul (coûts, taxes, scores de jeu, etc.) : il est probable que ces algorithmes changeront au fil du temps.
//              Commencez par créer une interface, puis effectuez des implémentations spécifiques dans les classes, en sélectionnant la classe lors de l'exécution.
//          - Lorsque vous avez des données qui entrent ou sortent du système : le point final (fichier, base de données, autre système) est susceptible de changer.
//              Il en va de même pour le format des données. À nouveau, commencez par définir une interface, puis une implémentation spécifique pour récupérer ou enregistrer les données selon les besoins.
// -----------
//  - Appliquez le principe ouvert/fermé à votre code :
//      Le calcul du gagnant est une étape pouvant faire l'objet de modifications. Dans le dernier chapitre, nous avons extrait une classe GameEvaluator.
//      Et si nous voulions modifier le jeu de manière à ce que la carte la moins forte gagne ? Nous pourrions ajouter un paramètre booléen indiquant quel type de calcul réaliser :
//                  evaluateWinner(List<Player> players, bool findHighCardWinner) {
//                      if (findHighCardWinner) { /* chercher le gagnant */ }
//                      else { /* chercher l'autre */ }
//                  };
//          --> Cependant, la méthode fait maintenant deux choses. Ce n'est pas une bonne idée.
//      Est-ce un si gros problème ?
//      Que se passerait-il si l'évaluation du gagnant s'effectuait en ajoutant encore plus de règles ? Cette méthode deviendrait difficile à comprendre, à tester et à gérer.
//      Dans ce cas, que devrions-nous faire ?
//      Nous devons convertir GameEvaluator en une interface. De cette façon, différentes règles peuvent être facilement créées sous forme d'implémentations spécifiques.
//      Toutes les implémentations de GameEvaluator disposeront d'une méthode evaluateWinner avec une liste de joueurs en paramètre.
//      Elles pourront ainsi effectuer toutes les vérifications souhaitées pour les mains des joueurs, et appliquer tous les algorithmes nécessaires pour calculer le gagnant.
//      Dans notre cas, nous créerons un GameEvaluator basé sur la victoire de la carte la plus forte ou la plus faible, en fonction de la partie choisie.
//      Faisons cela ensemble !
//      Nous allons utiliser le concept de l'injection de dépendance.
//      L'injection est le principe selon lequel un objet se voit attribuer (ou « injecter ») un objet à utiliser, au lieu d’instancier l'objet lui-même.
//      Vous disposez de l'objet par injection, via une méthode ayant pour paramètre une interface.
//      Et ailleurs dans le code, vous instanciez une implémentation de l'interface, puis utilisez cet objet pour l'injecter.
// -----------
//  - Étape 1 : l'injection de dépendance :
//     Dans notre jeu, nous « injecterons » le GameEvaluator de notre choix au lieu de laisser la classe contrôleur instancier l'une des deux implémentations de GameEvaluator.
//     Nous ajoutons un paramètre de type GameEvaluator au constructeur du contrôleur. Ensuite, nous pouvons transmettre l'implémentation de notre choix, en paramètre du constructeur.
//                  public GameController (GameEvaluator _gameEvaluator) {
//                       gameEvaluator = _gameEvaluator;
//                  }
//      --> Code :
//          Tout d'abord, nous commençons par ajouter une variable de classe qui va contenir le 'GameEvaluator', dans notre classe 'GameController'.
//          Et comme nous ne voulons pas que le 'Controller' instancie lui-même le 'GameEvaluator', nous modifions le constructeur pour qu'il prenne en paramètre ce 'GameEvaluator' et initie la variable.
//          Puis, nous le rajoutons partout où cela est nécessaire. Ceci nous ajoute de la flexibilité, car nous pouvons créer et utiliser d'autres 'GameEvaluator', sans avoir a modifier le 'Controller'.
//          C'est travailler de cette manière qui nous permet d'utiliser le principe 'O'.
//              --> Bien bien bien, le GameEvaluator est désormais injecté dans le GameController.
//                      --> Voyons comment rendre la partie GameEvaluator "ouverte".
// -----------
//  - Étape 2 : l'extraction de l'interface :
//                  public interface GameEvaluator {
//                      public Player evaluateWinner(List<Player> players);
//                  }
//                  public class HighCardGameEvaluator implements GameEvaluator {
//                  }
//                  public class LowCardGameEvaluator implements GameEvaluator {
//                  }
//      Le plus difficile est de savoir quelles sont les parties ouvertes et fermées. C'est ici que les interfaces sont utiles :
//          - La classe fermée (notre contrôleur) est celle qui ne change pas. Elle parcourt systématiquement l'enchaînement des événements, pour finalement calculer un gagnant.
//          - La partie ouverte (interface GameEvaluator) offre une implémentation souple, de sorte que nous pouvons facilement modifier les règles du jeu.
//      Cela est possible, car la classe fermée utilise la classe ouverte seulement via une interface. Pas mal, non ?
//      Le principe ouvert/fermé est utile lorsqu'on réalise des tâches qui ont des composantes flexibles (sources de données, algorithmes, etc.).
//      Faites de ces composantes flexibles la partie ouverte.
//          --> Faites un essai : extrayez l'interface GameEvaluator, et implémentez les deux évaluateurs spécialisés (carte forte et carte faible).
//      Voici les classes que vous pourrez obtenir :
//                  public interface GameEvaluator {
//                      public Player evaluateWinner(List<Player> players);
//                  }
//                  public class HighCardGameEvaluator implements GameEvaluator {
//                  }
//                  public class LowCardGameEvaluator implements GameEvaluator {
//                  }
//      Si vous avez besoin d'aide, consultez la solution fournie ci-dessous dans la vidéo :
//      --> Code :
//          Nous allons maintenant pleinement profiter du principe 'Open / Closed', en créant une couche d'abstraction entre la classe fermée, le 'Controller', et la classe fermée, le 'GameEvaluator'.
//          Pour faire cela, nous allons transformer le 'GameEvaluator' en une interface qui pourra avoir plusieurs implémentations.
//          Maintenant, nous pouvons ajouter sa première implémentation en créant la classe 'HighCardGameEvaluator', dans laquelle nous pouvons couper / coller notre méthode, dans l'actuelle interface.
//          Ainsi, l'interface ne contiens plus que le nom de la méthode et ses paramètres, et la classe d'implémentation contiens le contenu de la méthode.
//              --> Le 'GameEvaluator' est maintenant la partie ouverte, puisque nous pouvons créer une deuxième implémentation : 'LowCardGameEvaluator' qui implémentera une autre logique de calcul.
//              --> Ainsi, nous pourrons changer les règles du jeu sans avoir à modifier le 'Controller'.
// -----------
// - En résumé
//      - Le principe ouvert/fermé indique que les classes doivent être ouvertes à l'extension, mais fermées à la modification.
//      - Dans des systèmes existants, il peut être nécessaire de retravailler le code pour tirer parti du principe ouvert/fermé.
//              --> Dans le chapitre suivant, nous allons voir comment éviter un mauvais usage de l'héritage, grâce au principe de substitution de Liskov.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// « L » pour le principe de substitution de Liskov //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lorsque nous nous initions à la programmation orientée objet, nous sommes souvent contents de découvrir l'héritage. C'est un mécanisme qui fait écho au monde réel.
//      --> Nous créons une classe enfant qui partage certaines choses avec sa classe parent.
// Effectivement, c'est un bon moyen de réutiliser du code déjà écrit.
// Si nous prenons un exemple, nous pourrions comparer un zèbre à un cheval en se disant qu'un zèbre est un cheval qui a des rayures. Ce qui semble logique.
// Du point de vue héritage objet, partout où nous avons un cheval, nous pouvons placer un zèbre. Par contre, si nous donnons une carotte à un zèbre, nous risquons d'avoir des problèmes.
//      --> C'est le coeur du principe de substitution de Liskov.
//              --> L'informaticienne Barbara Liskov à préconisé d'utiliser l'héritage seulement si nous pouvons remplacer un objet d'une classe de base par un objet d'une sous-classe.
// Dans notre exemple, pour éviter les problèmes avant de tendre la main, il faudra vérifier que le cheval n'est pas un zèbre.
// -----------
//  - Découvrez la substitution de Liskov :
//      L'héritage est, à priori, une bonne idée. Vous disposez déjà d'un concept et vous voulez en ajouter un autre. Et ce concept n'est qu'une implémentation plus spécifique du concept d'origine.
//          --> C'est simple, il vous suffit de créer une nouvelle classe par héritage !
//      Cependant, il devient facile au fil du temps d'abuser de ce processus d'héritage. J'ai travaillé sur des projets où la hiérarchie des classes s'étendait sur 10 niveaux.
//      Il est facile de perdre le fil des opérations spécifiques effectuées par les classes filles. Tôt ou tard, il arrive que certaines classes soient ajoutées et dérèglent le système existant.
//          --> Il s'agit alors d'une violation du principe de substitution de Liskov, selon lequel :
//              L'ajout de classes héritées ne devrait pas entraver le fonctionnement d'un système déjà existant.
//      Ce principe doit son nom à Barbara Liskov, l'une des premières femmes aux États-Unis à avoir obtenu un doctorat en informatique.
//      Elle est également la créatrice des langages de programmation Argus et CLU.
//      C'est ce que j'appelle le principe zéro surprise. Lors de l'ajout d'une nouvelle classe dans la hiérarchie, le système existant ne doit pas dysfonctionner lorsqu'il utilise la nouvelle classe.
//      Dans le cas contraire, vous aurez une surprise. Et elle ne sera pas bonne.
// -----------
//  - Pourquoi utiliser le principe de substitution de Liskov ?
//      Imaginons que vous disposiez d'une classe Félin. Elle a une méthode appelée 'manger()'.
//      Pour nourrir votre chat, vous pouvez appeler la méthode avec une marque standard de croquettes pour chats en paramètre, par exemple Friskouz : le chat est content (comme peut l’être un chat).
//      Si vous ajoutez une nouvelle classe, Tigre, qui correspond bien à une sorte de Félin, la méthode 'manger()' sera de nouveau implémentée.
//      Cependant, les tigres ne raffolent pas de nourriture sous plastique. Ils mangent de la viande crue. Ce n’est pas ce qui était attendu ! Suuurprise !
//      Le problème survient lorsque vous estimez que l’appel de méthode “manger des Friskouz” convient à tous. Mais pourtant un tigre est bien un félin ? Donc cela devrait convenir.
//      En biologie animale, oui ; en programmation objet bien conçue, non ! Vous ne pouvez donc pas simplement entrer un tigre dans votre système, là où il y avait un Félin.
//      Et cela va à l'encontre du principe de substitution de Liskov puisque vous ne pouvez pas remplacer une classe de base (Félin), par une classe héritée (Tigre), sans impacter le reste du système.
//      Le principe de substitution de Liskov vous aide en limitant votre recours au mécanisme d'héritage.
//          --> S'il est facile de gérer les classes d'implémentation concrètes de bas niveau, il vaut mieux prendre du recul et réfléchir lors du traitement d'une abstraction de haut niveau.
//      Essayons par exemple de résoudre le problème du félin et du tigre. Vous disposez véritablement de deux classes concrètes (c'est-à-dire d'une implémentation spécifique).
//      Vous devez présenter quelques interfaces/abstractions de niveau supérieur :
//          - Carnivore, qui ne consomme que de la viande.
//          - Omnivore, qui consomme de la viande et d'autres aliments (comme Friskouz).
//      Désormais, lorsque vous ajoutez un animal quel qu'il soit, vous pouvez faire en sorte qu'il implémente l'une de ces deux interfaces.
// -----------
//  - Appliquez le principe de substitution de Liskov à votre code :
//      Dans le film Jurassic Park, ils ont commis l'erreur de laisser des personnes s'approcher des animaux carnivores.
//      Bon, OK, vous vouliez savoir comment utiliser les interfaces en conformité avec le principe de substitution de Liskov... OK !
//          --> Eh bien, la difficulté consiste à choisir où créer les interfaces dans la hiérarchie.
//      Le principe de ségrégation des interfaces nous apporte une aide. Vous découvrirez cela dans un chapitre ultérieur.
//      Tout comme dans l'exemple du félin, il semblait judicieux au départ de considérer le tigre comme un genre de félin. Mais le problème est apparu clairement au moment de l'implémentation.
//          --> Il est souvent difficile de savoir à l'avance à quel moment le principe de Liskov sera enfreint.
//              Cependant, lorsque vous découvrez une "infraction", vous devez repenser votre façon d'utiliser le concept d'héritage.
//      Aussi, lorsque vous envisagez d'utiliser le concept d'héritage, posez-vous les questions suivantes :
//          - Dans la classe fille, est-ce que toutes les redéfinitions de méthodes sont justifiées et pertinentes ?
//          - L'implémentation d'une méthode redéfinie risque-t-elle de poser problème, et de générer le lancement d'une exception ? Si tel est le cas, c'est ennuyeux.
//          - L'implémentation d'une méthode redéfinie conduit-elle à ignorer l'appel et à ne rien faire ? Généralement, ce n'est pas bon signe, mais cela peut se justifier.
//              Soyez attentif et voyez si c'est le cas pour une seule méthode (OK !) ou pour plusieurs méthodes (KO !).
//      Si nous avions introduit le concept du joker dans notre jeu de cartes, lequel ne dispose d'aucune valeur ni couleur, le fait de demander ces valeurs serait une erreur :
//                  class Joker extends PlayingCard {
//                      public Rank getRank() {
//                          throw new UnsupportedOperationException();
//                      }
//                      public Suit getSuit() {
//                          throw new UnsupportedOperationException();
//                      }
//                  };
//      Notre code ne prévoit pas qu'une carte puisse être sans valeur ou sans couleur. Donc l'implémentation d'un joker en tant que simple carte de jeu obtenue par héritage serait incorrecte.
//          --> Alors comment gérer le joker ?
//      Jusqu'à présent, nous avons correctement mis en œuvre les principes SOLID. Nous avons parlé des interfaces, puis retardé les implémentations.
//      Mais dans ce cas, nous disposons d'une classe concrète comme point de départ. Cela rend les choses plus complexes.
//      Rétrospectivement, nous aurions dû être informés de l'existence de jokers durant les discussions avec le client.
//      Mais il arrive parfois que de nouvelles choses surviennent, et vous devrez vous adapter... !
//      Imaginons à présent que vous deviez revenir en arrière et modifier les énumérations de valeurs et de couleurs pour supporter le nouveau concept (le joker). Quelle est votre solution ?
//          --> Faites l'expérience vous-même !
//          --> Ajoutez 'NONE' aux deux énumérations. La résolution du problème n'est donc pas trop complexe :
//                  package com.openclassrooms.cardgame.model;
//                  public enum Rank {
//                      NONE(0),
//                      TWO (2),
//                      THREE (3),
//                      FOUR (4),
//                      FIVE (5),
//                      SIX (6),
//                      SEVEN (7),
//                      EIGHT (8),
//                      NINE (9),
//                      JACK (10),
//                      QUEEN (11),
//                      KING (12),
//                      ACE (13);
//                      int rank;
//                      private Rank(int value) {
//                          rank = value;
//                      }
//                      public int value() {
//                          return rank;
//                      }
//                  }
//      Et pour les couleurs :
//                  package com.openclassrooms.cardgame.model;
//                  public enum Suit {
//                      NONE(0),
//                      DIAMONDS (1),
//                      HEARTS (2),
//                      SPADES (3),
//                      CLUBS (4);
//                      int suit;
//                      private Suit(int value) {
//                          suit = value;
//                      }
//                      public int value() {
//                          return suit;
//                      }
//                  }
// -----------
//  - En résumé :
//      Le principe de substitution de Liskov s'applique aux hiérarchies d'héritage.
//      Il est enfreint lorsqu'une classe dérivée ne peut prendre la place d'une classe de base sans provoquer un dysfonctionnement du système.
//      Afin d'avoir la certitude de ne pas enfreindre cette règle, essayez d'envisager des abstractions/interfaces de haut niveau avant les implémentations de bas niveau/concrètes.
//              --> Dans le chapitre suivant, nous réfléchirons à l'intérêt de conserver des interfaces de petite taille grâce au principe de ségrégation des interfaces.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// « I » pour Interface Segregation, le principe de ségrégation des interfaces ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons tous déjà utilisé les fonctions 'copie', et 'copie cachée' de nos boites e-mail. Chacun de ces deux champs déclenche un fonctionnement différent.
// Nous pouvons considérer ça comme une application du principe de 'Ségrégation des interfaces'.
// Celui-ci dit que : "Les implémentations d'une interface, ne doivent pas être obligées de faire plus de travail que nécessaire".
// Cela suppose que l'interface définisse un petit nombre d'opérations. Dans notre exemple, chaque type d'e-mail, à une façon d'être envoyé.
// En ne respectant pas le principe de ségrégation des interfaces, nous aurions une grande interface qui gérerait les trois types.
// Ainsi, quand nous voudrions envoyer un e-mail, la boite mail devrait choisir entre les trois types, ou pire, envoyer les trois types alors que ce n'est pas nécessaire.
// --> Les interfaces sont utiles, mais nous voulons qu'elles restent petites et maintenables. Dans le principe de responsabilité unique, nous avons vu l'avantage de coder des classes petites.
//          --> Ici, le concept est le même, mais pour les interfaces.
// Ce qu'il faut retenir, est qu'à chaque fois que nous ajoutons une méthode à une interface, dans chacune des classes qui l'implémente, nous devrons recoder la méthode.
//      --> Alors, si nous sommes sur le point de coder une méthode vide, ou qui ne devra pas être appelée, c'est sûrement que notre interface en demande trop.
// -----------
// Si vous vous sentez à l'aise avec le principe de la responsabilité unique, le principe de ségrégation des interfaces vous semblera évident. C'est la même logique, appliquée aux interfaces :
//      --> Une interface doit décrire un ensemble de comportements.
// Vous pouvez rencontrer les mêmes difficultés avec les interfaces qu'avec les classes. Vous ajoutez une nouvelle tâche (méthode) à une interface existante, plutôt que d'en créer une nouvelle.
//      --> Conséquence : désormais, toutes les classes d'implémentation doivent prendre en compte cette nouvelle méthode.
// Conserver des interfaces de taille réduite et de conception simple permet de réduire le couplage. Le couplage fait référence au degré de connexion entre deux éléments logiciels.
// Plus une interface définit d'éléments, plus une classe qui l’implémente devra faire de même. Cela rend cette classe moins facilement réutilisable.
//      --> Une interface en parfaite adéquation avec ses responsabilités est considérée comme dotée d'une cohésion élevée.
//          Comme la responsabilité unique, la cohésion élevée indique qu'une interface décrit une seule chose, et ce de manière efficace.
// -----------
//  - Appliquez le principe de ségrégation des interfaces à votre code ?
// Puisque vous souhaitez implémenter une GUI pour la vue, vous pouvez extraire une interface avec laquelle le contrôleur doit interagir.
// Pour cela, récupérez les méthodes actuellement situées dans la vue, et placez-les dans une nouvelle interface appelée GameViewable.
// -----------
// Ce que nous allons faire ici, est créer un niveau d'abstraction pour la 'Vue' :
//      - Nous commençons par renommer notre classe 'View.java' en 'CommandLineView.java'.
//      - Ensuite, nous créons une interface 'GameViewable' et les déclarations des méthodes dont nous avons besoin.
//          --> Si nous regardons à présent le 'GameController', nous pouvons voir qu'Eclipse à gait les changements, et utilise à présent la classe 'CommandLineView'.
//                  --> Toutefois, nous voulons utiliser l'interface.
//      - Donc, dans la classe 'GameController', nous remplaçons l'appel à la classe 'CommandLineView' par un appel à l'interface 'GameViewable'.
//      - Il faut maintenant revenir dans la classe 'CommandLineView', pour indiquer qu'elle implémente l'interface 'GameViewable'.
//      - Nous pouvons à présent vérifier, dans notre méthode 'main', que nous avons bien une implémentation de l'interface 'GameViewable' qui est passée au 'Controller'.
//          --> Nous avons ainsi créé un niveau d'abstraction entre l'implémentation concrète de la 'Vue' et le 'Controller'.
// -----------
//      public interface GameViewable {
//          void setController(GameController controller);
//          void promptForPlayerName();
//          void showPlayerName(int playerIndex, String name);
//          void showFaceDownCardForPlayer(int playerIndex, String name);
//          void promptForFlip();
//          void showCardForPlayer(int playerIndex, String name, String rank, String suit);
//          void showWinner (String winnerName);
//          void promptForNewGame();
//      }
// Ensuite, la vue CommandLineView implémente tout simplement les méthodes !
// Ceci dit, il est facile d'ajouter des responsabilités à une interface alors qu'elles ne devraient pas y être. Dans ce cas, l'interface va perdre sa cohésion.
// Par exemple, notre GameViewable traite des commandes envoyées par le contrôleur à la vue (suite à une séparation MVC correcte).
// Si vous vouliez ajouter une commande pour quitter le jeu, il serait tentant de conclure, et ce de manière hâtive, que la vue peut s'en charger :
//      public interface GameViewable {
//          // mauvais placement de cette idée
//          public void restartGame() {
//              // fait des choses sans qu'on lui demande
//              exitGame();
//          }
//      };
// Mais maintenant, l'interface gère une opération sans demande provenant du contrôleur.
//      --> Ce concept de quitter le jeu est une fonctionnalité qui devrait se trouver dans la classe GameController, et non dans l'interface GameViewable.
// -----------
//  - Faites l'expérience vous-même :
// À votre tour !  Ajoutez la fonctionnalité de fin du jeu (quitter le jeu) à la classe GameController afin de vous conformer au principe de ségrégation des interfaces.
// -----------
// Pour ajouter une fonctionnalité de fin de programme, plutôt que d'enrichir l'interface 'GameViewable', c'est dans le 'Controller' que nous allons travailler.
//              --> Effectivement, c'est lui, qui en fonction d'un évènement sur la 'Vue', décidera, ou non, de quitter le jeu.
//      - Pour faire cela, nous allons ajouter la méthode 'exitGame' dans le 'Controller'.
//      - Maintenant, dans 'CommandLineView', nous allons modifier la méthode 'promptForNewGame()'.
//              --> Ainsi, nous laissons le 'Controller' décider de la prochaine action à réalise en fonction de la saisie qui aura été faite.
//      - Nous pouvons maintenant implémenter la nouvelle méthode 'nextAction()'.
//              --> Si la saisie sur la 'Vue' est '+q', nous quittons le jeu, sinon, nous recommençons une partie.
// -----------
//  - Récapitulons !
//      --> La ségrégation des interfaces est le principe de responsabilité pour les interfaces.
//      --> Il s'agit d'un principe facile à enfreindre. La tentation consiste à ajouter une nouvelle méthode à une interface existante, car celle-ci existe déjà.
//      --> En cas de doute, il vaut mieux avoir deux interfaces présentant un nombre limité de méthodes à implémenter, plutôt qu'une seule disposant de nombreuses responsabilités.
//      --> Dans le chapitre suivant, nous veillerons à ce que nos implémentations de bas niveau ne pilotent pas les implémentations de niveau supérieur !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// « D » pour Dependency Inversion, le principe d'inversion des dépendances //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Aujourd'hui, nous avons tous un numéro de téléphone portable, qui est le moyen de contact pour nos amis, notre famille et nos collègues.
// Si demain, pour économiser, nous décidons de changer d'opérateur téléphonique, si notre numéro doit changer aussi, tous nos contacts doivent être informés de ce changement.
// C'est laborieux, et nous risquons de rater des appels. C'est exactement la situation que nous voulons éviter dans nos développements.
// Nous voulons que les classes de haut niveau dictent ce que font les classes de bas niveau, et non l'inverse.
// Dans notre exemple, nous préfèrerions que la problématique s'inverse, nous gardons notre numéro, et c'est notre opérateur qui s'adapte à la situation.
// Pour nos contacts, le changement est transparent.
//      --> L'inversion des dépendances est le principe de développement qui décrit cette idée :
//              --> Les classes de haut niveau, dans notre exemple, nos contacts, communiquent via un haut niveau d'abstraction, notre numéro de téléphone.
//              --> Ceci permet que les implémentations de bas niveau, le choix de notre opérateur dans notre exemple, n'impacte pas le haut niveau.
// Voyons comment utiliser l'inversion des dépendances dans notre jeu de cartes.
// -----------
// Le principe d'inversion des dépendances semble toujours plus compliqué qu'il ne l'est en réalité. Voici l'idée :
// Les classes de haut niveau ne sont pas censées changer à cause des modifications réalisées dans les classes de bas niveau.
// Les classes de haut niveau sont généralement celles qui pilotent notre système. Vous souhaitez qu'elles restent aussi stables que possible.
// -----------
//  - Pourquoi utiliser l'inversion des dépendances ?
// Prenons l'exemple de la conduite. Les classes de haut niveau sont les éléments avec lesquels vous êtes le plus en interaction : le volant, l'accélérateur et la pédale de frein.
// Elles indiquent aux classes d'implémentation de bas niveau (pneus, moteur, freins) ce qu'elles doivent faire.
// Voyons ce qu'il se passe avec les classes de haut niveau si vous passez d'un moteur à essence à un moteur électrique... Rien !
// Un automobiliste continue de conduire, d'accélérer et de freiner à l'aide des mêmes commandes.
// Si vous aviez enfreint le principe D, le passage à l'électrique (classe de bas niveau) aurait rendu obligatoire une modification de l'interface (une classe de haut niveau) pour le conducteur.
// Ce qui semble évident pour une voiture peut facilement tourner à la désorganisation dans du code.
// Vous attribuez des responsabilités aux classes de haut niveau. Elles définissent l'interface via laquelle elles communiquent.
// Dans la voiture, vous faites accélérer le moteur en appuyant sur la pédale d'accélérateur. Il incombe au moteur de se conformer à cette norme.
// -----------
//  - Appliquez l'inversion des dépendances à votre code :
// Dans notre jeu, la vue doit être « pilotée » par le contrôleur. Le contrôleur décide donc de l'interface. Toutes les vues doivent s'y conformer.
// Sinon, à chaque fois que vous modifiez l'interface, le contrôleur devrait être modifié pour se conformer à la vue (le processus s'effectue de manière rétroactive).
// Ajoutons une GUI simple. Nous savons quelle interface elle doit implémenter (GameViewable). L'ajout de cette nouvelle vue ne devrait pas entraîner de modifications du contrôleur.
// Elle devrait parfaitement s'intégrer. Créons-la ensemble :
// -----------
// Nous allons maintenant profiter du principe d'inversion de dépendance. En créant l'interface 'GameViewable', nous avons supprimé la dépendance du 'Controller' aux classes concrètes de bas niveau.
//      --> Le 'Controller' ne dépends plus que d'une classe de haut niveau, l'interface. Les vues implémentées doivent se plier à cette interface.
// Nous allons ainsi profiter de ce phénomène, pour ajouter un nouveau type de GameViewable, une classe qui réalise des affichages 'Swing' :
//      - Nous commençons par ajouter la nouvelle classe, qui bien sûr implémente 'GameViewable'.
//      - Nous la remplissons en créant notre interface graphique, puis en remplissant les différentes méthodes héritées en utilisant les paramètres de cette interface graphique.
//      - Ensuite, dans la méthode 'main', il faut maintenant passer en paramètre une instance de 'GameSwingView'.
// --> Nous avons modifié l'architecture de notre jeu pour que non seulement il soit MVC, mais qu'en plus, il applique les principes SOLID.
//          --> Ici, nous avons profité de l'inversion de dépendance pour ajouter une nouvelle implémentation de 'Vue' sans avoir à modifier le 'Controller'.
//          --> Dans la prochaine partie du cours, nous irons encore plus loin en implémentant des Design Patterns.
// -----------
// La façon la plus simple d'enfreindre le principe D est d'en savoir trop sur les implémentations.
//      --> Si vous connaissez le fonctionnement détaillé d'une implémentation, il devient tentant d'aller y écrire du code.
// Bon ! C'est une bonne chose que vous ayez appliqué les principes SOLID. Mais si vous ne l'aviez pas fait ?
// Il existe un endroit, entre le contrôleur et la vue, où peuvent être intégrés des couplages inutiles.
// Nous avons créé une interface pour les appels du contrôleur, et la vue qui l'implémente. Mais que se passe-t-il si le contrôleur modifie directement les composants graphiques de la vue ?
// Dans ce cas, le code GameController, ça ressemblerait à ceci :
//      public void addPlayerName(String playerName) {
//          // this knows too much about the view's implementation
//          view.textArea.append("[" + playerIndex + "][" + playerName +"]\n");
//      }
// Imaginons que vous vouliez modifier l'interface utilisateur afin d'améliorer son apparence. Remplacez la commande JTextArea par un ensemble de JLabel.
// Étant donné que le contrôleur connaît l'implémentation spécifique utilisée par la vue, il doit modifier son propre code pour gérer les nouvelles commandes.
// En d'autres termes, l'implémentation spécifique (implémentation GUI/de bas niveau) pilote à présent l'implémentation de haut niveau (le contrôleur). Mauvaise idée !
// -----------
//  - En résumé :
// L'inversion des dépendances nous dit que les concepts de haut niveau doivent communiquer par le biais d'abstractions de haut niveau.
// En d'autres termes : les classes de haut niveau ne devraient pas avoir à changer à cause des modifications apportées aux classes de bas niveau.
// Faites attention à ne pas en connaître trop sur les implémentations de bas niveau.
// Dans le chapitre suivant, nous examinerons plusieurs mauvaises pratiques ou pièges faciles inhérents à la programmation, et nous découvrirons comment les éviter.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Évitez les pratiques STUPID ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons décrit un ensemble de ligne directrices à suivre pour améliorer nos développements.
//      --> Un peu d'aide pour identifier les mauvaises pratiques serait maintenant la bienvenue.
// Un exemple phare, serait un code dans lequel nous aurions abusé du copier / coller pour implémenter des fonctionnalités qui se ressemeblent.
// Si nous voulions changer de framework ou de langage, nous devrions refactoriser le code, retester l'application, puis réaliser les changements.
// Après ça, si nous ou quelqu'un d'autre, doit à nouveau réaliser des modifications, le travail sera moins coûteux.
//      --> Voyons le détail des principes S.T.U.P.I.D., et retenons-les comme des pièges à éviter.
// -----------
// Vous avez découvert des approches efficaces pour concevoir vos développements. Envisageons à présent le processus inverse : les approches qui font empirer la situation.
//      --> Celles que vous voulez à tout prix éviter. Elles sont également associées à un acronyme, à l'instar de SOLID. Il s'agit de l'acronyme STUPID.
// La difficulté avec les concepts STUPID, c'est qu'ils semblent à priori recevables, à un moment donné. Au moins à court terme. Mais c'est leur maintenabilité à long terme qui fait défaut.
// Évitez par conséquent de vous laisser tenter, et trouvez un moyen de les remplacer par un principe SOLID. La meilleure façon d'éviter les mauvaises habitudes, c'est d'en prendre conscience.
// -----------
//  - S pour Singleton :
// Un singleton veille à ce qu'une seule instance d'une classe soit créée, ce qui peut sembler judicieux.
// Par exemple, si vous devez activer des sons dans votre système, vous disposez probablement d'une seule classe SoundManager.
// Vous appelez SoundManager.playSound(), et ce dernier définit le volume, charge le fichier audio et lance le lecteur multimédia de la plateforme.
//      --> Le problème survient lorsque vous commencez à envisager la plupart des fonctionnalités sous cet angle. Il devient tentant de recourir à un singleton pour tout.
// Vous vous retrouvez ensuite contraint de créer ces maudites classes managers qui gèrent les connexions, les vidéos, les bases de données et bien plus encore.
// Ce pattern finit alors par gérer des informations d'état. Ces informations sont des informations de modèle qui se retrouvent partagées dans l'ensemble des modules de votre application.
// En général, il n'est pas judicieux de rendre votre système dépendant de variables d'informations d'état. Le problème est que n'importe quelle partie du programme pourra modifier l'état.
// Reprenons l'exemple des sons. Votre code a paramétré le niveau du volume sur 4. Ensuite, d'autres parties du programme le paramètrent sur 11.
// Vous devez alors revenir en arrière et le reparamétrer sur 4. Ou vous devez identifier la partie fautive du code qui modifie le paramétrage de la valeur.
//      --> Quelle est la solution ?
//              --> Demandez-vous si vous avez vraiment besoin d'un singleton.
//                  Pourquoi cette classe doit-elle être accessible, comme s'il s'agissait de données générales ?
//                  S'il existe une seule raison pour qu'elle ne soit pas accessible à tous, c'est qu'elle ne doit pas être un singleton.
// -----------
//  - T pour Tight Coupling (couplage fort) :
// Voici le véritable problème d'un singleton : toute classe qui en utilise un est étroitement couplée à ce dernier.
// Cette classe ne peut être extraite et utilisée ailleurs. Elle emmène toujours le singleton avec elle.
//      --> Vous pouvez réduire le couplage en codant des interfaces plutôt que des implémentations.
// Vous avez vu précédemment ce qui arrive lorsque nous couplons étroitement le contrôleur à la vue (quand le contrôleur a un accès direct aux widgets de la vue).
//      --> La modification de la vue entraîne des modifications intempestives au niveau du contrôleur.
// Cette même situation, être dépendant d'une implémentation concrète plutôt que d'une interface, peut se produire dans beaucoup de cas de figure.
// Soyez conscient du fait que les changements apportés à l'implémentation d'une classe peuvent entraîner des modifications sur d'autres classes qui dépendent d'elle.
// -----------
//  - U pour Untestability :
// Les raisons pour qu'une classe soit difficile ou impossible à tester sont nombreuses. Mais bien souvent, elle se résument à un couplage fort avec un autre composant.
// Si votre classe a de trop nombreuses dépendances, pensez à la réécrire.
//      --> Un composant peut s'avérer difficile à tester lorsqu'il enfreint le principe de responsabilité unique et effectue trop de choses.
// C'est pour cette raison que nous avons codé deux GameEvaluators (high et low) au lieu d'une seule méthode avec un paramètre booléen pour sélectionner l'un ou l'autre.
//      --> Il est plus facile de tester une méthode qui ne fait qu'une seule chose.
// -----------
//  - P pour Premature Optimization (optimisation prématurée) :
// L'optimisation prématurée consiste à anticiper un problème avant qu'il ne devienne un problème.
// Ce n'est pas toujours une bonne chose ! Par exemple, pendant notre partie de cartes, nous avons besoin de mélanger le jeu.
// Nous utilisons le générateur de nombres aléatoires de Java pour créer des index et déplacer les cartes en permutant leurs positions.
// Le mélange des cartes peut être un processus lent et répétitif. Nous pourrions concevoir un algorithme ultra-rapide. Il serait plus performant mais ne serait pas à la portée de tous.
// Et les cartes ne sont pas mélangées si souvent que cela. Cela ne vaut donc pas la peine d'optimiser cet algorithme.
// -----------
//  - I pour Indescriptive Naming (nommage non descriptif) :
// Si ce problème semble facile à éviter, il n'en reste pas moins qu'il survient assez fréquemment. Il survient, car au moment d'écrire le code, le problème et la solution semblent logiques.
// Imaginons que vous ayez un rectangle à gérer. Vous nommez les variables de l'angle supérieur gauche x1 et y1. Logique.
// Quelques mois plus tard, lors d'une revue de code, vous (ou quelqu'un d'autre) voit ces variables. Qu'est-ce que x1 ? Vous devez lire le code pour le savoir.
// Si vous aviez appelé les variables upperLeftCornerX et upperLeftCornerY, vous auriez immédiatement su à quoi elles correspondaient.
// -----------
//  - D pour Duplication :
// La duplication est un piège dans lequel il est très facile de tomber. Vous devez ajouter une nouvelle fonctionnalité.
// Elle ressemble à une autre fonctionnalité, mais avec un fonctionnement légèrement différent. Que faites-vous ?
// Copier/coller/modifier. En répétant cette méthode, vous finissez par avoir du code dupliqué à de nombreux endroits.
// Si quelque chose de fondamental doit être modifié, toutes ces duplications doivent être identifiées et modifiées.
//      --> Alors, on ne doit jamais copier-coller ?
// Les opérations de copier-coller sont parfaites pour mettre quelque chose en place en peu de temps.
// Mais vous devrez revenir sur votre code et trouver une meilleure solution qui soit viable à long terme. Posez-vous ces questions :
//      - Pourquoi y a-t-il autant de similitudes entre ces deux implémentations ?
//      - Le code dupliqué peut-il être placé dans une classe de base commune ?
//      - Puis-je extraire une interface et placer les éléments légèrement différents dans des implémentations différentes ?
// Il n'existe aucune réponse applicable à toute situation. L'essentiel ici est de se rappeler que toutes ces approches STUPID sont simples à mettre en oeuvre.
// Elles semblent sensées sur le moment. Les problèmes qu'elles génèrent n'apparaissent que bien plus tard durant le projet.
// -----------
//  - En résumé :
// Signification de l'acronyme STUPID :
//      - Singleton.
//      - Tight coupling (couplage fort).
//      - Untestability (impossibilité de tester le code).
//      - Premature optimization (optimisation prématurée).
//      - Indescriptive naming (nommage non descriptif).
//      - Duplication.
// Les approches STUPID aboutissent à la conception de codes difficiles à gérer et à tester.
// Il est facile de tomber dans le piège des approches STUPID. Vous devez donc rester vigilant et vous poser les bonnes questions, grâce à l'approche SOLID.
// Testons à présent ce que vous avez appris des principes SOLID dans le quiz de fin de section. On se rejoint ensuite pour apprivoiser les design patterns !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Evaluation ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Question 1 :
// Un nouveau type d'indemnités de congé doit être ajouté dans un système logiciel pour les ressources humaines.
// Le code d'origine doit être considérablement modifié pour supporter la fonctionnalité. Quel est le principe de conception SOLID enfreint dans cette situation ?
// --> Ouvert/fermé.
// -----------
//  - Question 2 :
// Une classe dérivée implémente une méthode redéfinie en lançant une UnsupportedOperationException. Quel principe de conception SOLID est enfreint dans cette situation ?
// --> Substitution de Liskov.
// -----------
//  - Question 3 :
// Si une méthode d'une classe présente de trop nombreux cas d’exécution possibles, elle est difficile à tester. Quel principe de conception SOLID est enfreint dans cette situation ?
// --> Responsabilité unique.
// -----------
//  - Question 4 :
// Quel est le principe SOLID enfreint par l'extrait de code suivant ?
//          public interface I {
//              void drink();
//              void eat();
//              void move();
//              void rent();
//              void block();
//              void run();
//              void purchase();
//              void packForTrip();
//          };
// --> Ségrégation des interfaces.
// -----------
//  - Question 5 :
// Pourquoi l'extrait de code suivant correspond-il au « U » dans les pratiques STUPID ?
//          class Rectangle {
//              int x, y, w, h;
//              int getAreaInPixels() {
//                  Rectangle r = graphics.createRectangle(x, y);
//                  graphics.moveToPosition(r, w, h);
//                  graphics.scale(r, w, h);
//                  return graphics.multiply(r.w, r.h);
//          }
// --> Il est impossible à maintenir..
// -----------
//  - Question 6 :
// Quel extrait de code complète le code suivant et lui permet de se conformer au principe d'inversion des dépendances ?
//          interface Driveable {
//              void accelerate();
//              void steerRight();
//              void steerLeft();
//              void steerStraight();
//              void brake();
//          };
// --> class Driver {
//          Driveable vehicle;
//          void navigateLeft() {
//              vehicle.steerLeft();
//          }
//          void navigateRight() {
//              vehicle.steerRight();
//          }
//          void navigateStraight() {
//              vehicle.steerStraight();
//          }
//          void navigateSpeedUp() {
//              vehicle.accelerate();
//          }
//          void navigateSlowDown() {
//              vehicle.brake();
//          }
//      };
// -----------
//  - Question 7 :
// Lequel des extraits de code suivants complète correctement le principe ouvert/fermé de l'extrait de code suivant ?
//          interface Rollable {
//              int roll();
//          }
//          class Game {
//              Rollable r;
//              void setRollable(Rollable roller) {
//                  r = roller;
//              }
//              void takeTurn() {
//                  r.roll();
//              }
//          };
// --> class Die implements Rollable {
//          int roll() {
//              return Random.get(0, 6);
//          }
//      };
//      class TestWith6 implements Rollable {
//          int roll() {
//              return 6;
//          }
//      };
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Résolvez les problèmes de programmation courants grâce aux design patterns ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Codez efficacement grâce aux design patterns //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Un parapluie lorsqu'il peut pourrait-être un exemple de Design Pattern, ou modèle de conception. Une solution réutilisable à un problème commun.
// Il existe un concept similaire dans le monde du développement logiciel. Nous rencontrons des problèmes tout le temps, et ce sont souvent les mêmes.
// Plutôt que d'inventer une solution à chaque fois, nous préférons tirer parti des connaissances et de l'expérience de ceux qui y ont réfléchi avant nous.
//      --> Maintenant, l'étape la plus délicate est de savoir quels problèmes nous avons devant nous.
// Pour nous aider, chaque Design Pattern est décrit par quatre éléments clefs :
//      - Le nom : le parapluie.
//      - Le problème : nous souhaitons nous protéger de la pluie.
//      - La solution : avoir un objet dans un matériau imperméable qui peut se plier et se transporter facilement.
//      - Les conséquences : bonnes ou mauvaises.
// Nous allons ainsi détailler de cette manière plusieurs modèles de conception.
// Certains s'occupent de créer des objets, d'autres facilitent l'organisation des classes, d'autres vont nous aider à faire communiquer les objets entre eux.
// -----------
// Que se passerait-il si vous conduisiez une voiture et qu'un pneu crevait ?
// Ce problème est suffisamment fréquent pour que certaines personnes aient réfléchi à sa solution (autre qu'appeler au secours, bien sûr...).
// La solution est la roue supplémentaire dans votre coffre, juste au cas où. On l'appelle la roue de secours.
// C'est un exemple de design pattern. Un problème qui survient si souvent qu'on lui attribue un nom et une solution connue.
// Je n'ai qu'à utiliser les mots "roue de secours" pour que vous sachiez immédiatement de quoi je parle. Cependant, chaque véhicule applique ce principe de manière différente.
// Certaines roues de secours sont petites et d'autres sont de taille normale. Certaines sont faciles à trouver dans le coffre, et d'autres non.
//      --> Mais l'essentiel est que vous me compreniez quand je parle de roue de secours.
// -----------
//  - Qu'est-ce qu'un design pattern ?
// Un design pattern est une solution testée et réutilisable appliquée à un problème récurrent. Il décrit la nature statique ou dynamique des classes et des objets qui implémentent la solution.
// Vous êtes libre de personnaliser la solution en fonction de votre situation particulière, comme la dimension de la roue de secours, par exemple.
// Les patterns sont généralement caractérisés par quatre attributs :
//      - Nom :
//          Le nom vous permet de décrire la situation à un "niveau élevé". Dans un langage universel.
//      - Problème :
//          Le problème décrit la situation à laquelle peut être appliqué le pattern. C'est la partie la plus complexe – être capable de reconnaître le problème existant et de choisir le pattern approprié.
//          Par exemple, dans notre jeu de carte, nous devons créer des jeux différents, contenant des numéros de cartes différents. Un pattern existe pour ce cas de figure !
//      - Solution :
//          La solution décrit l'assemblage des classes et des objets qui vont rendre le pattern opérationnel.
//          Même si vous pouvez réaliser quelques modifications pour vous adapter à votre cas personnel, vous devez conserver l'esprit du pattern.
//          Par exemple, nous utiliserons un pattern pour créer nos paquets de cartes.
//              --> Le pattern ne nous renseigne pas sur la façon de créer des jeux de cartes, mais nous fournit plutôt une vue d'ensemble de la création d'objets en tout genre.
//      - Conséquences.
//          Les conséquences sont ce qui se produit lorsque vous appliquez le pattern. Chaque pattern dispose au moins d'une conséquence positive.
//          Il résout le problème. Mais il arrive parfois qu'il ait des conséquences négatives. Par exemple, avec la roue de secours :
//              --> La taille de la roue a un impact sur votre capacité à transporter d'autres objets dans le coffre.
// -----------
//  - D'où viennent les patterns ?
// En 1994, la bande des quatre, ou « Gang of Four » (Erich Gamma, Richard Helm, Ralph Johnson et John Vlissides), a publié le livre 'Design patterns: Elements of Reusable Object-Oriented Software'.
// Ces quatre auteurs ont examiné plus de 300 projets sur lesquels travaillaient d'autres développeurs. Ils se sont rendu compte que les mêmes problèmes réapparaissaient sans cesse.
// Ils ont également remarqué que ces divers projets résolvaient lesdits problèmes d'une façon globalement similaire.
// Leur livre aborde ces problèmes et leurs solutions, en les appelant « patterns ». Ils ont classé les patterns en trois sections :
//      - Les patterns de création – des patterns ayant trait à la création d'objets.
//      - Les patterns de structure – qui ont trait à l'organisation des classes et des objets.
//      - Les patterns de comportement – qui ont trait aux interactions entre les objets.
// Dans cette partie, nous analyserons des exemples de ces trois types.
// -----------
//  - Pourquoi utiliser un design pattern ?
// Vous rencontrez systématiquement des problèmes lors de la structuration d'un logiciel.
// Vous pouvez toujours « bidouiller » une solution, mais cela entraîne des problèmes difficiles à résoudre sur le long terme. Vous souhaitez éviter les mauvaises pratiques de programmation.
// Savoir reconnaître les patterns est une des méthodes permettant de garantir un code "propre".
// Le principal avantage d'un design pattern est qu'il vous permet d’être sûr que la solution fonctionne. Vous n'êtes pas dispensé de réfléchir, mais cela vous évite de réinventer la roue.
// Voyons d'autres avantages.
// Tout d'abord, l'intelligibilité du code. Les patterns sont déjà correctement documentés. Vous n'avez pas besoin de rejustifier vos choix d'organisation.
// Vous savez déjà quel doit être le résultat en termes d'implémentation. Il s'agit simplement de gérer les spécificités inhérentes à votre code.
// Un autre avantage concerne l’amélioration de la communication entre les développeurs :
//      --> ous n'avez pas besoin d’expliquer en détail vos choix de conception, vous pouvez directement faire référence au nom du ou des pattern(s) que vous avez choisi(s).
// Je n'ai pas besoin de dire, « Avez-vous l'une de ces roues supplémentaires dans votre coffre, au cas où vous seriez victime d'une crevaison ? ».
// Je n'ai qu'à demander si vous avez une roue de secours : vous savez de quoi je parle .:honte:
// -----------
//  - En résumé :
// Les patterns sont des solutions testées et réutilisables qui sont appliquées à des problèmes récurrents.
// Quatre mots décrivent les patterns :
//      - Nom.
//      - Problème.
//      - Solution.
//      - Conséquences.
// L'utilisation de patterns conduit à une meilleure compréhension et une plus grande maintenabilité.
// Il existe trois types de patterns :
//      --> De création.
//      --> De structure.
//      --> De comportement.
// Dans le prochain chapitre, nous examinerons le premier ensemble de patterns : ceux dédiés à la création d'objets, appelés "patterns de création".
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez des objets avec les design patterns de création /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Récemment, un de nos amis à commandé des t-shirts pour son équipe de basket. Il a fourni un ensemble de caractéristiques, et une société s'est chargée de les lui fabriquer.
//      --> C'est un pattern classique qui s'appelle le design pattern 'Factory'.
// L'objet qui souhaite quelque chose, notre ami, demande à un objet tiers, la société, de lui fabriquer les objets dont il a besoin.
// Ces t-shirts seront fabriqués en suivant des étapes, pour avoir une coupe, une couleur et une taille précise.
//      --> Là, c'est le design pattern 'Builder' qui est appliqué.
// Il y a un algorithme de base qui à un degré de variablilité à chaque étape.
// Nous allons détailler les avantages qu'il y a à utiliser les 'Factory' :
//      --> Le plus grand avantage est la flexibilité.
//          --> En déléguant la création d'un objet à un autre objet, nous pouvons configurer la 'Factory' de telle ou telle manière.
//              Par exemple, si on est en phase de test, la 'Factory' peut être paramétrée pour créer des objets de test.
//              En production, nous paramétrons la 'Factory' différemment, pour qu'elle nous créée des objets réels.
//          --> Un autre champs d'utilisation pourrait être celui d'une application, déployée sur différents serveurs.
//              Une 'Factory' pourrait renvoyer différents objets selon l'environnement d'exécution du code.
//                      --> Commençons à utiliser les Design Patterns de création !
// Dans ce chapitre, nous découvrirons les avantages et les applications liés à l'utilisation de design patterns de création.
// -----------
//  - Pourquoi utiliser des patterns de création ?
// Pour que vos systèmes fonctionnent, vous avez besoin d'instancier des objets. En général, vous créez ceux dont vous avez besoin, au moment voulu. Vous verrez souvent le code suivant :
//      --> new someClassName();
// Mais ce code pose un problème. Oui, oui : vous n'avez aucune flexibilité ! Vous créez un objet de type someClassName. Pour toujours.
// À moins de revenir en arrière sur votre code. Comme déjà vu précédemment, le retour en arrière et la modification de code existant peuvent entraîner des problèmes.
// Alors, y a-t-il une autre solution ? Essayez autant que possible d'éviter d'utiliser le mot-clé « new ».
// Mais, c’est avec new que je crée de nouveaux objets ! Comment l'éviter ?
// Vous ne pouvez pas l'éviter totalement, mais vous pouvez l'utiliser de manière plus judicieuse.
// Il existe un adage, en développement logiciel, qui affirme que tous les problèmes de programmation peuvent être résolus grâce à un niveau d’abstraction supplémentaire.
//      --> Si vous l'appliquez, vous pouvez confier la création de votre objet à “quelqu’un d’autre”.
// Ce quelqu’un d’autre est certes du code nouveau, mais vous gagnez en souplesse dans votre code et ce, via un niveau supplémentaire d’abstraction.
//      --> Et c'est à ce moment que les design patterns de création peuvent vous venir en aide ! Examinons quelques exemples spécifiques.
// -----------
//  - Qu'est-ce que le pattern Factory ?
// Le pattern Factory (fabrique) consiste à confier à d'autres objets le soin de créer des objets pour vous. L'objet Factory est configuré d'une certaine manière, puis invité à créer l'objet voulu.
// Certains jeux ne nécessitent que 32 cartes pour jouer. Dans quelle mesure pourrions-nous modifier notre application de manière à utiliser seulement 32 cartes ?
// Le paquet de cartes est généré dans le contrôleur, ou il lui est transmis. Nous allons donc transférer la création du jeu dans une classe Factory.
//      --> Une Factory est une classe qui instancie des objets d'une autre classe. Si vous modifiez la Factory, vous modifiez ce qui est créé. Nous pouvons donc avoir des Factory de 32 et 52 cartes.
//          Nous choisissons celle correspondant au type de jeu que nous utilisons. Elle crée le paquet de cartes, et nous le transmettons au contrôleur.
// Voici une classe DeckFactory qui crée des jeux normaux, de petite taille et de test, en fonction du paramètre :
//              public class DeckFactory {
//                  public static Deck makeDeck(DeckType type) {
//                      switch (type) {
//                          case Normal: return new NormalDeck();
//                          case Small: return new SmallDeck();
//                          case Test: return new TestDeck();
//                      }
//                      // fallback
//                      return new NormalDeck();
//                  }
//              }
// Ensuite, toute classe ayant besoin d'un jeu normal pourrait effectuer l'appel suivant :
//      --> Deck myDeck = DeckFactory.makeDeck(DeckType.Normal);
// Effectuons cela ensemble :
// -----------
// Nous allons utiliser une 'Factory' pour créer des jeux de différentes tailles :
//      - Nous commençons par créer une classe 'FeckFactory' dans notre package 'model'.
//      - Ensuite, nous utilisons une énumération pour représenter les différents types de jeu.
//      - Plutôt que de passer par une interface, puisque la plupart des opérations seront les mêmes pour les différents types de jeux, nous allons passer par une classe abstraite 'Deck'.
//          --> Donc nous ajoutons 'abstract' à la déclaration de la classe 'Deck' déjà existante. Cette classe gèrera les cartes, mais n'aura pas de constructeur.
//                  --> Commençons par le 'NormalDeck', la classe est créée aussi dans le package 'Model' et va étendre la classe 'Deck', et son constructeur créera 52 cartes.
//                  --> Puis nous pouvons créer la classe 'SmallDeck', qui étends aussi 'Deck', et dont le constructeur créera 32 cartes, donc allant du 7 à l'as.
//                  --> Enfin, nous créons la classe 'TestDeck', qui étends aussi 'Deck', et dont le constructeur va seulement créer des as.
//      - Maintenant si nous retournons à notre 'Factory', elle ne contient qu'une méthode statique qui prends en paramètre le type de 'Deck' à créer.
//          --> En se basant sur le type passé en paramètre, elle construit le type de 'Deck' demandé.
//      - Maintenant que la 'Factory' est créée, nous pouvons l'utiliser.
//          --> Dans la méthode 'main' de 'Games', nous n'allons pas instancier de 'Deck', nous allons demander à la 'Factory' de le faire.
//                  --> Nous pourrions utiliser exactement la même approche, si nous avions plusieurs types de 'GameEvaluator' par exemple.
// -----------
// --> Nous avons ajouté une certaine flexibilité en demandant à un autre objet (DeckFactory) de créer l'objet que nous voulons dans notre jeu (NormalDeck, SmallDeck ou TestDeck).
// Les patterns peuvent être modifiés en fonction de nos besoins. Nous pourrions ajouter une méthode à DeckFactory pour préconfigurer le type de jeux créés par ce dernier.
// Dans ce cas, la nouvelle méthodemakeDeck() n'aurait pas besoin de paramètre et renverrait le type de jeu précédemment configuré.
//      --> C'est pratique lorsque vous écrivez des tests unitaires.
// Durant le test, le type de jeu serait paramétré sur Test. Et pour un vrai jeu, il serait paramétré sur Normal ou Small.
// L'approche Factory est utile quand nous souhaitons pouvoir choisir parmi plusieurs implémentations spécifiques, au moment de l'exécution.
// Il vous suffit d'indiquer à la Factory votre demande, et elle y répondra !
// -----------
//  - En quoi consiste le pattern Prototype ?
// Les patterns de création Prototype créent un nouvel objet en clonant un objet déjà existant. De nouveau, vous préconfigurez un ou plusieurs objets, des "modèles".
// Ensuite, vous sélectionnez celui auquel doit ressembler votre nouvel objet, et vous demandez au prototype vous retournez un clone du modèle.
// C'est comme cela que les cellules de votre corps se renouvellent ! Lorsqu'une cellule se divise, elle crée une copie exacte d'elle-même. OK, mais comment ça fonctionne en Java ?
//      --> En Java, une affectation se fait par référence. Par exemple, dans le code ci-dessous, a et b font tous deux référence au même objet.
//              SomeClass a = new SomeClass();
//              SomeClass b = a;
//              // This also changes a.someField since a and b refer to the same thing.
//              b.someField = 5;
// Si vous souhaitiez un objet totalement nouveau pour 'b', mais encapsulant les mêmes valeurs que 'a' au moment de la copie, vous utiliseriez un clone :
//              SomeClass a = new SomeClass();
//              a.someField = 1202;
//              SomeClass b = a.clone();
//              // a.someField remains 1202 since it is a different object.
//              b.someField = 5;
// Le clonage est un pattern pratique lorsque vous voulez une copie exacte, ou du moins très proche, d'un objet existant.
// Il est également possible de créer un objet de façon normale (appel de new), puis de setter toutes les valeurs à l'identique de l'objet modèle. Mais le code sera plus lourd à écrire...
// Une autre mise en œuvre consiste à faire une recherche dans un catalogue. Vous créez un ensemble d'objets préconfigurés que vous enregistrez dans un catalogue, avec une clé de recherche.
// Ensuite, quand vous avez besoin d'un objet d'un type particulier, vous demandez au catalogue d'en fournir un.
// Le catalogue trouve l'objet correspondant à la clé, le clone, et vous donne le nouvel objet à utiliser.
// -----------
//  - En quoi consiste le pattern Builder ?
// Il arrive souvent de créer un objet à partir de sous-éléments constitutifs, qui doivent être assemblés dans un certain ordre. Mais comment contrôler la cohérence de l'ensemble ?
//      --> Grâce au pattern Builder ! Le builder suit un algorithme afin de réaliser l’assemblage des sous-parties. Et ces sous-parties peuvent varier.
// Si vous avez déjà commandé une formule dans un restaurant, vous avez fait l'expérience du pattern Builder. Chaque formule se compose d’un plat, d'un dessert et d'une boisson.
// Mais les plats peuvent changer. Pour le plat, vous avez le choix entre une viande, un poisson ou une omelette. Le dessert peut être une tarte, une crème ou un fruit.
// La boisson peut être un apéritif, un verre de vin ou un café.
//      --> La personne qui prend votre commande ajoute un élément de chaque catégorie pour constituer la formule, et le résultat se compose toujours de trois éléments.
// Dans notre jeu de cartes, nous pourrions utiliser ce pattern (même s'il manque un peu de maniabilité). Nous disposons d'un ensemble d'options à sélectionner.
// Nous pouvons sélectionner la taille du jeu, ainsi que les options de carte forte ou faible pour le gagnant.
//      --> Notre objet Builder renverrait les implémentations adéquates, en fonction des options choisies.
//              public interface GameBuilder {
//                  Game getGame();
//              }
//              public class NormalHighCardGameBuilder implements GameBuilder {
//                  public Game getGame() {
//                      return new Game(DeckFactory.makeDeck(DeckType.Normal), EvaluatorFactory.makeEvaluator(EvaluatorType.High));
//                  }
//              }
//              public class SmallHighCardGameBuilder implements GameBuilder {
//                  public Game getGame() {
//                      return new Game(DeckFactory.makeDeck(DeckType.Small),EvaluatorFactory.makeEvaluator(EvaluatorType.High));
//                  }
//              }
// -----------
//  - En quoi consistent les singletons ?
// Nous l’avons déjà vu dans le chapitre sur les pratiques STUPID, les singletons sont un risque. Relisez cette section si vous avez besoin de vous rafraîchir la mémoire.
//      --> L'un des auteurs du livre sur les design patterns a déclaré que s'il pouvait réécrire ce livre, il aurait laissé celui-ci de côté.
// Si nous avions créé un SoundManager et choisi d'en faire un singleton, le résultat aurait été le suivant :
//              class SoundManager {
//                  // Il faut garder en mémoire l'instance unique quelque part, nous allons donc garder une variable statique.
//                  private static SoundManager _instance = null;
//                  // Comme n'importe quelle classe, il y a des attributs.
//                  private int currentSoundLevel;
//                  // Rendre le constructeur privé afin qu'il ne soit appelé par rien d'autre que les méthodes de cette même classe.
//                  private SoundManager() {
//                      currentSoundLevel = 11;
//                  }
//                  // La méthode que les clients appellent pour accéder au singleton.
//                  public static SoundManager getInstance() {
//                      // Si nous n'avons pas déjà d'instance, en créer une maintenant.
//                      if (_instance == null)
//                          _instance = new SoundManager();
//                      // Retourner celle que nous venons de faire ou que nous avions déjà faite.
//                      return _instance;
//                  }
//                  // Rien de spécial à propos des autres méthodes.
//                  public void setVolume(int value) {
//                      currentSoundLevel = value;
//                  }
//              }
//      --> L'essentiel est que le constructeur soit rendu privé. Mais nous devons toujours fournir une méthode pour accéder au SoundManager que nous créons. C'est le rôle de la méthode getInstance().
// -----------
//  - En résumé :
//      --> Les patterns de création ajoutent un niveau d’abstraction à la création d'objets, ce qui offre plus de flexibilité aux applications.
//              --> Le pattern Factory  consiste à créer un objet pour un autre objet. Vous pouvez configurer votre Factory pour créer un objet comme vous le souhaitez.
//              --> Le pattern Prototype permet de créer un nouvel objet en clonant un objet existant.
//              --> Le pattern Builder permet de créer un objet complexe en assemblant divers autres objets et en suivant un algorithme.
// Maintenant que vous savez comment créer des objets de différentes manières, examinons comment il est possible d'organiser des objets en structures complexes.
//      --> Dans le prochain chapitre, nous allons découvrir quelques design patterns de structure.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisez vos classes avec les design patterns de structure ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Imaginons un monde dans lequel nous ne pourrions pas envoyer un e-mail à une liste d'adresses. Il faudrait copier / coller le message et l'envoyer séparément à chaque destinataire.
// Imaginons à présent un autre monde dans lequel, pour envoyer un e-mail à une liste d'adresses, il faudrait utiliser une interface différente.
//      --> En fait, nous n'avons pas à nous soucier de cela, car le mailing-list utilise un Design Pattern de 'Structure', plus précisémment, le 'Composite'.
// Le Design Pattern 'Composite', nous aide à traiter de la même manière, un objet isolé et un groupe d'objets.
//      --> Ainsi, le but des Design Pattern de 'Structure' est de cacher la complexité.
// La complexité réside souvent dans l'agencement des classes, et dans la coordination des objets.
//      --> Ce que nous cherchons à faire est de masquer la complexité des interactions, pour que le code client ait des points d'entrée simples et peu nombreux.
// Un autre exemple de Design Pattern de 'Structure', serait qu'une prise éléctrique fournit une tension d'environ 220V, alors que le PC portable attends du 19V.
//      --> Nous avons donc un adaptateur qui se charge de transformer la tension. Il existe aussi un Design Pattern, appelé aussi 'Adaptator', que nous pouvons aussi utiliser dans nos développements.
// Mettons que notre code appelle les méthodes d'une API qui envoie des e-mails.
// Aujourd'hui, nous découvrons une nouvelle API plus performante, mais les signatures de ces méthodes sont différentes de celles que nous utilisons déjà.
//      --> Plutôt que de casser notre code, nous pouvons utiliser un adaptateur, qui fera le pont entre notre code et la nouvelle API.
//              --> Dans ce chapitre, nous découvrirons quels avantages nous pouvons tirer de l'utilisation de design patterns de structure dans notre code.
// -----------
//  - En quoi consistent les design patterns de structure ?
// Je suis certain que vous avez déjà fait vos courses dans un supermarché : le choix est vaste. Quand vous avez terminé, vous apportez vos articles à la caisse et vous payez.
// Vous échangez avec la personne à la caisse. C'est assez simple.
//      --> Il s'agit précisément d'un exemple de pattern de structure où une interface simple masque une grande complexité.
// En tant que client du magasin, vous ne voulez pas vous préoccuper de la commande des produits, de leur livraison, de leur étiquetage ou de la mise en rayon. Vous voulez juste faire vos courses.
//      --> Les patterns de structure correspondent à des manières d'organiser les classes ou les objets de façon à ce qu'ils soient faciles à utiliser.
//          Il peut se passer beaucoup de choses en coulisses, mais en tant qu'utilisateur, vous n'avez pas besoin d'en connaître toute la complexité.
//      --> Il existe deux types de patterns de structure. Ceux qui organisent les classes et ceux qui organisent les objets. Nous étudierons les deux types.
// -----------
//  - En quoi consiste le pattern Adaptateur ?
// Ce pattern répond au problème qui survient lorsque vous disposez d'un code qui attend une interface (ensemble de méthodes), mais que l'implémentation que vous comptez utiliser en fournit d’autres.
// Comment se sortir de cette situation délicate ? Cela peut arriver par exemple, lorsque vous faites appel à une bibliothèque tierce, après avoir déjà codé une partie de votre système.
// La bibliothèque fait ce que vous voulez, mais ses classes disposent de méthodes dont les noms diffèrent du code que vous avez écrit. Plusieurs options s'offrent à vous.
//      --> L'une d'entre elles (la plus complexe/mauvaise) consiste à revenir en arrière et à modifier tout le code existant, afin qu’il puisse utiliser les nouvelles classes et méthodes.
//      --> L'autre consiste à créer un adaptateur. L'adaptateur présente l'interface attendue. Et ensuite, l'implémentation de chaque méthode de l'adaptateur appellera des classes de la bibliothèque.
// Voyons un exemple concret ! Mon portable dispose d'un connecteur HDMI. Mais j’utilise un vieil écran, qui a seulement un connecteur VGA.
//      --> J'ai besoin d'un adaptateur pour convertir les signaux et travailler en double écran !
// Dans notre jeu de cartes, imaginons que nous ayons créé une interface PlayableCard et que notre PlayingCard l'ait implémentée :
//              interface PlayableCard {
//                  void flip();
//              };
//              class PlayingCard implements PlayableCard {
//                  bool faceUp;
//                  void flip () {
//                  faceUp = !faceUp;
//                  }
//              };
// Mais un autre développeur de l’équipe a créé une classe CoolCard qui a l’air mieux que notre implémentation. Nous décidons donc d’utiliser celle-ci à la place :
//              class CoolCard {
//                  void turnOver() {
//                  // Implémentation cool ici.
//                  }
//              };
// Si nous utilisions cette nouvelle carte, chaque endroit faisant appel à notre opération flip() devrait être remplacé par turnOver().
// Cela n'a rien de très difficile dans notre jeu de cartes, mais imaginez cela sur un projet de plus grande ampleur !
//      --> Utilisons à la place un adaptateur qui ressemble à une PlayableCard, mais qui se comporte comme une CoolCard :
//              class PlayingCardAdapter implements PlayableCard {
//                  CoolCard thisCard;
//                  void flip() {
//                      thisCard.turnOver();
//                  }
//              };
// Avec ce PlayingCardAdapter, nous n'avons pas besoin de modifier tous les appels à flip() ! Nous devons cependant utiliser des objetsPlayingCardAdapter au lieu d'objetsPlayingCard.
//      --> Mais souvenez-vous, nous disposons d'une Factory qui fait tout cela ! La Factory est donc la seule partie du code qui doit être informée de l'ajout du nouveau concept CoolCard.
// -----------
//  - Qu'est-ce que le pattern Composite ?
// Il arrive parfois que vous souhaitiez traiter de la même façon un ensemble d'objets et des objets individuels. Prenons l'exemple du tracé d'une forme.
// Si vous avez une forme simple, mettons un cercle, vous feriez l'appel suivant :
//              Shape shape = new Circle();
//              shape.draw();
// Vous souhaiteriez également appeler tout un ensemble de formes, en procédant de la même façon :
//              Shape shapes = new ComplicatedDiagramOfABunchOfShapes();
//              shapes.draw();
// Le design pattern Composite fait cela ! Chaque élément, qu'il s'agisse d'une simple entité ou d'un ensemble, présente la même interface (mêmes méthodes).
//      --> L'implémentation d’une méthode au niveau de la collection réalisera l’appel de la méthode pour chacun de ses objets.
// Dans le chapitre suivant, nous ajouterons plusieurs vues à l'aide d'un autre pattern. Pour préparer cela, nous voulons que le contrôleur traite une ou plusieurs vues comme si elles étaient identiques.
// Nous plaçons toute la gestion de la vue dans une nouvelle classe composite :
//              public class GameViewables implements GameViewable {
//                  List<GameViewable> views;
//                  public GameViewables () {
//                      views = new ArrayList<GameViewable> ();
//                  }
//                  public void addViewable (GameViewable view) {
//                      views.add(view);
//                  }
//                  @Override
//                  public void showPlayerName(int playerIndex, String playerName) {
//                      for (GameViewable view : views) {
//                          view.showPlayerName(playerIndex, playerName);
//                      }
//                  }
//                  // Autres overrides de GameViewable ici.
//              }
// Nous avons remplacé le fait de disposer d’une unique vue par le fait de disposer d’une liste de plusieurs vues.
// Ensuite, partout où nous demandions une mise à jour dans l’affichage de la vue, nous passons en revue la liste des vues, en demandant à chacune d'actualiser son affichage.
//      --> Vous remarquerez cependant que nous n'avons pas eu à modifier les noms de tous ces appels de méthodes pour mettre cela en oeuvre.
// Une seule ou plusieurs vues, cela revient au même pour les appelants de la fonction showPlayerName.
// Effectuons cela ensemble :
// -----------
// Nous allons nous préparer à pouvoir afficher le jeu dans plusieurs canaux simultanément, il nous faut donc un moyen systématique pour traiter un ou plusieurs 'GameViewable' :
//      --> Puisque nous avons déjà une interface 'GameViewable', notre nouvelle classe 'GameViewables' va l'implémenter.
// Il y a trois idées principales pour cette classe :
//      - D'abord, nous gérons une liste de 'GameViewable'.
//      - Ensuite, nous créons une méthode pour ajouter un 'GameViewable' à la liste, ainsi qu'un 'Controller' qui instancie une ArrayList.
//      - Enfin, pour chaque appel effectué par le 'Controller', il faut répercuter l'appel dans la vue de la liste.
//              --> Dans un prochain chapitre, nous verrons comment utiliser cette classe pour afficher simultanément le jeu dans plusieurs 'Vues'.
// -----------
// - En quoi consiste le pattern Décorateur ?
// Le pattern Décorateur est similaire au pattern Composite dans le sens où il permet à un groupe d'objets de se comporter comme si les différents objets n'en formaient qu'un seul.
//      --> Seule différence, les objets gérés par les décorateurs disposent d’une nouvelle fonctionnalité, dont l’objet initial ne disposait pas.
// Imaginez que vous commandiez une coupe de glace. La coupe se compose pour l'essentiel d'une boule de glace. Vous la dégustez avec une cuillère.
// Vous pouvez aussi ajouter des nappages, ou des fruits... En quelque sorte, vous décorez la coupe de glace. Mais vous continuez bien à la manger à l'aide d'une cuillère.
//      --> L'interface reste donc la même, même si la coupe de glace est devenue plus complexe.
// Revenons à notre jeu de cartes. Nous introduirons une interface nommée IPlayer, implémentée par Player.
// Lorsque le joueur est gagnant, nous souhaiterions afficher quelque chose de spécial, avec son nom.
// Mais seulement s'il est gagnant. Nous ajoutons donc une classe Décorateur appelée WinningPlayer.
// Implémentons-la ensemble :
//      --> Nous allons faire en sortes que l'affichage du nom du gagnant soit un peu plus élaboré, en utilisant le Design Pattern 'Decorator'.
//              - D'abord, nous introduisons une nouvelle interface 'IPlayer', en renommant simplement 'Player' en 'IPlayer', ainsi que ses usages dans les autres classes.
//              - Par contre, nous avons quand même besoin d'une classe concrête 'Player', donc nous allons la créer.
//              - Ensuite, nous pouvons changer 'IPlayer' en interface, en modifiant sa définition de 'class' à 'interface'.
//              - Par la suite, nous copions / collons l'implémentation de l'ancienne classe dans la nouvelle classe.
//              - Enfin, comme 'IPlayer' est une interface, ces méthodes ne sont pas implémentées dans l'interface, il faut donc les ajouter.
//      --> Dans une seconde étape, nous créons un 'Decorator' 'WinningPlayer', qui lui aussi, implémente 'IPlayer'.
//              --> L'astuce dans le 'Decorator' est qu'il va disposer d'une instance du 'Player' gagnant. Cette instance, est setted dans son constructeur.
//              --> Nous implémentons la méthode 'getName' en ajoutant un petit peu de paillettes.
//              --> Pour le reste des méthodes, nous appliquons simplement les méthodes du 'Player' 'winner'.
//      --> Nous allons maintenant pouvoir utiliser notre 'Decorator', et c'est uniquement le gagnant qui doit être décoré.
//              - Nous retournons dans le 'Controller' 'GameController', où nous calculons le gagnant.
//              - Ici, puisque le 'Decorator' 'WinningPlayer' implémente IPlayer, nous pouvons remplacer sans problèmes un 'Player' par 'WinningPlayer'.
//                      --> Les vues, elles, n'ont pas à savoir que nous avons fait ce changement.
// Tout d'abord, créons une nouvelle implémentation d'une PlayableCard, appelée WinningPlayer :
// public class WinningPlayer implements IPlayer {
//     IPlayer winner;
//     public WinningPlayer (IPlayer player) {
//         winner = player;
//     }
//     public String getName() {
//         return "***** " + winner.getName() + " *****";
//     }
// }
// Notez que nous avons encore besoin du Player d'origine (il contient le nom du joueur). Ce nouveau décorateur reprend la méthode getName, en mettant légèrement en évidence son nom, mais il appelle ensuite le joueur d'origine pour s'exécuter normalement. La dernière partie est vraiment importante ! On ne remplace pas la fonctionnalité, mais on l’enrichit (en la décorant).
// -----------
//  - En résumé :
//      --> Les patterns de structure correspondent à des façons d'organiser les classes ou les objets pour qu'ils soient faciles à utiliser.
//                  --> Le pattern 'Adaptator' modifie l'interface d'une classe pour la rendre compatible.
//                  --> Le pattern 'Composite' permet de traiter identiquement un objet ou une collection d'objets.
//                  --> Le pattern 'Décorator' permet d'ajouter et de supprimer des comportements supplémentaires au moment de l'exécution.
// --> Dans le chapitre suivant, nous découvrirons la communication entre les objets en étudiant les design patterns comportementaux.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Manipulez les objets avec les design patterns de comportement /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Visualisons une intersection en ville, dont les feux tomberaient en panne, la situation deviendrait vite chaotique, parce que personne ne saurait s'il doit circuler ou non.
//      --> Quand les feux fonctionnent correctement, ils implémentent un Design Pattern de 'Comportement', le 'Mediator'.
// Chaque conducteur se réfère à la signalisation pour savoir s'il doit circuler ou non. Ainsi, les conducteurs n'ont pas besoin de communiquer entre eux.
// Nous avons les mêmes besoins dans nos applications. Il nous faut des moyens systématiques pour coordonner les projets.
//      --> C'est ici que les Design Pattern dits de 'Comportement' peuvent nous aider.
// Un autre exemple est le Design Pattern 'Observator', qui permet d'organiser la diffusion d'informations.
//      --> Il nous servira, si lorsqu'un objet change d'état, d'autres objets doivent être informés de ce changement d'état.
// Si dans notre code, nous avons besoin de choisir dynamiquement l'exécution de tel ou tel algorithme, nous pouvons compter sur le Design Pattern 'Strategy'.
//      --> En définissant une interface, puis une implémentation pour chaque algorithme, nous disposerons d'une organisation saine pour décider du choix de notre algorithme.
// --> Voyons comment mettre en oeuvre les Design Pattern de 'Comportement' dans du code Java.
// -----------
//  - Découvrez les design patterns comportementaux :
// Si vous avez déjà patienté dans un grand aéroport, vous avez assisté au décollage et à l'atterrissage de nombreux avions. Comment cela se déroule-t-il chaque jour, (presque) sans encombre ?
// Une solution possible serait que chaque pilote soit en communication avec tous les autres pilotes afin de décider en commun de qui décolle et qui atterrit :
//      --> Une approche ingérable avec plus d'une demi-douzaine d'avions...
// Il existe un pattern comportemental pour résoudre ce problème. On l'appelle la tour de contrôle : une place centrale responsable de la coordination de tous les autres objets.
// Au lieu de parler entre eux, les pilotes communiquent avec un contrôleur central. Le contrôleur envoie ensuite des instructions à tous les avions.
//      --> bDans le monde du logiciel, ce pattern est appelé un médiateur.
// Comme entre les avions, la communication est souvent complexe entre les objets.
//      --> Les patterns comportementaux fournissent aux objets des moyens de communiquer entre eux de manière intelligente et systématique.
// -----------
//  - Le pattern Observateur :
// Dans beaucoup de situations, vous allez disposer d'un objet portant des informations d'état dont les autres objets doivent avoir connaissance.
// Lorsque ces informations d'état changent, tous ces autres objets doivent en être informés. Vous utilisez souvent ce pattern, lorsque vous regardez la télévision ou que vous écoutez la radio !
// Vous est-il déjà arrivé d'entrer dans une pièce, de voir la télévision, de vous dire « ça a l'air pas mal », et de commencer à regarder ?
// La télévision diffuse ses programmes, sans avoir besoin de modifier son mode de fonctionnement parce qu'une personne de plus est dans la pièce.
// Bon, souvent, vous finissez par vous lasser et vous partez. La télé, elle, ne fera rien de spécial après votre départ. Elle continuera à diffuser son programme dans la pièce.
// C'est la même idée que porte le pattern Observateur.
//      --> Les auditeurs intéressés peuvent aller et venir, mais l'objet exposant les informations ne change pas en fonction du nombre de spectateurs.
// Imaginons qu'un grand nombre de personnes souhaitent assister, sans interagir, à notre jeu sur leur propre écran.
// Puisque nous avons utilisé le pattern Composite dans le dernier chapitre, nous pouvons gérer une vue ou plusieurs de la même manière dans le contrôleur.
//      --> Donc pas besoin de modifier le code dans le contrôleur !
// Maintenant, si vous cliquez sur le nouveau bouton, vous verrez de nouvelles fenêtres s'afficher et elles vous présenteront l'état du jeu.
//      --> Et encore mieux, elles s'actualiseront toutes en même temps !
// --> Nous allons effectuer tout cela ensemble, entrons dans le vif du sujet.
// -----------
//      --> Nous allons maintenant permettre la visualisation de notre jeu dans plusieurs interfaces graphiques simultanées, et ce, toujours sans toucher au 'Controller'.
// En utilisant le Design Pattern 'Composite', nous avons déjà créé une nouvelle implémentation 'GameViewables', capable de transmettre ses propres instructions à une List<GameViewable>.
// Ce que nous allons faire à présent, est de créer un nouveau type de 'Vue' Swing. Ce sera une 'Vue' passiven qui réalise uniquement des affichages.
// --> Donc au final, notre jeu aura une interface d'affichage et d'interaction, et plusieurs autres vues passives pour diffuser en simultané l'état du jeu.
//      - Commençons par créer la nouvelle 'Vue' passive, que nous allons appeler 'GameSwingPassiveView', une classe qui implémente de nouveau 'GameViewable', évidemment.
//      - Voyons à présent comment instancier ces vues multiples, en retournant dans la méthode 'main' de notre classe 'Games', et commencer par instancier une vue 'GameViewables'.
//      - Nous pouvons ensuite instancier une vue 'GameSwingView', puis ensuite réaliser une boucle pour instancier plusieurs vues 'GameSwingPassiveView'.
//          --> Ainsi, nous instancions les vues, nous créons les frames, puis nous ajoutons la 'PassiveView' à la liste des vues de 'GameViewables'.
//          --> Nous utilisons cette instruction afin de permettre d'avoir le temps de voir la création de fenêtres pour pouvoir déplacer les fenêtres sur l'écran.
//          --> Enfin, c'est bien l'instance de 'GameViewables' que nous fournissons au 'Controller'.
// -----------
// Vous pouvez utiliser ce pattern lorsque vous disposez d'informations qui doivent être diffusées vers plusieurs objets.
// Par exemple, vous pouvez avoir besoin d'envoyer un e-mail ou un texte, d'écrire dans un journal et de mettre à jour un écran, car une modification a eu lieu dans votre application.
//      --> Chacun des objets d'action (e-mail, texte, journal, écran) peut recevoir des instructions s’il implémente le pattern.
// -----------
//  - Le pattern Strategy :
// Dans sa forme la plus simple, le pattern Strategy est un polymorphisme.
//      --> Quand vous disposez d'une famille d'algorithmes, vous pouvez chacun les encapsuler dans une classe qui implémente une interface commune.
// La façon de cuire une pièce de viande dans un restaurant est un exemple. Chaque cuisson, de "bleu" à "bien cuit", est réalisée de façon fondamentalement similaire.
// Le chef place la viande sur le grill pendant un certain temps, la retourne de l'autre côté et la cuit un peu plus.
// Ensuite, il teste sa cuisson. L'algorithme est sélectionné pour chaque personne, puis exécuté.
//              interface PrepareSteak {
//                  public void cook(Steak);
//              };
//              class RareSteak implements PrepareSteak {
//                  public void cook(Steak) {=
//                      /* Pas trop longtemps. */
//                  }
//              };
//              class MediumRare implements PrepareSteak {
//                  public void cook(Steak) {
//                      /* S'assurer que c'est cuit. */
//                  }
//              };
//              class Medium implements PrepareSteak {
//                  public void cook(Steak) {
//                      /* Garder le steak sur le grill un peu trop longtemps. */
//                  }
//              };
//              class WellDoneSteak implements PrepareSteak {
//                  public void cook(Steak) {
//                      /* Oublier le steak et revenir plus tard. */
//                  }
//              };
// Ainsi, dans l'exemple ci-dessus, quand une personne commande un steak, vous créez l'objet correspondant en fonction de la commande (bleu, saignant, à point ou bien cuit).
//      --> Mais la méthode appelée est toujours la même :   cook()  .
// Ce pattern utilise le principe ouvert/fermé. Il permet de créer différentes implémentations selon les besoins, tandis que l'appelant des objets Strategy n'a jamais besoin d'être modifié.
//      --> Utilisez ce pattern lorsque vous voulez permettre le choix d'une approche différente de celle pensée initialement, en toute flexibilité et sans avoir à réécrire d'autres parties de votre code.
// -----------
//  - Le pattern État :
// En Java, vous ne pouvez pas ajouter de façon dynamique des méthodes à un objet, ou les modifier une fois qu'elles ont été créées.
//      --> Cependant, il arrive parfois d'avoir besoin qu'un objet se comporte différemment lorsque son état change.
//              --> Une des solutions pourrait consister à ajouter de nombreuses instructions if et switch. Mais cela aboutirait à une conception confuse.
// À la place, vous pourriez ajouter une nouvelle hiérarchie de classes qui encapsule ces différents comportements.
//      --> L'objet utilisé par le client modifie ensuite l'objet initial, à mesure que son état change : c'est le pattern État !
// Par exemple, je demande à mon fils d'aller me chercher un soda dans le réfrigérateur. Plutôt que de le faire lui-même, il appelle sa soeur en criant, puisqu'elle se trouve dans la cuisine.
// Elle choisit un soda qu'elle sait que j'apprécie, le sort du réfrigérateur et le lui lance. Mon fils me remet alors un soda vanille-orange.
// Le lendemain, je redemande à mon fils de m'apporter un soda. Cette fois, un ami est dans la cuisine.
//      --> Mon fils appelle son ami en criant, qui, lui, n'a aucune idée de ce que j'aime. L'ami choisit un soda au hasard et l'envoie à mon fils. Mon fils me ramène une eau gazeuse. Raté.
// De mon point de vue, mon fils se comporte différemment (et pas seulement comme un adolescent).
// Hier, j'ai obtenu ce que je voulais. Aujourd'hui, cela n'a pas été le cas. Pourtant, mon fils n'a pas changé.
//              class Son implements Person {
//                  private Person personInKitchen;
//                  public void setPersonInKitchen(Person p) {
//                      personInKitchen = p;
//                  }
//                  public Soda getDadASoda() {
//                      return personInKitchen.getSodaFromFridge();
//                  }
//                  public Soda getSodaFromFridge() {
//                      return searchForGingerAle();
//                  }
//              };
//              class Daughter implements Person {
//                  public Soda getSodaFromFridge() {
//                      return searchForVanillaOrange();
//                  }
//              };
//              class SonsFriend implements Person {
//                  public Soda getSodaFromFridge() {
//                      return grabWhateverIFindFirst();
//                  }
//              };
// Donc, dans le code ci-dessus, l'appel lancé au filsgetDadASoda() entraînera à son tour l'appel getSodaFromFridge() pour tout objet qui a comme variable déclaréepersonInKitchen.
// Étant donné que cette valeur peut changer, différents objets implémentent getSodaFromFridge() différemment. Néanmoins, j'appelle toujours la méthode getDadASoda() de mon fils.
// -----------
//  - En résumé :
//          --> Le pattern 'Observator' permet à un objet d’observer le changement d’état d’un autre objet et d’agir en conséquence.
//          --> Le pattern 'Strategy' permet de choisir à la volée d’exécuter certains algorithmes pour des situations spécifiques.
//          --> Le pattern 'État' permet de changer le comportement d’un objet lorsque son état change.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Revoyons ce que vous avez appris //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Félicitations ! Nous avons terminé ce cours, et réussi à coder un jeu de cartes robuste.
//      --> En apprenant à coder avec les principes S.O.L.I.D. et M.V.C., nous avons construit des compétences précieuses pour notre métier.
//      --> Nous avons vu en détail, les 5 piliers d'un code S.O.L.I.D. :
//              - S : 'Single Responsability Principle', une classe ne doit avoir qu'une seule raison de changer.
//              - O : 'Open / Closed Principle', une classe doit être ouverte à l'extension, mais fermée à la modification.
//              - L : 'Liskov Substitution Principle', le principe zéro surprise.
//              - I : 'Interface Segregation Principle', la responsabilité unique appliquée aux interfaces.
//              - D : 'Dependency Inversion Principle', ce sont les abstractions de haut niveau qui commandent les implémentations de bas niveau, et non l'inverse.
//      --> Nous avons vu comment séparer la responsabilité des classes, dans nos applications, en suivant le modèle M.V.C. :
//              - Model : contiens les données du système.
//              - View : affiche les informations, et génère les actions en fonction des actions de l'utilisateur.
//              - Controller : reçoit les demandes et orchestre les actions.
// Tous ces concepts nous aideront à écrire du code plus facile à maintenir, et à tester, par nous et par les autres.
// -----------
//  - Félicitations !
// Vous avez terminé ce cours. Vous avez maintenant les connaissances nécessaires pour :
//      - Organiser votre code Java à l'aide de l'architecture MVC.
//      - Appliquer les principes SOLID à votre code Java.
//      - Résoudre les problèmes de programmation courants à l'aide de design patterns.
// Il ne vous reste plus qu'à mettre ces nouvelles compétences en application !
// Tout d'abord en relevant le défi du quiz de fin de partie, puis en intégrant ces bonnes pratiques de programmation à vos propres projets !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Evaluation ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// - Qu’est-ce qu’un design pattern ?
//      --> Une solution réutilisable pour un problème récurrent.
// -----------
// - Lesquels des concepts suivants permettent de décrire un design pattern ?
//      --> Nom.
//      --> Conséquences.
//      --> Solution.
//      --> Problème.
// -----------
// - Quel design pattern est implémenté par l'extrait de code suivant ?
//              public class GetAShape {
//                  HashMap<String, Shape> lookup;
//                  public void addShapeForName(String name, Shape s) {
//                      lookup.insert(name, s);
//                  }
//                  public void getShapeForName(String name) {
//                      return lookup.get(name).clone();
//                  }
//              };
//      --> Prototype.
// -----------
//  - Quel design pattern est implémenté par l'extrait de code suivant ?
//              public interface Shape {
//                  void draw();
//              }
//              public Circle implements Shape {
//                  void draw() { /* implementation here */ }
//              }
//              public Drawing implements Shape {
//                  List<Shape> shapes;
//                  void draw() {
//                      for (shape: shapes) {
//                          shape.draw();
//                      }
//                  }
//              }
//      --> Composite.
// -----------
//  - Quel design pattern est implémenté par l'extrait de code suivant ?
//              class CircleConverter implements Shape {
//                  SuperCircle superCircle;
//                  public void draw() {
//                      superCircle.sketch();
//                  }
//              }
//      --> Adaptateur.
// -----------
//  - Quel design pattern est implémenté par l'extrait de code suivant ?
//              public class ShapeMaker {
//                  public void makeShape(String name) {
//                      switch (name) {
//                          case "circle": return new Circle();
//                          case "triangle": return new Triangle();
//                          case "hexagon": return new Hexagon();
//                      }
//                  }
//              }
//      --> Fabrique.
// -----------
//  - Quel design pattern est implémenté par l'extrait de code suivant ?
//              class TrafficSignalController {
//                  List<TrafficSignals> signals;
//                  public void attachSignal(TrafficSignal signal) {
//                      signals.add(signals);
//                  }
//                  public void turnRed() {
//                      for (signal : signals) {
//                          signal.turnRed();
//                      }
//                      updateAll();
//                  }
//                  public void updateAll() {
//                      for (signal : signals) {
//                          signal.update();
//                      }
//                  }
//              }
//      --> Observateur.
// -----------
//  - Dans l'extrait de code suivant, un objet (Palette) semble se comporter différemment alors que l’on appelle la même méthode (write). De quelle implémentation de design pattern s'agit-il ?
//              interface Writeable {
//                  void write();
//              };
//              class Crayon implements Writeable {
//                  void write() {
//                      // implementation here
//                  }
//              };
//              class Marker implements Writeable {
//                  void write() {
//                      // implementation here
//                  }
//              };
//              class Artist {
//                  void draw() {
//                      Writeable utensil = new Palette();
//                      utensil.write();    // draws in blue crayon
//                      utensil.write();    // draws in red marker
//                  }
//              };
//              class Palette implements Writeable {
//                  Writeable w;
//                  Palette() {
//                      w = new Crayon(Blue);
//                  }
//                  void write() {
//                      w.write();
//                      w = new Marker(Red);
//                  }
//              };
//      --> État.
// -----------
//  - Lequel des extraits de code suivants complète correctement le pattern Adaptateur ?
//              interface Brewable {
//                  void brew();
//              };
//              class CoffeeMaker {
//                  Brewable coffee;
//                  void makeACup() {
//                      coffee.brew();
//                  }
//              };
//      -->     class JavaBeans {
//                  void percolate() {
//                  // implementation
//                  }
//              };
//              class JavaAdapter implements Brewable {
//                  JavaBeans jb;
//                  void makeACup() {
//                      jb.percolate();
//                  }
//              };
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisez et packagez une application Java avec Apache Maven //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// -----------
// Nous savons que c'est un peu fastidieux pour compiler le code, gérer les dépendances vers les bibliothèques tierces et assembler tout cela pour en faire un livrable correct. Heureusement il y a Maven.
// À l'instar de make ou CMake pour les logiciels en C, Maven est un outil de gestion de projet logiciel pour Java maintenu par l'Apache Software Foundation.
// Grâce à Maven, vous allez pouvoir gérer les dépendances de votre projet et automatiser sa construction (compilation, test, production de livrable...).
// Dans ce cours, je vais vous montrer comment organiser un projet avec Apache Maven.
// Personnaliser sa construction et générer automatiquement non seulement les livrables mais aussi un site descriptif du projet et divers rapports.
//      --> Pré-requis :
//              - Apache Maven étant un outil de gestion de projet Java.
//                  Vous devez savoir programmer et compiler des applications en Java pour comprendre le fonctionnement de Maven ainsi que le contenu de ce cours.
//              - Je vous recommande donc vivement :
//                  - Avoir des connaissances en développement Java EE (essentiellement web).
//                  - Connaître les patrons MVC (Modèle, Vue, Contrôleur) et DAO (Data Access Object).
//      --> Les objectifs de ce cours :
//              - Apprendre le fonctionnement et les principes généraux de Maven.
//              - Intégrer l'utilisation de Maven dans votre IDE (Eclipse et IntelliJ).
//              - Initialiser un projet Maven.
//              - Organiser un projet Maven multi-modules.
//              - Personnaliser la construction (build) du projet avec des plugins.
//              - Générer un site documentaire du projet et des rapports sur la construction (résultat des tests, qualité du code...).
// Maven est utilisable sous Linux, Mac OS et Windows. Dans ce cours, je vais m'efforcer de vous montrer comment l'utiliser avec ces 3 systèmes d'exploitation.
// Cependant, je vous conseille fortement de vous pencher du côté de Linux si vous n'y êtes pas encore passé.
// Avec Java EE, vous entrez dans le monde du développement pour l'entreprise. Vous allez généralement travailler pour de moyennes et grosses entreprises.
// L'environnement de production de vos applicatifs sera souvent un environnement Linux (debian, CentOS, RedHat...). Il est donc important d'être familiarisé avec Linux.
// Si votre environnement de développement est également en Linux, vous serez plus proche de l'environnement de production et donc plus à même de reproduire les bugs.
// Mieux, corriger en amont ceux ne se produisant que sous Linux ou Mac OS et non sous Windows.
// De plus, une partie de l'outillage gravitant autour des projets informatiques d'entreprises (notamment en Java) est disponible sous Linux mais pas, ou pas aussi bien, sous Windows ou Mac OS.
// L'inverse est aussi vrai, si vous développez en .Net par exemple, mais ça ne nous concerne pas ici.
// Avant de commencer, voici quelques références sur Apache Maven à garder sous le coude :
//      - Le site officiel : https://maven.apache.org ;
//      - Un livre en français, sous licence Creative-commons CC BY-SA 4.0, écrit par Nicolas de Loof et Arnaud Héritier : Apache Maven - Version 2 et 3.
// Apache Maven™ est une marque déposée par l'Apache Software Foundation.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Organisez votre projet ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Configurez votre environnement de développement ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Installez les pré-requis :
// Avant de commencer, je vous conseille de créer un répertoire dédié pour votre environnement de développement.
// En effet, au fur et à mesure que vous allez avancer dans votre formation, vous allez utiliser de plus en plus d'outils et de frameworks.
// Ce répertoire va contenir tous ceux-ci (les différentes versions du JDK, Apache Maven, serveur Apache Tomcat...).
// Voici un exemple de l'arborescence que vous pouvez envisager :
// env
//   ├── java
//   │   ├── jdk1.7.0_80
//   │   ├── jdk1.8.0_131
//   │   ├── jre1.7.0_80
//   │   └── jre1.8.0_131
//   ├── maven
//   │   ├── apache-maven-3.5.0
//   │   └── repository
//   └── Tomcat
//         ├── apache-Tomcat-7.0.78
//         └── apache-Tomcat-8.5.15
// Le répertoire d'environnement peut vite grossir avec les différents JDK ainsi que les dépendances qui seront téléchargées par Maven.
//      --> Prévoyez au moins 1 Go d'espace libre sur la partition accueillant ce répertoire (plusieurs gigaoctets étant plus confortables).
// Maven est un outil écrit en Java et faisant de la compilation Java. Il vous faut donc avoir un JDK Java SE sur votre machine (à l'heure ou j'écris ces lignes, Maven requiert le JDK 1.7 minimum).
// Mais comme vous êtes déjà un développeur Java, ceci doit très certainement être déjà le cas !
//      --> Sinon, téléchargez le JDK de Java SE depuis le site d'Oracle et installez-le : http://www.oracle.com/technetwork/java/javase/downloads/index.html
// Pensez à vérifier le fichier téléchargé avec les checksums fournis sur la page de téléchargement ! Cela doit devenir une habitude générale pour tous vos téléchargements.
// -----------
//  - Installez Apache Maven :
//      - Téléchargement et installation
//          Téléchargez Apache Maven depuis le site officiel (les checksums sont aussi fournis sur la page de téléchargement) : https://maven.apache.org/download.cgi.
//          Prenez la version :
//              --> Binary tar.gz archive si vous êtes sous Linux ou Mac OS.
//              --> Binary zip archive si vous êtes sous Windows.
// Pour les utilisateurs Linux, il est possible que Maven soit disponible dans les dépôts de votre distribution.
// Afin de garder un contrôle certain sur la version de Maven que vous utilisez, je vous conseille de ne pas l'utiliser et de vous procurer la dernière version sur le site d'Apache Maven.
// Décompressez l'archive dans votre répertoire d'environnement de développement. Par exemple, si la version de Maven est 3.5.0 : /chemin/vers/repertoire/env/maven/apache-maven-3.5.0.
// -----------
//  - Définir les variables d'environnement :
// Ensuite, il faut définir le chemin vers le JDK grâce à la variable d'environnement JAVA_HOME et ajouter les binaires du JDK et de Maven au PATH :
// --> Sous Linux : ajoutez ces lignes, en les adaptant, à la fin de votre fichier ~/.bashrc (ou ~/.zshrc si vous utilisez Zsh) :
//              # Java
//              export JAVA_HOME="/chemin/vers/repertoire/env/java/jdk1.8.0_131"
//              MAVEN_HOME="/chemin/vers/repertoire/env/maven/apache-maven-3.5.0"
//              PATH="$PATH:$JAVA_HOME/bin:$MAVEN_HOME/bin"
//      --> Si votre fichier contient déjà une ligne du type PATH=..., conservez-la et ajoutez aussi la ligne ci-dessus dans le fichier.
// --> Sous Mac OS : Même principe que pour Linux.
// --> Sous Windows : Ouvrez les propriétés système (avec la commande Win + Pause), dans l'onglet « Avancé », cliquez sur le bouton « Variables d'environnement » :
//      Ajoutez une propriété nommée JAVA_HOME avec la valeur (à adapter) : C:\chemin\vers\repertoire\env\java\jdk1.8.0_131
//      Modifiez la propriété nommée Path en ajoutant ceci (à adapter) à la fin de la valeur déjà renseignée :
//      ;C:\chemin\vers\repertoire\env\java\jdk1.8.0_131\bin;C:\chemin\vers\repertoire\env\maven\apache-maven-3.5.0\bin
//          --> Remarquez l'utilisation du caractère ; comme séparateur de chemin dans le Path.
// -----------
//  - Tester l'installation :
// Testez maintenant l'installation de Maven :
//      - Sous Linux / Mac OS : ouvrez un nouveau terminal.
//      - Sous Windows : ouvrez une nouvelle console (Win + R, puis taper cmd, puis Entrée).
//          Exécutez la commande suivante : mvn -v.
//          Vous devriez obtenir un résultat ressemblant à ceci :
//                  Apache Maven 3.5.0 (ff8f5e7444045639af65f6095c62210b5713f426; 2017-04-03T21:39:06+02:00)
//                  Maven home: /chemin/vers/repertoire/env/maven/apache-maven-3.5.0
//                  Java version: 1.8.0_131, vendor: Oracle Corporation
//                  Java home: /chemin/vers/repertoire/env/java/jdk1.8.0_131/jre
//                  Default locale: fr_FR, platform encoding: UTF-8
//                  OS name: "linux", version: "4.9.0-3-amd64", arch: "amd64", family: "unix"
// -----------
//  - Configurez Apache Maven :
// La configuration de Maven se fait dans le fichier .m2/settings.xml, dans le répertoire home de l'utilisateur (~/.m2/settings.xml sous Linux).
// Ce fichier n'existe pas par défaut, copiez celui contenu dans le répertoire conf de l'installation de Maven.
// Maven télécharge les dépendances dans un repository local pour les gérer.
// Par défaut, il est situé dans le répertoire .m2/repository dans le home de l'utilisateur (~/.m2/repository sous Linux).
// Ce répertoire peut vite prendre beaucoup de place et je vous conseille de le sortir de votre home pour le mettre dans le répertoire d'environnement de développement.
// Pour cela, il faut modifier le fichier settings.xml comme ceci :
//          <settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"
//                      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                      xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd">
//                      ...
//                  <!-- localRepository
//                  | The path to the local repository maven will use to store artifacts.
//                  |
//                  | Default: ${user.home}/.m2/repository -->
//                  <localRepository>/chemin/vers/repertoire/env/maven/repository</localRepository>
//                      ...
//          </settings>
// Vous trouverez plus de détails sur la configuration de Maven dans la documentation officielle :
//      --> Configuration : https://maven.apache.org/configure.html.
//      --> Fichier settings.xml : https://maven.apache.org/settings.html.
// -----------
//  - Utilisez Apache Maven avec votre IDE :
//      - Eclipse :
//          - Installation :
//              Si vous avez téléchargé le package Eclipse IDE for Java EE Developpers ou Eclipse IDE for Java Developpers, le plugin de support de Maven est déjà embarqué.
//              Sinon, vous pouvez installer le plugin M2Eclipse.
//              Je vous conseille vivement d'utiliser le package Eclipse IDE for Java EE Developpers car il contient les éléments nécessaires au développement Java EE.
//              Notamment le support des serveurs d'application web.
//              Installez également, si ce n'est pas déjà le cas, le plugin m2e-wtp afin d'intéger la gestion de Maven à la Web Tools Platform d'Eclipse.
//          - Configuration :
//              N'hésitez pas à consulter la vidéo (à partir de 7'30" environ), je vous y guide pas à pas pour réaliser la configuration.
//              Ouvrez les préférences (Window > Preferences) :
//                  Maven
//                      Installations :
//                      Ajoutez une nouvelle installation externe : Cochez la nouvelle installation que vous venez de créer pour qu'elle devienne celle par défaut.
//                      User Settings : User Settings : /chemin/vers/home/utilisateur/.m2/settings.xml
//      - IntelliJ :
//          Le support de Maven est embarqué par défaut dans JetBrains IntelliJ.
//          - Configuration :
//              N'hésitez pas à consulter la vidéo (à partir de 9'00" environ), je vous y guide pas à pas pour réaliser la configuration.
//              Ouvrez les préférences par défaut (File > Other Settings > Default Settings...) :
//                  Build, Execution Deployment > Build Tools > Maven :
//                      Maven home directory : /chemin/vers/repertoire/env/maven/apache-maven-3.5.0.
//                      User settings file : /chemin/vers/home/utilisateur/.m2/settings.xml (si le chemin par défaut est incorrect, cochez la case Override et saisissez le bon chemin).
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez votre premier projet Maven //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Votre environnement de développement est prêt ? Alors, je vais vous montrer comment créer votre premier projet avec Apache Maven.
// Maven utilise une approche dite « convention over configuration » (ou convention plutôt que configuration en français).
//      --> Cela signifie que Maven a établi un certain nombre de conventions et que si vous les respectez, beaucoup de choses seront automatiques. Vous n'aurez donc que très peu de configuration à faire !
// Une des premières conventions concerne l'arborescence d'un projet Maven. Celle-ci étant fixée (cf. documentation), Maven vous permet de générer un squelette de votre projet.
// -----------
//  - Générer un squelette de projet Maven :
// Afin de générer le squelette d'un projet, Maven s'appuie sur des archétypes (ce sont des sortes de modèles).
// Ici, je vais tout simplement demander à Maven de me générer un squelette à partir de l'archétype quickstart.
// Lors du premier lancement, Maven va télécharger un certain nombre de dépendances, cela peut prendre quelques minutes.
// Si des téléchargements échouent, il vous suffit de relancer la commande pour que Maven recommence à télécharger ceux qui ont échoué.
// Voici comment générer le squelette en mode console :
// Ouvrez un terminal (ou une console) et placez-vous dans le répertoire où vous voulez créer le projet (Maven y créera un sous-répertoire pour votre nouveau projet).
//      --> cd /chemin/vers/repertoire/projet.
// Lancez la génération à partir de l'archétype :
//      --> mvn archetype:generate -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.1.
// Maven va vous poser des questions afin de personnaliser la génération de votre projet :
//      groupId : org.exemple.demo
//      artifactId : mon-appli
//      version (1.0-SNAPSHOT) : laissez vide
//      package (org.exemple.demo) : laissez vide
// Ensuite Maven vous demande de confirmer les paramètres, il vous suffit donc de presser la touche Entrée.
// Maven crée le squelette du projet : vous devriez voir un résultat comme celui-ci :
//      [INFO] ------------------------------------------------------------------------
//      [INFO] BUILD SUCCESS
//      [INFO] ------------------------------------------------------------------------
//      [INFO] Total time: 28.944 s
//      [INFO] Finished at: 2017-06-12T17:26:46+02:00
//      [INFO] Final Memory: 19M/308M
//      [INFO] ------------------------------------------------------------------------
// -----------
//  - Qu'est-ce qui a été généré ?
// Maven a créé le répertoire mon-appli (valeur de l'artifactId saisie plus tôt) et y a généré l'arborescence suivante :
// mon-appli
// ├── pom.xml
// └── src
//     ├── main
//     │   └── java
//     │       └── org
//     │           └── exemple
//     │               └── demo
//     │                   └── App.java
//     └── test
//         └── java
//             └── org
//                 └── exemple
//                     └── demo
//                         └── AppTest.java
// J'ai ainsi obtenu :
//      - Un fichier pom.xml à la racine de mon projet. C'est le fichier de description/configuration du projet Maven.
//      - Un répertoire src/main/java. C'est le répertoire contenant les sources de mon application, contenant pour l'instant un unique fichier App.java situé dans le package org.exemple.demo.
//      - Un répertoire src/test/java. C'est le répertoire contenant les sources des tests JUnit de mon application.
//          Il contient pour le moment un unique fichier AppTest.java situé dans le package org.exemple.demo.
// Dans le fichier pom.xml, vous retrouverez les paramètres saisis lors de la génération (groupId, artifactId, version) :
//      <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//          xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
//          <modelVersion>4.0.0</modelVersion>
//          <groupId>org.exemple.demo</groupId>
//          <artifactId>mon-appli</artifactId>
//          <version>1.0-SNAPSHOT</version>
//          <packaging>jar</packaging>
//          <name>mon-appli</name>
//          <url>http://maven.apache.org</url>
//          <properties>
//          <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
//          </properties>
//          <dependencies>
//          <dependency>
//              <groupId>junit</groupId>
//              <artifactId>junit</artifactId>
//              <version>3.8.1</version>
//              <scope>test</scope>
//          </dependency>
//          </dependencies>
//      </project>
// Vous remarquez également que l'application a une dépendance en « test » vers JUnit version 3.8.1. Nous y reviendrons plus loin dans ce cours.
// Le fichier App.java, quant à lui, n'est qu'un simple Hello world :
//      package org.exemple.demo;
//          /**
//          * Hello world!
//          *
//          */
//      public class App
//      {
//          public static void main( String[] args )
//          {
//              System.out.println( "Hello World!" );
//          }
//      }
// -----------
//  - Construisez votre nouveau projet :
// Même si ce n'est qu'un « hello world », votre projet semble être une application valide. Vous allez donc pouvoir le compiler… enfin, vous allez pouvoir laisser Maven le compiler pour vous !
// Ouvrez une console à la racine du projet (répertoire mon-appli), là où se trouve le fichier pom.xml :
//      --> mvn package
// Attendez un peu et... tada ! Vous avez un JAR de votre application : target/mon-appli-1.0-SNAPSHOT.jar !
// Mais Maven n'a pas fait que générer un JAR. Regardez la sortie affichée sur la console, vous devriez avoir quelque chose comme ceci :
//      [INFO] Scanning for projects...
//      [INFO]
//      [INFO] ------------------------------------------------------------------------
//      [INFO] Building mon-appli 1.0-SNAPSHOT
//      [INFO] ------------------------------------------------------------------------
//      [INFO]
//      [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ mon-appli ---
//      [INFO] Using 'UTF-8' encoding to copy filtered resources.
//      [INFO] skip non existing resourceDirectory /projets/mon-appli/src/main/resources
//      [INFO]
//      [INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ mon-appli ---
//      [INFO] Changes detected - recompiling the module!
//      [INFO] Compiling 1 source file to /projets/mon-appli/target/classes
//      [INFO]
//      [INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ mon-appli ---
//      [INFO] Using 'UTF-8' encoding to copy filtered resources.
//      [INFO] skip non existing resourceDirectory /projets/mon-appli/src/test/resources
//      [INFO]
//      [INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ mon-appli ---
//      [INFO] Changes detected - recompiling the module!
//      [INFO] Compiling 1 source file to /projets/mon-appli/target/test-classes
//      [INFO]
//      [INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ mon-appli ---
//      [INFO] Surefire report directory: /projets/mon-appli/target/surefire-reports
//      -------------------------------------------------------
//       T E S T S
//      -------------------------------------------------------
//      Running org.exemple.demo.AppTest
//      Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 sec
//      Results :
//      Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
//      [INFO]
//      [INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ mon-appli ---
//      [INFO] Building jar: /projets/mon-appli/target/mon-appli-1.0-SNAPSHOT.jar
//      [INFO] ------------------------------------------------------------------------
//      [INFO] BUILD SUCCESS
//      [INFO] ------------------------------------------------------------------------
//      [INFO] Total time: 1.307 s
//      [INFO] Finished at: 2017-06-12T18:50:44+02:00
//      [INFO] Final Memory: 16M/209M
//      [INFO] ------------------------------------------------------------------------
// En effet, Maven a :
//      --> Copié les ressources de l'application (j'y reviendrai plus tard).
//      --> Compilé les sources de l'application.
//      --> Compilé les sources des tests.
//      --> Exécuté les tests sur l'application (1 test exécuté, aucune erreur).
//      --> Généré un JAR de l'application.
// Vous pouvez lancer votre application Java flambant neuve :
//      --> java -cp target/mon-appli-1.0-SNAPSHOT.jar org.exemple.demo.App.
// Ce qui devrait vous afficher un magnifique :
//      --> Hello World!
// -----------
//  - Résumons :
// Dans ce chapitre, j'ai survolé rapidement la gestion de projet Java avec Apache Maven.
// Voici les choses importantes à retenir :
//      --> Maven utilise une approche « convention over configuration » (ou convention plutôt que configuration en français).
//      --> L'arborescence d'un projet Maven est fixée par convention. Elle comporte :
//              --> Un fichier pom.xml à la racine qui sert à décrire et configurer le projet Maven.
//              --> Un répertoire src/main/java contenant les sources de l'application.
//              --> Un répertoire src/test/java contenant les sources des tests JUnit de l'application.
//      --> Pour créer un nouveau projet Maven, vous pouvez générer l'arborescence en utilisant un archétype grâce à la commande mvn archetype:generate.
//      --> Compilez votre projet, exécutez les tests et construisez un JAR de votre application en une seule commande : mvn package.
//              Si la compilation et tous les tests passent sans encombre, un fichier target/<artifactId>-<version>.<packaging> est généré (soit target/mon-appli-1.0-SNAPSHOT.jar dans mon exemple).
// Dans les chapitres suivants, je vais entrer plus dans le détail du fonctionnement et de la configuration de Maven.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Décrivez votre projet /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant que vous avez créé votre premier projet avec Maven, je vais vous faire entrer un peu plus en profondeur dans la définition de votre projet Maven.
// Tout se passe – ou presque – dans le fichier pom.xml. Je suis sûr que vous l'aviez deviné ! Ce fichier, au format XML, permet de définir le POM (Project Object Model) utilisé par Maven.
// Dans ce chapitre, je vais vous montrer comment décrire votre projet dans ce modèle (POM).
// Certains éléments vous paraîtront peut-être superflus au premier abord, mais vous verrez qu'ils seront utiles à différentes étapes de la construction du projet par Maven.
// C'est ce que vous découvrirez tout au long du cours, et notamment dans la deuxième partie « Automatisez la construction de votre projet ».
// Avant de commencer, voici le lien vers la documentation officielle, et en particulier sur le contenu du fichier pom.xml :
//      --> https://maven.apache.org/pom.html.
// Ouvrez le fichier pom.xml et on y va !
// Le fichier pom.xml est au format XML. Il va contenir beaucoup de choses, alors n'hésitez pas à l'aérer et y ajouter des commentaires.
// -----------
//  - Les informations de base :
// Je commence par ajouter quelques informations de base sur le projet. Je découpe cela en plusieurs parties comme ceci :
//      <?xml version="1.0" encoding="UTF-8"?>
//      <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//          xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
//          <modelVersion>4.0.0</modelVersion>
//          <!-- =============================================================== -->
//          <!-- Informations du projet -->
//          <!-- =============================================================== -->
//          <!-- ===== Informations Maven ===== -->
//          <groupId>org.exemple.demo</groupId>
//          <artifactId>mon-appli</artifactId>
//          <version>1.0-SNAPSHOT</version>
//          <packaging>jar</packaging>
//          <!-- ===== Informations générales ===== -->
//          <name>Mon Application</name>
//          <description>
//              La super application qui sert à faire ceci/cela...
//          </description>
//          <url>http://www.exemple.org/mon-appli</url>
//          <!-- ===== Organisation ===== -->
//          <organization>
//              <name>Mon Entreprise</name>
//              <url>http://www.exemple.org</url>
//          </organization>
//          <!-- ===== Licences ===== -->
//          <licenses>
//              <license>
//                  <name>Apache License, Version 2.0</name>
//                  <url>https://www.apache.org/licenses/LICENSE-2.0.txt</url>
//              </license>
//          </licenses>
//          ...
//      </project>
// -----------
//  - Les coordonnées du projet Maven :
// Un premier bloc définit les informations du projet relatives à Maven, avec :
//      - groupId : identifiant de l'organisation gérant le projet. Cet identifiant reprend la notation des packages Java.
//          En général, celui-ci correspond au package de base de l'application, mais ce n'est pas obligatoire.
//      - artifactId : identifiant du projet.
//      - version : version du projet.
//      - packaging : type de packaging devant être généré par Maven (jar, war, ear...). J'y reviendrai plus tard.
// Un projet Maven est identifié par ses coordonnées : groupId:artifactId:version.
// Dans mon exemple, les coordonnées du projet sont donc 'org.exemple.demo:mon-appli:1.0-SNAPSHOT'.
// -----------
//  - Les versions du projet :
// Toujours par convention, Maven donne un statut particulier aux versions ayant pour suffixe -SNAPSHOT.
// En effet, cela veut dire que le code de cette version de l'application n'est pas figé. C'est une version en cours de développement.
// Par opposition, si la version ne se termine pas par le suffixe -SNAPSHOT, cela signifie qu'il s'agit d'une release de l'application et que son code est figé.
// Les versions snapshot font l'objet de traitements particuliers, notamment dans la gestion des dépendances. Je reviendrai sur ce point dans le chapitre traitant des dépendances.
//      --> Ainsi, vous l'aurez compris, pendant le développement de votre application, vous devez avoir le suffixe -SNAPSHOT pour en faire une version snapshot.
//      --> Et une fois la version terminée, prête à être déployée, vous devez enlever ce suffixe pour en faire une version release, ce qui indique que le code est fixé.
// -----------
//  - Les informations générales du projet :
// Ensuite, viennent les informations générales du projet, avec les balises :
//      - name : le nom du projet.
//      - description : la description du projet.
//      - url : URL du projet ou de l'application en production.
// -----------
//  - L'organisation gérant le projet :
// Vous pouvez préciser des informations concernant l'organisation gérant le projet, avec la balise organization.
// Si vous travaillez comme prestataire de service, vous mettrez ici les informations du client pour lequel vous développez le projet.
// -----------
//  - Les licences du projet :
// Vous pouvez indiquer la ou les licences du projet grâce à la balise <licenses> et une sous-balise <license> par licence.
// Ceci est important si le projet est disponible publiquement ou s'il est sous licence libre.
// Toutes ces informations seront reprises, entre autres, lors de la génération du site descriptif du projet par Maven. Je vous montrerai cela dans la deuxième partie de ce cours.
// -----------
//  - Les propriétés :
// Très bien, vous avez vu qu'il était possible de définir tout un tas d'informations pour notre projet.
//      --> Mais il est possible d'ajouter un peu de généricité dans tout cela grâce aux propriétés. Celles-ci sont des sortes de constantes.
// Elles sont remplacées par leur valeur lors de l'exécution de Maven en utilisant la notation ${maPropriete} (qui sera remplacée par la valeur de la propriété maPropriete).
// Vous pouvez définir les propriétés directement dans le fichier pom.xml, grâce à la balise <properties> :
//      <project>
//          ...
//          <!-- =============================================================== -->
//          <!-- Properties -->
//          <!-- =============================================================== -->
//          <properties>
//              <maPropriete>la valeur de la propriété</maPropriete>
//              <uneAutrePropriete>la valeur de la propriété</uneAutrePropriete>
//          </properties>
//          ...
//      </project>
// Voici un exemple d'utilisation des propriétés : je voudrais utiliser dans mon projet un framework composé de plusieurs bibliothèques mais ne définir qu'une seule fois sa version.
//      <project>
//          ...
//          <properties>
//              <apache.struts.version>2.5.10.1</apache.struts.version>
//          </properties>
//          ...
//          <dependencies>
//              <!-- ===== Apache Struts ===== -->
//              <dependency>
//                  <groupId>org.apache.struts</groupId>
//                  <artifactId>struts2-core</artifactId>
//                  <version>${apache.struts.version}</version>
//              </dependency>
//              <dependency>
//                  <groupId>org.apache.struts</groupId>
//                  <artifactId>struts2-json-plugin</artifactId>
//                  <version>${apache.struts.version}</version>
//              </dependency>
//          </dependencies>
//          ...
//      </project>
// L'utilisation des propriétés n'est pas limitée au fichier pom.xml.
// En effet, il est possible de demander à Maven de remplacer les propriétés aussi dans les fichiers dits resource. Cela s'appelle filter des fichiers ressource dans le jargon de Maven.
// -----------
//  - Propriétés pré-définies :
// En plus des propriétés que vous pouvez définir vous-même grâce à la balise <properties>, il existe également des propriétés pré-définies :
//      - project.basedir : donne le chemin vers le répertoire de base du projet, c'est-à-dire la racine de votre projet où se trouve le fichier pom.xml.
//      - project.baseUri : donne le chemin vers le répertoire de base du projet, mais sous forme d'URI.
//      - maven.build.timestamp : donne l'horodatage du lancement du build Maven.
// -----------
//  - Propriétés particulières :
// Vous pouvez aussi accéder à des propriétés particulières grâce aux préfixes suivants :
//      - env. : permet de renvoyer la valeur d'une variable d'environnement. Par exemple, ${env.PATH} renvoie la valeur de la variable d'environnement PATH.
//      - project. : renvoie la valeur d'une balise dans le fichier pom.xml du projet, en utilisant le point (.) comme séparateur de chemin pour les sous-balises.
//          L'exemple ci-dessous est accessible via ${project.organization.name}.
//          <project>
//              <organization>
//                  <name>1.0</name>
//              </organization>
//          </project>
//      - settings. : renvoie la valeur d'une balise dans le(s) fichier(s) settings.xml utilisé(s) par Maven. Utilise la notation pointée comme pour les propriétés de project.
//      - java. : renvoie la valeur d'une propriété système de Java. Ces propriétés sont les mêmes que celles accessibles via java.lang.System.getProperties().
//          Par exemple, ${java.version} renvoie la version de Java. Pour plus de détails, consultez la JavaDoc.
// La plupart des conventions établies par Maven (chemin des sources, chemin de génération...) sont mises en œuvre grâce au Super POM.
//      --> En effet, de base, le POM d'un projet hérite du Super POM qui définit les valeurs par défaut que va utiliser Maven.
// Ne vous étonnez donc pas si ${project.build.directory} vous renvoie une valeur alors que vous ne l'avez pas définie dans votre fichier pom.xml. Elle provient du Super POM !
// Enfin, sachez que certaines propriétés permettent de définir des configurations par défaut de Maven ou de certains plugins.
// C'est le cas par exemple de la propriété project.build.sourceEncoding ajoutée par l'archétype quickstart lors du mvn archetype:generate.
// -----------
//  - Le build :
// En plus des informations de base et des propriétés, vous pouvez paramétrer les différents éléments du processus de construction de Maven, qu'on appelle le build.
// J'introduis simplement le build dans ce chapitre, car la deuxième partie du cours lui est consacrée. Je rentrerai plus dans le détail à ce moment-là.
// La configuration du build se fait grâce à la balise <build> et ses sous-balises.
// Voici un exemple où je définis un chemin de sortie autre que celui par défaut (${project.basedir}/target) :
//      <project>
//          ...
//          <!-- =============================================================== -->
//          <!-- Build -->
//          <!-- =============================================================== -->
//          <build>
//              <directory>${project.basedir}/output</directory>
//          </build>
//          ...
//      </project>
// En reprennant l'exemple utilisé précédemment, je peux, par exemple, rendre le JAR généré exécutable en demandant à Maven d'indiquer la classe Main dans le Manifest du JAR :
//      <project>
//          ...
//          <!-- =============================================================== -->
//          <!-- Build -->
//          <!-- =============================================================== -->
//          <build>
//              <!-- Gestion des plugins (version) -->
//              <pluginManagement>
//                  <plugins>
//                      <!-- Plugin responsable de la génération du fichier JAR -->
//                      <plugin>
//                          <groupId>org.apache.maven.plugins</groupId>
//                          <artifactId>maven-jar-plugin</artifactId>
//                          <version>3.0.2</version>
//                      </plugin>
//                  </plugins>
//              </pluginManagement>
//              <plugins>
//                  <plugin>
//                      <groupId>org.apache.maven.plugins</groupId>
//                      <artifactId>maven-jar-plugin</artifactId>
//                      <configuration>
//                          <archive>
//                              <!-- Création du Manifest pour la définition de la classe Main -->
//                              <manifest>
//                                  <mainClass>org.exemple.demo.App</mainClass>
//                              </manifest>
//                          </archive>
//                      </configuration>
//                  </plugin>
//              </plugins>
//          </build>
//          ...
//      </project>
// Après avoir relancé la construction du projet avec mvn package, vous pourrez désormais lancer votre application Java sans indiquer la class main dans la ligne de commande :
// java -jar target/mon-appli-1.0-SNAPSHOT.jar
// -----------
//  - Filtrer des fichiers ressources :
// Les fichiers ressources sont des fichiers qui n'ont pas à être compilés, mais simplement copiés dans le livrable généré par Maven.
// Par convention, ces fichiers se trouvent dans le répertoire src/main/resources (répertoire à créer si besoin).
// Un peu plus haut, je vous disais qu'il était possible de dire à Maven de remplacer les propriétés par leur valeurs dans des fichiers en filtrant les fichiers ressource.
// Voyons tout de suite un exemple. Vous avez un fichier info.properties chargé par votre application et vous voulez mettre dans ce fichier une propriété contenant la version du projet.
//      --> Vous mettez ce fichier dans le répertoire src/main/resources.
//      -->Dans ce fichier, vous utilisez la même syntaxe que dans le fichier pom.xml :
//              --> # Propriété contenant la version du projet.
//              --> org.exemple.demo.version=${project.version}.
// Ensuite vous indiquez à Maven, dans le fichier pom.xml, de filtrer les fichiers du répertoire src/main/resources avec la balise <filtering> :
//      <project>
//          ...
//          <build>
//              <resources>
//                  <resource>
//                      <directory>src/main/resources</directory>
//                      <filtering>true</filtering>
//                  </resource>
//              </resources>
//          </build>
//          ...
//      </project>
// Si vous avez des fichiers à ne pas filtrer dans le répertoire src/main/resources, il est possible de faire des sous-répertoires dans ce dernier afin d'organiser vos fichiers.
// Voici un exemple où seulement les fichiers du sous-dossier filtered doivent être filtrés :
//      src/main/resources
//      ├── filtered
//      │   └── info.properties
//      └── raw
//          └── fichierX
//      <project>
//          ...
//          <build>
//              <resources>
//                  <resource>
//                      <directory>src/main/resources/filtered</directory>
//                      <filtering>true</filtering>
//                  </resource>
//                  <resource>
//                      <directory>src/main/resources/raw</directory>
//                      <filtering>false</filtering>
//                  </resource>
//              </resources>
//          </build>
//          ...
//      </project>
// Je vous invite à consulter la documentation car le filtrage ne s'arrête pas à cela.
// Il est notamment possible d'importer la valeur des propriétés utilisées lors du filtrage depuis des fichiers properties externes avec la balise <filters>.
// Si vous voulez aller plus loin sur la configuration du build dans le POM, vous pouvez consulter la documentation.
// -----------
//  - Les profils :
// Les profils permettent de créer des options dans le build Maven.
// Vous pouvez par exemple envisager deux environnements cibles (un de test, un de production).
// Ainsi, vous pourrez embarquer, dans le JAR généré, des fichiers de configurations différents en fonction de la cible.
// Pour cela, pas besoin de mettre à la main les bons fichiers dans le répertoire src/main/resources avant le build.
// Il suffit de créer deux profils (test et prod), chacun définissant un répertoire de fichiers ressources différent :
//      <project>
//          ...
//          <!-- =============================================================== -->
//          <!-- Profils -->
//          <!-- =============================================================== -->
//          <profiles>
//              <!-- Profil pour l'environnement de test -->
//              <profile>
//                  <id>test</id>
//                  <build>
//                      <resources>
//                          <resource>
//                              <directory>src/main/resources/conf-test</directory>
//                          </resource>
//                      </resources>
//                  </build>
//              </profile>
//              <!-- Profil pour l'environnement de production -->
//              <profile>
//                  <id>prod</id>
//                  <build>
//                      <resources>
//                          <resource>
//                              <directory>src/main/resources/conf-prod</directory>
//                          </resource>
//                      </resources>
//                  </build>
//              </profile>
//          </profiles>
//          ...
//      </project>
// Il ne vous reste plus qu'à mettre les fichiers de configuration de test et de production dans leur répertoire ressource respectif.
// Puis d'activer le bon profil lors du lancement du build Maven grâce à l'option -P :
//      - # Pour construire un livrable pour l'environnement de test : mvn package -P test.
//      - # Pour construire un livrable pour l'environnement de production : mvn package -P prod.
// -----------
//  - Activation automatique des profils :
// Les profils peuvent également être activés automatiquement en fonction de certains critères définis dans la sous-balise <activation> :
//      <!-- Profil activé automatiquement si la version du JDK est 1.8
//              et sous-versions mineures (1.8.0_131 par exemple) -->
//      <profile>
//          <activation>
//              <jdk>1.8</jdk>
//          </activation>
//          ...
//      </profile>
//      <!-- Profil activé automatiquement si la propriété système "environnement" vaut "test" -->
//      <profile>
//          <activation>
//              <property>
//                  <name>environnement</name>
//                  <value>test</value>
//              </property>
//          </activation>
//          ...
//      </profile>
// Dans cet exemple, pour activer le deuxième profil, vous pouvez lancer Maven comme ceci : mvn package -Denvironnement=test.
// Je vous recommande de vous pencher un peu plus sur les profiles, en consultant la documentation.
// Vous y trouverez notamment de plus amples informations sur l'activation des profils en fonction du système d'exploitation, de l'architecture, de la présence d'un fichier...
// -----------
//  - Conclusion :
// Dans ce chapitre, je vous ai montré comment décrire votre projet en y ajoutant des informations générales.
// Informations qui serviront à Maven au cours du build et qui seront reprises dans la génération du site de votre projet (nous verrons cela dans la deuxième partie du cours).
// Je vous ai également présenté les propriétés qui permettent d'apporter un peu plus de souplesse et d'automatisation dans le build en généralisant des éléments.
// Enfin, je vous ai parlé des profils qui servent à créer différentes alternatives dans le build du projet Maven.
// Dans le chapitre suivant, nous allons parler d'architecture et voir comment mieux organiser votre projet avec Maven.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découpez votre projet en couches applicatives /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Du simple patron MVC à une architecture multi-tiers :
//      - Le patron MVC :
//          Vous connaissez déjà le patron de conception MVC (Modèle-Vue-Contrôleur).
//          Pour rappel, avec cette organisation, lorsqu'un utilisateur interagit avec votre application :
//              --> Son action est prise en charge par le Contrôleur.
//              --> Le Contrôleur fait alors appel au Modèle. Celui-ci va réaliser l'action fonctionnelle et éventuellement interagir avec une base de données.
//              --> Une fois le travail du Modèle terminé, le Contrôleur met à jour la Vue qui est renvoyée à l'utilisateur.
//      - Améliorer le patron MVC à l'aide du patron DAO :
//          Cette organisation est bien, mais il est possible de l'affiner, en structurant notamment la partie Modèle.
//          En effet, cette partie contient tout le cœur de fonctionnement de l'application, de la logique métier à la gestion des données.
//          Une manière d'améliorer les choses est d'utiliser par exemple le patron DAO (Data Access Object), permettant de mieux gérer la persistance des données en l'isolant du reste du traitement.
//      - Séparer les responsabilités avec une architecture multi-tiers :
//          Je vous propose d'aller plus loin, en adoptant une 'architecture multi-tiers'.
//          Avec cette architecture en couches, l'utilisateur interagit avec votre application :
//              --> Via la couche Présentation. Cette couche contient les parties Contrôleur et Vue du patron MVC.
//              --> Une fois l'action utilisateur identifiée, la couche Présentation fait appel à la couche Métier.
//                  Celle-ci est responsable de la logique métier de l'application, c'est-à-dire de l'implémentation des règles de gestion fonctionnelles.
//              --> Si des accès à la base de données sont nécessaires, alors la couche Métier appelle la couche Persistance. C'est dans cette couche que l'on retrouve le patron DAO.
//              --> Et toutes ces couches partagent une « vision commune » du domaine fonctionnel en s'appuyant sur le Modèle. En effet, ce modèle contient les JavaBeans manipulés dans l'application.
//          Ce modèle ne doit pas être confondu avec le modèle du patron MVC. Ce dernier est en fait réparti ici sur les couches métier, persistance et modèle.
//          Une chose importante est que chaque couche n'appelle que la couche immédiatement en dessous d'elle et n'a aucune connaissance des couches supérieures.
//              --> Cette approche présente plusieurs avantages :
//                      --> Imaginez que votre projet comporte une application web et des batches de traitement en masse.
//                              Vous pouvez créer 2 couches de présentation (une pour l'application web, l'autre pour les batches) et partager les mêmes couches métier, persistance et modèle.
//                      --> Un autre avantage est qu'il est possible de développer et tester les couches séparément en mettant en place des interfaces.
// -----------
//  - Séparer les couches applicatives avec Maven :
// Vous pouvez matérialiser le découpage de l'architecture multi-tiers grâce à des modules Maven. Chaque couche de l'architecture fait alors l'objet d'un module dédié.
// Les modules sont des sortes de « sous-projets » Maven, rattachés à un projet Maven principal (appelé projet parent).
//      --> Ils fournissent chacun leurs propres livrables et il est possible de créer des dépendances entres eux.
// Les noms des modules sont en anglais car ces noms sont bien plus courants en développement.
// Vous remarquez que j'ai renommé la couche persistance en module consumer.
// J'ai, en effet, généralisé la responsabilité de cette couche à la consommation de « services » externes, par exemple une base de données ou des webservices.
// Ainsi, votre projet Maven principal va devenir un meta-projet, agrégeant des modules. Dans le jargon de Maven, on appelle cela un projet multi-modules.
// -----------
//  - Les projets multi-modules :
// Un projet multi-modules est organisé comme ceci :
//      projet-x
//      ├── module-a
//      │   ├── pom.xml
//      │   └── src
//      │       ├── main
//      │       │   └── java
//      │       │       └── ...
//      │       └── ...
//      ├── module-b
//      │   ├── pom.xml
//      │   └── ...
//      ├── pom.xml
// Les modules sont dans des sous-dossiers dans le répertoire du projet parent.
// Ils ont chacun une arborescence classique de projet Maven avec leur propre fichier pom.xml.
// -----------
//  - Créer un projet multi-modules :
// Mettons cela en pratique. Nous allons créer un projet de gestion de ticket d'incident. Il contiendra une application web et un jeu de batches.
//      - Créer le squelette d'un projet multi-modules :
//          Pour créer un projet multi-modules :
//              --> Commencez par créer le projet parent à l'aide de l'archétype maven-archetype-quickstart :
//                      mvn archetype:generate \
//                          -DarchetypeGroupId=org.apache.maven.archetypes \
//                          -DarchetypeArtifactId=maven-archetype-quickstart \
//                          -DarchetypeVersion=1.1 \
//                          -DgroupId=org.exemple.demo \
//                          -DartifactId=ticket \
//                          -Dversion=1.0-SNAPSHOT
//              --> Allez dans le répertoire du projet qui vient d'être créé :
//                      cd ticket
//              --> Supprimez le répertoire src, il ne sert à rien :
//                      rm -r ./src
//              --> Éditez le fichier pom.xml :
//                  Modifiez le packaging du projet. Il faut utiliser le packaging pom au lieu de jar :
//                      <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                          xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
//                          <modelVersion>4.0.0</modelVersion>
//                          ...
//                          <groupId>org.exemple.demo</groupId>
//                          <artifactId>ticket</artifactId>
//                          <version>1.0-SNAPSHOT</version>
//                          <packaging>pom</packaging>
//                          ...
//                      </project>
//              --> Supprimez la dépendance vers junit :
//                      <project>
//                          ...
//                          <dependencies>
//                              <dependency>
//                                  <groupId>junit</groupId>
//                                  <artifactId>junit</artifactId>
//                                  <version>3.8.1</version>
//                                  <scope>test</scope>
//                              </dependency>
//                          </dependencies>
//                          ...
//                      </project>
//              --> Créez ensuite tous les modules (sous-projets Maven) à l'aide d'archétypes :
//                      --> ticket-batch (archétype maven-archetype-quickstart).
//                      --> ticket-webapp (archétype maven-archetype-webapp).
//                      --> ticket-business (archétype maven-archetype-quickstart).
//                      --> ticket-consumer (archétype maven-archetype-quickstart).
//                      --> ticket-model (archétype maven-archetype-quickstart).
//                  ## module : ticket-batch
//                  mvn -B archetype:generate \
//                      -DarchetypeGroupId=org.apache.maven.archetypes \
//                      -DarchetypeArtifactId=maven-archetype-quickstart \
//                      -DarchetypeVersion=1.1 \
//                      -DgroupId=org.exemple.demo \
//                      -DartifactId=ticket-batch \
//                      -Dpackage=org.exemple.demo.batch
//                  ## module : ticket-webapp
//                  ## Remarquez ici l'utilisation de l'archetype "webapp"
//                  mvn -B archetype:generate \
//                      -DarchetypeGroupId=org.apache.maven.archetypes \
//                      -DarchetypeArtifactId=maven-archetype-webapp \
//                      -DgroupId=org.exemple.demo \
//                      -DartifactId=ticket-webapp \
//                      -Dpackage=org.exemple.demo.webapp
//                  ## module : ticket-business
//                  mvn -B archetype:generate \
//                      -DarchetypeGroupId=org.apache.maven.archetypes \
//                      -DarchetypeArtifactId=maven-archetype-quickstart \
//                      -DarchetypeVersion=1.1 \
//                      -DgroupId=org.exemple.demo \
//                      -DartifactId=ticket-business \
//                      -Dpackage=org.exemple.demo.business
//                  ## module : ticket-consumer
//                  mvn -B archetype:generate \
//                      -DarchetypeGroupId=org.apache.maven.archetypes \
//                      -DarchetypeArtifactId=maven-archetype-quickstart \
//                      -DarchetypeVersion=1.1 \
//                      -DgroupId=org.exemple.demo \
//                      -DartifactId=ticket-consumer \
//                      -Dpackage=org.exemple.demo.consumer
//                  ## module : ticket-model
//                  mvn -B archetype:generate \
//                      -DarchetypeGroupId=org.apache.maven.archetypes \
//                      -DarchetypeArtifactId=maven-archetype-quickstart \
//                      -DarchetypeVersion=1.1 \
//                      -DgroupId=org.exemple.demo \
//                      -DartifactId=ticket-model \
//                      -Dpackage=org.exemple.demo.model
//              --> Une fois ceci fait, le fichier pom.xml du projet parent devrait ressembler à ceci (j'ai ajouté des commentaires pour que cela soit plus lisible) :
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                      xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
//                      <modelVersion>4.0.0</modelVersion>
//                      <!-- =============================================================== -->
//                      <!-- Informations du projet -->
//                      <!-- =============================================================== -->
//                      <!-- ===== Informations Maven ===== -->
//                      <groupId>org.exemple.demo</groupId>
//                      <artifactId>ticket</artifactId>
//                      <version>1.0-SNAPSHOT</version>
//                      <packaging>pom</packaging>
//                      <!-- ===== Informations générales ===== -->
//                      <name>ticket</name>
//                      <url>http://maven.apache.org</url>
//                      <!-- =============================================================== -->
//                      <!-- Properties -->
//                      <!-- =============================================================== -->
//                      <properties>
//                          <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
//                      </properties>
//                      <!-- =============================================================== -->
//                      <!-- Modules -->
//                      <!-- =============================================================== -->
//                      <modules>
//                          <module>ticket-batch</module>
//                          <module>ticket-webapp</module>
//                          <module>ticket-business</module>
//                          <module>ticket-consumer</module>
//                          <module>ticket-model</module>
//                      </modules>
//                  </project>
// --> Vous remarquez que les modules sont listés dans la balise <modules>.
// -----------
//  - Définir les dépendances entre les modules :
// L'arborescence de votre projet multi-modules est créée, passons maintenant à la définition des dépendances entre les modules.
// Nous le verrons plus en détail dans le chapitre suivant, mais nous allons gérer ces dépendances en deux temps :
//      --> Dans le POM du projet parent, nous listerons les dépendances et leur version de manière globale pour le projet.
//      --> Dans le POM de chaque module, nous définirons quelles sont les dépendances à utiliser.
//      - Dans le POM du projet parent :
//          Ouvrez le POM du projet parent et ajoutez-y une section dependencyManagement :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Gestion des dépendances -->
//                      <!-- =============================================================== -->
//                      <dependencyManagement>
//                          <dependencies>
//                              <!-- ===== Modules ===== -->
//                              <dependency>
//                                  <groupId>org.exemple.demo</groupId>
//                                  <artifactId>ticket-batch</artifactId>
//                                  <version>1.0-SNAPSHOT</version>
//                              </dependency>
//                              <dependency>
//                                  <groupId>org.exemple.demo</groupId>
//                                  <artifactId>ticket-webapp</artifactId>
//                                  <version>1.0-SNAPSHOT</version>
//                              </dependency>
//                              <dependency>
//                                  <groupId>org.exemple.demo</groupId>
//                                  <artifactId>ticket-business</artifactId>
//                                  <version>1.0-SNAPSHOT</version>
//                              </dependency>
//                              <dependency>
//                                  <groupId>org.exemple.demo</groupId>
//                                  <artifactId>ticket-consumer</artifactId>
//                                  <version>1.0-SNAPSHOT</version>
//                              </dependency>
//                              <dependency>
//                                  <groupId>org.exemple.demo</groupId>
//                                  <artifactId>ticket-model</artifactId>
//                                  <version>1.0-SNAPSHOT</version>
//                              </dependency>
//                              <!-- ===== Bibliothèques tierces ===== -->
//                              ...
//                          </dependencies>
//                      </dependencyManagement>
//                      ...
//                  </project>
//      - Dans les POM des modules :
//          Il ne vous reste plus qu'à définir les dépendances à utiliser dans les POM des modules dans la section dependencies.
//          Les dépendances à définir sont celles-ci :
//          Commençons, par exemple, avec le module ticket-business. Il faut ajouter les dépendances vers les modules :
//              --> ticket-consumer.
//              --> ticket-model.
//          Ouvrez le POM du module ticket-business ajoutez-y les dépendances suivantes :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Dépendances -->
//                      <!-- =============================================================== -->
//                      <dependencies>
//                          <!-- ===== Modules ===== -->
//                          <dependency>
//                              <groupId>org.exemple.demo</groupId>
//                              <artifactId>ticket-consumer</artifactId>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.exemple.demo</groupId>
//                              <artifactId>ticket-model</artifactId>
//                          </dependency>
//                          <!-- ===== Bibliothèques tierces ===== -->
//                          <!-- JUnit -->
//                          ...
//                      </dependencies>
//                      ...
//                  </project>
//          Vous remarquez que je n'ai pas précisé de version dans les dépendances. En effet, cela est géré au niveau du POM du projet parent via la section <dependencyManagement>.
//          Il ne vous reste plus qu'à procéder de même pour les autres modules.
//          --> Après cela, votre projet est prêt, vous pouvez commencer les développements, en répartissant les différents éléments dans leurs couches respectives.
// -----------
//  - Construire un projet multi-modules :
// La construction d'un projet multi-modules se fait comme pour un projet simple :
//      --> Vous vous placez dans le répertoire du projet parent.
//      --> Vous lancez vos commandes de build Maven dans ce répertoire. Ceci va lancer le build sur chacun des modules.
//              Par exemple, pour packager votre projet, faites :
//                  --> cd /chemin/vers/projet-multi-modules.
//                      mvn package.
// --> Ceci va générer les livrables de chaque module dans le repertoire target de chacun de ces modules.
// -----------
//  - Résumons :
// Nous avons vu comment structurer votre projet en utilisant une architecture multi-tiers.
// Dans cette architecture en couches, chaque couche communique avec celle immédiatement inférieure et n'a aucune connaissance des couches supérieures.
// Vous avez pu voir qu'il était possible de matérialiser cette organisation dans un projet Maven grâce aux modules.
// Votre projet et maintenant bien structuré, les différents éléments le constituant sont clairement identifiés.
//      --> Afin de terminer son organisation, il ne vous reste plus qu'à gérer les dépendances vers les bibliothèques tierces. C'est justement ce que nous allons voir dans le prochain chapitre.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérez efficacement les dépendances ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Ajouter une dépendance :
//      --> Un petit rappel : un projet Maven (projet, module, bibliothèque...) est identifié par ses coordonnées sous le format 'groupId:artifactId:version'.
// Comme nous l'avons vu dans le chapitre précédent, pour ajouter une dépendance à votre projet, il suffit d'ajouter une balise <dependency> dans la section <dependencies>.
// Prenons un exemple. Dans votre application, vous manipulez des collections et vous aimeriez vous appuyer sur la bibliothèque Apache Commons Collections.
// Apache Commons est un projet de l'Apache Software Foundation fournissant du code et des composants réutilisables en Java.
// Ce projet contient bon nombre de sous-projets, chacun focalisé sur un aspect particulier.
// Voici comment ajouter une dépendance vers org.apache.commons:commons-collections4:4.1 :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Dépendances -->
//                      <!-- =============================================================== -->
//                      <dependencies>
//                          <!-- ===== Modules ===== -->
//                          ...
//                          <!-- ===== Bibliothèques tierces ===== -->
//                          <dependency>
//                              <groupId>org.apache.commons</groupId>
//                              <artifactId>commons-collections4</artifactId>
//                              <version>4.1</version>
//                          </dependency>
//                      </dependencies>
//                      ...
//                  </project>
// Reprenons le cas du projet de gestion de ticket initié dans le chapitre précédent :
//      - Ajoutez cette dépendance dans le module ticket-webapp.
//      - Relancez un packaging du projet ticket (avec la commande mvn package).
//      - Ouvrez le fichier WAR généré (ticket-webapp/target/ticket-webapp.war).
//          --> Vous voyez que la dépendance a été intégrée :
// ticket-webapp.war
// ├── ...
// └── WEB-INF
//     └── lib
//         ├── commons-collections4-4.1.jar
//         └── ...
// -----------
//  - Où trouver des dépendances ?
//      --> Mais comment fait Maven pour récupérer les dépendances que j'ajoute à mon projet ?
// Eh bien pour cela, Maven utilise des repositories. Un repository est un endroit où sont stockées des dépendances sous un format imposé par Maven.
// Par défaut, Maven utilise le repository central. Celui-ci se trouve à l'adresse : http://repo1.maven.apache.org/maven2/.
// Quand vous ajoutez une dépendance à votre projet, Maven la télécharge depuis ce repository et la stocke dans votre repository local.
//      --> C'est le chemin que nous avions configuré dans le fichier settings.xml dans le premier chapitre de ce cours.
// Pour rechercher parmi les dépendances disponibles dans le repository central de Maven, vous pouvez utiliser ce site : http://search.maven.org.
// -----------
//  - La transitivité des dépendances :
// Maven gère également la transitivité des dépendances.
//      --> Cela signifie que Maven est capable d'ajouter automatiquement les dépendances requises par les dépendances que vous avez ajoutées.
// Dans votre application web (module ticket-webapp), vous aimeriez utiliser sur la bibliothèque Apache Commons Text.
// Cette dernière s'appuie elle-même sur la bibliothèque Apache Commons Lang.
//      - Ajoutez simplement la dépendance vers org.apache.commons:commons-text:1.1 :
//                  <project>
//                      ...
//                      <dependencies>
//                          ...
//                          <dependency>
//                              <groupId>org.apache.commons</groupId>
//                              <artifactId>commons-text</artifactId>
//                              <version>1.1</version>
//                          </dependency>
//                      </dependencies>
//                      ...
//                  </project>
//      - Relancez un packaging du projet ticket (avec la commande mvn package).
//      - Ouvrez le fichier WAR généré (ticket-webapp/target/ticket-webapp.war) : vous voyez que les bibliothèques commons-text et commons-lang ont été intégrées :
// ticket-webapp.war
// ├── ...
// └── WEB-INF
//     └── lib
//         ├── commons-lang-3.5.jar
//         ├── commons-text-1.1.jar
//         └── ...
// -----------
//  - Ignorer des sous-dépendances :
// Nous avons pour le moment vu des cas assez simples, mais dans certains cas, la transitivité peut vite faire gonfler le nombre de dépendances car elle ajoute les dépendances en cascade.
// Si on a des dépendances telles que A → B → C → D, alors A dépendra de B, C et D.
// Si A n'utilise qu'une petite partie de B qui n'a pas besoin de C, alors il est possible d'indiquer à Maven d'ignorer la dépendance B → C dans A.
//      --> A ne dépendra alors que de B et plus de C et D.
// Reprenons l'exemple de commons-text. Imaginez que dans votre module ticket-webapp, vous n'utilisiez que du code de commons-text qui n'a pas besoin de commons-lang.
// Vous allez pouvoir exclure la dépendance vers commons-lang de la chaîne de transitivité de commons-text dans ticket-webapp.
//      --> Ajoutez pour cela une section <exclusions> dans la déclaration de la dépendance vers commons-text dans ticket-webapp :
//                  <project>
//                      ...
//                      <dependencies>
//                          ...
//                              <dependency>
//                                  <groupId>org.apache.commons</groupId>
//                                  <artifactId>commons-text</artifactId>
//                                  <version>1.1</version>
//                              <exclusions>
//                                  <!-- La dépendance vers commons-lang3 est exclue -->
//                                  <exclusion>
//                                      <groupId>org.apache.commons</groupId>
//                                      <artifactId>commons-lang3</artifactId>
//                                  </exclusion>
//                              </exclusions>
//                          </dependency>
//                      </dependencies>
//                      ...
//                  </project>
//      --> Si vous relancez un packaging du projet, vous verrez que la bibliothèque commons-text est intégrée au WAR généré mais pas la bibliothèque commons-lang.
// -----------
//  - Définir la portée d'une dépendance
// Il se peut que la dépendance que vous voulez ajouter ne soit liée qu'à un contexte particulier comme l'exécution des tests par exemple.
// C'est le cas de la dépendance vers JUnit ajoutée par l'archétype quickstart.
//      --> En effet, il s'agit d'un framework de test unitaire et cette bibliothèque n'a pas à être déployée avec votre application en production.
// Pour indiquer cela à Maven, les dépendances sont attachées à un scope.
//      --> Par défaut ce scope est compile. Ce scope indique que la dépendance est utilisée lors de la compilation et sera accessible dans tous les contextes.
// Il existe d'autres scopes. Si je reprends la dépendance vers JUnit, vous remarquez qu'elle est attachée au scope test.
// Cela veut dire qu'elle n'est accessible que lors de la compilation des tests et leur exécution.
// Il existe aussi des scopes comme provided ou runtime.
//      --> Avec provided indique que la dépendance est disponible à la compilation, mais elle devra être fournie par le contexte d'exécution (le serveur d'application par exemple).
//      --> Avec runtime en revanche, la dépendance n'est pas accessible lors de la compilation, mais elle est disponible à l'exécution.
// Voici un tableau récapitulatif des scopes, de leur transitivité et des contextes dans lesquels la dépendance correspondante est accessible :
// Scope    Transitif*  Compilation     Test    Exécution
// compile      ✓          ✓            ✓        ✓
// test                                  ✓
// provided                 ✓            ✓
// runtime      ✓                        ✓        ✓
// * Si la colonne n'est pas cochée (✓), cela signifie que la transitivité en tant que sous-dépendance s'arrête là.
//      --> Donc lorsque vous ajoutez à votre projet une dépendance vers X et que X a une dépendance vers Y, si le scope de la dépendance vers Y dans X est :
//              --> Transitif (compile ou runtime), Maven ajoute la dépendance vers Y à votre projet.
//              --> Non transitif (test ou provided), Maven n'ajoute pas la dépendance vers Y à votre projet.
// De manière plus précise, si votre projet a une dépendance vers X et X une dépendance vers Y, voici le scope qui sera donné par Maven à Y dans votre projet en fonction :
//      --> Du scope de X dans votre projet (colonne de gauche).
//      --> Du scope de Y dans X (ligne d'entête).
// Scope : X↓ ❘ Y→     compile     test     provided    runtime
// compile             compile      ∅        ∅         runtime
// test                test         ∅        ∅         test
// provided            provided     ∅        ∅         provided
// runtime             runtime      ∅        ∅         runtime
// -----------
//  - Utilisation des différents scopes :
// Je vais prendre des exemples pour illustrer l'utilisation des scopes dans le module ticket-webapp.
// Je vais ajouter les dépendances suivantes :
//      - junit:junit pour faire des tests unitaires.
//      - javax.servlet:servlet-api pour pouvoir implémenter une servlet.
//      - javax.validation:validation-api pour pouvoir utiliser l'API de validation de Bean (JSR 303).
//      - org.apache.bval:bval-jsr comme implémentation de l'API de validation de Bean (JSR 303).
//                  <project>
//                      ...
//                      <dependencies>
//                          <dependency>
//                              <groupId>junit</groupId>
//                              <artifactId>junit</artifactId>
//                              <version>4.12</version>
//                              <scope>test</scope>
//                          </dependency>
//                          <dependency>
//                              <groupId>javax.servlet</groupId>
//                              <artifactId>servlet-api</artifactId>
//                              <version>2.5</version>
//                              <scope>provided</scope>
//                          </dependency>
//                          <dependency>
//                              <groupId>javax.validation</groupId>
//                              <artifactId>validation-api</artifactId>
//                              <version>1.1.0.Final</version>
//                              <scope>compile</scope>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.apache.bval</groupId>
//                              <artifactId>bval-jsr</artifactId>
//                              <version>1.1.2</version>
//                              <scope>runtime</scope>
//                          </dependency>
//                      </dependencies>
//                      ...
//                  </project>
// Voici l'explication sur les scopes utilisés :
// Dépendance        Scope           Explication
// junit             test               Cette bibliothèque de test unitaire n'est utile que pour la phase de test.
// servlet-api       provided           J'ai besoin de cette bibliothèque lors de la compilation pour créer une Servlet.
//                                      Cependant, je ne dois pas l'avoir dans les WAR générés car elle entrerait en conflit avec celle fournie par le serveur d'application Java EE lors de l'éxécution.
// validation-api    compile            J'ai besoin de cette bibliothèque lors de la compilation pour utiliser les annotations de cette API dans mes Beans.
// bval-jsr          runtime            Cette bibliothèque est une implémentation de l'API de validation de Bean (JSR 303).
//                                      Mon code ne l'utilise pas directement, donc elle n'est pas nécessaire à la compilation.
//                                      Cependant, à l'éxécution de l'application, une implémentation de l'API est nécessaire afin de procéder à la validation des Beans.
//                                      Cette bibliothèque est une des implémentations possibles (il y a aussi org.hibernate:hibernate-validator).
//      --> La mise en œuvre de l'API de validation de Bean (JSR 303) s'appuie sur le mécanisme de SPI (Service Provider Interfaces).
// Ainsi, l'interface de l'API est découplée de l'implémentation. L'implémentation est chargée et « cablée » dynamiquement par la JVM à l'exécution.
// Après un mvn clean package, voici donc les bibliothèques contenues dans le WAR :
// ticket-webapp.war
// ├── ...
// └── WEB-INF
//     └── lib
//         ├── bval-core-1.1.2.jar  (sous-dépendance de bval-jsr)
//         ├── bval-jsr-1.1.2.jar
//         ├── commons-lang3-3.5.jar (sous-dépendance de bval-jsr)
//         └── validation-api-1.1.0.Final.jar
// -----------
//  - Gérer les dépendances de manière globale :
// Vous vous souvenez sûrement que nous avions vu dans le chapitre précédent qu'il est possible de gérer vos dépendances de manière globale dans votre projet.
//      --> Cela se fait grâce à la section <dependencyManagement> dans le POM du projet parent.
// Vous pouvez ainsi lister toutes les dépendances utilisables dans les modules dans le projet parent, fixer leurs versions, gérer les exclusions...
// Il ne vous reste plus qu'à ajouter simplement les dépendances dans vos modules sans (presque) vous soucier du reste.
// Vous centralisez et homogénéisez ainsi la gestion des dépendances dans votre projet.
//      --> Mettons cela en pratique dans le projet ticket :
// Dans le POM du projet parent, ajoutez :
//                  <project>
//                      ...
//                          <dependencyManagement>
//                              <dependencies>
//                              ...
//                                  <dependency>
//                                      <groupId>junit</groupId>
//                                      <artifactId>junit</artifactId>
//                                      <version>4.12</version>
//                                      <scope>test</scope>
//                                  </dependency>
//                                  <dependency>
//                                      <groupId>javax.validation</groupId>
//                                      <artifactId>validation-api</artifactId>
//                                      <version>1.1.0.Final</version>
//                                  </dependency>
//                                  <dependency>
//                                      <groupId>org.apache.bval</groupId>
//                                      <artifactId>bval-jsr</artifactId>
//                                      <version>1.1.2</version>
//                                      <scope>runtime</scope>
//                                  </dependency>
//                                  <dependency>
//                                      <groupId>javax.servlet</groupId>
//                                      <artifactId>servlet-api</artifactId>
//                                      <version>2.5</version>
//                                      <scope>provided</scope>
//                                  </dependency>
//                              </dependencies>
//                          </dependencyManagement>
//                          ...
//                      </project>
// Dans le module ticket-webapp, conservez uniquement ceci :
//                      <project>
//                          ...
//                          <dependencies>
//                              ...
//                              <dependency>
//                                  <groupId>junit</groupId>
//                                  <artifactId>junit</artifactId>
//                              </dependency>
//                             <dependency>
//                                  <groupId>javax.validation</groupId>
//                                  <artifactId>validation-api</artifactId>
//                              </dependency>
//                              <dependency>
//                                  <groupId>org.apache.bval</groupId>
//                                  <artifactId>bval-jsr</artifactId>
//                              </dependency>
//                              <dependency>
//                                  <groupId>javax.servlet</groupId>
//                                  <artifactId>servlet-api</artifactId>
//                              </dependency>
//                          </dependencies>
//                          ...
//                      </project>
// -----------
//  - Utiliser une « Bill Of Materials » :
// Il est courant qu'un framework soit composé de plusieurs modules (ex. : Spring®, Apache Struts™...).
//      --> Dans ce cas, au lieu de définir, une par une, toutes les dépendances vers ces modules, il est possible d'utiliser, si elle existe, une « Bill Of Materials» (BOM).
// Il s'agit d'un fichier POM spécifique, mis à disposition par les mainteneurs du framework. Il contient la définition des dépendances fournies par celui-ci.
//      --> Pour l'utiliser, il suffit d'importer le POM de cette « Bill Of Materials » dans la section dependencyManagement de votre projet avec le type pom  et le scope import.
// Voici un exemple avec la BOM de Spring :
//                      <project>
//                          ...
//                          <dependencyManagement>
//                              <dependencies>
//                                  <dependency>
//                                      <groupId>org.springframework</groupId>
//                                      <artifactId>spring-framework-bom</artifactId>
//                                      <version>4.3.11.RELEASE</version>
//                                      <type>pom</type>
//                                      <scope>import</scope>
//                                  </dependency>
//                              </dependencies>
//                              ...
//                          </dependencyManagement>
//                          ...
//                      </project>
// -----------
//  - Versions Snapshot et Release :
// Il y a un concept fort dans Maven qui s'appelle la reproductibilité de la construction.
// Cela veut dire que si vous ne changez rien et relancez un packaging de votre projet, vous devez obtenir le même livrable (à quelques deltas près comme les dates de construction...).
// Ceci concerne également les dépendances que vous avez ajoutées à votre projet.
// Pour garantir au maximum cette reproductibilité avec les dépendances, il y a un principe de base : une version d'une dépendance est conventionnellement immuable.
// Cela veut dire qu'une fois la version publiée, elle ne sera plus modifiée. Si un changement doit intervenir dans le code, une nouvelle version sera publiée.
//      --> Ces versions s'appellent des releases.
// Cependant, il arrive que vous deviez dépendre d'un élément en cours de développement.
//      --> Dans ce cas, la version de cette élément sera une version snapshot. Cela est précisé dans Maven avec le suffixe -SNAPSHOT à la fin de la version.
// Une version snapshot peut être modifiée à tout moment et elle fait donc l'objet d'un traitement particulier dans Maven.
// -----------
//  - Résumons :
// Résumons ce que nous venons de voir dans ce chapitre.
//      - Les dépendances s'ajoutent grâce à la balise <dependency>.
//      - Elles sont rattachées à un scope qui par défaut est compile, mais vous pouvez en spécifier d'autres comme runtime ou test par exemple.
//      - Suivant leur scope, Maven ajoute automatiquement les sous-dépendances : c'est la transitivité des dépendances. Cependant, vous pouvez exclure des sous-dépendances avec la balise <exclusions>.
// Voici un tableau récapitulatif des scopes, de leur transitivité et des contextes dans lesquels la dépendance correspondante est accessible :
// Scope     Transitif   Compilation     Test   Exécution
// compile     ✓             ✓            ✓       ✓
// test                                    ✓
// provided                  ✓             ✓
// runtime     ✓                           ✓       ✓
//      --> Les versions de type release sont immuables, contrairement aux versions de type snapshot (version avec le suffixe -SNAPSHOT).
// Enfin, je vous conseille de gérer les dépendances globalement au niveau du projet parent pour les projets multi-modules.
//      --> Cela se fait grâce à la section <dependencyManagement>. Si elle est disponible, vous pouvez importer dans cette section la « Bill Of Materials » des frameworks.
// -----------
//  - Conclusion :
// Nous arrivons à présent à la fin de cette première partie du cours.
// Vous savez maintenant comment créer un nouveau projet Maven mais aussi comment bien l'organiser et gérer ses dépendances.
// Dans la partie suivante, je vais vous apprendre à automatiser et personnaliser la construction de votre projet.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Automatisez la construction de votre projet ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Familiarisez-vous avec le cycle de vie du build Maven /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - De quoi est composé le build lifecycle ?
// Afin d'automatiser la construction d'un projet, Maven s'appuie sur des cycles de vie de construction appelés build lifecycle dans le jargon de Maven.
//      --> Il y a 3 build lifecycles de base dans Maven :
//              - default : qui permet de construire et déployer le projet.
//              - clean : qui permet de nettoyer le projet en supprimant les éléments issus de la construction de celui-ci.
//              - site : qui permet de créer un site web pour le projet.
// Ces build lifecycles sont découpés en phases qui sont exécutées séquentiellement les unes à la suite des autres.
// Si je prends l'exemple du build lifecycledefault, nous y retrouvons, entre autres, les phases :
//      - validate : vérifie que la configuration projet est correcte (POM, pas d'éléments manquants...).
//      - compile : compile les sources du projet.
//      - test : teste le code compilé avec les classes de tests unitaires contenues dans le projet.
//      - package : package les éléments issus de la compilation dans un format distribuable (JAR, WAR...).
//      - install : installe le package dans votre repository local.
//      - deploy : envoie le package dans le repository distant défini dans le POM.
// --> Ainsi, la construction du projet (le build lifecycle) est un enchaînement d'étapes (les phases) permettant d'obtenir le résultat final.
// -----------
//  - Lancer un build lifecycle :
// Quand vous lancez une construction Maven en ligne de commande, vous précisez simplement une phase d'un des build lifecycles.
//      --> Maven se charge d'exécuter, dans l'ordre, toutes les phases qui composent le build lifecycle jusqu'à la phase indiquée.
// Vous vous rappelez de la commande mvn package ?
//      --> Eh bien dans cette commande, vous indiquiez la phase package du build lifecycledefault. Maven avait alors exécuté les phases validate, compile, test et enfin package.
// Pour les projets multi-modules, quand vous lancez la commande mvn sur le projet parent, Maven lance le build lifecycle dans chaque sous-projet (module).
// Cela, les uns à la suite des autres, en respectant l'ordre des dépendances inter-modules.
// Il vous est aussi possible de chaîner l'exécution de plusieurs build lifecycles dans une seule commande Maven. Si vous lancez mvn clean package par exemple, Maven va :
//      --> Dans un premier temps, nettoyer le projet en exécutant le build lifecycle clean.
//      --> Puis, il va lancer le build lifecycle default jusqu'à la phase package.
// -----------
//  - Les goals :
// Nous avons vu qu'un build lifecycle est constitué d'une série de phases. Mais la granularité de l'exécution de Maven est encore plus fine.
//      --> En effet, les phases sont découpées en tâches. Chaque tâche est assurée par un plugin Maven. Dans le jargon de Maven, ces tâches s'appellent des goals.
// Par exemple, la phase test est réalisée par défaut par le goal 'surefire:test', c'est-à-dire le goal test du plugin surefire.
// Maven fournit de base un certain nombre de plugins.
//      --> Nous en avions déjà vu un dans la partie précédente quand nous avions ajouté la désignation de la classe Main dans le manifest du fichier JAR à générer :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Build -->
//                      <!-- =============================================================== -->
//                      <build>
//                          <!-- Gestion des plugins (version) -->
//                          <pluginManagement>
//                              <plugins>
//                                  <!-- Plugin responsable de la génération du fichier JAR -->
//                                  <plugin>
//                                      <groupId>org.apache.maven.plugins</groupId>
//                                      <artifactId>maven-jar-plugin</artifactId>
//                                      <version>3.0.2</version>
//                                  </plugin>
//                              </plugins>
//                          </pluginManagement>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-jar-plugin</artifactId>
//                                  <configuration>
//                                      <archive>
//                                          <!-- Création du Manifest pour la définition de la classe Main -->
//                                          <manifest>
//                                              <mainClass>org.exemple.demo.App</mainClass>
//                                          </manifest>
//                                      </archive>
//                                  </configuration>
//                              </plugin>
//                          </plugins>
//                      </build>
//                      ...
//                  </project>
// -----------
//  - Résumons :
// Afin de construire un projet, Maven s'appuie sur des build lifecycles.
//      --> Ces build lifecycles sont un enchaînement de différentes étapes : les phases.
//      --> Les phases sont découpées en tâches, appelées goals, et réalisées par des plugins Maven.
// Dans le chapitre suivant, nous verrons les principaux plugins Maven et vous montrer comment personnaliser la construction de votre projet en les câblant aux différentes phases des build lifecycles.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Personnalisez la construction avec les plugins ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant que vous avez une meilleure vision du processus d'exécution d'un build Maven, nous allons pouvoir personnaliser la construction de votre projet grâce aux plugins maven.
// Le but est d'adapter et d'enrichir le POM afin de coller le plus possible à votre besoin et ainsi d'automatiser au maximum la construction et la génération des livrables de votre projet.
// -----------
//  - Les plugins déjà câblés aux phases :
//      --> Rappe : les phases d'un build lifecycle sont découpées en tâches réalisées par les goals de différents plugins : http://maven.apache.org/ref/3.5.0/maven-core/lifecycles.html.
// Suivant le build lifecycle et le packaging utilisés, différents goals sont câblés par défaut aux différentes phases : http://maven.apache.org/ref/3.5.0/maven-core/default-bindings.html.
// Pour le packaging JAR, voici le câblage par défaut (pour la version 3.5.0 de Maven) :
//                  <phases>
//                      <process-resources>
//                          org.apache.maven.plugins:maven-resources-plugin:2.6:resources
//                      </process-resources>
//                      <compile>
//                          org.apache.maven.plugins:maven-compiler-plugin:3.1:compile
//                      </compile>
//                      <process-test-resources>
//                          org.apache.maven.plugins:maven-resources-plugin:2.6:testResources
//                      </process-test-resources>
//                      <test-compile>
//                          org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile
//                      </test-compile>
//                      <test>
//                          org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test
//                      </test>
//                      <package>
//                          org.apache.maven.plugins:maven-jar-plugin:2.4:jar
//                      </package>
//                      <install>
//                          org.apache.maven.plugins:maven-install-plugin:2.4:install
//                      </install>
//                      <deploy>
//                          org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy
//                      </deploy>
//                    </phases>
// -----------
//  - Affiner la configuration de la compilation :
// J'aimerais que lors de la compilation, Maven m'affiche les utilisations de méthodes dépréciées (@Deprecated) ainsi que les avertissements de compilation (warnings).
// Je remarque dans la documentation que la phase compile est assurée par le goal compile du plugin org.apache.maven.plugins:maven-compiler-plugin :
//                    <phases>
//                        ...
//                        <compile>
//                            org.apache.maven.plugins:maven-compiler-plugin:3.1:compile
//                        </compile>
//                        ...
//                    </phases>
// Je vais dans la documentation des plugins : https://maven.apache.org/plugins/index.html.
// Et plus précisément dans la documentation du goal compile du plugin maven-compiler-plugin : https://maven.apache.org/plugins/maven-compiler-plugin/compile-mojo.html.
// J'obtiens ainsi une description du goal et la liste des options de configuration qui lui sont applicables.
// Deux options retiennent mon attention :
// Name                   Type        Description
// showDeprecation       boolean        Sets whether to show source locations where deprecated APIs are used.
//                                      Default value is:false.
//                                      User property is:maven.compiler.showDeprecation.
// showWarnings          boolean        Set to true to show compilation warnings.
//                                      Default value is:false.
//                                      User property is:maven.compiler.showWarnings.
// Par défaut, ces deux options sont à false. Pour les activer, il y a deux solutions :
//      --> Soit en ajoutant une section <configuration> dans la définition du plugin dans le POM :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Build -->
//                      <!-- =============================================================== -->
//                      <build>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-compiler-plugin</artifactId>
//                                  <version>3.1</version>
//                                  <configuration>
//                                      <showDeprecation>true</showDeprecation>
//                                      <showWarnings>true</showWarnings>
//                                  </configuration>
//                              </plugin>
//                          </plugins>
//                      </build>
//                      ...
//                  </project>
//      --> Soit en utilisant les propriétés données par les lignes « User property is: ... » :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Propriétés -->
//                      <!-- =============================================================== -->
//                      <properties>
//                          <maven.compiler.showDeprecation>true</maven.compiler.showDeprecation>
//                          <maven.compiler.showWarnings>true</maven.compiler.showWarnings>
//                      </properties>
//                      ...
//                  </project>
// -----------
//  - Définir la classe Main du JAR :
// Dans la première partie nous avions déjà vu comment définir la classe Main dans le manifest du JAR généré par Maven.
// Si je reprends le même principe que dans la section précédente, voici comment j'en suis arrivé à cette configuration.
//      - Dans la documentation, la phase package est assurée par le goal jar du plugin org.apache.maven.plugins:maven-jar-plugin :
//                  <phases>
//                      ...
//                      <package>
//                          org.apache.maven.plugins:maven-jar-plugin:2.4:jar
//                      </package>
//                      ...
//                  </phases>
//      - Je vais dans la documentation du goal jar du plugin maven-jar-plugin : https://maven.apache.org/plugins/maven-jar-plugin/jar-mojo.html.
//      - Je repère l'option archive qui me renvoie à la documentation de Maven Archiver où j'obtiens les éléments de configuration du manifest :
//              --> http://maven.apache.org/shared/maven-archiver/index.html#class_manifest.
//      - J'en déduis la configuration adéquate et je l'ajoute au POM :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Build -->
//                      <!-- =============================================================== -->
//                      <build>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-jar-plugin</artifactId>
//                                  <version>3.0.2</version>
//                                  <configuration>
//                                      <archive>
//                                          <manifest>
//                                              <mainClass>org.exemple.demo.App</mainClass>
//                                          </manifest>
//                                      </archive>
//                                  </configuration>
//                              </plugin>
//                          </plugins>
//                      </build>
//                      ...
//                  </project>
// -----------
//  - Gérer les plugins de manière globale :
//      --> Il est fortement recommandé de définir les versions des plugins utilisés.
// Comme pour les dépendances, il est possible de le faire de manière globale au projet via la section <pluginManagement> dans le POM parent.
// Vous pouvez ainsi fixer les versions des plugins mais aussi leur configuration de manière globale.
// Si je reprends les exemples précédents, voici ce que j'obtiens dans le POM parent :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Build -->
//                      <!-- =============================================================== -->
//                      <build>
//                          <!-- ===== Gestion des plugins ===== -->
//                          <pluginManagement>
//                             <plugins>
//                                  <plugin>
//                                      <groupId>org.apache.maven.plugins</groupId>
//                                      <artifactId>maven-compiler-plugin</artifactId>
//                                      <version>3.1</version>
//                                      <configuration>
//                                          <showDeprecation>true</showDeprecation>
//                                          <showWarnings>true</showWarnings>
//                                      </configuration>
//                                  </plugin>
//                                  <plugin>
//                                      <groupId>org.apache.maven.plugins</groupId>
//                                      <artifactId>maven-jar-plugin</artifactId>
//                                      <version>3.0.2</version>
//                                  </plugin>
//                              </plugins>
//                          </pluginManagement>
//                      </build>
//                      ...
//                  </project>
// Et dans mon module, il ne me reste plus que :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Build -->
//                      <!-- =============================================================== -->
//                      <build>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-jar-plugin</artifactId>
//                                  <configuration>
//                                      <archive>
//                                          <manifest>
//                                              <mainClass>org.exemple.demo.App</mainClass>
//                                          </manifest>
//                                      </archive>
//                                  </configuration>
//                              </plugin>
//                          </plugins>
//                      </build>
//                      ...
//                  </project>
// Je n'ai pas mis la configuration de la classe Main dans la section <pluginManagement> du POM parent.
//      --> En effet, tous les modules n'ont pas de classe Main (ou du moins pas la même !).
// -----------
//  - Ajouter de nouveaux plugins dans les phases :
// J'ai défini 3 profils permettant de spécifier l'environnement cible de ma construction (développement, test, production) :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Profils -->
//                      <!-- =============================================================== -->
//                      <profiles>
//                          <!-- Profil pour l'environnement de développement -->
//                          <profile>
//                              <id>target-dev</id>
//                              ...
//                          </profile>
//                          <!-- Profil pour l'environnement de test -->
//                          <profile>
//                              <id>target-test</id>
//                              ...
//                          </profile>
//                          <!-- Profil pour l'environnement de production -->
//                          <profile>
//                              <id>target-prod</id>
//                              ...
//                          </profile>
//                      </profiles>
//                      ...
//                  </project>
// Lors du build avec Maven, je veux m'assurer qu'au moins un des profils est activé.
//      --> Je vais pour cela utiliser le goal enforce du plugin maven-enforcer-plugin : https://maven.apache.org/enforcer/maven-enforcer-plugin/.
// J'ajoute donc ce plugin. Il faut aussi que je câble son goal enforce à la phase validate du build lifecycle default.
//      --> Cela se fait grâce à la section <executions> :
//                  <project>
//                      ...
//                      <build>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-enforcer-plugin</artifactId>
//                                  <version>1.4.1</version>
//                                  <executions>
//                                     <execution>
//                                          <!-- je choisis un nom unique pour définir cette exécution -->
//                                          <id>enforce-profile-target</id>
//                                          <!-- je branche l'exécution à la phase "validate" -->
//                                          <phase>validate</phase>
//                                          <!-- cette exécution lancera le goal "enforce" -->
//                                          <goals>
//                                              <goal>enforce</goal>
//                                          </goals>
//                                          <!-- La configuration du plugin propre à cette exécution -->
//                                          <configuration>
//                                              <rules>
//                                                  <requireActiveProfile>
//                                                      <profiles>target-dev,target-test,target-prod</profiles>
//                                                      <all>false</all>
//                                                  </requireActiveProfile>
//                                              </rules>
//                                          </configuration>
//                                      </execution>
//                                  </executions>
//                              </plugin>
//                          </plugins>
//                      </build>
//                      ...
//                  </project>
// Si je lance maintenant mon build sans activer de profil target-... cela me renvoie une erreur :
//                  $ mvn package
//                  ...
//                  [WARNING] Rule 0: org.apache.maven.plugins.enforcer.RequireActiveProfile failed with message:
//      --> Il faut activer un des profils target :
//                  Profile "target-dev" is not activated.
//                  Profile "target-test" is not activated.
//                  Profile "target-prod" is not activated.
//                  ...
//                  BUILD FAILURE
//      --> Alors qu'en activant un des profils, je n'ai plus de problème :
//                  $ mvn package -Ptarget-dev
//                  ...
//                  BUILD SUCCESS
// -----------
//  - Conclusion :
// Maven fournit un certain nombre de plugins de base.
// Suivant le build lifecycle et le packaging utilisés, différents goals de ces plugins sont câblés par défaut aux différentes phases :
//      --> http://maven.apache.org/ref/3.5.0/maven-core/default-bindings.html.
//      --> http://maven.apache.org/ref/3.5.0/maven-core/lifecycles.html.
// Référez-vous à la documentation des plugins pour trouver le plugin qu'il vous faut et connaître son fonctionnement.
//      --> Il est fortement recommandé de définir les versions des plugins utilisés.
// Comme pour les dépendances, il est possible de gérer les plugins de manière globale au projet via la section <pluginManagement> dans le POM parent.
// Vous pouvez câbler des nouveaux goals aux phases grâce aux sections <executions> des plugins.
// Dans le prochain chapitre, je vous montrerai comment utiliser les plugins pour parfaire le packaging de vos livrables.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Packagez vos livrables ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans le chapitre précédent, nous avons vu comment personnaliser la construction de votre projet Maven avec les plugins.
//      --> Abordons maintenant la génération des livrables de votre projet.
// Je vais vous montrer comment générer, par exemple, un WAR de votre application web ou un ZIP de vos batchs.
// Le but est d'obtenir un livrable contenant tout le nécessaire : votre application, bien sûr, mais aussi ses dépendances, les fichiers de configuration...
// Dans ce chapitre, je m'appuierai sur des exemples concrets portant sur le projet de gestion de tickets d'incidents vu dans les chapitres précédents.
// -----------
//  - Générer un WAR de l'application web :
// Dans ce premier volet, le but est de générer un fichier WAR pour le déploiement de l'application web.
// Je ne vais pas me contenter simplement de la génération de base du WAR, réalisée par le plugin maven-war-plugin.
// Je vais étoffer le processus de construction afin :
//      --> D'ajouter automatiquement certaines informations du projet dans les JSP.
//      --> De m'assurer qu'aucune version SNAPSHOT ne soit envoyée en production.
// -----------
//  - Filtrer les ressources de la webapp :
// Afin d'ajouter automatiquement certaines informations du projet dans les JSP, je vais utiliser le même mécanisme que pour les fichiers de ressource classiques : le filtrage.
// Cependant, les JSP ne sont pas des ressources classiques, elles doivent être ajoutées au répertoire WEB-INF du WAR.
//      --> Le plugin maven-war-plugin fait déjà cela et permet également de mettre en place le filtrage de ces web resources.
// Je commence donc par ajouter le plugin maven-war-plugin dans la section <pluginManagement> du POM parent :
//                  <project>
//                      ...
//                      <build>
//                          <pluginManagement>
//                              <plugins>
//                                  <plugin>
//                                      <groupId>org.apache.maven.plugins</groupId>
//                                      <artifactId>maven-war-plugin</artifactId>
//                                      <version>3.1.0</version>
//                                  </plugin>
//                                  ...
//                              </plugins>
//                          </pluginManagement>
//                      </build>
//                      ...
//                  </project>
//      --> Dans l'arborescence standard d'un projet Maven, le répertoire contenant les web resources est src/main/webapp.
// Je configure ensuite le plugin maven-war-plugin dans le module ticket-webapp afin d'activer le filtrage des web resources suivantes :
//      - jsp/_include/header.jsp : fragment JSP contenant le header de toutes les pages HTML de l'application web. Je vais y injecter le nom « public » de l'application.
//      - jsp/_include/footer.jsp : fragment JSP contenant le footer de toutes les pages HTML de l'application web. Je vais y injecter notamment le nom de l'organisation et la version de l'application.
//      - jsp/about.jsp : page « À propos » où je vais injecter quelques informations sur le projet (version, date du build...)
//                  <project>
//                      ...
//                      <build>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-war-plugin</artifactId>
//                                  <configuration>
//                                      <webResources>
//                                          <resource>
//                                              <filtering>true</filtering>
//                                              <directory>src/main/webapp</directory>
//                                              <includes>
//                                                  <include>jsp/_include/header.jsp</include>
//                                                  <include>jsp/_include/footer.jsp</include>
//                                                  <include>jsp/about.jsp</include>
//                                              </includes>
//                                          </resource>
//                                      </webResources>
//                                  </configuration>
//                              </plugin>
//                              ...
//                          </plugins>
//                      </build>
//                      ...
//                  </project>
// Je complète ensuite le POM du module ticket-webapp pour ajouter les propriétés utiles pour la suite :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Propriétés -->
//                      <!-- =============================================================== -->
//                      <properties>
//                          <!-- Le nom "public" de l'application -->
//                          <application.name>TicketTac</application.name>
//                          <!-- Le format à utiliser pour afficher la date du build -->
//                          <maven.build.timestamp.format>dd/MM/yyyy</maven.build.timestamp.format>
//                          <!-- Propriété servant à contourner le bug du non remplacement
//                               de la propriété maven.build.timestamp lors du filtrage des ressources -->
//                          <buildTimestamp>${maven.build.timestamp}</buildTimestamp>
//                      </properties>
//                      ...
//                  </project>
// Comme je vous l'indiquais dans la première partie de ce cours, il est intéressant d'ajouter des informations complémentaires dans le POM, comme le nom de l'organisation, l'URL de son site web...
// Il ne me reste plus qu'à utiliser les propriétés dans les JSP afin que leurs valeurs soient injectées lors du filtrage par le plugin maven-war-plugin :
//      --> jsp/_include/header.jsp :
//                  <%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8" %>
//                  <nav class="navbar navbar-inverse navbar-fixed-top">
//                      <div class="container">
//                          <div class="navbar-header">
//                              <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
//                                  <span class="sr-only">Toggle navigation</span>
//                                  <span class="icon-bar"></span>
//                                  <span class="icon-bar"></span>
//                                  <span class="icon-bar"></span>
//                              </button>
//                              <a class="navbar-brand" href="#">${application.name}</a>
//                          </div>
//                          <div id="navbar" class="collapse navbar-collapse">
//                              <ul class="nav navbar-nav">
//                                  <li class="active"><a href="..">Accueil</a></li>
//                                  <li><a href="../jsp/about.jsp">A propos</a></li>
//                              </ul>
//                          </div><!--/.nav-collapse -->
//                      </div>
//                  </nav>
//      --> jsp/_include/footer.jsp :
//                  <%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8" %>
//                  <footer class="footer">
//                      <div class="container">
//                          <p>
//                              ${application.name} - version ${project.version}
//                              &copy; <a href="${organization.url}">${organization.name}</a>
//                          </p>
//                      </div>
//                  </footer>
//                  <!-- Bootstrap -->
//                  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"
//                          integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa"
//                          crossorigin="anonymous"></script>
//      --> jsp/about.jsp :
//                  <%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8" %>
//                  <!DOCTYPE html>
//                  <html lang="fr">
//                  <head>
//                      <meta charset="utf-8" />
//                      <meta http-equiv="X-UA-Compatible" content="IE=edge" />
//                      <meta name="viewport" content="width=device-width, initial-scale=1" />
//                      <title>${application.name} - A propos</title>
//                      <!-- Bootstrap -->
//                      <link rel="stylesheet"
//                            href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"
//                            integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u"
//                            crossorigin="anonymous" />
//                      <link rel="stylesheet"
//                            href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css"
//                            integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp"
//                            crossorigin="anonymous" />
//                      <link rel="stylesheet" href="../style/custom.css" />
//                  </head>
//                  <body>
//                  <%@ include file="_include/header.jsp" %>
//                  <div class="container">
//                      <ul>
//                          <li>Application : ${application.name}</li>
//                          <li>Version : ${project.version}</li>
//                          <li>Date du build : ${maven.build.timestamp}</li>
//                     </ul>
//                  </div>
//                  <%@ include file="_include/footer.jsp" %>
//                  </body>
//                  </html>
// -----------
//  - Les vérifications supplémentaires pour la cible « production » :
// Afin de m'assurer qu'aucune version SNAPSHOT ne soit envoyée en production, je vais encore une fois utiliser le plugin maven-enforcer-plugin.
//      --> Cependant, cette vérification concerne uniquement les constructions ayant pour cible la production.
// Donc, je vais ajouter l'exécution de ce plugin dans un profil dédié à la cible production.
// Si je reprends les profils que j'ai créés dans le chapitre précédent, je vais donc ajouter le plugin au build du profil target-prod :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Profils -->
//                      <!-- =============================================================== -->
//                      <profiles>
//                          ...
//                          <profile>
//                              <id>target-prod</id>
//                              <build>
//                                  <plugins>
//                                      <plugin>
//                                          <groupId>org.apache.maven.plugins</groupId>
//                                          <artifactId>maven-enforcer-plugin</artifactId>
//                                          <executions>
//                                              <execution>
//                                                  <id>enforce-target-prod-no-snapshot</id>
//                                                  <phase>validate</phase>
//                                                  <goals>
//                                                      <goal>enforce</goal>
//                                                  </goals>
//                                                  <configuration>
//                                                      <rules>
//                                                          <!-- Le projet et son parent ne doivent pas être en SNAPSHOT -->
//                                                          <requireReleaseVersion />
//                                                          <!-- Aucune dépendance ne doit être en SNAPSHOT -->
//                                                          <requireReleaseDeps />
//                                                      </rules>
//                                                  </configuration>
//                                              </execution>
//                                          </executions>
//                                      </plugin>
//                                  </plugins>
//                              </build>
//                          </profile>
//                      </profiles>
//                      ...
//                  </project>
// Voila ! Tout ce que j'avais besoin de faire de particulier pour la génération du WAR a été mis en place.
// Passons maintenant à un deuxième volet du projet : les batchs.
// -----------
//  - Générer une archive pour votre jeu de batchs :
//      --> L'objectif est de générer une archive (un fichier TAR.GZ et un fichier ZIP) pour le jeu de batchs de l'application de gestion de tickets.
// Cette archive contiendra :
//      - Le JAR du module ticket-batch.
//      - Les JAR de toutes ses dépendances.
//      - Les fichiers de configuration (modifiables facilement par l'administrateur).
//      - les scripts shell de lancement de chaque batch.
// Voici comment je vais organiser l'archive :
//      --> Le répertoire bin contiendra les scripts shell de lancement des batchs.
//      --> Le répertoire conf contiendra les fichiers de configuration.
//      --> Le répertoire lib contiendra le JAR du module ticket-batch ainsi que les JAR des dépendances.
// archive
// ├── bin
// │   ├── batch-X.sh
// │   ├── batch-Y.sh
// │   └── ...
// ├── conf
// │   ├── config.properties
// │   ├── db-X.properties
// │   └── ...
// └── lib
//     ├── ticket-batch-*.jar
//     ├── ticket-business-*.jar
//     ├── ticket-model-*.jar
//     ├── commons-lang3-*.jar
//     └── ...
// -----------
//  - Préparer le terrain :
// Pour commencer, je vais créer l'arborescence suivante pour héberger les fichiers à inclure dans l'archive :
// src/data
// ├── scripts
// │   ├── batch-X.sh
// │   ├── batch-Y.sh
// │   └── ...
// └── conf
//     ├── config.properties  (conf. de l'application)
//     ├── db-X.properties    (conf. de la base de données)
//     └── ...
// Je ne vous détaille pas le contenu des ces fichiers, cela ne vous sera pas utile ici.
// -----------
//  - Configuration du JAR des batchs :
// Étant donné que je vais fournir les JAR des dépendances à côté du JAR du module ticket-batch, je vais ajouter le classpath au manifest de ce JAR.
//      --> Ainsi, toutes les classes seront trouvées automatiquement par la JVM lors de l'exécution du JAR.
// Pour cela, je complète la configuration du plugin maven-jar-plugin :
//                  <project>
//                      ...
//                      <build>
//                          <plugins>
//                              <!-- Création du JAR -->
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-jar-plugin</artifactId>
//                                  <configuration>
//                                      <archive>
//                                          <manifest>
//                                              <addClasspath>true</addClasspath>
//                                              <classpathPrefix></classpathPrefix>
//                                          </manifest>
//                                      </archive>
//                                  </configuration>
//                              </plugin>
//                              ...
//                          </plugins>
//                      </build>
//                      ...
//                  </project>
// -----------
//  - Assembler le tout dans une archive :
// Afin de générer les fichiers d'archive, je vais utiliser le plugin maven-assembly-plugin.
//      - Définition de l'assemblage :
//          La définition des assemblages se fait grâce à des fichiers XML dans le répertoire src/assembly.
//          Je crée donc un nouveau fichier src/assembly/archive-deploy.xml :
//                  <assembly xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                            xmlns="http://maven.apache.org/ASSEMBLY/2.0.0"
//                            xsi:schemaLocation="http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd">
//                      <!-- Identifiant de l'assemblage -->
//                      <id>archive-deploy</id>
//                      <!-- Les formats d'archive à générer -->
//                      <formats>
//                          <format>tar.gz</format>
//                          <format>zip</format>
//                      </formats>
//                      <!-- lib : dépendances + JAR ticket-batch -->
//                      <dependencySets>
//                          <dependencySet>
//                              <outputDirectory>lib</outputDirectory>
//                              <scope>runtime</scope>
//                          </dependencySet>
//                      </dependencySets>
//                      <fileSets>
//                          <!-- Scripts shell de lancement -->
//                          <fileSet>
//                              <directory>src/data/scripts</directory>
//                              <outputDirectory>bin</outputDirectory>
//                              <!-- Droits UNIX sur les fichiers (-rwx-rx-rx) -->
//                              <fileMode>0755</fileMode>
//                          </fileSet>
//                          <!-- Fichiers de configuration -->
//                          <fileSet>
//                              <directory>src/data/conf</directory>
//                              <outputDirectory>conf</outputDirectory>
//                          </fileSet>
//                      </fileSets>
//                  </assembly>
//          Voici quelques explications sur les différents éléments contenus dans ce fichier :
//              --> id : l'identifiant de l'assemblage. Maven va se servir de cet identifiant dans le nom des fichiers générés : <project.finalName>-<id>.<format>.
//                          --> Ce qui donnerait par exemple : ticket-batch-1.0-SNAPSHOT-archive-deploy.tar.gz.
//              --> formats : les formats de fichier à générer. Ici un fichier tar.gz et un fichier zip.
//              --> dependencySets : ajout d'un ensemble de dépendances. Ici, j'ajoute toutes les dépendances de runtime (scope runtime et compile) du projet dans le répertoire de destination lib.
//              --> fileSets : ajout d'un ensemble de fichiers. Ici, j'ajoute deux ensembles de fichiers :
//                      --> Les scripts de lancement des batchs contenus dans le répertoire src/data/scripts, dans le répertoire de destination bin.
//                              J'y positionne les droits Unix, notamment celui d'exécution : <fileMode>0755</fileMode> (-rwxr-x-rx).
//                      --> Les fichiers de configuration contenus dans le répertoire src/data/conf, dans le répertoire de destination conf.
//      - Câbler la génération des fichiers d'archive :
// La dernière étape consiste à câbler la génération des fichiers d'archive à la phase package :
//                  <project>
//                      ...
//                      <build>
//                         <plugins>
//                              ...
//                              <!-- Création des archives de déploiement -->
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-assembly-plugin</artifactId>
//                                  <configuration>
//                                      <descriptors>
//                                          <descriptor>src/assembly/archive-deploy.xml</descriptor>
//                                      </descriptors>
//                                  </configuration>
//                                  <executions>
//                                      <execution>
//                                          <id>assembly-archive-deploy</id>
//                                          <phase>package</phase>
//                                          <goals>
//                                              <goal>single</goal>
//                                          </goals>
//                                      </execution>
//                                  </executions>
//                              </plugin>
//                          </plugins>
//                      </build>
//                      ...
//                  </project>
//          Et voilà, maintenant, si vous lancez la commande suivante, les fichiers archives de l'assemblage archive-deploy seront générés automatiquement dans le répertoire target :
//              --> mvn package
// Si vous voulez aller plus loin dans les assemblages, vous pouvez consulter la documentation.
// -----------
//  - Conclusion :
// Nous avons vu deux exemples de personnalisation de la construction et de la génération de livrables de projet Maven.
// Je vous invite à tester cela et faire vos propres expériementations.
// Dans le prochain chapitre, vous verrons qu'il est possible d'utiliser Maven pour générer un site web pour votre projet.
// Ce site va donner des informations générales sur le projet mais aussi des informations sur ses différents modules, la documentation, des rapports sur l'exécution des tests.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Générez un site pour votre projet /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans les chapitres précédents, nous avons vu comment utiliser Maven pour :
//      - Construire votre projet.
//      - Gérer ses dépendances.
//      - Générer les livrables.
// Dans ce chapitre, je vais vous montrer qu'il est aussi possible d'utiliser Maven pour générer un site web pour votre projet. Vous y retrouverez :
//      - Des informations générales sur celui-ci.
//      - La Javadoc.
//      - Des rapports sur l'exécution des tests, la qualité du code...
// Je vous montrerai également comment y ajouter vos propres éléments.
// -----------
//  - Configuration de base du site !
//      - Convention sur l'arborescence :
// Par convention, les sources servant à la génération du site du projet se trouvent dans le répertoire src/site, lui-même organisé de cette manière :
// src
// └── site
//     ├── apt
//     │   ├── xxx.apt
//     │   └── ...
//     ├── fml
//     │   ├── faq.fml
//     │   └── ...
//     ├── markdown
//     │   ├── yyy.md
//     │   └── ...
//     ├── ...
//     ├── resources
//     │   ├── css
//     │   │   └── style.css
//     │   ├── img
//     │   │   ├── zzz.png
//     │   │   └── ...
//     │   └── ...
//     └── site.xml
// Pas de panique, voici quelques explications :
//      --> Le fichier src/site/site.xml est le site descriptor. Il permet de définir la structure du site.
//      --> Les répertoires apt, markdown, fml... hébergent les fichiers source des pages du site qui seront converties en HTML par Maven.
//          Ces répertoires accueillent des fichiers de leur format respectif :
//              - apt : Format Almost Plain Text.
//              - fml : Format FAQ Markup Language.
//              - markdown : Format Markdown.
//              - Autres formats supportés par Maven...
//      --> Le répertoire resources pour les autres ressources :
//              - css/style.css : fichier CSS permettant d'ajuster le style par défaut
//              - ...
// -----------
//  - Le site descriptor :
// Le fichier src/site/site.xml est le site descriptor. Il permet de définir la structure du site.
// Je ne vais pas détailler ici toutes les possiblités, mais vous en présenter quelques-unes. Je vous laisse le soin d'aller voir la documentation si vous voulez en voir plus :
//      --> https://maven.apache.org/plugins/maven-site-plugin/examples/sitedescriptor.html.
//      --> https://maven.apache.org/doxia/doxia-sitetools/doxia-decoration-model/decoration.html.
// Je crée donc ce fichier site.xml :
//                  <project xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://maven.apache.org/DECORATION/1.7.0"
//                           xsi:schemaLocation="http://maven.apache.org/DECORATION/1.7.0 http://maven.apache.org/xsd/decoration-1.7.0.xsd">
//                      <!-- Utilisation du template de site fluido -->
//                      <skin>
//                          <groupId>org.apache.maven.skins</groupId>
//                          <artifactId>maven-fluido-skin</artifactId>
//                          <version>1.6</version>
//                     </skin>
//                      <!-- Affichage de la date et de la version à droite dans le bandeau du haut -->
//                      <publishDate position="right"/>
//                      <version position="right"/>
//                      <body>
//                          <!-- Ajout d'un fil d'ariane -->
//                          <breadcrumbs>
//                              <item name="Accueil" href="index.html"/>
//                          </breadcrumbs>
//                          <!-- ===== Menus ===== -->
//                          <!-- Ajout d'un menu vers le projet parent -->
//                          <menu ref="parent" inherit="top"/>
//                          <!-- Ajout d'un menu vers les différents modules du projet -->
//                          <menu ref="modules" inherit="top"/>
//                      </body>
//                  </project>
// Ce fichier est « filtré » par Maven. Il est donc possible d'utiliser les propriétés Maven.
// -----------
//  - Configuration du site dans le POM :
// Il faut ensuite ajouter dans le POM parent les informations de déploiement du site.
//                  <project>
//                      <!-- =============================================================== -->
//                      <!-- DistributionManagement -->
//                      <!-- =============================================================== -->
//                      <distributionManagement>
//                          <site>
//                              <id>site-projet</id>
//                              <url>scp://exemple.org/www/</url>
//                          </site>
//                      </distributionManagement>
//                      ...
//                  </project>
// L'ajout de ces informations est requis par Maven, même si vous ne comptez pas déployer le site automatiquement. Dans ce cas, vous pouvez utiliser une URL de cette forme : scp://localhost/tmp/.
// -----------
//  - Générer le site :
//      - Ajout du plugin maven-site-plugin :
//          Afin de générer le site, vous allez utiliser le plugin maven-site-plugin.
//          Vous ajoutez le plugin dans la section  <pluginManagement>  du POM parent :
//                  <project>
//                      ...
//                      <build>
//                          <pluginManagement>
//                              <plugins>
//                                  <plugin>
//                                      <groupId>org.apache.maven.plugins</groupId>
//                                      <artifactId>maven-site-plugin</artifactId>
//                                      <version>3.6</version>
//                                      <configuration>
//                                          <!-- Je veux le site en français -->
//                                          <locales>fr</locales>
//                                      </configuration>
//                                  </plugin>
//                              </plugins>
//                          </pluginManagement>
//                      </build>
//                      ...
//                  </project>
//      - Génération du site :
//          Pour générer le site, nous allons utiliser le build lifecycle site.
//          Étant donné qu'il s'agit d'un projet multi-module, la génération du site est un peu plus complexe que pour un projet simple. En effet, il va falloir que Maven :
//              - Génère un site pour le projet parent et pour chaque module (cela correspond au goal site du plugin maven-site-plugin).
//              - Agrège tous ces sites en un seul.
//          Cette dernière étape est réalisée automatiquement dans la phase site-deploy, via le goal deploy.
//          Cependant vous ne voulez peut-être pas déployer le site, soit pour vous rendre compte avant du résultat, soit pour obtenir le site agrégé et le tester avant de le déployer.
//              --> Cela est possible grâce au goal stage. Par défaut, ce goal génère le site agrégé dans le répertoire target/staging.
//          Afin d'exécuter un goal d'un plugin précis, il suffit d'utiliser la syntaxe suivante :
//              --> mvn <plugin>:<goal>, Ce qui donne par exemple : mvn site:stage.
//          Pour la partie <plugin>, il faut donner le « préfixe » du nom du plugin. Les noms des plugins fournis par Maven ont cette forme : maven-${prefix}-plugin.
//              --> Donc pour le plugin maven-site-plugin le préfixe est site.
//          Allons-y, générons le site agrégé :
//              - cd /chemin/vers/projet/parent.
//              - mvn package site site:stage. Vous remarquez que j'enchaîne ici 3 exécutions :
//                  --> La phase package.
//                  --> La phase site.
//                  --> Le goal site:stage.
//          Vous devez faire précéder la génération du site de la phase package.
//              --> Sans quoi Maven ne va pas trouver les modules du projet lors de la génération du site car ils ne sont pas dans votre repository local !
//          Il ne vous reste plus qu'à ouvrir le fichier target/staging/index.html.
// -----------
//  - Ajouter des pages personnalisées :
// Maintenant que vous savez générer le site, ajoutons-y vos propres pages.
// C'est ici que vous allez utiliser les dossiers apt, fml, markdown...
//      --> Je vous propose d'ajouter 2 pages dans le site :
//              - Une page de documentation expliquant comment est organisé le projet.
//              - Une foire aux questions.
// -----------
//  - Ajout d'une page :
// Pour la page de documentation, je vais utiliser le format Markdown.
//      --> Je crée donc le répertoire src/site/markdown, et j'y crée un fichier architecture.md :
//                  ## Architecture du projet
//                  ### Généralités
//                  Lorem ipsum dolor sit amet, consectetur adipisicing elit,
//                  sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
//                  Une image :
//                  ![Dépendances entre les modules](img/dependances_modules.png)
//                  ### L'application web
//                  Lorem ipsum dolor sit amet, consectetur adipisicing elit,
//                  sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
//                  ### Les batches
//                  Lorem ipsum dolor sit amet, consectetur adipisicing elit,
//                  sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
// Dans ce fichier j'utilise une image : img/dependances_modules.png. Je la mets donc dans le répertoire resources/img.
// Enfin, j'ajoute une entrée de menu dans le site descriptor pour pouvoir accéder à cette page :
//                  <project>
//                      ...
//                      <body>
//                          ...
//                          <!-- ===== Menus ===== -->
//                          <!-- Ajout d'un menu vers la documentation -->
//                          <menu name="Documentation">
//                              <!-- Entrée de menu vers la page Architecture -->
//                              <item name="Architecture" href="architecture.html"/>
//                          </menu>
//                      </body>
//                  </project>
// Vous remarquez ici que le lien pointe vers architecture.html et non pas architecture.md.
//      --> En effet, Maven va convertir le fichier architecture.md en une page HTML architecture.html.
// Il ne reste plus qu'à relancer la génération du site pour obtenir les éléments que nous venons d'ajouter.
//      - mvn package site site:stage.
// -----------
//  - Ajout d'une FAQ :
// Pour ajouter une page de Foire aux questions, il suffit de suivre la même démarche que pour l'ajout d'une page.
//      --> Sauf que vous pouvez utiliser le format FAQ Markup Language, plus adapté à l'écriture d'une FAQ.
// Je crée le fichier src/site/fml/faq.fml :
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <faqs xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://maven.apache.org/FML/1.0.1"
//                        xsi:schemaLocation="http://maven.apache.org/FML/1.0.1 http://maven.apache.org/xsd/fml-1.0.1.xsd"
//                        title="Foire Aux Questions"
//                        toplink="false">
//                      <part id="general">
//                          <title>Général</title>
//                          <faq id="why-x">
//                              <question>
//                                  Pourquoi ... ?
//                              </question>
//                              <answer>
//                                  <p>
//                                      Lorem ipsum dolor sit amet, consectetur adipisicing elit. Aliquam aperiam architecto assumenda
//                                      consequuntur delectus deleniti dolores dolorum ex excepturi explicabo ipsa, labore magnam maxime,
//                                      modi
//                                      nemo sint, sit veniam voluptate.
//                                  </p>
//                                  <p>...</p>
//                              </answer>
//                          </faq>
//                          <faq id="how-x">
//                              <question>
//                                  Comment ... ?
//                              </question>
//                              <answer>
//                                  <p>...</p>
//                              </answer>
//                          </faq>
//                      </part>
//                      <part id="install">
//                         <title>Installation</title>
//                          <faq id="how-install">
//                              <question>
//                                  Comment installer ... ?
//                              </question>
//                              <answer>
//                                  <p>
//                                      Lorem ipsum dolor sit amet, consectetur adipisicing elit. Aliquam aperiam architecto assumenda
//                                      consequuntur delectus deleniti dolores dolorum ex excepturi explicabo ipsa, labore magnam maxime,
//                                      modi
//                                      nemo sint, sit veniam voluptate.
//                                  </p>
//                                  <source>apt-get install xxx</source>
//                             </answer>
//                          </faq>
//                      </part>
//                  </faqs>
//      --> J'ajoute une entrée de menu dans le site descriptor pour pouvoir accéder à cette FAQ :
//                  <project>
//                      ...
//                      <body>
//                          ...
//                          <!-- ===== Menus ===== -->
//                          <!-- Ajout d'un menu vers la documentation -->
//                          <menu name="Documentation">
//                              <!-- Entrée de menu vers la page Architecture -->
//                              <item name="Architecture" href="architecture.html"/>
//                              <!-- Entrée de menu vers la page FAQ -->
//                              <item name="FAQ" href="faq.html"/>
//                          </menu>
//                      </body>
//                  </project>
// -----------
//  - Générez des rapports :
//      --> https://maven.apache.org/plugins/maven-site-plugin/examples/configuring-reports.html
// -----------
//  - Rapports de base :
// Maven permet de générer, de base, un certain nombre de rapports sur votre projet :
//      - Projet :
//          - Résumé du projet (nom, version, description, organisation...).
//          - Liste des modules du projet.
//          - Membres du projet (contributeur, développeurs...).
//          - Licence du projet (section <licenses>).
//          - Gestion de la distribution du projet (section <distributionManagement>).
//          - Listes de diffusion (section <mailingLists>).
//          - Dépôt des sources du projet (section <scm>).
//          - Intégration continue (section <ciManagement>).
//          - Gestion des anomalies (section <issueManagement>).
//      - Plugins :
//          - Gestion des plugins (section <pluginManagement>).
//          - Liste des plugins utilisés dans le projet/module.
//      - Dépendances :
//          - Gestion des dépendances (section <dependencyManagement>).
//          - Liste des dépendances utilsées dans le projet/module.
//          - Convergence des dépendances entre les différents modules du projet.
// Pour ajouter ces rapports au site, il faut ajouter un menu dans le fichier site.xml :
//                  <project>
//                      ...
//                      <body>
//                          ...
//                          <!-- ===== Menus ===== -->
//                          <!-- Ajout d'un menu vers les différents rapport -->
//                          <menu ref="reports" inherit="top"/>
//                      </body>
//                  </project>
// Il faut également ajouter le plugin de génération des rapports dans le POM parent.
//      --> Attention, ce plugin est un plugin de rapport et non de contraction. Il doit donc être ajouté à la section <reporting> et non <build>.
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Gestion des rapports -->
//                      <!-- =============================================================== -->
//                      <reporting>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-project-info-reports-plugin</artifactId>
//                                  <version>2.7</version>
//                              </plugin>
//                          </plugins>
//                      </reporting>
//                  </project>
// -----------
//  - Sélectionner certains rapports seulement :
// Il existe d'autres plugins permettant de créer des rapports. Chaque rapport est fourni par un goal d'un de ces plugins.
// Par défaut, quand vous ajoutez un plugin de rapport, tous ses goals sont exécutés, donc tous les rapports sont générés.
// Si vous le souhaitez, vous pouvez ne lancer que certains goals en ajoutant une section <reportSets> :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Gestion des rapports -->
//                      <!-- =============================================================== -->
//                      <reporting>
//                          <plugins>
//                              <!-- ===== Rapport d'information général sur le projet ===== -->
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-project-info-reports-plugin</artifactId>
//                                  <version>2.7</version>
//                                  <reportSets>
//                                      <reportSet>
//                                          <reports>
//                                              <report>index</report>
//                                              <report>summary</report>
//                                              <report>plugins</report>
//                                          </reports>
//                                      </reportSet>
//                                  </reportSets>
//                              </plugin>
//                          </plugins>
//                      </reporting>
//                  </project>
// -----------
//  - Ajouter d'autres rapports :
// Pour générer des rapports supplémentaires, il suffit d'ajouter les plugins correspondants.
// Par exemple, pour générer un rapport sur les tests :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Gestion des rapports -->
//                      <!-- =============================================================== -->
//                      <reporting>
//                          <plugins>
//                              ...
//                              <!-- ===== Rapport sur les tests ===== -->
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-surefire-report-plugin</artifactId>
//                                  <version>2.20</version>
//                                  <configuration>
//                                      <linkXRef>false</linkXRef>
//                                  </configuration>
//                                  <reportSets>
//                                      <reportSet>
//                                          <reports>
//                                              <report>report-only</report>
//                                          </reports>
//                                      </reportSet>
//                                  </reportSets>
//                              </plugin>
//                          </plugins>
//                      </reporting>
//                  </project>
// Vous remarquez ici qu'aucun test n'a été exécuté. En effet, les rapports sont générés par projet/modules.
// Le projet parent ne contient aucun test, seuls ses modules en contiennent, je n'ai donc aucun test affiché ici.
// Que diriez-vous d'avoir ici un affichage global de tous les tests de tous les modules ?
// Pour le moment, il n'y a rien… Eh bien, c'est possible grâce à l'agrégation de rapports.
// -----------
//  - Agréger des rapports :
//      --> Certains plugins de rapport permettent d'agréger les rapports des modules au niveau du projet parent.
// J'ajoute pour cela un deuxième reportSet :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Gestion des rapports -->
//                      <!-- =============================================================== -->
//                      <reporting>
//                          <plugins>
//                              ...
//                              <!-- ===== Rapport sur les tests ===== -->
//                              <plugin>
//                                 <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-surefire-report-plugin</artifactId>
//                                  <version>2.20</version>
//                                  <configuration>
//                                      <linkXRef>false</linkXRef>
//                                  </configuration>
//                                      <!-- reportSet d'agrégation des rapports des sous-projets (modules) -->
//                                      <reportSet>
//                                          <id>aggregate</id>
//                                          <reports>
//                                              <report>report</report>
//                                          </reports>
//                                          <!-- ne pas exécuter ce sous-rapport dans les sous-projets -->
//                                          <inherited>false</inherited>
//                                          <configuration>
//                                              <aggregate>true</aggregate>
//                                          </configuration>
//                                      </reportSet>
//                                      <!-- reportSet non agrégé, exécuté dans tous les sous-projets (modules) -->
//                                      <reportSet>
//                                          <id>modules</id>
//                                          <!-- exécuter ce sous-rapport dans les sous-projets -->
//                                          <inherited>true</inherited>
//                                          <reports>
//                                              <report>report</report>
//                                          </reports>
//                                          <configuration>
//                                              <aggregate>false</aggregate>
//                                          </configuration>
//                                      </reportSet>
//                              </plugin>
//                          </plugins>
//                      </reporting>
//                  </project>
// J'obtiens ainsi :
//      --> Le rapport agrégé dans le projet parent.
//      --> Le rapport « normal » dans chaque module.
// Notez l'utilisation de la base <inherited> :
//      --> false pour le reportSet d'agrégation.
//      --> true pour le reportSet de base.
// Notez également que l'ordre de déclaration des reportSet est important.
//      --> Pour le plugin surefire-report, le reportSet d'agrégation doit être déclaré avant l'autre, sinon l'agrégation ne fonctionnera pas.
// Pour la génération de la Javadoc, la configuration serait celle-ci :
//                  <project>
//                      ...
//                      <!-- =============================================================== -->
//                      <!-- Gestion des rapports -->
//                      <!-- =============================================================== -->
//                      <reporting>
//                          <plugins>
//                              ...
//                              <!-- ===== Génération de la Javadoc ===== -->
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-javadoc-plugin</artifactId>
//                                  <version>2.9</version>
//                                  <configuration>
//                                      <quiet>true</quiet>
//                                      <locale>fr</locale>
//                                  </configuration>
//                                  <reportSets>
//                                      <!-- reportSet exécuté dans tous les modules -->
//                                      <reportSet>
//                                         <reports>
//                                              <report>javadoc</report>
//                                          </reports>
//                                      </reportSet>
//                                      <!-- reportSet d'agrégation des rapports des sous-modules -->
//                                      <reportSet>
//                                          <id>aggregate</id>
//                                          <inherited>false</inherited>
//                                          <reports>
//                                              <report>aggregate</report>
//                                          </reports>
//                                      </reportSet>
//                                  </reportSets>
//                              </plugin>
//                          </plugins>
//                      </reporting>
//                  </project>
// Je vous ai gardé le meilleur pour la fin : un rapport sur la qualité du code avec Checkstyle :
//                  <project>
//                      ...
//                      <reporting>
//                          <plugins>
//                              ...
//                              <!-- ===== Rapport d'analyse du code par Checkstyle ===== -->
//                              <plugin>
//                                  <groupId>org.apache.maven.plugins</groupId>
//                                  <artifactId>maven-checkstyle-plugin</artifactId>
//                                  <version>2.17</version>
//                                  <configuration>
//                                      <configLocation>src/build/checkstyle.xml</configLocation>
//                                      <linkXRef>false</linkXRef>
//                                  </configuration>
//                                  <reportSets>
//                                      <!-- reportSet exécuté dans tous les modules -->
//                                      <reportSet>
//                                          <reports>
//                                              <report>checkstyle</report>
//                                          </reports>
//                                      </reportSet>
//                                      <!-- reportSet d'agrégation des rapports des sous-modules -->
//                                      <reportSet>
//                                          <id>checkstyle-aggregate</id>
//                                          <inherited>false</inherited>
//                                          <configuration>
//                                              <skipExec>true</skipExec>
//                                          </configuration>
//                                          <reports>
//                                              <report>checkstyle-aggregate</report>
//                                          </reports>
//                                      </reportSet>
//                                  </reportSets>
//                              </plugin>
//                          </plugins>
//                      </reporting>
//                  </project>
// -----------
//  - Résumons :
//      --> Maven permet de générer un site pour le projet. Utilisez pour cela la commande mvn package site site:stage.
//      --> Par convention, les sources servant à la génération du site du projet se trouvent dans le répertoire src/site.
//      --> La description du site se fait grâce au site descriptor : fichier src/site/site.xml.
//      --> Vous pouvez ajouter des ressources dans le répertoire src/site/resources.
//      --> Vous pouvez ajouter vos propres pages en utilisant des fichiers aux formats APT, FML, Markdown...
//      --> Vous pouvez générer des rapports en ajoutant des plugins de rapport dans la section <reporting>.
//      --> Vous pouvez configurer et agréger des rapports grâce aux sections <reportSet>.
// N'hésitez pas à consulter la documentation pour approfondir ce sujet et découvrir la multitude de choses réalisables :
//      --> https://maven.apache.org/guides/mini/guide-site.html.
//      --> https://maven.apache.org/plugins/maven-site-plugin/.
// -----------
//  - Le mot de la fin :
// Voilà, nous arrivons au bout de ce cours sur Apache Maven.
// Vous en avez fini avec le temps perdu sur toutes les opérations manuelles comme la compilation, le packaging ou l'ajout de bibliothèques tierces...
//      --> Grâce à Maven, vous pouvez désormais gérer facilement les dépendances de votre projet.
//      --> Vous êtes capable d'automatiser sa construction mais également la génération de vos différents livrables et même un site web sur votre projet.
// -----------
//  - Ressources :
// Vous pouvez retrouver les ressources utilisées dans ce cours, comme le projet de gestion de tickets, sur github :
//      --> https://github.com/oc-courses/organisez-et-packagez-une-application-java-avec-apache-maven.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Entraînez-vous à créer un projet Maven complet ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// À vous de jouer :
// Vous devez créer un nouveau projet Maven. Vous êtes libre de choisir le nom de votre projet et son sujet, mais vous devez respecter les consignes suivantes :
//      - Votre projet doit être un projet multi-modules.
//      - Vous organiserez votre projet en vous appuyant sur une architecture multi-tiers telle que présentée dans le cours.
//      - Votre projet fourniera une application web et un jeu de batchs.
// Vous n'avez pas à développer l'application, seulement créer le projet Maven et quelques éléments pour pourvoir tester le résultat :
//      - Une classe Main dans le module des batchs exécutée automatiquement au lancement du JAR.
//      - Une JSP et un fichier web.xml dans le module de l'application web.
//      - Au moins une classe de test unitaire (même avec un seul test passant toujours) dans chaque module.
// Pensez également à bien gérer les dépendances entre les modules et suivre les recommendations et bonnes pratiques vues tout au long du cours (gestion des dépendances, des plugins...).
// Vous devez personnaliser le construction du votre projet Maven comme ceci :
//      --> Un JAR des sources de chaque module est généré automatiquement pendant la phase "package" si le profile "with-sources" est activé.
//      --> Un JAR de la JavaDoc de chaque module est généré automatiquement pendant la phase "package".
//      --> Une archive (zip et/ou tar.gz) est généré automatiquement pendant la phase "package" du module des batchs, comprenant :
//              - Le JAR du module des batchs.
//              - Les JAR de toutes les dépendances (scope compile et runtime).
//              - Les modules batchs et application web contiennent un fichier info.properties contenant une propriété application.version remplie automatiquement par Maven avec la version de projet lors du build..
// Possibilité de générer un site web pour le projet avec au minimum :
//      - Une page de documentation de l'installation (le contenu n'est pas important, cela peut être un simple "Lorem ipsum...").
//      - Un rapport sur les dépendances du projet.
//      - Un rapport sur l'exécution des tests agrégé au niveau projet parent et détaillé dans chaque modules
// -----------
//  - Vérifiez votre travail :
// Alors, vous êtes allé au bout ? Suivez le guide pour vérifier votre travail !
// Vérifiez que vous avez bien les éléments suivants :
//      --> Les fichiers POM (pom.xml) sont correctement indentés et suffisamment lisibles (saut de lignes, commentaires...).
//      --> Le projet Xxx est bien un projet Maven multi-modules comprennant les modules :
//              - xxx-batch.
//              - xxx-business (ou xxx-metier).
//              - xxx-consumer (ou xxx-persistance).
//              - xxx-model (ou xxx-modele).
//              - xxx-webapp (ou xxx-application-web).
//              - xxx étant l'artifactId du projet parent.
//      --> Chaque module a comme package de base :
//              - xxx-batch : zzz.yyy.xxx.batch.
//              - xxx-business : zzz.yyy.xxx.business.
//              - xxx-consumer : zzz.yyy.xxx.consumer.
//              - xxx-model  : zzz.yyy.xxx.model.
//              - xxx-webapp : zzz.yyy.xxx.webapp.
//              - xxx étant l'artifactId du projet parent.
//              - zzz.yyy étant le groupId du projet parent.
//      --> Le POM parent contient la définition suivante :
//                  <project>
//                    ...
//                    <build>
//                      <plugins>
//                        <plugin>
//                          <groupId>org.apache.maven.plugins</groupId>
//                          <artifactId>maven-javadoc-plugin</artifactId>
//                          <configuration>
//                            ...
//                          </configuration>
//                          <executions>
//                            <execution>
//                              <id>javadoc-jar</id>
//                                <phase>package</phase>
//                                <goals>
//                                  <goal>jar</goal>
//                                </goals>
//                            </execution>
//                          </executions>
//                        </plugin>
//                      </plugins>
//                      ...
//                    </build>
//                    ...
//                  </project>
//      --> Le POM parent contient la définition suivante :
//                  <project>
//                    ...
//                    <profiles>
//                      <profile>
//                        <id>with-sources</id>
//                        <build>
//                          <plugins>
//                            <plugin>
//                             <groupId>org.apache.maven.plugins</groupId>
//                              <artifactId>maven-source-plugin</artifactId>
//                              <configuration>
//                                ...
//                              </configuration>
//                              <executions>
//                                <execution>
//                                  <id>source-jar</id>
//                                    <phase>package</phase>
//                                    <goals>
//                                      <goal>jar</goal>
//                                    </goals>
//                                </execution>
//                              </executions>
//                            </plugin>
//                          </plugins>
//                          ...
//                        </build>
//                      </profile>
//                    </profiles>
//                    ...
//                  </project>
//          La section <executions> n'est pas obligatoire car par défaut, le goal source-jar est câblé sur la phase package.
//      --> La section <dependencies> de chaque module comprend bien les dépendances vers les autres modules telles que :
//              - batch --> {model, business}.
//              - business --> {model, consumer}.
//              - consumer --> {model}.
//              - model --> {}.
//              - webapp --> {model, business}.
//      --> Les dépendances vers les bibliothèques tierces mais aussi les modules.
//      --> Tous les plugins utilisés dans les sections build du projet sont listés dans la section <dependancyManagement> du POM parent, avec au minimum le groupId, l'artifactId et la version.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Testez votre code Java pour réaliser des applications de qualité //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous voulez savoir si vous développez des logiciels en Java de qualité
// Vous voulez être sûr de produire des livrables conformes aux attentes et aux besoins de vos clients ?
// Vous souhaitez minimiser les bugs qui rendent fous les utilisateurs comme les développeurs ?
//      --> Le test est LA réponse que vous recherchez. Au-delà de la simple vérification de votre travail, le test pilote la conception de votre produit.
// Dans ce cours, vous découvrirez les tests automatisés. Vous coderez vous-même les tests de votre application en utilisant le framework JUnit 5.
// Vous comprendrez quels types de tests choisir grâce à la pyramide de tests. Vous apprendrez aussi à maîtriser le développement piloté par les tests ou TDD.
// Vous serez ainsi capable de sortir votre produit avec confiance !
// Alors, prêt à construire des applications de qualité ? Allons-y !
// Objectifs pédagogiques :
//      - Ecrire des tests unitaires.
//      - Affiner des tests unitaires.
//      - Ecrire des tests d'intégration et de bout en bout.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Écrivez des tests unitaires ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Choisissez les bons tests automatisés avec la pyramide de tests ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tout le monde peut faire des erreurs, surtout lorsque l'on est contraint par les échéances de livraison.
// Prendre le temps de vérifier ce que l'on a produit, en particulier en développement, permet de garantir la livraison d'un produit de qualité.
// Et cela peut aussi nous éviter quelques moments gênants devant le client lors d'une démonstration !
// À ce sujet, un des exemples les plus frappants est sans aucun doute le vol inaugural du lanceur européen Ariane 5.
//      --> 10 ans de recherches et de développement se soldant par un échec cuisant au décollage...
// Le tout à cause d'un système de guidage hérité d'Ariane 4, et non testé dans des simulations adaptées aux scénarios d'Ariane 5.
// Ces simulations auraient pu éviter la perte de plusieurs centaines de millions de dollars.
// Je comprends ce que tester veut dire de manière générale, mais qu'est-ce que cela signifie quand on travaille avec du code ?
// -----------
//  - En quoi consistent les tests ?
// En développement, les tests visent à vérifier que le produit codé fonctionne comme prévu selon des scénarios prédéfinis et représentatifs.
//      --> Cela permet de garantir la qualité de ce qui est codé, malgré les contraintes du projet, comme les délais, par exemple.
// La manière la plus directe de faire des tests, c'est d'effectuer des tests manuels par des humains.
// En informatique, de nombreuses équipes ont employé des testeurs, qui prennent la responsabilité de la qualité d'une application.
// Ils vérifient les logiciels durant une phase de projet nommée recette, ou même après, lorsque le logiciel est en activité, en production.
// Quand vous codez de plus en plus de fonctionnalités, tester manuellement l'exécution d'un produit et de toutes ses fonctionnalités est une activité répétitive et peu créative.
// De plus, coder une fonctionnalité peut avoir un impact à un autre endroit du logiciel. Donc, si l'on est rigoureux, il faudrait retester tout le produit à chaque développement !
//      --> L'alternative est de développer des programmes spécifiques qui vérifient le code de nombreuses façons différentes.
// C'est ce que l'on appelle des tests automatisés. Comme il s'agit de code, l'exécution de ces tests est rapide et peut être répétée à de multiples reprises pour un coût très faible.
// Vous avez le choix entre de nombreux types de tests automatisés, chacun avec ses avantages et ses inconvénients.
// -----------
//  - Découvrez les différents types de tests automatisés :
//      --> Les 3 types de tests automatisés les plus courants sont :
//              - Les tests unitaires.
//              - Les tests d'intégration.
//              - Les tests fonctionnels.
// Mike Cohn, l'un des fondateurs du mouvement Agile, présente ces types de tests sous forme de pyramide des tests, en particulier dans le livre Succeeding with Agile (en anglais).
// En utilisant cette métaphore, l'auteur préconise la répartition de ces types de tests dans un projet de développement agile selon la pyramide ci-dessous.
//      Fonctionnel.         Plus lent, doit être intégré, plus réaliste.
//      Intégration.
//      Unitaire.            Plus rapide, plus isolé, moins réaliste.
// Cette illustration indique qu'il y a davantage de tests rapides et autonomes à la base de la pyramide, puis de moins en moins à mesure que l'on grimpe vers le sommet.
//      --> Plus on approche du sommet, plus les tests sont longs et complexes à exécuter, tout en simulant des scénarios de plus en plus réalistes.
// -----------
//  - Tests unitaires :
// La plus grosse section, à la base de la pyramide, est constituée des tests unitaires qui testent de "petites" unités de code.
// Plus précisément, ils testent que chaque fonctionnalité extraite de manière isolée se comporte comme attendu.
// Ils sont très rapides et faciles à exécuter. Si vous avez cassé quelque chose, vous pouvez le découvrir vite et tôt.
// De bons tests unitaires sont stables, c'est-à-dire que le code de ces tests n'a pas besoin d'être modifié, même si le code de l'application change pour des raisons purement techniques.
//      --> Ils deviennent donc rentables, car ils ont été écrits une seule fois, mais exécutés de nombreuses fois.
// Cependant, seules des unités individuelles de code sont testées, vous avez donc besoin d'autres tests permettant de s'assurer que ces unités de code fonctionnent entre elles.
// -----------
//  - Tests d'intégration :
// Au milieu de la pyramide se trouvent les tests d'intégration.
//      --> Ils vérifient si vos unités de code fonctionnent ensemble comme prévu – en présupposant que vos tests unitaires soient passés !
// Comme les tests d'intégration vérifient les interactions entre les unités, vous avez plus de certitude concernant le bon fonctionnement de l'application finale.
// Ils peuvent nécessiter l'exécution de composants extérieurs (base de données, services web externe, etc.).
// Le lancement de ces composants et l'interaction entre vos unités de code développées rendent ces types de test plus lents et potentiellement moins stables.
// Mais vous simulez des scénarios plus proches de l'utilisation finale de l'application.
// -----------
//  - Tests fonctionnels :
// Enfin, au sommet de la pyramide, les tests fonctionnels (appelés end-to-end en anglais), visent à simuler le comportement d'un utilisateur final sur l'application, depuis l'interface utilisateur.
// L'ensemble du code développé est pris comme une boîte noire à tester, sans connaissance des briques et des unités de code qui la composent.
//      --> Les simulations obtenues sont donc les plus proches de l'application utilisée dans des conditions réelles.
// Ces tests nécessitent toute l'infrastructure nécessaire à l'application. Ces types de tests sont les plus lents à exécuter, et testent une partie beaucoup plus grande de votre code développé.
// Cela crée une plus forte dépendance qui rend vos tests moins stables, donc moins rentables.
// Potentiellement, une modification simple de l'interface utilisateur (la couleur d'un bouton) pourrait nécessiter de recoder le test fonctionnel associé.
// Pourquoi cette répartition des tests est-elle préconisée ?
//      --> La simulation au plus près de la réalité n'est-elle pas plus importante que la rapidité et la rentabilité ?
// Oui, bien sûr, la simulation de scénarios "réalistes" est très importante. Mais écrire et exécuter des tests est un investissement qui a un coût.
// L'automatisation des tests n'a de réelle valeur ajoutée que si l'on arrive à exécuter ces tests sans les modifier de nombreuses fois.
//      --> La pratique montre qu'il est plus facile de rentabiliser un test unitaire qu'un test fonctionnel.
// De plus, plus un bug est détecté tôt, moins son coût de correction est élevé.
// Or, pour qu'une nouvelle unité de code développée puisse être couverte par un test fonctionnel, il faut développer le code de l'interface utilisateur associée.
// Il faut donc que le code d'accès aux données nécessaires. Si l'unité de code présente des bugs, sa détection sera alors beaucoup plus tardive, et son coût beaucoup plus élevé.
// Enfin, les bonnes pratiques visant à coder beaucoup de tests unitaires poussent le développeur à coder des unités de code plus robustes et autonomes.
// Ces pratiques favorisent aussi une détection très tôt des bugs, ces derniers ont donc moins d'impact en termes de coût sur le projet.
// -----------
//  - Les mauvaises pratiques dans la réalité des projets :
// Malheureusement, ces préconisations agiles, datant de plus de dix ans, ne sont pas toujours suivies.
// En effet, de nombreuses équipes de développement, soumises à des contraintes fortes de délais et de coûts, ont développé de mauvaises pratiques de tests.
// La plus connue est sûrement la mauvaise pratique (ou anti-pattern en anglais) du cône de glace de tests, illustré ci-dessous.
// Elle vient souvent du fait qu'un projet ait été développé sans tests unitaires au début.
// Puis, pour rattraper la situation, les développeurs codent des tests fonctionnels et d'intégration, qui couvrent le plus de code possible en peu de temps de développement.
// Regardez bien, le cône de glace de tests, c'est la pyramide de tests inversée !
// Avec une telle répartition, le produit développé est beaucoup moins maintenable (il est plus difficile à faire évoluer dans le temps par les développeurs).
// Ainsi, les tests deviennent obsolètes très vite et on retourne à des pratiques de tests manuelles coûteuses et peu efficaces (la crème glacée sur le schéma).
// -----------
//  - Découvrez d'autres finalités pour les tests :
// Dans votre produit numérique, savoir que des tests existent et en parsemer quelques-uns dans votre code ne suffit pas à avoir confiance en son code.
// Revenons à l'exemple de la fusée Ariane. Ils avaient exécuté des tests pendant des années ! Mais personne n'avait pensé à tester ce problème particulier.
// -----------
//  - Testez pour faire face à l'inattendu :
// Lorsque vous codez une fonctionnalité pour implémenter une user story ou résoudre un problème, il est facile d'imaginer un bon scénario :
//      --> Celui où le logiciel est utilisé exactement de la façon attendue, sans aucune difficulté.
// Par exemple, un utilisateur pourrait cliquer dans votre application dans le bon ordre, ne rencontrer aucun problème et tout se terminerait par le résultat attendu.
// Une user story est une description synthétique d'un besoin fonctionnel précis.
// Souvent, on peut l'exprimer sous forme de phrase contenant le type d'utilisateur concerné, l'action à faire, et l'objectif de cette action.
// Par exemple : En tant que libraire, je veux rechercher la disponibilité d'un livre en stock, afin de répondre rapidement à la demande d'un client.
// Cependant, la réalité correspond rarement à nos attentes.
//      --> Il y aura toujours des scénarios alternatifs, des comportements utilisateurs inattendus, des problèmes réseau, un service web externe non disponible.
// Il y aura souvent plus de mauvais chemins que ce que vous pouvez envisager.
//      --> Mais comment m'assurer que mon produit fonctionnera, si je ne peux pas penser à tous les scénarios possibles ?
// Voici plusieurs pistes de solution :
//      - Le risque zéro n'existe pas. Réduisez le risque en combinant les scénarios attendus, les cas limites courants, et les risques de non-disponibilité des services extérieurs dont vous dépendez.
//      - Plus vos tests seront unitaires, moins il y aura de combinaisons de scénarios alternatifs. Ceci doit vous conforter dans le respect de la pyramide des tests vue précédemment.
//      - Collaborez avec les membres de votre équipe, les responsables de la valeur de votre produit numérique (product owner), les autres développeurs et les testeurs.
// -----------
//  - Testez pour faciliter la maintenance :
// Plus vous codez de tests et plus vous vous assurez qu'ils restent à jour, plus la confiance en votre produit va grandir.
// Ces tests vont grandement faciliter la correction et la maintenance du code. En particulier, si un bug bloquant a lieu après la mise en production de votre produit.
// Disposer de tests existants permet de vérifier très rapidement si les corrections apportées cassent quelque chose dans le code existant.
//      --> Ils testent la non-régression de votre produit.
// La mise en production de la correction s'effectue en confiance et cette réactivité  donne aussi confiance au client.
// La régression, c'est lorsqu'une fonctionnalité existante se déroulait correctement et ne fonctionne plus suite à une correction ou à une mise à jour.
// Gardez en tête que, du point de vue du client, la régression d'un produit numérique peut impacter très négativement sa confiance.
// Donc n'hésitez pas à dépenser votre énergie à assurer cette non-régression. Les tests automatisés sont là pour vous aider.
// -----------
//  - Testez pour communiquer :
// Oui, les tests peuvent vous aider à communiquer !
// Quand vous êtes en plein développement, vous avez une compréhension profonde du code, de ce qu'il est censé accomplir, et de comment vous le vérifierez.
// Un peu comme dans la lecture d'un livre – vous connaissez le contexte et l'importance de chaque interaction dans l'histoire.
// Mais si vous preniez une page au hasard et que vous la donniez à quelqu'un d'autre, il n'aurait aucune idée de ce qu'il se passe.
//      --> C'est la même chose avec le code. Imaginez que vous changiez subitement de projet, et qu'un autre développeur doive finir votre code. Comment saurait-il par où commencer ?
// Les cas de tests sont là pour ça : ils décriront le comportement attendu du logiciel.
// La lecture de vos tests doit permettre de comprendre non seulement ce que votre code est censé faire, mais aussi comment il fonctionne et à quel point il est opérationnel.
// Si vous écrivez des tests, un autre développeur sera capable de comprendre ce que vous essayiez d'accomplir, et aura toute confiance pour modifier des éléments du code que vous aviez écrit.
//      --> Le test va au-delà d'une simple manière de corriger le code, c'est un véritable état d'esprit agile.
// Dans le chapitre suivant, vous allez apprendre comment intégrer cet état d'esprit dans votre façon de coder.
// -----------
//  - En résumé :
//      --> L'automatisation des tests réduit le besoin de vérifications manuelles et, elle peut vous donner la confiance nécessaire pour automatiser complètement la sortie de votre produit numérique.
//      --> La pyramide de tests vous donne un modèle pour vous aider à écrire des tests qui vous donnent confiance en votre code, à mesure que vous y apportez des changements.
//      --> Les tests unitaires vérifient les classes, ou autres unités de code, rapidement et de façon exhaustive, pour s'assurer qu'elles tiennent leurs promesses.
//      --> Les tests d'intégration vérifient que les classes et les parties de votre application qui doivent fonctionner ensemble le font en collaborant comme prévu.
//      --> Les tests fonctionnels vérifient du point de vue de l'utilisateur final qu'on sera capable de résoudre ses problèmes en utilisant votre application lorsqu'elle est active.
//              Pour une application web, cela passe souvent par une simulation d'interactions sur le navigateur.
//      --> Au-delà de la vérification, les tests permettent, entre autres, de mieux faire face à l'inattendu, d'améliorer la réactivité de la maintenance, et de mieux communiquer entre développeurs.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Écrivez votre premier test JUnit avec le TDD //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Comprenez la démarche du développement piloté par les tests :
// Après ce premier chapitre théorique, vous en savez un peu plus sur les tests unitaires.
//      --> Passons dès à présent à la pratique et écrivons notre premier test !
// Mais comment procéder ?
// Pour vous concentrer sur l'essentiel, la démarche est la suivante :
//      --> Savoir ce qu'on teste.
//      --> Installer le framework de tests.
//      --> Coder son test !
// Un framework de test est un outillage composé à la fois d'une bibliothèque Java et des fonctionnalités intégrées à l'IDE, permettant de créer et d'exécuter des tests automatisés.
// Commençons par décortiquer les deux premières étapes.
// -----------
//  - Identifiez le système à tester :
// Avant de commencer, posez-vous 5 minutes et identifiez ce que vous allez tester. Il s'agit de votre application.
// Plus précisément, on s'intéresse d'abord au test unitaire. Donc nous devons identifier la fonctionnalité à tester, qui sera implémentée en Java sous la forme d'une ou plusieurs classes.
// C'est le système à tester ou SUT (system under test) en anglais.
// Le système à tester donne des résultats (ou plus généralement des sortants) à partir de données ou de paramètres de test (ou plus généralement des entrants).
//      --> Puis, en vérifiant les résultats, le test est déclaré en succès ou en échec.
// De manière plus formelle, il existe une manière standard de structurer un test. C'est la méthode AAA, ou Arrange - Act - Assert :
//      - Arrange (organiser) : initialisez tous les entrants nécessaires et le système à tester si besoin.
//      - Act (agir) : exécutez le système à tester avec les entrants précédemment initialisés dans des sortants que vous conservez.
//      - Assert (vérifier) : validez les sortants en fonction de ce qui est attendu par rapport à vos entrants. Vous en concluez alors si c'est en succès ou en échec.
// Le figure ci-dessous illustre toute la cinématique globale du test.
// Ici, vous voyez que l'on se focalise sur le système à tester et qu'on ne perd pas de temps sur la manière dont les tests vont être exécutés par vos outils.
// En effet, c'est le rôle du framework de tests, que vous allez installer, et qui s'occupera de tout cet aspect automatiquement ensuite. Dans ce cours, nous allons utiliser JUnit.
// Je vais vous montrer comment écrire des tests JUnit en développant un calculateur très basique. Nous allons créer une classe capable d’additionner deux nombres.
// Mais notre première étape sera d’écrire nos tests JUnit ! Surprenant ?
//      --> C'est tout l'esprit de la démarche TDD (Test-driven development), qui est le fil rouge pour ce cours. Mais qu'est-ce que le TDD ?
// -----------
//  - Utilisez le TDD : rouge-vert-refactor !
// Le TDD, pour test-driven development en anglais, ou développement piloté par les tests, consiste à ce que le code de votre application suive un plan fixé par les tests.
// En réalité, on a plutôt tendance à faire l'inverse, coder l'application, puis la tester de manière manuelle ou automatique.
// Mais en codant d'abord le test, vous vous demandez directement quel objectif doit accomplir le code de votre application.
//      --> Vous allez coder ce qui est nécessaire, pas plus, et ce code répondra au besoin exprimé clairement par le test.
// Kent Beck, l'inventeur du TDD, a fait découvrir à de nombreux développeurs le modèle suivant, appelé red-green-refactor.
//      --> Dans ce modèle, vous répétez cycliquement les étapes suivantes :
//              - Écrivez un test unitaire qui échoue.
//              - Écrivez le code qui permet de réussir le test.
//              - Nettoyez le code tout en gardant les tests en succès.
//              - Écrivez le prochain test et recommencez !
// Les tests qui échouent sont décrits comme rouges. Comme dans les feux de circulation, le rouge vous dit de vous arrêter et de faire fonctionner votre code.
// Quand le test est réussi, on passe au vert. Le vert vous dit de faire du refactoring.
//      --> Cela signifie simplement que vous essayez de rendre votre code plus lisible et/ou plus élégant sans changer son comportement.
// Étant donné que le test est déjà en place, il vous dira immédiatement si vous cassez le moindre comportement, garantissant que vous êtes toujours concentré sur la fonctionnalité à tester en priorité.
// La méthode du TDD présente un autre avantage. En effet, si vous écrivez votre code après votre test, ce code est plus facile à tester.
// Eh oui, ce code a été fait pour être testé et est généralement plus clair !
// En effet, de la même façon que vous écrivez un test dédié à chaque classe/fonction, le TDD vous encourage à développer des produits à partir de nombreuses petites classes.
// Chacune de ces petites classes, faisant une chose et la faisant bien. Cela ajoute à la clarté du code. Il est plus facile de suivre un élément que cinquante !
// À mesure que vous codez les tests, vous engrangez également des connaissances sur le code que vous devez développer pour réussir ces tests.
// Cela vous oriente vers une conception plus modulaire, c’est-à-dire que votre code n’est pas concentré dans seulement quelques classes.
// Le code modulaire est flexible et plus facile à modifier. Le TDD vous facilite la tâche.
// -----------
//  - Codez votre premier test unitaire JUnit :
// Entrons dans le vif du sujet ! Avant de pouvoir tester, il nous faut un projet Java. Créons-en un !
// Si vous ne l’avez pas déjà fait, il vous faut une JDK, l'outil de build Maven, et un IDE, pour vous faciliter le travail.
// Dans les exemples et les screencasts qui suivent, je vais utiliser la JDK 11 et Eclipse (qui contient Maven et Git) :
//      - J'ai installé AdoptOpenJDK 11 (VM HotSpot).
//      - J'ai choisi la version Entreprise Java Developer, gratuite.
//      - J'ai activé le thème Darkest Dark Theme de DevStyle sur le Marketplace Eclipse.
//      - Si j'ai besoin de lignes de commandes hors d'Eclipse, j'utilise Cmder sous Windows. Il a un client Git fourni, c'est pratique !
// Vous pouvez très bien utiliser un autre IDE comme le très populaire IntelliJ ou NetBeans, selon vos préférences personnelles.
// Les quatre parties ci-dessous reprennent les étapes principales du screencast pour créer un projet Maven, importer JUnit, créer puis exécuter votre premier test unitaire.
// Créez votre projet Maven et importez 'junit-jupiter' ainsi que 'maven-surefire-plugin'.
// Dans Eclipse, créez votre projet Maven, puis créer une première classe de test : clic droit sur 'src/test/java' > New > Junit Test Case (others) > package 'com.openclassroom.testing'.
// Pour lancer tous les test du projet Maven, on peux :
//      --> Clic droit sur le projet > Run as > Maven Test.
//      --> Dans une console, exécuter 'mvn test', qui va lancer tous les tests du projet Maven du répertoire dans lequel nous nous trouvons.
// -----------
//  - Organisez et packagez une application Java avec Apache Maven :
// Si vous utilisez Eclipse, pensez à :
//      --> Vous placer en perspective Java.
//      --> Cocher la case Create a simple project, au moment de la création de votre projet, comme indiqué dans le screencast.
//      --> Maven a besoin d'identifier votre projet.
//              Pour cela, il faut définir un groupId selon le même format que les paquetages : une sorte d'URL inversé, et un artifactId sous la forme d'un identifiant.
//              Choisissez comme groupId : com.openclassrooms.testing et artifactId : premiertest.
// Après avoir créé le projet Maven, ouvrez le fichier pom.xml, il devrait ressembler à ça :
//                  <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
//                      <modelVersion>4.0.0</modelVersion>
//                      <groupId>com.openclassrooms.testing</groupId>
//                      <artifactId>premiertest</artifactId>
//                      <version>0.0.1-SNAPSHOT</version>
//                  </project>
// Nous allons indiquer à Maven que nous construisons un projet en Java 11 et utilisons le framework JUnit 5 pour les tests. Il faut pour cela :
//      - Indiquer certaines valeurs dans les balises properties.
//      - Se rendre sur le site Mvn Repository pour trouver la bonne dépendance JUnit.
//      - Déclarer une version récente d'un plugin de Maven, pour que ce dernier détecte bien les tests JUnit 5.
// N'hésitez pas à revoir le screencast pour bien maîtriser ces trois étapes. Néanmoins, nous n'allons pas rentrer dans les détails de la configuration ici. Ce n'est pas important pour notre cours.
// Voici à quoi doit ressembler votre fichier pom.xml, après avoir ajouté toutes les bonnes valeurs :
//                  <project xmlns="http://maven.apache.org/POM/4.0.0"
//                      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                      xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
//                      <modelVersion>4.0.0</modelVersion>
//                      <groupId>com.openclassrooms.testing</groupId>
//                      <artifactId>premiertest</artifactId>
//                      <version>0.0.1-SNAPSHOT</version>
//                      <!-- Indiquer l'encodage et le projet en Java 11 -->
//                      <properties>
//                          <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
//                          <maven.compiler.source>11</maven.compiler.source>
//                          <maven.compiler.target>${maven.compiler.source}</maven.compiler.target>
//                      </properties>
//                      <!-- Déclaration de la dépendance vers JUnit -->
//                      <dependencies>
//                          <dependency>
//                              <groupId>org.junit.jupiter</groupId>
//                              <artifactId>junit-jupiter</artifactId>
//                              <version>5.5.1</version>
//                              <scope>test</scope>
//                          </dependency>
//                      </dependencies>
//                      <!-- Pour être compatible avec JUnit 5 -->
//                      <build>
//                          <plugins>
//                              <plugin>
//                                 <artifactId>maven-surefire-plugin</artifactId>
//                                  <version>2.22.2</version>
//                              </plugin>
//                          </plugins>
//                      </build>
//                  </project>
// Si vous utilisez une JDK 8, remplacez la valeur 11 par 1.8 à la ligne 10 de ce fichier.
// -----------
//  - Créez votre première classe de tests :
// Maintenant que l'on a un projet Java bien configuré, nous allons commencer par créer une classe de tests.
//      --> Cette nouvelle classe contiendra tous les tests que vous utiliserez pour vérifier votre calculateur.
// Maven structure les projets Java ainsi :
//      - Le code de l'application se trouve dans le dossier src/main/java.
//      - Les tests seront dans src/test/java.
// Nous allons utiliser un nom de classe se terminant par Test. C'est une convention qui aidera les autres développeurs avec qui vous travaillez.
//      --> Nous allons créer une classe dans le dossier src/test/java nommée CalculatorTest.
// Avec Eclipse, créez un nouveau fichier dans src/test/java, de type "JUnit Test Case". Puis utilisez le nom de paquetage com.openclassrooms.testing et le nom de classe CalculatorTest.
// -----------
//  - Structurez votre premier test unitaire :
// Ce fichier, généré par l'IDE, contient un squelette de test minimal :
//      - Aux lignes 3 et 5, on importe les bibliothèques JUnit.
//      - A la ligne 10, l'annotation @Test indique que la méthode 'test()' de CalculatorTest est un test.
//      - A la ligne 11, la méthode 'fail()' fait échouer le test, en expliquant qu'il n'est pas implémenté.
//          --> Cette classe n'est qu'un squelette de tests, donc cette ligne permet de rappeler au développeur qu'il pense à le coder !
// Allons-y, modifions ce squelette pour en faire un vrai test. L'objectif est de vérifier si notre calculateur sait ajouter deux nombres positifs.
// C'est parti :
//      - Renommez la méthode pour un nom plus descriptif de l'objectif du test, par exemple : testAddTwoPositiveNumbers.
//          Évitez les noms du type testMaMethodeAdd. Ce nom indique uniquement que vous avez un test pour une méthode, mais pas ce que ce test doit vérifier !
//      - Organisez les entrants (Arrange) : déclarez deux entiers positifs à ajouter puis une nouvelle instance de notre classe à tester (le fameux SUT).
//          Ensuite, déclarez une instance de Calculator. Votre IDE détecte alors un problème : votre classe Calculator n'existe pas !
//              --> Il faut donc créer la classe Calculator dans src/main/java, et votre IDE vous aide pour cela !
//              --> Vous devriez maintenant avoir une classe Calculator créée, vide, et votre classe de test devrait à présent reconnaître le mot clé Calculator.
//      - Agissez sur la classe à tester (Act) : ensuite, appelez la méthodeadd()de Calculator avec les paramètres entrants. Vous récupérerez ainsi le résultat sortant.
//          Comme précédemment, votre IDE va détecter un problème et va vous aider à créer automatiquement la méthode 'add()'.
//              --> Cela, avec la bonne signature, donc les bons types de paramètres et le bon type de retour !
//      - Vérifiez les sortants par des affirmations (Assert) : enfin, vérifiez que le nombre attendu par cette addition est bien le résultat de la méthode add() précédente.
//          On utilise pour cela des assertions ou affirmations en français. JUnit fournit des méthodes d'assertions.
//          Elles prennent en premier paramètre ce qui est attendu (le bon résultat), et en deuxième paramètre, votre sortant de l'étape précédente.
// Votre classe de test devrait alors ressembler à cela :
//                  class CalculatorTest {
//                      @Test
//                      void testAddTwoPositiveNumbers() {
//                          // Arrange
//                          int a = 2;
//                          int b = 3;
//                          Calculator calculator = new Calculator();
//                          // Act
//                          int somme = calculator.add(a, b);
//                          // Assert
//                          assertEquals(5, somme);
//                      }
//                  }
// Et votre classe Calculator, créée automatiquement par votre IDE (ici Eclipse), devrait être comme ceci :
//                  public class Calculator {
//                      public int add(int a, int b) {
//                          // TODO Auto-generated method stub
//                          return 0;
//                      }
//                  }
//      --> Si l'assertion est fausse, le test est tout de suite en échec. S'il y a plusieurs assertions, toutes les assertions doivent être vraies.
//      --> C'est pour cela qu'en général, il est préférable d'avoir une seule assertion par test, pour mieux cibler le test.
// Dans son ouvrage Test-Driven Development: By Example (en anglais), Kent Beck suggère de commencer par écrire son assertion.
// J'ai souvent procédé ainsi, car cela m'aide à commencer par la question : Qu'est-ce que je veux tester ?
// À partir de là, on peut travailler à rebours pour déterminer de quoi on a besoin pour tester une action spécifique (quelle méthode appeler) et une organisation spécifique (ce dont la classe a besoin).
// -----------
//  - Exécutez votre test :
// Votre test est écrit, bravo !  Vous pouvez maintenant l'exécuter.
//      --> Votre IDE vous permet d'exécuter votre test via le menu contextuel sur la classe de test (dans Eclipse Run As - JUnit test). Vous obtiendrez l'écran suivant : Mais le test échoue !
// C'est normal, vous avez créé la méthode 'add()', mais vous ne l'avez pas encore implémentée dans la classe Calculator.
// Celle-ci renvoie donc toujours 0 ! Il reste juste à coder la méthode  add()  en retournant non pas 0, mais a + b, la somme des deux arguments de la méthode :
//                  --> return a + b;.
// Modifiez le fichier Calculator et relancez le test :
// C'est plus satisfaisant, non ? C'est pratique de pouvoir lancer les tests directement dans Eclipse. Mais vous pouvez aussi exécuter votre test avec Maven en ligne de commandes.
// Cela sera utile lorsque vous aurez plusieurs tests. En effet, Maven est là pour automatiser toute la construction de votre projet, et donc le lancement de tous les tests !
// Avec Eclipse, il faudrait cliquer sur le projet premiertest, dans le menu contextuel puis Run As - Maven test. En ligne de commandes, ce serait :
//                  --> mvn test.
// Ça y est, vous avez créé et exécuté votre premier test unitaire, félicitations ! De plus, vous l'avez fait selon la méthode TDD !
// Cela vous perturbe d'avoir codé le test avant la classe à tester ? C'est normal. Croyez-moi, au début cela ne paraît pas intuitif.
// Mais une fois l'habitude prise, vous serez au contraire séduit par cette méthode et l'aide que peut vous apporter l'IDE à construire petit à petit le squelette de votre code, à partir des tests.
// Essayez d’ajouter une méthode 'Calculator.multiply' ! Pensez à écrire votre test d’abord et passez-le au rouge avant d’écrire le code !
//      --> Au début du prochain chapitre, nous partirons d'une base de code contenant la solution à cet exercice. Mais cherchez d'abord par vous-même !
// -----------
//  - En résumé :
//      --> JUnit est un framework de test qui vous aide à vous concentrer sur les tests à réaliser.
//      --> Pour utiliser JUnit, vous devez ajouter une dépendance de test à votre outil de développement.
//      --> Développez des logiciels à l’aide de red-green-refactor en :
//              --> Commençant par écrire les tests en décrivant ce que vous devez développer (ils sont en échec, donc rouges).
//              --> Faisant réussir les tests ; et passez-les au vert en écrivant le code de la manière la plus directe possible.
//              --> Améliorant la lisibilité de votre code en effectuant du refactoring sans casser le test.
// --> Maintenant que vous maîtrisez les bases, rendons nos tests plus compréhensibles et plus structurés dans le prochain chapitre !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Structurez vos tests unitaires avec les annotations JUnit /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous avez réussi à coder votre premier test unitaire JUnit et à comprendre la démarche TDD.
//      --> Pour donner un maximum d'informations à vos classes et à vos méthodes de test JUnit, vous allez utiliser les annotations Java.
// Une annotation Java, c’est un mot clé précédé du symbole 'arobase', que l’on place juste au-dessus d’un élément en Java : un nom de classe, de méthode, ou même de paramètre de méthode.
//      --> Elle permet de donner une information précise pour décrire cet élément.
// Et cette information peut être utilisée pour modifier la manière dont votre code va être exécuté.
//      --> Dans le cas des tests, le framework JUnit 5 va se servir des annotations pour savoir comment lancer les tests.
// Par exemple, dans le chapitre précédent, on a placé l’annotation @Test au-dessus de chaque méthode qui devait être lancée comme un test.
// Grâce aux annotations, vous n'avez pas à coder le lancement des tests ou d'autres fonctionnalités propres aux tests.
// Vous avez simplement à ajouter des annotations, et JUnit s'occupe de tout !
// JUnit offre de nombreuses annotations utiles, et je vais vous en présenter quelques-unes.
// Elles peuvent vous aider à rendre vos tests plus pertinents et vous économiser des lignes de code !
// Pour utiliser ces annotations, il suffit de les ajouter juste avant la ligne qui déclare votre classe de test ou votre méthode.
// Sur l'extrait de code ci-dessous, tous les mots clés précédés d'un @ sont des annotations JUnit 5.
//                  public class MaClasseDeTest {
//                      @BeforeEach
//                      public void methodeAppeleeAvantChaqueTest() {
//                          ...
//                      }
//                      @AfterEach
//                      public void methodeAppeleeApresChaqueTest() {
//                          ...
//                      }
//                      @BeforeAll
//                      public static void methodeAppeleeAvantTousLesTests() {
//                          ...
//                      }
//                      @AfterAll
//                      public static void methodeAppeleeApresTousLesTests() {
//                          ...
//                      }
//                      @Test
//                      public void unTest() {
//                          // Arrange
//                          ...
//                          // Act
//                          ...
//                          // Assert
//                          ...
//                      }
//                  }
// -----------
//  - Découvrez les annotations principales de JUnit :
// Reprenons notre classe CalculatorTest. Étant donné que nous testons un calculateur, améliorons pas à pas CalculatorTest, en utilisant les annotations basiques suivantes :
//      - @BeforeAll.
//      - @AfterAll.
//      - @BeforeEach.
//      - @AfterEach.
//      - Puis d'autres plus sophistiquées comme :
//              - @ParameterizedTest.
//              - @Timeout.
// Pour partir sur la même base de code que ce cours, je vous conseille vivement de cloner le dépôt GitHub associé à ce cours :
// git clone https://github.com/geoffreyarthaud/oc-testing-java-cours.git.
// Puis placez-vous dans la branche de ce chapitre : git checkout p1ch3.
// Ensuite, importez le projet en tant que projet Maven.
// Voyons de plus près les étapes principales de ce screencast :
//      - Les annotations pour faire une action avant ou après vos tests.
//      - Les annotations pour rendre paramétrables les tests.
//      - La gestion du temps de traitement.
// -----------
//  - Effectuez des actions avant ou après vos tests grâce aux annotations :
// Pour notre exemple de calculateur, nous allons nous fixer les objectifs suivants pour nos tests :
//      --> Avant chaque test, initialiser une instance du calculateur.
//      --> Après chaque test, mettre la valeur du calculateur à null.
//      --> Mesurer le temps de traitement de l'ensemble des tests de CalculatorTest.
// Tout d'abord, stockons l'instance en cours du calculateur et une variable de temps du début des tests (ce sera pour l'objectif 3) dans notre classe de tests :
//                  public class CalculatorTest {
//                      private static Instant startedAt;
//                      private Calculator calculatorUnderTest;
//                      ...
// Ensuite, pour répondre à l'objectif 1 (initialiser une instance du calculateur avant chaque test), créons une méthode pour initialiser le calculateur (et ajouter un message à la console).
// Il faut rajouter l'annotation @BeforeEach. Cela donne :
//                      @BeforeEach
//                      public void initCalculator() {
//                         System.out.println("Appel avant chaque test");
//                          calculatorUnderTest = new Calculator();
//                      }
// Et c'est tout ! Ou presque. Il faut à présent supprimer les initialisations de Calculator dans les méthodes de tests pour utiliser l'instance calculatorUnderTest. Avant, on avait ce code :
//                  public void testAddTwoPositiveNumbers() {
//                      // Arrange
//                      int a = 2;
//                      int b = 3;
//                      Calculator calculator = new Calculator();
//                      // Act
//                      int somme = calculator.add(a, b);
//                      ...
// On obtient, après remplacement, les deux tests suivants :
//                      @Test
//                      public void testAddTwoPositiveNumbers() {
//                          // Arrange
//                          int a = 2;
//                          int b = 3;
//                          // Act
//                          int somme = calculatorUnderTest.add(a, b);
//                          // Assert
//                          assertEquals(5, somme);
//                      }
//                      @Test
//                      public void multiply_shouldReturnTheProduct_ofTwoIntegers() {
//                          // Arrange
//                          int a = 42;
//                          int b = 11;
//                          // Act
//                          int produit = calculatorUnderTest.multiply(a, b);
//                          // Assert
//                          assertEquals(462, produit);
//                      }
// Ensuite, pour l'objectif 2 (après chaque test, mettre la valeur du calculateur à null), nous allons utiliser l'annotation @AfterEach :
//                      @AfterEach
//                      public void undefCalculator() {
//                          System.out.println("Appel après chaque test");
//                          calculatorUnderTest = null;
//                      }
// Mettre la variable calculatorUnderTest à null n'a pas de réelle utilité ici. C'est juste pour montrer l'utilisation de cette annotation.
// Enfin, pour l'objectif 3 (mesurer le temps de traitement de l'ensemble des tests de CalculatorTest), nous allons créer des méthodes statiques annotées avec @BeforeAll et @AfterAll :
//                      @BeforeAll
//                      static public void initStartingTime() {
//                          System.out.println("Appel avant tous les tests");
//                          startedAt = Instant.now();
//                      }
//                      @AfterAll
//                      static public void showTestDuration() {
//                          System.out.println("Appel après tous les tests");
//                          Instant endedAt = Instant.now();
//                          long duration = Duration.between(startedAt, endedAt).toMillis();
//                          System.out.println(MessageFormat.format("Durée des tests : {0} ms", duration));
//                      }
// Une méthode et une variable statiques sont des éléments d'une classe qui appartiennent à la classe elle-même et non à chaque instance de classe.
// Grâce à ces quatre annotations, JUnit ne vous impose pas d'effectuer ces actions dans des méthodes avec un nommage spécifique comme 'setUp' ou 'tearDown()'.
// Donc, profitez-en, soyez descriptif dans vos noms de méthodes !
// Pourquoi ces méthodes et la variables startedAt sont-elles statiques ?
// C'est un héritage des anciennes versions de JUnit.
// Les méthodes appelées avant ou après tous les tests sont donc statiques car considérées comme liées à l'objet de la classe de test, et non à une instance particulière.
// En fait, ces méthodes pourraient très bien être déclarées comme étant non statiques, mais vous devrez ajouter l'annotation @TestInstance(Lifecycle.PER_CLASS) à la classe de tests.
// Pour ce cours, je code avec JUnit 5. Si vous êtes amené à coder sur des projets existants avec JUnit 4, les noms des annotations diffèrent légèrement.
// -----------
//  - Jouez avec les entrants et les sortants grâce aux tests paramétrés :
// Vous avez déjà vu l’annotation @Test. Imaginez que vous souhaitiez effectuer le même traitement de tests (l'étape Act), sur des entrants différents (de l'étape Arrange).
//      --> Ainsi vous pourrez vérifier différents cas de figure.
// Pour rappel :
//      - Etape Arrange : je paramètre les entrants des tests.
//      - Etape Act : j'effectue l'action sur la classe à tester.
//      - Etape Assert : je vérifie les résultats (sortants) de l'action.
// JUnit 5 vous simplifie la vie ! Grâce à l'annotation '@ParameterizedTest', à la place de '@Test'.
// Une première possibilité consiste à fournir plusieurs entrants, et le résultat attendu doit être le même pour tous.
// Par exemple, toute multiplication par zéro doit donner nécessairement zéro !
// Nous allons fournir les différents entrants possibles avec l'annotation '@ValueSource'.
// Cette annotation accepte tous les types primitifs Java standard comme les valeurs ints, longs, strings, etc.
// Ensuite, la méthode de test elle-même est dotée d'un argument. Cela donne le résultat ci-dessous.
//                      @ParameterizedTest(name = "{0} x 0 doit être égal à 0")
//                          @ValueSource(ints = { 1, 2, 42, 1011, 5089 })
//                          public void multiply_shouldReturnZero_ofZeroWithMultipleIntegers(int arg) {
//                              // Arrange -- Tout est prêt !
//                              // Act -- Multiplier par zéro
//                              int actualResult = calculatorUnderTest.multiply(arg, 0);
//                              // Assert -- ça vaut toujours zéro !
//                              assertEquals(0, actualResult);
//                          }
// Sympathique, non ? Et avez-vous remarqué que l'annotation @ParametrizedTest accepte un paramètre pour formater le nom du test en fonction du paramètre ?
// Bon, une liste d'entrants, c'est pas mal, mais vous aimeriez peut-être que votre test ait plusieurs paramètres ?
// Par exemple, pour tester l'addition, fournir une liste d'éléments contenant chacun deux nombres entrants et la somme attendue de ces deux nombres ?
// JUnit 5 a une annotation pour cela. Vous pouvez utiliser @CsvSourse à la place de @ValueSource. Voici un exemple d'utilisation :
//                          @ParameterizedTest(name = "{0} + {1} should equal to {2}")
//                          @CsvSource({ "1,1,2", "2,3,5", "42,57,99" })
//                          public void add_shouldReturnTheSum_ofMultipleIntegers(int arg1, int arg2, int expectResult) {
//                              // Arrange -- Tout est prêt !
//                              // Act
//                              int actualResult = calculatorUnderTest.add(arg1, arg2);
//                              // Assert
//                              assertEquals(expectResult, actualResult);
//                          }
// La liste d'entrants/sortants est formatée sous forme de chaînes de caractères, et chaque chaîne possède un jeu de paramètres, séparé par des virgules.
//      --> Dans l'exemple ci-dessus, les triplets de valeur :
//              - 1, 1 et 2.
//              - 2, 3 et 5.
//              - 42, 57 et 99.
// Représentent chacun un jeu de paramètres. Chacun de ces jeux de paramètres est utilisable pour la méthode de test, mais aussi pour le formatage du nom du test affiché dans les résultats JUnit.
// -----------
//  - Testez la vitesse de vos traitements :
// Certaines fonctionnalités peuvent prendre du temps à être traitées.
//      --> Si vous souhaitez vérifier que ce délai ne soit pas trop long, vous pouvez décider de faire échouer le test à partir d'un délai que vous estimez trop long.
// L'annotation '@Timeout' est faite pour ça. Elle prend en argument le délai à partir duquel vous souhaitez faire échouer le test (en secondes par défaut) :
//                      @Timeout(1)
//                          @Test
//                          public void longCalcul_shouldComputeInLessThan1Second() {
//                              // Arrange
//                              // Act
//                              calculatorUnderTest.longCalculation();
//                              // Assert
//                              // ...
//                          }
// Dans notre classe Calculator, la méthode longCalculation peut ressembler à cela :
//                          public void longCalculation() {
//                              try {
//                                  // Attendre 2 secondes
//                                  Thread.sleep(2000);
//                              } catch (InterruptedException e) {
//                                  e.printStackTrace();
//                              }
//                          }
// Dans ce cas, votre test échouera au bout d'une seconde.
// Si vous remplacez la valeur 2 000 par 500 (en ms, c'est-à-dire une demi-seconde) dans longCalculation, votre test passera en succès au bout d'une demi-seconde !
// N'abusez pas de l'annotation @Timeout. En effet, dans un travail d'équipe, tout le monde peut exécuter les tests, et vous ne maîtrisez pas la puissance de la machine qui va exécuter les tests.
//      --> Vous risqueriez d'obtenir des faux positifs à cause d'un ordinateur lent ou d'un serveur surchargé.
// -----------
//  - En résumé :
// Les annotations JUnit vous aident à écrire des tests plus clairs sans répétitions inutiles. Voici quelques annotations courantes :
// Annotation               Quand l’utiliser
// @BeforeEach          Exécutez une méthode avant chaque test. C’est un très bon emplacement pour installer ou organiser un prérequis pour vos tests.
// @AfterEach           Exécutez une méthode après chaque test. C’est un très bon emplacement pour nettoyer ou satisfaire à une postcondition.
// @BeforeAll           Désignez une méthode statique pour qu’elle soit exécutée avant tous vos tests. Vous pouvez l’utiliser pour installer d’autres variables statiques pour vos tests.
// @AfterAll            Désignez une méthode statique pour qu’elle soit exécutée après tous vos tests. Vous pouvez utiliser ceci pour nettoyer les dépendances statiques.
// @ParametrizedTest    Vous souhaitez réutiliser le même test avec plusieurs entrants (@ValueSource) voire plusieurs entrants/sortants (@CsvSource).
// @Timeout             Si vous testez une méthode qui ne doit pas être trop lente, vous pouvez la forcer à échouer le test.
// Maintenant que vous avez annoté vos méthodes de tests, voyons de plus près la manière de coder l'étape Assert de vos tests, et en particulier les différents types d'assertions...
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Donnez du sens à vos assertions avec AssertJ //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous avez réussi à coder vos premiers tests unitaires suivant une structuration JUnit 5. Nous allons à présent nous intéresser à l'objectif de vos tests et à ce qu'ils doivent vérifier.
// En particulier, vous allez découvrir comment mieux coder vos assertions.
// Pour rappel, l'assertion représente la dernière étape de vérification, qui est donc intimement liée à l'objectif de votre test unitaire.
// Mais auparavant, comprenez en quoi le TDD et expliciter clairement l'objectif des tests sont importants pour votre application, et en particulier pour réduire son coût !
// -----------
//  - Utilisez le TDD pour éviter le coût des incompréhensions :
// Le développement piloté par les tests, ou TDD pour « test-driven development », vous aide à éviter ce problème.
//      --> Comme vous l’avez vu précédemment, le TDD permet de créer un nouveau test automatique avant d’écrire du code.
// Pour éviter toute confusion sur ce que le logiciel est censé faire, il est essentiel que votre test explique clairement ce qui est testé.
// Ainsi, vous restez concentré sur la résolution d’un problème à la fois, et les autres membres de votre équipe comprennent mieux ce que vous essayez d’accomplir !
//      --> Pourquoi est-ce que je devrais procéder ainsi ?
// Plusieurs études ont montré que plus un bug est découvert tardivement, plus il est coûteux de le corriger. Le coût peut être multiplié jusqu’à des centaines de fois !
// Le TDD vous permet de communiquer sur ce que vous testez, afin de détecter les bugs quand vous êtes en train de coder.
// Il peut vous éviter de coder les mauvaises choses, ou de mal comprendre un cas de test. Si vous découvrez que votre code est mauvais pendant que vous l’écrivez, vous pouvez le corriger immédiatement.
//      --> Le TDD vous aide à faire cela en rendant vos cas de tests lisibles pour les autres. Cela vous permet également de gagner en confiance sur ce que votre code est censé réaliser !
// S’il se passe un an avant que vous ne découvriez que votre application comporte des erreurs, il vous faudra peut-être partir à la chasse au bug à travers toute votre base de code !
//      --> Mais comment je fais pour rendre mes tests suffisamment significatifs pour éviter les erreurs ?
// Il existe des frameworks en complément de JUnit pour vous aider :
//      - Hamcrest (qui était inclus avec JUnit 4 mais séparé depuis JUnit 5).
//      - AssertJ.
//      - Truth.
// Ils sont tous là pour vous aider à affiner vos assertions, et rendre ainsi votre code de test plus lisible.
// Dans ce cours, nous allons utiliser AssertJ car il présente les avantages suivants :
//      --> Il permet de créer un code lisible, en particulier les assertions, proches du langage naturel.
//      --> Il est simple à utiliser pour les développeurs.
// -----------
//  - Codez des tests faciles à lire avec AssertJ :
// Reprenons un test du chapitre précédent. Il utilisait assertEquals de JUnit.
//                      @Test
//                          public void testAddTwoPositiveNumbers() {
//                              // Arrange
//                              int a = 2;
//                              int b = 3;
//                              // Act
//                              int somme = calculatorUnderTest.add(a, b);
//                              // Assert
//                              assertEquals(5, somme);
//                          }
// L'assertion à la ligne 11 est assez mathématique, normal pour un calculateur ! Mais dans la vie quotidienne, diriez-vous « assert equals », ou littéralement « affirmer l'égalité » ?
// L’objectif est que vos tests expriment ce que doivent faire vos fonctionnalités.
// Les tests sont des outils pour communiquer avec d’autres développeurs, mais aussi avec vous-même dans quelques jours ou quelques mois.
// Si vous comprenez quel comportement est attendu, alors vous savez si ça fonctionne !
// La bibliothèque populaire 'AssertJ', utilisée par de nombreux projets Java, permet de rendre les assertions de tests un peu plus naturelles à lire que les assertions de JUnit.
// Elle permet de chaîner plusieurs vérifications pour en faire une plus complexe. Voici quelques exemples :
// Cas de test                                                                  Assertions JUnit                                        Assertions AssertJ
// Un nom est compris entre 5 et 10 caractères.                             assertTrue(name.length > 4 && name.length < 11);        assertThat(name) .hasSizeGreaterThan(4) .hasSizeLessThan(11);
// Un nom est situé dans la première moitié de l'alphabet.                  assertTrue(                                             assertThat(name).isBetween("A", "M");
//                                                                              name.compareTo("A") >= 0
//                                                                              && name.compareTo("M") <= 0);
// Une date et heure locale se situent aujourd'hui ou dans le futur.        assertTrue(                                             assertThat(dateTime.toLocalDate())
//                                                                              dateTime.toLocalDate().isAfter(LocalDate.now())         .isAfterOrEqualTo(LocalDate.now());
//                                                                              || dateTime.toLocalDate().isEqual(LocalDate.now()));
// Vous voyez à travers ces exemples que les assertions de AssertJ sont plus riches et plus lisibles.
//      --> En cas d'échec d'un test unitaire, comparé à assertTrue de JUnit, le message d'erreur sera plus lisible.
// Ainsi, si l'on reprend la dernière assertion sur les dates, en cas d'échec du test, voici le message d'erreur avec JUnit :
//                  --> org.opentest4j.AssertionFailedError: expected: <true> but was: <false>
// Et avec AssertJ :
//                  --> java.lang.AssertionError:
//                          Expecting:
//                          <2019-08-29>
//                          to be after or equal to:
//                          <2019-08-30>
// Vous voyez la différence ? AssertJ donne un résultat bien plus précis.
// -----------
//  - Utilisez AssertJ avec le calculateur :
// Êtes-vous prêt à essayer d’utiliser AssertJ ?
// Nous allons revoir les tests unitaires du calculateur en exploitant cette bibliothèque, et ajouter un nouveau test pour une nouvelle fonctionnalité du calculateur :
//      --> Lister l'ensemble des chiffres utilisés d'un nombre entier.
// Reprenons ensemble les étapes principales vues dans le screencast.
// -----------
//  - Installez AssertJ sous forme de dépendance Maven :
// Parcourez le site mvnrepository.com pour y trouver assertj-core. Copiez-collez la dépendance dans votre fichier pom.xml, sous la dépendance à JUnit :
//                  <dependencies>
//                          <dependency>
//                              <groupId>org.junit.jupiter</groupId>
//                              <artifactId>junit-jupiter</artifactId>
//                              <version>5.5.1</version>
//                              <scope>test</scope>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.assertj</groupId>
//                              <artifactId>assertj-core</artifactId>
//                              <version>3.13.2</version>
//                              <scope>test</scope>
//                          </dependency>
//                      </dependencies>
// À la sauvegarde de ce fichier, votre IDE s'occupera de télécharger et d'installer AssertJ sur votre projet.
// -----------
//  - Migrez vers AssertJ pour les tests d'addition et de multiplication :
// Tous les tests que nous avons effectués jusqu'à présent présentent des assertions simples : vérifier si le résultat était égal à un nombre.
//      --> Donc, pour passer de JUnit pur à AssertJ, nous allons remplacer toutes les assertions :
//                  assertEquals(expectedNumber, actualNumber)
// Par :
//                  assertThat(actualNumber).isEqualTo(expectedNumber);
// Par exemple, pour le test simple de l'addition :
//                  assertThat(somme).isEqualTo(5);
// La différence n'est pas énorme, je vous le concède. Mais ne trouvez-vous pas que c'est plus lisible ?
// Au début de mon utilisation de JUnit, je me posais toujours la question : dans assertEquals, quel élément mettre en premier ou deuxième argument, ce que l'on teste ou ce qui est attendu ?
// Au moins, avec AssertJ, on met toujours l'objet à tester (le fameux SUT) en argument de assertThat.
// AssertJ ne remplace pas JUnit. Cette bibliothèque apporte simplement une panoplie très complète d'assertions.
//      --> JUnit est toujours utilisé pour ses annotations et l'orchestration des tests.
// Voyons à présent un autre exemple d'utilisation de AssertJ, qui nécessiterait un code plus complexe et moins lisible en JUnit pur.
// -----------
//  - Utilisez AssertJ pour la nouvelle fonctionnalité à développer :
// Nous allons développer la fonctionnalité suivante : à partir d'un nombre entier, le calculateur donne l'ensemble des chiffres utilisés pour former ce nombre.
// L'ordre des chiffres indiqués n'est pas important.
// En bon praticien du TDD, vous avez désormais compris que l'on va d'abord coder les tests :
//      - Un test pour un nombre positif.
//      - Un test pour un nombre négatif.
//      - Un test pour le nombre zéro.
// Dans le screencast, vous avez pu voir que l'autocomplétion proposée par l'IDE est très pratique, et c'est l'une des forces principales de AssertJ.
// Dès que l'on a mis l'expression assertThat(monObjet), l'IDE propose les assertions adaptées en fonction du type d'objet.
//                  @Test
//                      public void digitsSet_shouldReturnsTheSetOfDigits_ofPositiveInteger() {
//                          // GIVEN
//                          int number = 95897;
//                          // WHEN
//                          Set<Integer> actualDigits = calculatorUnderTest.digitsSet(number);
//                          // THEN
//                          // assertThat(actualDigits).??? à compléter
//                      }
// Nous avons délaissé la notation classique Arrange/Act/Assert pour une autre notation équivalente Given (étant donné)/When (quand)/Then (alors).
// Cette dernière est issue du BDD (Behaviour-driven development), notion que l'on abordera dans la troisième partie.
// Retenez simplement pour l'instant que cette notation se rapproche plus de la manière d'exprimer une fonctionnalité, un comportement d'application.
// D'après la fonctionnalité, on peut en déduire que l'on va vérifier si un ensemble non ordonné de nombres correspond exactement à la liste de chiffres à laquelle on doit s'attendre.
// Parmi toutes les méthodes de AssertJ, certaines concernent les listes et les ensembles. Elles commencent souvent par contains[...].
// Si vous regardez bien, la méthode containsExactlyInAnyOrder paraît parfaitement adaptée : le même contenu, mais peu importe l'ordre. Voici donc le test complet avec cette méthode :
//                  @Test
//                  public void listDigits_shouldReturnsTheListOfDigits_ofPositiveInteger() {
//                      // GIVEN
//                      int number = 95897;
//                      // WHEN
//                      Set<Integer> actualDigits = calculatorUnderTest.digitsSet(number);
//                      // THEN
//                      assertThat(actualDigits).containsExactlyInAnyOrder(5, 7, 8, 9);
//                      }
// En JUnit pur, on doit reconstruire l'ensemble à comparer et utiliser à nouveau assertEquals, c'est moins sémantique :
//                      @Test
//                      public void listDigits_shouldReturnsTheListOfDigits_ofPositiveInteger() {
//                          // GIVEN
//                          int number = 95897;
//                          // WHEN
//                          Set<Integer> actualDigits = calculatorUnderTest.digitsSet(number);
//                          // THEN
//                          Set<Integer> expectedDigits = Stream.of(5, 7, 8, 9).collect(Collectors.toSet());
//                          assertEquals(expectedDigits, actualDigits);
//                      }
// Après, soyons francs. Le langage, même avec AssertJ, est toujours un peu robotisé, n’est-ce pas ?
// Vous ne pouvez pas l’éviter car Java est un langage de programmation.
//      --> Ce qui est important, c’est que vous ayez un langage fluide, qui puisse être utilisé pour décrire votre intention un peu plus naturellement.
// Dans tous les cas, ce n’est que la partie émergée de l’iceberg. Parcourez la documentation de AssertJ pour découvrir toute l'API que vous pouvez utiliser.
// Et si vous aimez le Seigneur des Anneaux, les exemples utilisés dans cette documentation sont faits pour vous !
// -----------
//  - En résumé :
//          --> En décrivant les tests avec un langage clair, vous pouvez détecter toute incompréhension rapidement.
//          --> Plus vous découvrez un défaut ou une incompréhension dans votre code tardivement, plus il sera coûteux de le corriger.
//          --> Les assertions de AssertJ fournissent des assertions plus lisibles. Vous pouvez les combiner de différentes manières pour exprimer clairement ce que vous testez.
// Ces derniers chapitres vous ont permis de vous approprier les tests unitaires, l'esprit dans lequel il faut les coder et une première technique pour que vous soyez opérationnel.
// Avant d'approfondir sur des notions plus avancées de tests, nous allons aborder un autre thème :
//      --> Vous aider à vérifier que vous codez efficacement vos tests et que votre code d'application reste de qualité.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Contrôlez la couverture de vos tests et la qualité du code ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous avez réussi à écrire vos premiers tests unitaires et à comprendre l'importance de la démarche du TDD.
// Mais pour être sûr que votre code est bien testé et que vos tests sont de qualité, quelques vérifications s'imposent : est-ce que vous avez réalisé suffisamment de tests ?
// Est-ce que vos développeurs ont bien traité l'étape de refactor (souvenez-vous en TDD : rouge-vert-refactor) afin de garder un code de qualité ?
//      --> Java propose de nombreux outils qui permettent de vous aider à effectuer ces types de vérification pour :
//              --> Maîtriser la notion de couverture de code par vos tests et mettre en pratique avec JaCoCo
//              --> Améliorer la qualité du code avec le formatage, et la détection de code mal écrit, source de bugs potentiels.
//              --> Sécuriser votre produit en vérifiant les dépendances de votre code, notamment avec le projet OWASP.
// Vous pouvez même intégrer ces vérifications de manière automatisée durant le build, c'est-à-dire l'étape de construction de votre application.
// C'est l'un des objectifs des outils tels que Maven ou Gradle : fournir un moyen de lancer le build avec l'ensemble des vérifications, grâce à des plugins et un fichier de configuration.
// Depuis votre poste de travail, vous verrez, nous allons lancer des commandes permettant d'effectuer toutes ces vérifications.
// Mais si vous travaillez en équipe, vous pouvez aussi automatiser le lancement de ces vérifications à un autre système que votre ordinateur.
// Ainsi, vous recevez des alertes si des tests échouent, ou s'il y a un autre problème de qualité. De ces vérifications, vous pouvez extraire des rapports.
// Nous allons découvrir dans ce chapitre SonarCloud, qui prend la forme d'une interface web pour développeurs.
// Ces outillages sont appelés à évoluer très rapidement. N'hésitez pas à confronter régulièrement les apports effectués dans ce cours avec votre propre veille technologique.
// Pour suivre ce chapitre avec les exemples donnés, vous pouvez vous placer sur la bonne branche du dépôt de code du cours : git checkout -f p1ch6.
// -----------
//  - Maîtrisez la couverture de code par vos tests :
// Si vous faites du TDD, vous avez créé au moins un test avant de coder la fonctionnalité, c'est déjà très bien !
// Mais au moment de coder la fonctionnalité, vous allez sûrement coder tous les cas d'application de votre fonctionnalité, les exceptions éventuelles.
// Donc, lorsque vous exécuterez les tests, le système ne va pas forcément exécuter toutes les instructions du code de votre fonctionnalité, car les tests n'auront pas forcément prévu tous les cas.
//      --> Un code est couvert par les tests s'il est exécuté par au moins un test.
// Par exemple, avec le calculateur, vous avez codé un test pour tester l'addition de deux entiers.
// Vous en profitez pour coder l'addition de deux nombres à virgule (type double, ajoutez les lignes 11 à 17 ci-dessous) :
//                  public class Calculator {
//                      public int add(int a, int b) {
//                          return a + b;
//                      }
//                      public int multiply(int a, int b) {
//                          return a * b;
//                      }
//                      public double add(double a, double b) {
//                          return a + b;
//                      }
//                      public double multiply(double a, double b) {
//                          return a * b;
//                      }
//                      ...
//                  }
// Or, votre test ne s'occupe que des nombres entiers. Le cas de l'addition de deux nombres à virgule de type double n'est pas couvert par les tests, comme l'illustre la figure ci-dessous.
// La couverture de tests est en fait la proportion entre la quantité de code couverte par vos tests et la quantité de code totale. Il s'exprime souvent sous la forme d'un pourcentage.
// C'est quoi la "quantité" de code ? Et comment je mesure cette proportion ?
//      --> C'est une très bonne question, car la quantité de code peut se mesurer de différentes façons.
// Cela peut conduire à des pourcentages différents ! Sur le comment faire, vous l'avez deviné, vous n'allez pas vérifier à la main le code qui ne serait pas couvert par vos tests !
// Des outils existent pour cela, et nous allons découvrir comment le faire avec Eclipse, mais aussi avec Maven.
// -----------
//  - Les différentes façons de mesurer la quantité de code :
// Avant de lire ce qui suit, prenez le temps de réfléchir à quel élément vous allez compter, en prenant en compte le fait que cela va servir à mesurer une couverture de code par des tests.
// On peut identifier 4 façons principales de mesurer une quantité de code, en comptant :
//      - Le nombre de lignes : c'est ce qui semble le plus intuitif. Mais est-ce le plus juste ? Évidemment, les outils de comptage vont éliminer les lignes inutiles, vides, ou de commentaires.
//              --> Mais il est possible d'avoir des lignes plus complexes que d'autres.
//      - Le nombre d'instructions : pour prendre en compte la complexité d'une ligne, on peut compter toutes les instructions.
//              Mais lorsqu'un développeur code des tests, il étudie les différents cas possibles, y compris les cas d'exception qui doivent être traités avec la même importance.
//              Et ceci, même si les cas d'exception nécessitent souvent moins de code.
//      - Le nombre de branches : au lieu de compter linéairement le code, on va compter le nombre de zones de code par rapport à des conditions.
//              Typiquement, un ensemble d'instructions if/else génère deux zones de code, que l'on appelle aussi branches. Cela permet de prendre en compte à parts égales les différents cas possibles.
//      - Le nombre de fonctions/méthodes : cette fois, on va compter juste le nombre de fonctions/méthodes de l'application.
//              Dès que cette méthode est appelée au moins une fois, le code est indiqué comme couvert, peu importe le nombre de lignes ou de branches parcourues au sein de cette fonction.
// Il n'y a pas de méthode de mesure parfaite. Chacune possède ses avantages et ses inconvénients. Parfois, il faudra prendre en compte plusieurs mesures.
//      --> Si je dois prévoir tous les cas avec mes tests, je dois atteindre 100 % de couverture selon tous les types de mesure ?
// Cela peut être très difficile à atteindre. Sur des projets réels, atteindre 70-80 % avec la mesure de votre choix semble être un bon compromis de départ.
// Au-delà du pourcentage, veillez à prioriser les parties critiques de votre code, à tester au mieux avec des tests unitaires.
// Nous verrons dans la troisième partie les tests d'intégration et les tests fonctionnels, qui peuvent aussi compléter cette couverture, pour des parties moins critiques.
//      --> Et cela, sans oublier de respecter la pyramide des tests !
// -----------
//  - Mesurez la couverture des tests avec Eclipse :
// Passons à la pratique ! Le paquetage d'installation d'Eclipse fournit un outil de mesure de couverture qui se nomme EclLemma.
// Pour le tester, c'est très simple, nous allons voir la couverture du code par le test CalculatorTest.
// Pensez à ajouter les méthodes 'add' et 'multiply' pour les types doubles dans la classe Calculator :
//                  public double add(double a, double b) {
//                      return a + b;
//                  }
//                  public double multiply(double a, double b) {
//                      return a * b;
//                  }
// Puis, démarrez le test CalculatorTest ; mais au lieu de choisir Run As... sur le menu contextuel, vous allez choisir Coverage As... puis JUnit Test Case comme d'habitude.
// Ensuite, votre test va se dérouler comme d'habitude, avec la fenêtre JUnit de résultat. Mais regardez maintenant le code de Calculator, il y a des surlignages verts et rouges.
// Dans le code source de Calculator, les lignes sont représentées :
//      - En vert lorsque la classe de tests a parcouru ces lignes.
//      - En rouge lorsque la classe de tests n'a pas parcouru ces lignes.
//      - En jaune pour les blocs conditionnels if, while, ou ici try/catch pour lesquels toutes les conditions n'ont pas été parcourues.
//              Ici, il s'agit d'un try/catch, la partie try (ligne 27) est bien parcourue, mais aucune exception n'a été lancée, donc la partie catch (ligne 28) n'est pas parcourue.
//      - Sans surlignage pour les noms de méthodes ou ponctuations ne correspondant pas à du code.
// Un nouvel encart s'est aussi ouvert, généralement en bas de l'interface d'Eclipse, il s'agit de l'encart Coverage, indiquant un résultat de couverture.
// Il est possible que votre rapport diffère de l'illustration, tout simplement parce que votre rapport n'est pas basé sur le nombre de lignes mais sur un autre indicateur.
// Vous obtenez différents pourcentages, par rapport au nombre de lignes, ainsi que les quantités de lignes :
//      - Un pourcentage total de 95,2 % en nombre de lignes.
//      - Un pourcentage de 80 % pour tout ce qui est dans src/main/java.
//      - Un pourcentage de 100 % pour tout ce qui est dans src/test/java.
// Votre code ne contient qu'un test et vous l'avez exécuté, donc le code source du test a été totalement parcouru, c'est normal !
// Donc, le pourcentage le plus significatif est celui de src/main/java, et non le pourcentage total, car ce qui vous intéresse, c'est bien le pourcentage du code de l'application !
// Nous avons abordé auparavant plusieurs façons de mesurer la couverture des tests.
// Dans Eclipse, vous pouvez changer la façon de mesurer grâce à l'icône d'option 'v' à droite de l'encart Coverage.
// Constatez qu'en changeant la méthode de mesure, vos pourcentages changent !
// En passant du compteur de lignes au compteur d'instructions, on passe de 95 % à 96,1 % pour le pourcentage total !
// -----------
//  - Obtenez des rapports de couverture avec Maven et JaCoCo :
// Insérez l'appel au plugin JaCoCo dans le fichier de configuration pom.xml, dans les balises <plugins> entre les lignes 21 et 22 :
//                  <plugins>
//                      ...
//                      <plugin>
//                          <groupId>org.jacoco</groupId>
//                          <artifactId>jacoco-maven-plugin</artifactId>
//                          <version>0.8.5</version>
//                          <executions>
//                              <execution>
//                                  <goals>
//                                      <goal>prepare-agent</goal>
//                                  </goals>
//                              </execution>
//                              <execution>
//                                  <id>report</id>
//                                  <phase>test</phase>
//                                  <goals>
//                                      <goal>report</goal>
//                                  </goals>
//                              </execution>
//                          </executions>
//                      </plugin>
//                  </plugins>
// Pensez à vérifier sur mvnrepository.com s'il existe une version plus récente du plugin.
//      --> Cette déclaration permet de déclencher JaCoCo durant la construction des sources et de rédiger un rapport après l'exécution des tests.
// Ensuite, en ligne de commandes, lancez la commande : mvn clean package.
// À la fin de l'exécution de la commande, vous pouvez voir que JaCoCo a été appelé.
// Le rapport se trouve alors dans le dossier target/site/jacoco.
// Ouvrez dans votre navigateur le fichier index.html, et vous obtenez un rapport cliquable dans le navigateur.
// Ce rapport privilégie les mesures instructions et branches, et extrait de fait le code des tests (tout ce qui est dans src/test/java est exclu) pour ne pas polluer les pourcentages obtenus.
// Vous pouvez accéder aux changements effectués sur le fichier pom.xml en vous plaçant sur la branche p1ch6-fin : git checkout -f p1ch6-fin.
// -----------
//  - Améliorez autrement la qualité de votre code :
// Dans ce cours, nous nous focalisons essentiellement sur les tests automatisés. Mais n'oublions pas l'objectif de cette pratique :
//      --> Améliorer la qualité et gagner en confiance sur notre produit numérique.
// Dans ce paragraphe, nous allons aborder un aspect différent : c'est l'amélioration grâce au formatage du code et à l'analyse de code automatisée.
// -----------
//  - Formatez et nettoyez votre code avec votre IDE :
// Grâce à votre IDE, vous allez pouvoir améliorer le format de votre code, et surtout le rendre cohérent sur tout votre projet.
// C’est une pratique courante des équipes d’avoir des conventions de codage.
// Elles garantissent la cohérence du code pour des éléments importants comme le placement de l'accolade, ou le nombre d'espaces ou de tabulations pour l'indentation de votre code.
// Cela peut sembler anecdotique, mais avec peu d'efforts, on peut rendre un code plus lisible, ce qui permet au développeur de se concentrer sur le fond du code, et moins sur sa forme.
// En Java, on peut écrire une condition if sans accolades ; cela signifie que seule l'instruction suivante sera exécutée (à gauche sur l'illustration).
// Si, lors d'une évolution, on insère une instruction pour tracer dans un fichier de log une action utilisateur.
// Visuellement, à cause d'une indentation trompeuse, le développeur croit que cela n'a pas d'impact sur son code.
// Apple a cassé SSL il y a quelques années en oubliant les accolades. Oups. Heureusement, votre IDE est là pour formater votre code et insérer les accolades tout de suite.
// Eclipse vous facilite le nettoyage de code de deux façons différentes.
// -----------
// - Les options Formatter dans Eclipse :
// Les options de formatage permettent de changer l'aspect visuel de votre code sans rien changer dans son contenu.
// Dans le menu Preferences, puis Java - Code Style - Formatter, vous obtenez des options pour choisir un profil de formatage :
// Cliquez sur New..., choisissez un nom, et vous entrez alors dans les options de formatage.
// À gauche se trouvent les options, et à droite une fenêtre de prévisualisation.
// Changez quelques options et sauvegardez. Vous pouvez aussi importer un jeu d'options existant, grâce à l'option Import...
// Je vous propose d'importer mon jeu d'options, qui se trouve à la racine du dépôt de code :  Eclipse-Formatter_oc-testing.xml.
// -----------
//  - Les options Clean Up dans Eclipse :
// Les options de nettoyage vont plus loin que le formatage. Elles permettent de rendre la syntaxe du code plus cohérente et changent parfois votre code pour un autre code équivalent !
// Dans le menu Preferences, puis Java - Code Style - Clean Up, vous obtenez des options pour choisir un profil de Clean Up, de la même façon que Formatter.
// Après avoir créé un nouveau profil de Clean Up, vous obtenez aussi une fenêtre d'options, à plusieurs onglets cette fois.
// Testez chaque option et regardez leur résultat sur la fenêtre à droite. Cela va vous permettre de consolider vos connaissances en Java, croyez-moi !
// De la même façon, vous pouvez importer des options de nettoyage.
//      --> Testez mon profil qui se trouve à la racine du dépôt : Eclipse-Cleanup_oc-testing.xml.
// En complément, l'option Java - Editor - Save Actions vous permet d'effectuer des nettoyages à chaque fois que vous sauvegardez !
// Ces options permettent d'effectuer le formatage selon le profil de formatage, mais aussi du nettoyage, comme le Clean Up.
// Cependant, vous devrez repréciser ce que vous voulez nettoyer, indépendamment de votre profil Clean Up.
// -----------
//  - Analysez automatiquement votre code avec SonarCloud :
// Bon, votre code est bien plus lisible, c'est déjà une première étape.
// La deuxième étape ne va pas directement améliorer la qualité de votre code, mais "seulement" vous alerter précisément sur les différents problèmes que peuvent poser certaines parties de votre code.
//      --> En effet, un code mal écrit peut :
//              - Conduire clairement à un bug.
//              - Créer une faille de sécurité.
//              - Rendre le code moins maintenable, toute évolution sera plus difficile et plus coûteuse à coder.
// C'est là qu'un outil comme SonarCloud peut vous aider. Il va :
//      --> Analyser votre code.
//      --> Envoyer son analyse au serveur SonarCloud.
//      --> Faire un rapport web dynamique pour lister les problèmes, les prioriser et vous expliquer comment améliorer votre code.
// Pour réaliser tout cela, SonarCloud se base sur des règles qui ont été prédéfinies.
// Ces dernières ont été créées pour pouvoir émettre un jugement sur des risques potentiels.
// Cela s’apparente un peu au fait de répondre à un questionnaire en ligne pour vérifier votre santé, mais en plus fiable.
//      --> SonarCloud possède une vaste base de données des différents types de bugs logiciel connus.
//      --> Il trouve du code qui fait des actions qui n’étaient probablement pas voulues, qui pourrait causer un risque de sécurité, ou qui ne suit pas les bonnes pratiques.
//      --> SonarCloud reprend aussi les rapports de couverture du code par les tests effectués par JaCoCo.
//              En termes de mesure, SonarCloud utilise une mesure qui effectue la moyenne entre le nombre de lignes et le nombre de branches, afin d'obtenir un seul pourcentage "hybride".
// SonarCloud propose ses propres serveurs pour mener à bien toutes ces tâches.
// C'est gratuit pour du code open source, hébergé par exemple sur GitHub. Voici une démonstration de l'utilisation de SonarCloud. Vous aurez besoin :
//      - D'avoir votre propre compte GitHub.
//      - De savoir forker un dépôt open source, de préférence Java.
// Pour créer votre compte GitHub et effectuer un fork, je vous renvoie sur le cours Installez votre environnement de développement Java avec Eclipse.
//      --> Forkez le dépôt de ce cours. Puis clonez-le sur votre ordinateur avec la commande : git clone https://github.com/<votre_identifiant>/oc-testing-java-cours.git.
//      --> Ensuite, vous allez créer votre compte SonarCloud :
//              - Sur la page d'accueil de SonarCloud, cliquez sur l'icône de GitHub  en dessous de "Analyze your repo".
//              - Acceptez la demande d'autorisation pour lier votre compte GitHub et SonarCloud.
//              - Votre compte est créé et vous pouvez créer votre projet SonarCloud :
//              - Cliquez sur Create a new project, puis Choose an organization on GitHub.
//              - Acceptez la nouvelle demande d'autorisation de GitHub.
//              - Ne changez rien et cliquez sur Continue et Create Organization.
//      --> Vous pouvez alors (enfin !) sélectionner votre projet GitHub et cliquer sur Set Up :
//              - Une nouvelle fenêtre vous propose différents outils, cliquez sur Manually.
//              - Sur cette nouvelle fenêtre, sélectionnez Maven et vous obtenez une ligne de commandes Maven pour construire votre projet et envoyer les résultats à Sonar :
//              - Copiez ces lignes, mais selon l'invite de commandes que vous utilisez, il vous faudra la modifier pour enlever les caractères "\" et obtenir une ligne du style :
//                  mvn verify sonar:sonar -Dsonar.projectKey=ocstudent-ide_oc-testing-java-cours
//                  -Dsonar.organization=ocstudent-ide -Dsonar.host.url=https://sonarcloud.io
//                  -Dsonar.login=ee836b16f89559b22237d5720b35b03b92ec402d.
//              - Exécutez cette commande sur votre nouveau dépôt !
// Vous êtes en train de construire la branche master du dépôt de cours. Elle contient du code que nous verrons dans les prochains chapitres.
// Pas d'inquiétude ! Cela permet à Sonar d'obtenir un rapport plus complet qu'avec juste les deux classes de Calculator et CalculatorTest.
// Après exécution de cette commande, et un petit temps d'attente sur SonarCloud, vous allez obtenir enfin votre rapport Sonar !
// Toutes les étapes d'inscription sont fastidieuses mais ne sont à faire qu'une seule fois.
// Ensuite, il suffit juste de lancer cette même ligne de commande pour obtenir un rapport à jour.
//      --> Une foule d'informations sont disponibles sur cet écran :
//              - Des informations sur la branche construite, les nombre de lignes de code, le langage.
//              - Le nombre d'avertissements relevés par thèmes :
//                      - Reliability - Bugs : bugs potentiels de votre application.
//                      - Security - Vulnerabilities : problèmes potentiels de sécurité.
//                      - Maintenability - Code smells : problèmes de syntaxe pouvant rendre votre code moins lisible et moins maintenable (littéralement "mauvaises odeurs de code").
//              - La couverture du code par les tests et le nombre de tests unitaires.
//              - La duplication de code : proportion de code qui semble être du copier-coller.
//                  Plus le pourcentage est élevé, moins bonne est la qualité, car hormis les tests, il faut toujours regrouper du code commun et ne pas faire du copier-coller.
// Ce cours n'a pas vocation à vous apprendre toutes les ficelles. Je vous laisse découvrir cet outil par vous-même, il est très intuitif.
//      --> Découvrons cependant ensemble un exemple d'alerte soumise par Sonar.
// SonarCloud est mis à jour régulièrement. Le nombre et le type d'alertes peuvent donc changer en fonction du contenu de cours.
// Cliquez sur le nombre de codes smell. Vous obtenez un écran listant les alertes et sur la gauche des critères pour trier et filtrer ces résultats :
// Cliquez sur le premier item de la liste. Vous obtenez alors un extrait de votre propre code source annoté de l'alerte Sonar !
// Sur cette alerte, vous pouvez cliquer sur See Rule, et Sonar vous explique la règle et même souvent comment corriger le problème !
// Certes, c'est en anglais, mais vous allez faire de très grands progrès en Java si vous vous y mettez et cherchez à comprendre ce qui est écrit.
// Sonar vous permet de gérer ces alertes, de les affecter à une autre personne de l'équipe, etc.
// -----------
//  - Les autres outils de vérification :
//      - Surefire et le site Maven :
//          Avec Maven, vous utilisez le plugin Surefire pour exécuter les tests (il est donc activé par défaut dans Maven), mais aussi pour avoir des rapports sur vos tests et générer un rapport HTML.
//          Maven crée un rapport XML quand vos tests échouent, mais peut créer un rapport HTML si vous exécutez : mvn site.
//          Maven place vos rapports dans target/site/surefire-report.html. Ce n’est peut-être pas le système le plus élégant, mais il vous indiquera les résultats de vos tests.
//          Plus généralement, la commande mvn site permet de générer un site HTML statique regroupant différentes informations que peuvent générer vos plugins Maven.
//          C'est un outillage plus ancien que SonarCloud en termes de tableau de bord, mais si votre fichier pom.xml déclare beaucoup de plugins liés à des rapports sur votre code.
//          Cette commande regroupe le tout dans un site HTML, consultable depuis votre propre machine.
//      - L'audit de sécurité des dépendances :
//          L'outil de OWASP Dependency Checker, qui scanne les vulnérabilités de sécurité.
//          OWASP offre des ressources et conseils de valeur pour construire des applications sécurisées. Cela vaut vraiment le coup d’aller voir le cours OWASP d’OpenClassrooms !
//      - Les autres outils d'audit de code :
//          - L’outil Java Checkstyle observe votre code source et vous indique des problèmes de code, principalement liés au formatage de votre code.
//              Par exemple, il permet de vérifier les dénominations de variables et de classes. Il est configurable, et les configurations prédéfinies sont nombreuses.
//              Vous pouvez même commencer par utiliser les styles Java de Google et Oracle.
//          - Les auditeurs de code PMD et FindBugs, plutôt orientés sur des jeux de règles similaires à ceux de SonarCloud.
// -----------
//  - En résumé :
//          --> Les outils de build comme Maven et Gradle permettent d'automatiser le lancement des tests mais aussi d'autres vérifications de qualité.
//          --> L'étude de la couverture du code par les tests permet de vérifier si vos tests parcourent l'ensemble de votre code. Il existe plusieurs types de mesure.
//          --> L'IDE Eclipse permet de vérifier visuellement où vos tests passent. Maven via le plugin JaCoCo permet d'évaluer cette couverture en ligne de commandes.
//          --> L'audit automatisé de code permet de vérifier si vous écrivez un code bien construit, qu'il ne produit pas de bugs connus, ni certaines failles de sécurité potentielles.
//                  Il est maintenable, c'est-à-dire que d'autres développeurs pourront travailler dessus sans perdre trop de temps.
//          --> SonarCloud est un outillage permettant d'effectuer l'audit de code et de l'afficher sous forme de rapports détaillés et interactifs.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Affinez vos tests unitaires ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Étiquetez vos tests avec des annotations JUnit avancées ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quand vous cherchez quelque chose dans un livre, vous pouvez généralement vérifier la table des matières et passer directement au bon chapitre.
// Si vous devez parcourir chaque page pour trouver ce que vous cherchez, soit le sommaire est mauvais, soit il est mal structuré.
// Le même constat s’applique aux tests. Voyons quelques façons de rendre vos tests lisibles.
// Nous allons utiliser de nouvelles annotations de JUnit 5.
//      --> Si vous êtes amené à travailler avec des tests JUnit 4 à migrer vers JUnit 5, vous pouvez le faire en douceur grâce à la dépendance junit-vintage-engine.
// Si vous souhaitez vous exercer vous-même sur les exemples abordés ci-dessous appliqués au calculateur, vous pouvez partir d'une base de code avec la branche de ce chapitre p2ch1.
// Vous pouvez le faire à partir du même dépôt de code de cours (pour rappel, il s'agit de https://github.com/geoffreyarthaud/oc-testing-java-cours) : git checkout -f p2ch1.
// -----------
//  - Catégorisez vos tests JUnit 5 avec @Tag :
// Avec JUnit 5, catégoriser des tests est devenu plus facile. Vous pouvez utiliser en particulier l'annotation '@Tag' de JUnit5.
// Elle vient remplacer l’utilisation de '@Category' de JUnit 4, peu pratique car vous deviez créer une interface vide à chaque fois.
// Voici un exemple d'utilisation des tags pour le calculateur :
//                  @Test
//                  @Tag("QuatreOperations") // ce test fait partie des tests des 4 opérations de base
//                      public void testAddTwoPositiveNumbers() {
//                          // Arrange
//                          int a = 2;
//                          int b = 3;
//                          // Act
//                          int somme = calculatorUnderTest.add(a, b);
//                          // Assert
//                          assertThat(somme).isEqualTo(5);
//                          assertEquals(5, somme);
//                      }
//                  @Test
//                  @Tag("QuatreOperations") // ce test fait partie des tests des 4 opérations de base
//                  public void multiply_shouldReturnTheProduct_ofTwoIntegers() {
//                      // Arrange
//                      int a = 42;
//                      int b = 11;
//                      // Act
//                      int produit = calculatorUnderTest.multiply(a, b);
//                      // Assert
//                      assertEquals(462, produit);
//                  }
// Comme pour des articles web possédant plusieurs tags, un test peut posséder plusieurs tags.
//      --> Et pour ne pas se répéter, on peut aussi placer l'annotation '@Tag' au niveau d'une classe, ce qui permet d'ajouter ce tag à tous les tests de cette classe !
// En complément de l’annotation '@Tag', voici deux autres annotations très pratiques : '@DisplayName' et '@Nested'.
// Regardons les points les plus intéressants de nos 3 annotations étape par étape.
// Voici un code plus complet contenant ces trois annotations :
//                  @Tag("ConversionTests") // (1)
//                  @DisplayName("Réussir à convertir entre différentes unités.") // (2)
//                  public class ConversionCalculatorTest {
//                      private ConversionCalculator calculatorUnderTest = new ConversionCalculator();
//                      @Nested // (3)
//                      @Tag("TemperatureTests") // (4)
//                      @DisplayName("Réussir à convertir des températures") // (4)
//                      class TemperatureTests {
//                          @Test
//                          @DisplayName("Soit une T° à 0°C, lorsque l'on convertit en °F, alors on obtient 32°F.")
//                          public void celsiusToFahrenheit_returnsAFahrenheitTempurature_whenCelsiusIsZero() {
//                              Double actualFahrenheit = calculatorUnderTest.celsiusToFahrenheit(0.0);
//                              assertThat(actualFahrenheit).isCloseTo(32.0, withinPercentage(0.01));
//                          }
//                          @Test
//                          @DisplayName("Soit une T° à 32°F, lorsque l'on convertit en °C, alors on obtient 0°C.")
//                          public void fahrenheitToCelsius_returnsZeroCelciusTempurature_whenThirtyTwo() {
//                              Double actualCelsius = calculatorUnderTest.fahrenheitToCelsius(32.0);
//                              assertThat(actualCelsius).isCloseTo(0.0, withinPercentage(0.01));
//                          }
//                      }
//                      @Test
//                      @DisplayName("Soit un volume de 3.78541 litres, en gallons, on obtient 1 gallon.")
//                      public void litresToGallons_returnsOneGallon_whenConvertingTheEquivalentLitres() {
//                          Double actualLitres = calculatorUnderTest.litresToGallons(3.78541);
//                          assertThat(actualLitres).isCloseTo(1.0, withinPercentage(0.01));
//                      }
//                      @Test
//                      @DisplayName("L'aire d'un disque de rayon 1 doit valoir PI.")
//                      public void radiusToAreaOfCircle_returnsPi_whenWeHaveARadiusOfOne() {
//                          Double actualArea = calculatorUnderTest.radiusToAreaOfCircle(1.0);
//                          assertThat(actualArea).isCloseTo(PI, withinPercentage(0.01));
//                      }
//                  }
//      --> (1) Ligne 1 : '@Tag désigne' tous les tests de la classe comme étant des tests de conversion, avec un tag nommé "ConversionTests".
//      --> (2) Ligne 2 : '@DisplayName' vous permet de nommer vos tests de façon lisible par tous.
//      --> (3) Ligne 7 : '@Nested' vous permet de grouper vos tests dans une classe interne. Avec @Nested, si un seul test échoue, tout le groupe désigné par cette annotation échoue !
//      --> (4) Ligne 8-9 : vous pouvez ajouter '@Displayname' et '@Tag' à chaque bloc '@Test' et '@Nested'.
// Grâce à ces annotations, quand le test JUnit5 est exécuté, les résultats sont également lisibles plus naturellement.
// -----------
//  - Utilisez '@ExtendWith' pour modifier l'exécution des tests :
// '@ExtendWith' vous permet de modifier le déroulement des tests menés par JUnit 5.
// Oui, JUnit s'occupe de tout comme on l'a vu ; nous avions besoin uniquement de '@Test' pour désigner ces méthodes comme tests.
// Les annotations '@BeforeEach', '@AfterEach', etc., permettaient de regrouper des traitements communs !
//      --> Mais il existe des situations où vous aurez besoin de personnaliser le déroulement des tests ou la gestion des classes de tests.
// Voici un exemple : imaginez un cas où on aurait besoin d'une extension qui permette à notre classe de test d'utiliser une classe de log pour afficher les messages, au lieu d'utiliser 'println'.
// Utiliser une classe de log (ou logger) est une pratique courante pour afficher les messages sur la console au lieu d'utiliser 'println'.
// Comme elle est configurable, enregistrer les messages dans un fichier (dit de log) en plus ou à la place d'un affichage à l'écran, et ce, sans modifier le code de l'application ou du test.
// Ajoutez la dépendance suivante dans votre fichier pom.xml (vous pouvez choisir une version plus récente si vous le souhaitez, en consultant mvnrepository.com) :
//                  <dependency>
//                      <groupId>org.apache.logging.log4j</groupId>
//                      <artifactId>log4j-core</artifactId>
//                      <version>2.12.1</version>
//                  </dependency>
// Créez la classe LoggingExtension dans le même paquetage que CalculatorTest avec le contenu suivant :
//                  package com.openclassrooms.testing;
//                  import org.apache.logging.log4j.LogManager;
//                  import org.apache.logging.log4j.Logger;
//                  import org.junit.jupiter.api.extension.ExtensionContext;
//                  import org.junit.jupiter.api.extension.TestInstancePostProcessor;
//                  public class LoggingExtension implements TestInstancePostProcessor {
//                  @Override
//                     public void postProcessTestInstance(Object testInstance, ExtensionContext context) throws Exception {
//                          Logger logger = LogManager.getLogger(testInstance.getClass());
//                          testInstance.getClass()
//                                  .getMethod("setLogger", Logger.class)
//                                  .invoke(testInstance, logger);
//                      }
//                  }
// Nous n'allons pas détailler le mécanisme de cette classe. Sachez simplement que cette extension implémente une interface permettant de manipuler la classe de test, juste après sa création.
// Puis utilisez cette extension dans la classe de test CalculatorTest.
// Nous ajoutons l'annotation '@ExtendWith', puis nous ajoutons une instance de classe Logger et une méthode 'setLogger()' associée. Ensuite, on remplace tous les println par logger.info :
//                  @ExtendWith(LoggingExtension.class)
//                  public class CalculatorTest {
//                      private static Instant startedAt;
//                      private Calculator calculatorUnderTest;
//                      private Logger logger;
//                      public void setLogger(Logger logger) {
//                          this.logger = logger;
//                      }
//                      @BeforeEach
//                      public void initCalculator() {
//                          logger.info("Appel avant chaque test");
//                          calculatorUnderTest = new Calculator();
//                      }
//                      @AfterEach
//                      public void undefCalculator() {
//                          logger.info("Appel après chaque test");
//                          calculatorUnderTest = null;
//                      }
//                      ...
//                  }
// Puis créez un fichier log4j2.properties dans le dossier src/test/resources avec le contenu suivant :
//                  appender.console.type = Console
//                  appender.console.name = STDOUT
//                  appender.console.layout.type = PatternLayout
//                  appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1} - %m%n
//                  rootLogger.level = info
//                  rootLogger.appenderRefs = stdout
//                  rootLogger.appenderRef.stdout.ref = STDOUT
// Ce fichier indique tout ce que le composant de log a besoin de savoir pour bien formater les messages.
// Et grâce à l'extension, vos classes de tests sont munies d'un logger !
// -----------
//  - Découvrez @Disabled :
// Vous êtes-vous déjà retrouvé dans une situation où vous travaillez dur sur un projet, mais la personne à côté de vous n’arrête pas de parler ?
// Et vous n’arrivez à rien faire parce que vous êtes tellement distrait ? Vous vous êtes peut-être senti coupable, mais je suis sûr que vous avez souhaité disposer d’un bouton "muet".
// J’ai connu des tests exactement comme ça ! Certains qui avaient échoué et qui me donnaient des lignes et des lignes de texte en rouge, dont je ne savais pas du tout quoi faire.
// Évidemment, il vaut mieux corriger le test si vous le pouvez.
// Néanmoins, même si cela doit rester temporaire, si le test a été mal écrit ou que vous ne comprenez même son objectif, dites-lui simplement de se taire !
//      --> Vous pouvez le faire en utilisant le '@Disabled' de JUnit.
// Par exemple, ajouter l’annotation suivante avant votre '@Test' empêcherait le test de s’exécuter et expliquerait pourquoi ! Par exemple :
//                  --> @Disabled("Stoppé car cela échoue tous les mardis").
// Assurez-vous de spécifier pourquoi vous ignorez le test et promettez de revenir le corriger plus tard !
// Il existe de nombreuses autres annotations et extensions utiles. Assurez-vous de consulter la documentation officielle de JUnit pour la liste exhaustive !
// -----------
//  - En résumé :
//      --> Nous pouvons classer les tests en catégories en utilisant '@Tag' de JUnit5.
//      --> '@ExtendWith' peut être utilisé pour modifier le déroulement des tests.
//      --> '@Disabled' peut être utilisé pour faire taire temporairement les tests inutiles ou problématiques.
// Retrouvez le code de ce chapitre intégré en choisissant la branche p2ch2 du dépôt de code.
// Cette fois, nous avons fait le tour des annotations JUnit 5 les plus importantes.
// Il est temps d'aborder un sujet nouveau et central de ce chapitre, à savoir les bonnes pratiques à suivre pour savoir si vos tests sont bien unitaires et efficaces !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Appliquez le principe FIRST pour écrire de bons tests /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avez-vous déjà eu à vous occuper d’une plante ? Vous n’avez peut-être pas la main verte, mais vous avez probablement une idée des soins à donner aux plantes.
// Vous savez qu’il leur faut de l’eau, mais pas trop. Vous savez qu’elles ont besoin de lumière.
// Quoi d’autre ? De la terre ? En fonction de la plante, vous vous souviendrez de certains principes quand vous en aurez besoin. Ce ne sont pas des règles, mais plutôt des lignes directrices.
// Le développement de logiciels a beaucoup de grands principes pour vous aider à éviter les erreurs bêtes et à écrire du meilleur code.
// Deux grands ingénieurs, Tim Ottinger et Brett Schuchert, qui ont écrit certains chapitres du livre Clean Code (en anglais), ont inventé un acronyme.
//      --> Celui-ci décrit les principes qu’ils utilisent pour enseigner comment écrire d’excellents tests : F.I.R.S.T..
// -----------
//  - F pour fast (rapide) :
// Qu’appelle-t-on rapide ? Vous devriez viser de nombreuses centaines ou milliers de tests par seconde. Cela vous semble trop ? Pas si chaque test unitaire ne teste qu’une classe.
// Vous saurez si votre test n’est pas assez rapide une fois que vous l’aurez lancé ! D’après Tim Ottinger, même un quart de seconde est péniblement lent.
//      --> Les tests peuvent s’accumuler – surtout si vous en avez des milliers !
// Le travail avec des fichiers ou la communication par un réseau peuvent sérieusement ralentir vos tests.
// C’est pour cela qu’il est utile d’utiliser des remplacements nommés mocks (simulacres). Nous les explorerons plus en profondeur un peu plus loin dans cette partie.
//      --> Votre IDE permet de vérifier les temps d'exécution des tests.
// Si vous subissez des ralentissements à cause d'accès réseau ou disque, essayez d’en faire abstraction en utilisant des mocks !
// -----------
//  - I pour isolé et indépendant :
// Avez-vous déjà eu à résoudre un problème complexe en le divisant en petites entités sur lesquelles vous pouviez travailler séparément ?
// Parfois, cela aide à rester concentré et à résoudre les problèmes.
//      --> Un problème ==> une cause du problème ==> une solution. C’est pareil pour les tests. Quand ils échouent, il vous faut comprendre pourquoi.
// Les principes AAA ou GIVEN/WHEN/THEN que nous avons vus précédemment dans ce cours peuvent vous aider ici :
//      --> Chaque test organise sa propre classe de sous-tests, et ne fait qu’une assertion par test.
// Cela garantit que vos tests utilisent des données séparées : vous pouvez les isoler pour qu’ils n’interfèrent pas les uns avec les autres.
// Il y a très peu de recoupements à partir de là, vos tests restent donc indépendants.
// Si en essayant d’avoir une seule assertion par test, vous vous retrouvez à créer plus de deux ou trois tests pour chaque action, demandez-vous si vos tests en font trop.
// Un bon moment pour changer cela est lorsque vous faites du TDD.
// Voici un exemple de tests simples qui ne respectent pas l'isolation :
//                  public class CalculatorTest {
//                  private Calculator calculatorUnderTest;
//                  private int cacheFactorial;
//                  @Test
//                  public void fact12_shouldReturnsTheCorrectAnswer() {
//                      // GIVEN
//                      final int number = 12;
//                      // WHEN
//                      // Calculer 12! et sauve la valeur pour un autre test
//                      cacheFactorial = calculatorUnderTest.fact(number);
//                      // THEN
//                      assertThat(cacheFactorial).isEqualTo(12 * 11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2);
//                  }
//                  @Test
//                  public void digitsSetOfFact12_shouldReturnsTheCorrectAnswser() {
//                      // GIVEN
//                      // 12! est mis en cache par le test précédent
//                      // WHEN
//                      final Set<Integer> actualDigits = calculatorUnderTest.digitsSet(cacheFactorial);
//                      // THEN
//                      assertThat(actualDigits).containsExactlyInAnyOrder(0, 1, 4, 6, 7, 9);
//                  }
//              }
// Si le premier test échoue pour n'importe quelle raison ou que l'ordre des tests est changé, le deuxième test peut aussi être impacté !
// En effet, la variable 'cacheFactoria' (ligne 5) est affectée d'une valeur au premier test (ligne 14) puis un deuxième test s'appuie sur cette valeur pour qu'il soit en succès (ligne 27).
// Vous voulez rendre votre test reproductible et éviter d’avoir des effets de bord, c'est-à-dire un état de votre système à tester qui change et dont le changement se répercute sur d'autres tests.
// Pour cela, pendant l'étape 'Arrange' ou 'Given', vous devez vous assurer de commencer vos tests avec une nouvelle instance de votre système et des données dédiées à chacun de vos tests.
// Comme vous pouvez le voir, les tests peuvent facilement échouer pour des raisons externes quand ils sont liés par une dépendance partagée.
// Contrairement au code de l'application, lorsque vous testez, il peut être acceptable de vous répéter, si cela préserve l’isolement de vos tests.
// -----------
//  - R pour répétable :
// Si vous écrivez un test qui vous donne la confiance nécessaire en votre code, il doit vous dire la même chose, peu importe où, ou combien de fois, vous l’exécutez.
//      --> Mais parfois les tests deviennent instables et doivent être lancés plusieurs fois pour réussir.
// Par exemple, l'utilisation du "hasard", c'est-à-dire utiliser des nombres ou des chaînes de caractères aléatoires, peut provoquer des comportements inattendus pour vos tests.
// Sur l'exemple de notre calculateur, cela peut consister à utiliser des nombres aléatoires pour le test suivant : multiplier par un nombre puis diviser par ce même nombre redonne le nombre de départ :
//                  @Test
//                  public void multiplyAndDivide_shouldBeIdentity() {
//                      // GIVEN
//                      final Random r = new Random();
//                      final int a = r.nextInt() % 100; // Nombre aléatoire entre 0 et 99
//                      final int b = r.nextInt() % 10; // Nombre aléatoire entre 0 et 9
//                      // WHEN on multiplie a par b puis on divise par b
//                      final int c = calculatorUnderTest.divide(calculatorUnderTest.multiply(a, b), b);
//                      // THEN on ré-obtient a
//                      assertThat(c).isEqualTo(a);
//                  }
// Ce test fonctionne... sauf si ce nombre utilisé pour multiplier et diviser est 0 ! (variable b à la ligne 6). Auquel cas, le test va échouer à cause d'une exception de division par zéro !
// Vos tests doivent aussi être reproductibles quel que soit l'environnement d'exécution.
// En général, votre application, et a fortiori vos tests, ne dépendent pas du système sur lequel ils sont exécutés (Windows, Linux, OSX), ni de l'encodage ou des paramètres locaux du système.
// Voici un exemple de code non reproductible à cause de paramètres liés au système. Voyons cela avec JShell.
// Pour formater un nombre, si vous êtes sur un système configuré pour être français, avec JShell, vous devriez obtenir ces résultats :
//                  jshell> String.format("%,d", 123456789);
//                  $1 ==> "123 456 789"
// Mais si votre système est américain, ou que vous simulez un système américain avec la commande :
//                  jshell -R-Duser.language="us-US"
// Vous obtiendrez un résultat différent pour le formatage des nombres !
//                  jshell> String.format("%,d", 123456789);
//                  $1 ==> "123,456,789"
// Il existe beaucoup d'exemples comme celui-ci : formatage des caractères de fin de ligne, encodage du système par défaut, formatage des dates, etc.
// -----------
//  - S pour self-validating (autovalidation) :
// Ce terme a clairement été inventé par un groupe d’ingénieurs. Levez la main si vous pensez savoir ce que l’autovalidation signifie.
// Cela signifie en fait que l’exécution de vos tests ne laisse aucun doute sur leur succès ou leur échec.
// JUnit accomplit cela et échoue en rouge, ce qui vous laisse faire le rouge-vert-refactor. De plus, l’échec acceptable n’existe pas, contrairement à ce que l’on entend parfois.
// Si un test n’est pas fiable, il ne doit pas être exécuté. C’est pour cela que nous pouvons utiliser '@Disabled' temporairement ! Voire supprimer le code du test.
// Grâce à Git ou tout autre système de versionnement de code, vous pouvez vous permettre de supprimer des portions de code que vous estimez inutiles.
// Si vous vous trompez, il suffit de reconsulter l'historique du code et de réhabiliter ce qui a été effacé.
//      --> Évitez donc de commenter des tests inutiles ou nuisibles, et n'utilisez '@Disabled' que temporairement.
// En utilisant un framework de test comme JUnit, des bibliothèques d’assertions, et en écrivant des tests spécifiques, vous pouvez garantir qu’en cas d’échec d’un test, vous aurez des rapports clairs.
// Des rapports qui seront donc clairs et sans ambiguïté qui vous diront exactement ce qui a réussi ou échoué.
// En complément, nous avons vu en première partie qu'utiliser AssertJ vous aide aussi à obtenir des rapports encore plus clairs grâce à des assertions plus sémantiques.
// Il peut encore rester des cas limites de test avec des résultats ambigus, en voici un exemple.
// Toujours sur le formatage des nombres, si on s'assure que l'application formate un résultat au format français :
//              @Test
//              public void format_shouldFormatAnyBigNumber() {
//                  // GIVEN
//                  int number = 1234567890;
//                  // WHEN
//                  String result = solutionFormatter.format(number);
//                  // THEN
//                  assertThat(result).isEqualTo("1 234 567 890");
//              }
// Si vous copiez-collez ce code ci-dessus, votre test va échouer.
// L'explication de l'échec du test n'est pas très parlante, au contraire !
// On pourrait passer des heures à chercher à comprendre, ou bien utiliser '@Disabled' que l'on a vu au chapitre précédent, pour jeter l'éponge !
// Dans ce cas précis, il se trouve que les caractères espaces entre les triplets de chiffres ne sont pas des espaces standard. Si vous copiez-collez le code ci-dessous :
//              @Test
//              public void format_shouldFormatAnyBigNumber() {
//                  // GIVEN
//                  int number = 1234567890;
//                  // WHEN
//                  String result = solutionFormatter.format(number);
//                  // THEN
//                  // Attention les espaces entre les chiffres ci-dessous ne sont pas standards.
//                  assertThat(result).isEqualTo("1 234 567 890");
//              }
// Votre test va passer en succès. Bizarre, non ? Évitez donc de perdre trop de temps avec ce genre de tests, source de confusion, ou commentez votre code pour bien expliquer !
// -----------
//  - T pour thorough :
// Tout d’abord, d’après Clean Code, le T représentait au début « timely », ou opportun.
// L’idée était que vos tests devraient être écrits au plus près possible du moment où vous écrivez le code.
// En écrivant vos tests quand vous écrivez votre code, le test et le code peuvent être conçus pour respecter le F.I.R.S.T.
// Dans son livre Clean Code, Tim Ottinger écrit :
// « Les tests post-facto demandent aux développeurs d’avoir le courage de refactorer du code qui fonctionne, jusqu’à obtenir une série de tests qui satisfont aux principes FIRST. »
// Si vous commencez par tester, vous êtes prêt à tester votre code de façon approfondie, car il a été conçu pour cela.
// C'est le principe même du TDD, que nous avons déjà abordé. Voire lors de l'écriture du test selon le principe AAA, c'est de commencer par l'assertion, puis coder le test.
// Aujourd’hui, on considère souvent que le T signifie approfondi (« thorough »), c’est-à-dire que votre code est testé largement pour des cas négatifs et positifs.
// Étant donné que la meilleure manière d’écrire des tests approfondis est de s’assurer d’avoir écrit du code largement testable, ces deux aspects tendent vers le même résultat.
// Pour piloter la conception de votre code avec le TDD, et établir la base de votre pyramide de tests, posez-vous certaines des questions suivantes :
//      --> Est-ce que j’ai un test de scénario nominal pour chaque cas que j’ai codé ?
//      --> Est-ce que j’ai pensé aux scénarios alternatifs et cas limites ? Et si la date de naissance d’un vampire était après sa mort, en raison de sa résurrection ?
//              Est-ce que mon système pourrait le gérer ? En supposant que vous travaillez en Transylvanie ?
//      --> Est-ce que chacune de mes exceptions lancées est testée ?
//      --> Est-ce qu’il existe un scénario où, sans changer le type de données utilisé dans mon test, je peux causer un comportement inattendu ?
//              Que se passera-t-il si je passe une chaîne nulle ou vide ?
//      --> Est-ce que j’ai pensé à la sécurité en priorité ? Malheureusement, ce point est toujours le dernier de la liste.
//              Est-ce que ce code peut uniquement être exécuté par les utilisateurs qui ont le droit de le faire ? Et si ce n’est pas le cas ?
// Le fait de vous poser ces questions, et de combiner vos tests avec les autres étages de la pyramide, peut vous donner l’assurance que vous avez été aussi exhaustif que possible.
// Rappelez-vous que ces principes sont là pour vous guider.
// À mesure que vous faites des choix dans la conception de votre produit, vous pouvez vous reposer sur eux pour vous rappeler ce que vous devez prendre en compte.
// Les bons tests vous apportent sans cesse des points positifs, alors que les mauvais tests deviennent des éléments auxquels vous ne pouvez pas vous fier.
//      --> Si vous suivez l’acronyme F.I.R.S.T., vous réunissez les conditions pour vous assurer une fondation solide de la pyramide de tests.
// -----------
//  - Quelques exemples concrets :
// Dans le screencast ci-dessous, nous allons analyser quelques exemples de tests ne respectant pas le principe F.I.R.S.T et trouver des solutions.
// Le code de départ de ce screencast se trouve sur le même dépôt Git.
//      --> Si vous n'avez pas encore cloné ce dépôt, voici pour rappel la commande : git clone https://github.com/geoffreyarthaud/oc-testing-java-cours.git.
//      --> Et choisissez la branche correspondant à ce chapitre : git checkout p2ch3.
// -----------
//  - Nommez vos tests unitaires :
// Les conventions de nommage sont indissociables du F.I.R.S.T. et sont extrêmement importantes pour construire du code lisible.
//      --> Comment décider du nom que vous allez donner à votre test unitaire ?
// Le nom de la classe est facile : vous groupez généralement vos tests par CUT (classe sous test), donc la classe de test et la classe portent des noms correspondants.
//      --> Par exemple, MyClassTest testerait MyClass. Facile, non ? Mais qu’en est-il des noms de méthode ?
// Pendant longtemps, les développeurs (et en particulier les développeurs Java), avaient l'habitude de suivre cette même convention en écrivant les tests unitaires.
// Qu’est-ce que la méthode 'testAdd()'' vous dit sur le test ? Eh bien, vous savez qu’elle teste le « add » (addition), mais est-ce une assertion de bon ou de mauvais chemin ?
// Est-ce que je teste les nombres négatifs, positifs, ou est-ce que je vérifie simplement que la méthode existe ?
// De façon plus importante, est-ce qu’elle prouve les cas de tests sur lesquels je travaille ?
// Le nom du test ne me permet pas de le savoir, donc je ne serai absolument pas plus avancé si le test échoue !
// Les développeurs ont créé de nombreuses conventions de nommage pour les tests.
//      --> En Java, on utilise généralement le « camel case », qui est un mélange de 'lettresEnMajusculesEtEnMinusculesSansUnderscore'.
// Néanmoins, quand vous écrivez des tests, votre objectif est de communiquer avec d’autres personnes, et d’obtenir des résultats de test dont vous pouvez discuter dans la vraie vie.
// On a souvent besoin d'exprimer plusieurs éléments au travers du titre. Par exemple, décrire chaque étape de 'Arrange/Act/Assert' ou 'Given/When/Then'.
// Ce que l'on peut faire, c'est du camel case pour chaque élément à décrire et les lier par des caractères underscore.
// Voici quelques exemples, choisissez ce qui vous convient, tant que vous restez cohérent et descriptif :
//                  MethodName_StateUnderTest_ExpectedBehavior.
//                      --> Exemple : add_twoPositiveIntegers_returnsTheirSum().
//                      --> Variante : Add_TwoPositiveIntegers_ReturnsTheirSum().
// Note : Ceci n’est pas du “camel case”, vous pouvez donc décider si vous mettez une capitale à chaque nouvel élément ou non.
//                  MethodName_ExpectedBehavior_StateUnderTest.
//                      --> Exemple : add_returnsTheSum_ofTwoPositiveIntegers().
//                      --> Variante : Add_ReturnsTheSum_OfTwoPositiveIntegers().
//                  givenStateUnderTest_whenMethodAction_thenExpectedBehavior.
//                      --> Exemple : givenTwoPostiveIntegers_whenAdded_thenTheyShouldBeSummed.
//                      --> Variante : givenTwoPositiveIntegerWhenAddedThenTheyShouldBeSummed().
// Pour rappel, ce ne sont que quelques exemples des nombreux styles que vous pouvez trouver !
// Le but sous-jacent de tous ces styles de nommage est de garantir que vous communiquiez clairement sur ce sur quoi portent vos tests.
// Vous avez déjà vu que JUnit5 vous permet d’utiliser l’attribut @DisplayName pour mieux nommer vos tests.
// Cela vient en complément d’un bon nom de méthode, et vous permet de vous assurer que vous communiquez clairement sur ce que vous testez.
//      --> Quoi que vous choisissiez, ou trouviez dans un projet, souvenez-vous d’être cohérent.
// -----------
//  - En résumé :
// Assurez-vous que vos tests portent des noms qui décrivent clairement ce qu’ils testent. Choisissez un style et tenez-vous à celui-ci !
// Utilisez les principes F.I.R.S.T. pour que vos tests demeurent :
//      - Fast (Rapide) : Une demi-seconde, c’est déjà trop lent.
//          Vous avez besoin que des milliers de tests soient exécutés en moins de quelques secondes.
//      - Isolé et indépendant : Quand un test échoue, il vous faut savoir ce qui a échoué.
//          Testez un élément à la fois et n’utilisez plus d’une assertion que s’il le faut vraiment.
//      - Répétable : Vous ne pouvez pas vous fier aux tests qui échouent certaines fois et réussissent d’autres.
//          Vous devez construire des tests qui n’interfèrent pas les uns avec les autres et qui sont assez autonomes pour donner toujours le même résultat.
//      - Self-validating (Autovalidation) : Utilisez les bibliothèques d’assertions disponibles, écrivez des tests spécifiques, et laissez votre framework de test s’occuper du reste.
//          Vous pouvez vous y fier pour exécuter vos tests et générer des rapports de tests clairs.
//      - Thourough (Approfondi) : Utilisez le TDD et écrivez vos tests en écrivant votre code.
//          Explorez toute la gamme d’actions possibles de votre méthode et écrivez beaucoup de tests unitaires.
// --> La dernière lettre T mérite qu'on s'y attarde un peu plus. En effet, il est important que vous maîtrisiez la manière de tester différents scénarios, et en particulier les cas limites. Ça se passe... au prochain chapitre !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Améliorez la conception de vos classes en vous protégeant d'événements inattendus /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Avez-vous déjà été sûr à 100 % des horaires d’ouverture d’un restaurant précis ? Vous y êtes allé des millions de fois.
// Puis, un jour férié, vous avez faim et vous voulez aller y manger, mais vous vous apercevez soudainement que vous ne savez pas s’il est ouvert ou non !
// L’écriture d’un test pour les cas qui sortent de l’ordinaire permet d'anticiper des situations exceptionnelles.
// Ainsi, vous éviterez d’être surpris par des échecs inattendus après la mise en service ! Vous vous souvenez de l'exemple de la fusée Ariane du premier chapitre ?
// Vous voulez disposer de tests unitaires de qualité, n’est-ce pas ?
// Cela implique de prendre en compte une gamme de situations inhabituelles dans lesquelles votre application pourrait être utilisée, et de les tester.
// Comment les envisager ? Les testeurs qui nous ont précédés y ont pensé, et il existe de nombreux types de scénarios inattendus différents à prendre en considération quand on écrit des tests.
// -----------
//  - Tirez parti des cas limites pour les scénarios alternatifs :
//          Les cas limites (ou « edge cases » en anglais) sont des cas de test conçus pour gérer l’inattendu à la limite de votre système et de vos limites de données.
//          --> Quelle est la limite de notre système ? Et pourquoi parlons-nous de limites de données ?
//          C’est ce qui arrive lorsque les données avec lesquelles vous travaillez correspondent aux cas les plus extrêmes de vos règles métiers ou des types de données Java.
//      - Cas limites dus aux règles métiers :
//          Les règles métiers (ou règles de gestion) permettent de traduire le besoin du client pour un produit en exigence claire, que le développeur va pouvoir coder.
//          Imaginez que vous travailliez pour une entreprise qui propose de la musique en streaming sur Internet.
//          Pour pouvoir écouter de la musique sans interruptions publicitaires pénibles, vos utilisateurs auront peut-être besoin d’un abonnement payant pour le mois en cours.
//          Aussi existe-t-il peut-être des quotas sur le nombre de chansons qui peuvent être écoutées simultanément. Ce sont des exemples de règles métiers.
//              --> Que se passerait-il si un utilisateur lançait une chanson longue de deux minutes, une minute avant l’expiration de son abonnement ?
//              --> Que se passerait-il si deux chansons étaient lancées presque au même moment, l’utilisateur écouterait-il les deux ?
//          Les règles métiers doivent répondre à ce genre de cas limite, et coder des tests pour ces exemples-là permet d'enrichir vos scénarios alternatifs.
//      - Cas limites dus aux limitations techniques et physiques :
//          En principe, votre système sait gérer les nombres entiers de base, le fameux type int ou Objet Integer en Java.
//          Le plus grand nombre positif qu’un tel type peut contenir est environ 2,147,483,647. Ce nombre spécial est stocké dans 'Integer.MAX_VALUE'.
//          Si vous développiez un calculateur, que se passerait-il d’après vous si vous ajoutiez 1 à cette valeur ? 1 de plus que le maximum ? Ce type de cas limite est une condition limite.
//          Le simple fait d’ajouter 1 au nombre le plus élevé peut, de façon contre-intuitive, donner un nombre négatif très bas. Vous ne me croyez pas ? Prouvons-le !
//          Au début de ce cours, je vous ai précisé que je travaillais avec AdoptOpenJDK 11. Mais les exemples jusqu'ici fonctionnaient aussi avec une JDK 8.
//          Ici, nous allons utiliser la ligne de commandes JShell, qui nécessite une JDK 9 ou plus récent. AdopOpenJDK 11 fonctionnera donc parfaitement ici.
//          JShell est une interface interactive de lignes de commandes pour coder en Java sans avoir à compiler les fichiers au préalable.
//          Pour voir ce qu’en pense Java, utilisez JShell. Voici un exemple de ce que vous pourriez voir. La valeur de la deuxième ligne après est la réponse à Integer.MAX_VALUE +1. :
//                  jshell> Integer.MAX_VALUE
//                      $1 ==> 2147483647
//                  jshell> Integer.MAX_VALUE + 1
//                      $2 ==> -2147483648
//              --> C’est un nombre négatif très bas ! Je n’ai ajouté qu’1 ! Comment votre calculateur doit-il gérer cela ?
//          Voilà une nouvelle question à poser au responsable de votre produit (le product owner si vous travaillez en pratique agile).
//          Vous pourriez utiliser le type Long, mais cela ne ferait que reporter le problème au nombre 'Long.MAX_VALUE' (qui vaut certes la valeur respectable de 9 223 372 036 854 775 807 ).
//          Java propose aussi un classe BigInteger, qui vous permet de vous affranchir de toute limite !
//              --> Magique, non ? Mais attention aux performances sur les très grands nombres ! C'est le prix de la magie.
//          Voici un exemple qui fonctionne aux limites :
//                  jshell> Integer.MAX_VALUE + 1
//                      $1 ==> -2147483648
//                  jshell> Long.MAX_VALUE + 1
//                      $2 ==> -9223372036854775808
//                  jshell> BigInteger.valueOf(Integer.MAX_VALUE).add(BigInteger.ONE)
//                      $3 ==> 2147483648
//                  jshell> BigInteger.valueOf(Long.MAX_VALUE).add(BigInteger.ONE)
//                      $4 ==> 9223372036854775808
//          Avec BigInteger, la syntaxe est moins agréable, certes, mais cela peut répondre à la règle métier, et vous pouvez imaginer assez vite le test JUnit à coder !
//      - Comment trouver de bons cas limites à tester ?
//          Voici de bonnes questions à poser lorsque l’on recherche des cas limites :
//              --> Quelle serait une valeur saugrenue à passer dans cette méthode, qui serait néanmoins légalement permise par son type défini ?
//                      Par exemple, passer une chaîne nulle, vide, ou incroyablement longue à Integer.parseInt(String) ?
//              --> Mon application fonctionnera-t-elle encore dans quelques années ?
//                      Est-ce que mes règles business autorisent des volumes de data croissants (par exemple d’en collecter davantage) ?
//                      Est-ce que j’ai des compteurs ou des chaînes qui vont évoluer jusqu’à poser problème par la suite ?
//              --> Si vous écrivez une méthode, demandez-vous : « Que pourrais-je essayer de faire pour la casser ? ».
//                      Cela nécessite-t-il des arguments que je pourrais essayer de passer avec des valeurs inhabituelles ?
//                      Comme des valeurs nulles, des objets mal configurés, ou des chaînes vides, par exemple.
//              --> Dois-je coder avec un degré de précision défini pour mes cas de test (par exemple, exactitude à deux décimales près) ?
//                      Comment doit se comporter mon code s’il doit arrondir plusieurs fois ? Par exemple, diviser par deux et arrondir ; @Test diviser par deux et arrondir à nouveau.
//                      Serait-il toujours assez précis ?
//          Quand vous commencez à tester vos cas limites, souvenez-vous que s’ils échouent et qu’il n’y a pas de solution, vous pouvez trouver une façon élégante de gérer l’échec.
//          Discutez-en toujours avec votre équipe et votre responsable de produit. Vous n’avez pas la prérogative de décider tout seul de ce qui va se passer.
// -----------
//  - Utilisez des cas pathologiques pour vos scénarios alternatifs :
// Avez-vous déjà passé une très mauvaise journée ? L’une de celles où tout semble s’être ligué contre vous ? Votre train a peut-être été retardé, ou vous étiez coincé dans les bouchons ?
// Votre café du matin vous est peut-être tombé des mains tout seul ? Même Internet est contre vous !
// Votre produit doit fonctionner dans ce même monde réel, rempli d’imperfections et de problèmes.
// Quand vous publiez votre code, il sera exécuté sur n'importe quelle machine, loin de votre ordinateur.
// Des imprévus peuvent survenir. La bonne exécution de votre produit peut dépendre de la connectivité du réseau intranet ou Internet.
// Elle peut aussi dépendre indirectement du système d’exploitation sur lequel votre JVM fonctionne. Si vous y réfléchissez, il y a de nombreux éléments en jeu.
// De temps en temps, l’un d’entre eux rencontrera des problèmes, malgré tous vos efforts.
//      --> Les cas pathologiques (ou corner cases) ont lieu lorsque plusieurs cas limites se présentent ou se mélangent avec des dysfonctionnements extérieurs évoqués précédemment.
// On ne peut pas toujours prévoir, mais vous pouvez poser des questions qui vous aideront à tester votre code pour des situations susceptibles d’affecter votre capacité à respecter vos engagements.
// Ci-dessous, vous trouverez quelques questions à poser lorsque l’on recherche des cas pathologiques.
// Pour rappel, tous les cas pathologiques ne sont pas à tester. Votre but est d’en identifier quelques-uns, puis de prioriser ceux que vous devez gérer. Voyez :
//      --> Qu’advient-il des données de mes utilisateurs si mon programme crashe ? Reste-t-il des données incomplètes quelque part ? Est-ce que cela pose problème ?
//      --> Mon code risque-t-il de violer certaines obligations légales ?
//      --> Mon code risque-t-il de violer des promesses ou accords d'affaires ?
//      --> Comment mon programme gère-t-il les problèmes externes ?
//      --> Et s’il y avait une panne du réseau imprévisible ?
//      --> Et si le serveur se trouvait à court d’espace disque ?
//      --> Et s’il y avait un problème avec l’un des services dont nous dépendons ?
//      --> Que se passe-t-il si mon utilisateur fait deux fois la même chose ?
//              --> Mon programme se comportera-t-il comme prévu ?
//              --> Que doit-il faire ?
//      --> Si d’autres services dont je dépends (comme une base de données ou Google) deviennent lents, qu’advient-il du reste de mon logiciel ?
// Vous vous poserez beaucoup d’autres questions en fonction de votre application.
//      --> Il n’y a pas de règle immuable pour envisager les cas pathologiques, mais le brainstorming autour de différentes situations est une façon de vous aider à trouver les questions à poser.
// -----------
//  - En résumé :
//      --> Les tests de cas limites (« edge cases ») sont des tests conçus pour vérifier l’inattendu aux limites de votre système et de vos limites de données.
//      --> Les tests de cas pathologiques (« corner cases ») testent des situations improbables dans lesquelles votre application pourrait se retrouver.
// Prenez en compte vos règles métiers et limites techniques pour vous guider dans la définition des cas de tests improbables.
// Après avoir vu en détail comment tester de manière approfondie, il est temps de passer à une pratique encore un peu plus avancée des tests unitaires.
//      --> En particulier par l'utilisation d'objets de simulation, ou "mocks" en anglais.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Simulez des composants externes aux tests avec Mockito ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Un punching-ball, un mannequin de crash-test, et un simulateur de voiture de course. Qu’ont en commun ces trois éléments ?
// En plus de recevoir des coups, ils remplacent quelque chose de réel. Par exemple, un punching-ball vous permet de vous entraîner à la boxe sans avoir à frapper quelqu’un.
// Un  mannequin de crash-test permet aux ingénieurs de mesurer la sécurité de leur voiture sans blesser de vraies personnes.
// Un simulateur de voiture de course vous permet d'incarner un coureur automobile mondialement connu en toute sécurité, et avec de nouvelles tentatives illimitées !
// Dans les tests logiciels, on utilise généralement un acteur de substitution qui joue le rôle de la classe que vous avez besoin d’utilise.
// C’est ce qu’on appelle un test double en anglais (doublure de test). Le principe, c'est d'utiliser du code qui prétend être l’élément dont vous avez besoin pour vos tests.
//      --> Les mocks (simulacres en français) sont les tests doubles les plus utilisés pour les tests unitaires.
// Imaginez un matériau magique que vous pourriez transformer en punching-ball ou en mannequin de simulation d’impact.
// Les mocks sont très polyvalents quand il s’agit de prétendre être d’autres classes et interfaces, en écrivant très peu de code !
// Choisissez l’élément que vous voulez simuler, définissez-le, et dites « presto » !
// Ils vous permettent aussi de vérifier comment le mock a été utilisé à l'exécution, pour que vous soyez sûr que la simulation ait été suffisamment convaincante.
// -----------
//  - Comprenez la nouvelle architecture du calculateur :
// Jusqu'à présent, nous avons effectué des tests unitaires sur la classe Calculator.
// Pour vous montrer l'intérêt des mocks, nous avons besoin d'une architecture de code plus complexe. La voici :
//      - La classe existante Calculator est toujours là pour effectuer les calculs directs.
//      - La classe CalculationModel contient les données de calcul.
//      - L'interface CalculatorService utilise CalculationModel pour déclarer une méthode de calcul.
//      - La classe CalculatorServiceImpl implémente l'interface CalculatorService et utilise pour cela la classe Calculator.
//      - A la fin de ce chapitre, l'interface SolutionFormatter offre un service pour formater la réponse à un calcul.
//          Elle est implémentée par la classe SolutionFormatterImpl, et sera utilisée par la classe CalculatorServiceImpl.
//              --> Pourquoi une telle architecture, alors que les fonctionnalités paraissent simples ?
// Nous n'allons pas rentrer dans les détails, car ce n'est pas l'objet du cours. Pour simplifier, cette architecture répond à deux exigences :
//      --> Chaque classe est responsable d'une seule tâche. Ici, on ne met pas dans la même classe les tâches de calcul, la représentation des données de calcul et la présentation du résultat.
//      --> Un service doit être construit à partir d'une interface et d'une ou plusieurs implémentations.
//              Si un service B a besoin d'utiliser un service A, alors la classe d'implémentation BImpl possède un objet faisant référence à l'interface du service A et non à une de ses implémentations.
// Grâce à cette architecture, notre système de calculateur possède plusieurs classes qui collaborent. Donc, nous allons pouvoir créer des simulacres de certaines d'entre elles.
// -----------
//  - Créez et utilisez des mocks :
// Pour mocker efficacement les objets autour de votre système à tester, voici la démarche à suivre :
//      --> Identifiez un comportement unique que vous testez avec votre classe sous-test (CUT).
//      --> Demandez-vous quelles classes sont nécessaires au comportement à tester.
//      --> Hormis votre CUT, envisagez toutes les autres classes pour le mocking.
//      --> Ne mockez pas les classes qui ne servent quasiment qu’à porter des valeurs.
//      --> Installez les mocks requis.
//      --> Testez votre CUT.
//      --> Vérifiez que vos mocks ont été correctement utilisés.
// Cette démarche s'applique pour le calculateur, selon 4 temps :
//      --> Transformation d'un test du service CalculatorService en mockant la classe du Calculator.
//      --> Vérification dans les assertions que les mocks ont été utilisés.
//      --> Configuration d'un mock pour les exceptions.
//      --> Application du TDD avec mocking pour intégrer une nouvelle classe qui formate le résultat d'un calcul.
// Comme le modèle du calculateur a été refactorisé, je vous conseille de vous placer directement dans la nouvelle branche dédiée à ce chapitre : git checkout -f p2ch4.
// -----------
//  - Installez Mockito :
// Mockito est une bibliothèque qui s'importe comme JUnit avec Maven. Dans le fichier pom.xml, ajoutez la balise dep.junit.version avec la version adaptée dans les properties :
//                  <properties>
//                      <dep.junit.version>5.5.1</dep.junit.version>
//                      <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
//                      <maven.compiler.source>11</maven.compiler.source>
//                      <maven.compiler.target>${maven.compiler.source}</maven.compiler.target>
//                  </properties>
// Puis parmi les dependencies, supprimez celle faisant référence à junit-jupiter, et remplacez-la par :
//                  <dependency>
//                      <groupId>org.junit.jupiter</groupId>
//                      <artifactId>junit-jupiter-api</artifactId>
//                      <version>${dep.junit.version}</version>
//                      <scope>test</scope>
//                  </dependency>
//                  <dependency>
//                      <groupId>org.junit.jupiter</groupId>
//                      <artifactId>junit-jupiter</artifactId>
//                      <version>${dep.junit.version}</version>
//                      <scope>test</scope>
//                  </dependency>
//                  <dependency>
//                      <groupId>org.mockito</groupId>
//                      <artifactId>mockito-junit-jupiter</artifactId>
//                      <version>3.1.0</version>
//                      <scope>test</scope>
//                  </dependency>
// Cela permet d'importer Mockito et de s'assurer que l'on garde bien la version souhaitée de JUnit 5.
// -----------
//  - Créez votre premier mock :
// Partons de la classe CalculatorService initiale. Regardez le code ci-dessous, il contient beaucoup de tests superflus :
//                  public class CalculatorServiceTest {
//                      Calculator calculator = new Calculator();
//                      // Une instance réelle du calculateur est utilisée
//                      CalculatorService classUnderTest = new CalculatorServiceImpl(calculator);
//                      @Test
//                      public void add_returnsTheSum_ofTwoPositiveNumbers() {
//                          final int result = classUnderTest.calculate(
//                                  new CalculationModel(CalculationType.ADDITION, 1, 2)).getSolution();
//                          assertThat(result).isEqualTo(3);
//                      }
//                      @Test
//                      public void add_returnsTheSum_ofTwoNegativeNumbers() {
//                          final int result = classUnderTest.calculate(
//                                  new CalculationModel(CalculationType.ADDITION, -1, 2))
//                                  .getSolution();
//                          assertThat(result).isEqualTo(1);
//                      }
//                      @Test
//                      public void add_returnsTheSum_ofZeroAndZero() {
//                          final int result = classUnderTest.calculate(
//                                  new CalculationModel(CalculationType.ADDITION, 0, 0)).getSolution();
//                          assertThat(result).isEqualTo(0);
//                      }
//                  }
// Vous voyez comment ce test utilise une instance Calculator réelle ? Ce test vérifie le fonctionnement de deux classes ici !
// De plus, étant donné que nous avons déjà dû tester Calculator dans CalculatorTest, le comportement de Calculator est vérifié une deuxième fois !
//      --> En quoi est-ce un problème ?
// Vous vous souvenez du F.I.R.S.T. et du "I" pour le principe d’isolation des tests ? Un test unitaire, une unité de code testée.
// Si ce test échoue, est-ce dû à Calculator ou CalculatorService ? Cependant, il faut savoir trouver l'équilibre entre :
//      - S'autoriser à se répéter quand on code pour tester différents scénarios alternatifs (cf. chapitre précédent).
//      - Recopier les mêmes tests, mais de manière non unitaire.
// Alors, que faire ? Demandez-vous quelle est la responsabilité de la classe CalculationService : résoudre des calculs définis par la classe de données CalculationModel.
// Vous pouvez tester vos situations selon un scénario principal et des scénarios alternatifs, sans retester la classe Calculator.
// Cette dernière n’est pas la classe que vous testez, mais un élément qui aide votre CUT à accomplir son travail.
// Cela s’appelle un collaborateur, et constitue un candidat de mock idéal.
// Nous allons donc remplacer les tests existants par un test par opération de base. D'abord, il faut déclarer Mockito comme une extension à notre classe de tests :
//                  @ExtendWith(MockitoExtension.class)
//                  public class CalculatorServiceTest {
// Ensuite, analysons ce qui doit être mocké :
//      - La classe CalculatorService est la classe à tester, on ne mocke pas.
//      - La classe Calculator est un collaborateur au service et effectue un traitement, on mocke.
//      - La classe CalculationModel porte uniquement des données en entrée et en sortie, on ne mocke pas !
// Remplaçons les déclarations de Calculator et CalculatorService par le code suivant :
//                  @ExtendWith(MockitoExtension.class)
//                  public class CalculatorServiceTest {
//                      @Mock
//                      Calculator calculator;
//                      CalculatorService classUnderTest;
//                      @BeforeEach
//                      public void init() {
//                          classUnderTest = new CalculatorServiceImpl(calculator);
//                      }
//                  }
// L'annotation @Mock déclare le mock, on n'a plus besoin d'initialiser sa valeur. Et le service est déclaré dans une méthode d'initialisation @BeforeEach, c'est plus propre.
// Ensuite, que doivent faire nos tests ? Prenons l'exemple de l'addition.
// Nous devons vérifier qu'avec un modèle de calcul d'addition, la classe Calculator est bien appelée et donne le résultat voulu :
//      --> Comme Calculator est un mock et non plus l'objet réel, on doit lui indiquer quoi faire lorsqu'il sera appelé, ce sera dans l'étape Arrange ou Given.
//      --> Ensuite, on effectue le traitement en appelant la méthode calculate, comme c'était fait dans le test initial.
//      --> Enfin, dans l'étape Assert ou Then, on vérifie le résultat mais aussi que la classe Calculator a bien été appelée.
// Après avoir ajouté la ligne d'import :
//                  import static org.mockito.Mockito.*;
// Nous obtenons le test suivant pour l'addition :
//                  @Test
//                  public void calculate_shouldUseCalculator_forAddition() {
//                      // GIVEN
//                      when(calculator.add(1, 2)).thenReturn(3);
//                      // WHEN
//                      final int result = classUnderTest.calculate(
//                              new CalculationModel(CalculationType.ADDITION, 1, 2)).getSolution();
//                      // THEN
//                      verify(calculator).add(1, 2);
//                      assertThat(result).isEqualTo(3);
//                  }
// À la ligne 4, les méthodes when et thenReturn de Mockito permettent de paramétrer le mock en affirmant que si la méthode add(1, 2) est appelée sur la classe (mockée) Calculator.
// Donc, nous retournons le résultat 3. C'est grâce à cette ligne que l'on isole bien le test du service.
//      --> Aucun échec de test ne peut venir de Calculator, car on le simule, et on indique comment simuler.
// De plus, à la ligne 11, on vérifie, grâce à la méthode verify de Mockito, que la classe (mockée) Calculator a été utilisée, en particulier la méthode add(1, 2).
// Donc, nous avons bien vérifié qu'en mettant en entrée un objet CalculationModel de type "addition", nous appelons bien la bonne méthode d'addition du calculateur.
//      --> C'est bien la responsabilité du service CalculatorService.
// -----------
//  - Paramétrez vos mocks avec des paramètres génériques :
// Jusqu'à présent, vous avez utilisé les méthodes when et verify avec des paramètres précis d'addition ou d'une autre opération du calculateur.
//      --> Mais vous pouvez aussi définir le comportement de votre mock ou vérifier l'utilisation du mock sans connaître certains paramètres.
// Par exemple, dans le test d'addition, nous aurions pu ne pas préciser les paramètres dans when, grâce à la méthode 'any()'.
// Cette méthode prend en paramètre le typage du paramètre à fixer : when(calculator.add(any(Integer.class), any(Integer.class))).thenReturn(3);.
// Cela signifie que si la méthode add du calculateur est appelée, quels que soient les paramètres, elle renverra 3 !
// De la même façon, si vous souhaitez vérifier qu'une méthode de votre mock a été appelée quels que soient les paramètres : verify(calculator).add(any(Integer.class), any(Integer.class));.
//      --> Cette assertion vérifie que la méthode add a été appelée sur le calculateur, peu importent les paramètres !
// Donc le test suivant passe avec succès, où les paramètres d'addition sont choisis au hasard :
//                  @Test
//                  public void calculate_shouldUseCalculator_forAnyAddition() {
//                      // GIVEN
//                      final Random r = new Random();
//                      when(calculator.add(any(Integer.class), any(Integer.class))).thenReturn(3);
//                      // WHEN
//                      final int result = classUnderTest.calculate(
//                              new CalculationModel(CalculationType.ADDITION,
//                                  r.nextInt(), r.nextInt())).getSolution();
//                      // THEN
//                      verify(calculator).add(any(Integer.class), any(Integer.class));
//                      assertThat(result).isEqualTo(3);
//                  }
// Il s'agit d'un exemple, mais évitez d'utiliser des paramètres au hasard pour vos tests, dans la mesure du possible.
//      --> Votre test doit être répétable (le fameux R de F.I.R.S.T.).
// Lorsque vous vérifiez l'appel d'une fonctionnalité, vous pouvez vérifier le nombre de fois que la méthode a été appelée, grâce à la méthode 'times()'.
// Dans le test précédent, vous pouvez remplacer la ligne 13 par la ligne suivante : verify(calculator, times(1)).add(any(Integer.class), any(Integer.class));.
//      --> Cette vérification est plus stricte que la précédente, car si le calculateur est appelé plus d'une fois, le test échouera !
// Vous pouvez aussi vérifier qu'une méthode n'est PAS appelée avec 'times(0)' : verify(calculator, times(0)).sub(any(Integer.class), any(Integer.class));.
// Ou avec plus de sens avec la méthode 'never()' : verify(calculator, never()).sub(any(Integer.class), any(Integer.class));.
// -----------
//  - Exceptions de mocking :
// Vous pouvez également utiliser Mockito pour configurer vos mocks afin qu'ils lancent des exceptions.
//      --> Si vous souhaitez simuler l'exception de la division par 0, vous pouvez le faire !
// Pour cela, dans l'étape Arrange/Given, il suffit de remplacer 'thenReturn()' par 'thenThrow()'.
// Par exemple, vous voulez tester que si une division par 0 a lieu, le service retourne une exception IllegalArgumentException.
// En effet, dans cet exemple, le besoin émis est que le service doit traiter l'exception ArithmeticException pour renvoyer une exception de type IllegalArgumentException. Voici le code de test :
//                  @Test
//                  public void calculate_shouldThrowIllegalArgumentException_forADivisionBy0() {
//                      // GIVEN
//                      when(calculator.divide(1, 0)).thenThrow(new ArithmeticException());
//                      // WHEN
//                      assertThrows(IllegalArgumentException.class, () -> classUnderTest.calculate(
//                              new CalculationModel(CalculationType.DIVISION, 1, 0)));
//                      // THEN
//                      verify(calculator, times(1)).divide(1, 0);
//                  }
//      --> Quelle est cette syntaxe à la ligne 7 ?
// Avec JUnit 5, il s'agit de la syntaxe pour vérifier qu'une ligne de code peut générer une exception ! Cette méthode assertThrows prend en paramètres :
//      --> La classe d'exception à laquelle on doit s'attendre.
//      --> La ligne de code sous forme de lambda. Un lambda est une possibilité de Java 8 pour intégrer une action à faire comme paramètre de méthode.
//              Ici, mettez simplement l'action à faire précédée des symboles  () ->.
// Ce test va donc vérifier à la ligne 7 que la bonne exception est lancée, mais aussi à la ligne 11 que la méthode de division a été appelée !
// -----------
//  - Appliquez le TDD avec Mockito :
// Imaginez que votre responsable vous demande de mettre à jour ce CalculationService pour qu’il puisse présenter des versions de grands nombres facilement lisibles aux utilisateurs.
// Il vous donne comme exemple d’afficher le nombre 100020 comme « 100 020 ». Voyons comment vous pouvez utiliser le TDD avec le mocking pour coder cette évolution sans régression.
//      --> C'est-à-dire sans créer des bugs à d'autres endroits de votre programme.
// Voici simplement les classes à modifier. D'abord, créez le test. La solution formatée doit être portée par la classe CalculationModel.
//                  @Test
//                  public void calculate_shouldFormatSolution_forAnAddition() {
//                      // GIVEN
//                      when(calculator.add(10000, 3000)).thenReturn(13000);
//                      // WHEN
//                      final String formattedResult = classUnderTest
//                          .calculate(new CalculationModel(CalculationType.ADDITION, 10000, 3000))
//                          .getFormattedSolution();
//                      // THEN
//                      assertThat(formattedResult).isEqualTo("13 000");
//                  }
// Pour que ce code compile, vous devez ajouter un attribut à la classe CalculationModel, ainsi que son getter/setter :
//                  public class CalculationModel {
//                      // ...
//                      private String formattedSolution;
//                      // ...
//                      public String getFormattedSolution() {
//                          return formattedSolution;
//                      }
//                      public void setFormattedSolution(String formattedSolution) {
//                          this.formattedSolution = formattedSolution;
//                      }
//                  }
// De toute façon, le test échoue (c'est rouge), car la classe CalculationModel, si elle prévoit de stocker des solutions formatées, n'est pas responsable du formatage !
// On doit alors se rendre compte que :
//      --> Le service CalculationService doit rendre un résultat formaté.
//      --> Si l'on souhaite bien modulariser son code, le formatage doit être effectué par un autre service qui sera appelé par CalculatorService.
// La classe CalculatorService dépend d'un autre service, SolutionFormatter, qui, lui, est fourni au constructeur.
// Lors du calcul, la méthode alimente la solution formatée en appelant le service SolutionFormatter :
//                  public class CalculatorServiceImpl implements CalculatorService {
//                      private final Calculator calculator;
//                      private final SolutionFormatter solutionFormatter;
//                      public CalculatorServiceImpl(Calculator calculator,
//                              SolutionFormatter solutionFormatter) {
//                          this.calculator = calculator;
//                          this.solutionFormatter = solutionFormatter;
//                      }
//                      @Override
//                      public CalculationModel calculate(CalculationModel calculationModel) {
//                          // ...
//                          calculationModel.setSolution(response);
//                          calculationModel.setFormattedSolution(solutionFormatter.format(response));
//                          return calculationModel;
//                      }
// Pour que le code compile, créons une nouvelle interface SolutionFormatter :
//                  public interface SolutionFormatter {
//                      String format(int solution);
//                  }
// Il faut ensuite modifier la classe de test du service CalculatorServiceTest. En effet, le code suivant ne compile plus :
//                  @ExtendWith(MockitoExtension.class)
//                  public class CalculatorServiceTest {
//                      @Mock
//                      Calculator calculator;
//                      CalculatorService classUnderTest;
//                      @BeforeEach
//                      public void init() {
//                          classUnderTest = new CalculatorServiceImpl(calculator);
//                      }
//                      // ...
// Car CalculatorServiceImpl a besoin d'une instance de SolutionFormatter ! Que faire ? Utilisons un mock ! L'initialisation de la classe de test devient donc :
//                  @ExtendWith(MockitoExtension.class)
//                  public class CalculatorServiceTest {
//                      @Mock
//                      Calculator calculator;
//                      @Mock
//                      SolutionFormatter solutionFormatter;
//                      CalculatorService classUnderTest;
//                      @BeforeEach
//                      public void init() {
//                          classUnderTest = new CalculatorServiceImpl(calculator, solutionFormatter);
//                      }
//                      // ...
// Et le test est complété par un when supplémentaire pour fixer le comportement du solutionFormatter mocké :
//                  @Test
//                  public void calculate_shouldFormatSolution_forAnAddition() {
//                      // GIVEN
//                      when(calculator.add(10000, 3000)).thenReturn(13000);
//                      when(solutionFormatter.format(13000)).thenReturn("13 000");
//                      // WHEN
//                      final String formattedResult = classUnderTest
//                          .calculate(new CalculationModel(CalculationType.ADDITION, 10000, 3000))
//                          .getFormattedSolution();
//                      // THEN
//                      assertThat(formattedResult).isEqualTo("13 000");
//                  }
// Et le test passe enfin ! C'est vert ! Vous comprenez la démarche ?
// Le TDD se marie avec Mockito, il s'agit juste de coder dans le bon ordre, et cela deviendra naturel avec l'expérience !
//      --> Mais où est l'implémentation de SolutionFormatter ?
// En effet, aucune implémentation n'a été codée ! Pour cela, il suffit de coder le test unitaire de SolutionFormatter.
// Et pour que le test compile et passe avec succès, il faudra évidemment implémenter l'interface SolutionFormatter !
// -----------
//  - En résumé :
//      --> Dans les tests de logiciel, on utilise habituellement un acteur de remplacement pour jouer le rôle de la classe que vous avez besoin d’utiliser.
//              Ce remplaçant s’appelle une doublure de test ou test double en anglais.
//      --> Un mock, ou une simulation, est un type de doublure de test simple à créer, et qui vous permet également de tester comment on interagit avec lui.
//      --> Mockito vous permet de définir comment vos mocks doivent se comporter (avec when) et vérifier si ces mocks sont bien utilisés (avec verify).
//      --> En faisant du TDD, vous pouvez être amené à coder des évolutions avec des services complémentaires. Mockito vous aide à pratiquer le TDD facilement grâce aux mocks.
// Vous avez découvert les rudiments de Mockito, passons maintenant à ses fonctions avancées.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez les fonctions avancées de Mockito ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous avez créé vos premiers mocks avec Mockito, sur des cas simples. Nous allons creuser un peu plus et découvrir des fonctionnalités avancées de Mockito. Allons-y !
// -----------
//  - Utilisez ArgumentCaptor pour vérifier les appels aux mocks :
// Dans le chapitre précédent, vous avez vu comment paramétrer le fonctionnement du mock grâce à la méthode 'when()'.
// Cela vous avait permis de donner un comportement simulé à la classe Calculator, par exemple pour l'addition :
//                  when(calculator.add(1, 2)).thenReturn(3);
// Vous pouviez vérifier que votre classe à tester CalculatorService utilisait bien la classe Calculator avec les bons arguments, et renvoyait le bon résultat :
//                  verify(calculator).add(1, 2);
//                  // Vérifie si la méthode add() a été appelée.
//                  assertThat(result).isEqualTo(3);
// Ici, l'exemple est simple et les arguments sont des types simples int.
// Mais si vous manipulez des classes de données plus complexes, il se peut que votre classe à tester s'occupe elle-même de créer des objets de données.
// Alors, vous ne pourrez  plus utiliser le combo 'when/verify' de l'exemple précédent, car vous ne savez pas comment la classe à tester transforme en interne ses propres données.
// Voici un exemple concret :
// Vous souhaitez mettre en place un service de calcul par lots, c'est-à-dire en mode batch.
// À partir d'un fichier ou d'une liste de chaînes de caractères contenant des opérations, vous voulez obtenir la liste des résultats des calculs.
// La responsabilité de ce nouveau service BatchCalculatorService est de :
//      --> Transformer un flux de chaînes de caractères en modèles de calcul.
//      --> Appeler la classe CalculatorService pour chaque modèle de calcul.
// Voici un exemple de test pour cette classe n'utilisant pas Mockito :
//                  public class BatchCalculatorServiceTest {
//                      BatchCalculatorService batchCalculatorServiceNoMock;
//                      @BeforeEach
//                      public void init() {
//                          batchCalculatorServiceNoMock = new BatchCalculatorServiceImpl(
//                                  new CalculatorServiceImpl(new Calculator(),
//                                  new SolutionFormatterImpl()));
//                      }
//                      @Test
//                      public void givenOperationsList_whenbatchCalculate_thenReturnsCorrectAnswerList()
//                              throws IOException, URISyntaxException {
//                          // GIVEN
//                          final Stream<String> operations =
//                              Arrays.asList("2 + 2", "5 - 4", "6 x 8", "9 / 3").stream();
//                          // WHEN
//                          final List<CalculationModel> results =
//                              batchCalculatorServiceNoMock.batchCalculate(operations);
//                          // THEN
//                          assertThat(results)
//                              .extracting(CalculationModel::getSolution)
//                              .containsExactly(4, 1, 48, 3);
//                      }
//                  }
// Remarquez déjà comment fonctionne la classe à tester. Elle prend en entrée un 'Stream<String>' et ramène en sortie une 'List<CalculcationModel>'.
// Ce test vérifie si les bons résultats sont transmis, mais ne s'occupe pas directement de la responsabilité de la classe 'BatchCalculatorService'.
// Profitez-en pour voir comment AssertJ vous simplifie la vie aux lignes 24 à 26 ! La variable 'results' contient une liste de 'CalculationModel'.
// Avec la méthode extracting, on transforme cette liste en liste de solutions, en appelant pour chaque item de la liste, la méthode 'getSolution()'.
// Ensuite, on vérifie que cette liste est égale à la liste d'arguments fournie en ligne 26. La notation de la ligne 25 utilise aussi les lambdas de Java 8.
// Alors mockons ! La mise en place du mock ne devrait pas vous poser de soucis. Gardons l'ancien test, et créons le mock :
//                  @ExtendWith(MockitoExtension.class)
//                  public class BatchCalculatorServiceTest {
//                      @Mock
//                      CalculatorService calculatorService;
//                      BatchCalculatorService batchCalculatorService;
//                      BatchCalculatorService batchCalculatorServiceNoMock;
//                      @BeforeEach
//                      public void init() {
//                          batchCalculatorService = new BatchCalculatorServiceImpl(calculatorService);
//                          batchCalculatorServiceNoMock = new BatchCalculatorServiceImpl(
//                                  new CalculatorServiceImpl(new Calculator(),
//                                  new SolutionFormatterImpl()));
//                      }
// Maintenant, nous allons vérifier que le service de calcul a bien été appelé autant de fois que nécessaire, avec les bons arguments à chaque fois.
// Au lieu d'utiliser 'when()', nous allons utiliser une classe plus générale, 'ArgumentCaptor'. Son rôle est d'enregistrer les arguments utilisés lors d'un appel de mock.
// Ici, on veut capturer les modèles de calcul utilisés pour appeler le service de calcul. Voici comment on déclare cela :
//                  final ArgumentCaptor<CalculationModel> calculationModelCaptor =
//                      ArgumentCaptor.forClass(CalculationModel.class);
// Lors de l'étape d'assertion, nous allons rapatrier tous les modèles de calcul utilisés.
// On en profite pour vérifier que la classe 'CalculatorService' a bien été utilisée autant de fois que de calculs dans le flux de données :
//                  verify(calculatorService, times(4)).calculate(calculationModelCaptor.capture());
//                  final List<CalculationModel> calculationModels = calculationModelCaptor.getAllValues();
// La variable 'calculationModels' contient donc une liste de 4 éléments correspondant chacun à un modèle de calcul utilisé à l'appel du service 'CalculatorService'.
// Il suffit alors de vérifier pour chaque classe de modèle si elle correspond à ce qui est attendu vis-à-vis du flux de données initial.
// AssertJ nous aide à coder plus rapidement, car tout de même, pour chaque modèle de calcul, il y a 3 arguments (opérande gauche, type d'opération, opérande droit).
// Cela fait 12 valeurs à vérifier pour la liste complète !
// Voici le code complet du test :
//                  @Test
//                  public void givenOperationsList_whenbatchCalculate_thenCallsServiceWithCorrectArguments()
//                          throws IOException, URISyntaxException {
//                      // GIVEN
//                      final Stream<String> operations =
//                          Arrays.asList("2 + 2", "5 - 4", "6 x 8", "9 / 3").stream();
//                      final ArgumentCaptor<CalculationModel> calculationModelCaptor =
//                          ArgumentCaptor.forClass(CalculationModel.class);
//                      // WHEN
//                      batchCalculatorService.batchCalculate(operations);
//                      // THEN
//                      verify(calculatorService, times(4)).calculate(calculationModelCaptor.capture());
//                     final List<CalculationModel> calculationModels =
//                          calculationModelCaptor.getAllValues();
//                      assertThat(calculationModels)
//                              .extracting(CalculationModel::getLeftArgument,
//                                          CalculationModel::getType,
//                                          CalculationModel::getRightArgument)
//                              .containsExactly(
//                                      tuple(2, CalculationType.ADDITION, 2),
//                                      tuple(5, CalculationType.SUBTRACTION, 4),
//                                      tuple(6, CalculationType.MULTIPLICATION, 8),
//                                      tuple(9, CalculationType.DIVISION, 3));
//                  }
// Avec AssertJ, on utilise à nouveau la méthode extracting pour extraire les données à vérifier, et nous pouvons le faire sous forme de blocs de données appelés tuple.
// Avec un peu de concentration, on se rend compte que le code est plus synthétique et plus clair qu'effectuer 12 vérifications.
// -----------
//  - Utilisez when() avec des réponses complexes :
// Dans l'exemple précédent, nous avons pu vérifier les appels au service de calcul, c'est déjà très bien.
// Mais nous n'avons pas vérifié si la méthode 'batchCalculate' de 'BatchCalculatorService' renvoie bien la liste des résultats envoyés par le service de calcul !
// Voici deux méthodes pour le faire.
// -----------
//  - La fonction de réponse :
// Jusqu'à présent, nous avons vu que 'when()' est associé à 'thenReturn()' ou 'thenThrow()'.
//      --> Mais il se peut que vouliez donner une réponse en fonction des arguments appelés, et non pas juste une réponse simple par rapport à des arguments simples.
// Dans ce cas, vous pouvez utiliser la fonction de réponse 'then()' associée à 'when()'.
// Grâce aux lambdas, nous allons donner en argument de 'then()' une action permettant de renvoyer un résultat en fonction du contenu du 'when()'.
// Dans notre exemple, pour simuler correctement le service de calcul, nous allons construire un mock qui renvoie un résultat en fonction du type d'opération.
// Si l'opération est une addition, on renvoie le modèle de calcul avec la réponse 4, et on donne un résultat différent pour chaque type d'opération.
// Cela peut revenir à créer une méthode  answer  ayant la forme suivante :
//                  public CalculationModel answer(InvocationOnMock invocation) {
//                      final CalculationModel model = invocation.getArgument(0, CalculationModel.class);
//                                      switch (model.getType()) {
//                                      case ADDITION:
//                                          model.setSolution(4);
//                                          break;
//                                      case SUBTRACTION:
//                                          model.setSolution(1);
//                                          break;
//                                      case MULTIPLICATION:
//                                          model.setSolution(48);
//                                          break;
//                                      case DIVISION:
//                                          model.setSolution(3);
//                                          break;
//                                      default:
//                                      }
//                                      return model;
//                                  });
//                  }
// La classe 'InvocationOnMock' permet de connaître les arguments de l'appel au mock.
// Ici, on souhaite connaître le type d'opération pour donner une réponse différente en fonction.
// De plus, on réutilise la classe en entrée 'CalculationModel' pour la renvoyer complétée de la réponse.
// Nous allons ensuite utiliser une syntaxe plus concise avec les lambdas. À l'étape 'Arrange/Given', on appelle :
//      --> 'when()' pour qu'il traite n'importe quel type d'arguments avec 'any()'.
//      --> Puis 'then()' pour construire la réponse sous forme de lambda.
// Cela donne le code suivant :
//                  when(calculatorService.calculate(any(CalculationModel.class)))
//                          .then(invocation -> {
//                              final CalculationModel model = invocation.getArgument(0, CalculationModel.class);
//                              switch (model.getType()) {
//                              case ADDITION:
//                                  model.setSolution(4);
//                                  break;
//                              case SUBTRACTION:
//                                  model.setSolution(1);
//                                  break;
//                              case MULTIPLICATION:
//                                  model.setSolution(48);
//                                  break;
//                              case DIVISION:
//                                  model.setSolution(3);
//                                  break;
//                              default:
//                              }
//                              return model;
//                          });
// Notre mock est capable de traiter n'importe quelle opération.
//      --> Il donnera alors la solution 4 si c'est une addition, 1 si c'est une soustraction, 48 si c'est une multiplication et 3 si c'est une division.
// Le test va ensuite vérifier que le service a bien été appelé 4 fois et que les résultats sont conformes, de la même façon qu'avec le test sur des objets non mockés :
//                  @Test
//                  public void givenOperationsList_whenbatchCalculate_thenCallsServiceAndReturnsAnswer()
//                          throws IOException, URISyntaxException {
//                      // GIVEN
//                      final Stream<String> operations =
//                          Arrays.asList("2 + 2", "5 - 4", "6 x 8", "9 / 3").stream();
//                      when(calculatorService.calculate(any(CalculationModel.class)))
//                      .then(invocation -> {
//                          final CalculationModel model = invocation.getArgument(0, CalculationModel.class);
//                          switch (model.getType()) {
//                          case ADDITION:
//                              model.setSolution(4);
//                              break;
//                          case SUBTRACTION:
//                              model.setSolution(1);
//                              break;
//                          case MULTIPLICATION:
//                              model.setSolution(48);
//                              break;
//                          case DIVISION:
//                              model.setSolution(3);
//                              break;
//                          default:
//                          }
//                          return model;
//                      });
//                      // WHEN
//                      final List<CalculationModel> results =
//                          batchCalculatorService.batchCalculate(operations);
//                      // THEN
//                      verify(calculatorService, times(4)).calculate(any(CalculationModel.class));
//                      assertThat(results).extracting("solution").containsExactly(4, 1, 48, 3);
//                  }
// Avec la fonction de réponse, vous avez le moyen le plus général pour construire une réponse sophistiquée.
//      --> Mais dans certains cas, vous pouvez aussi employer un moyen plus simple : la réponse multiple.
// -----------
//  - Alternative : la réponse multiple :
// Avec 'when()', vous pouvez donner une réponse précise ou une fonction de réponse, mais vous pouvez aussi donner plusieurs réponses.
// Le mock va alors utiliser ces réponses dans l'ordre des appels effectués :
//      - Au premier appel du mock, ce dernier renvoie la première réponse.
//      - Puis au deuxième appel, la deuxième réponse fournie.
//      - Et ainsi de suite...
//      - Au bout de la dernière réponse, le mock revient à la première réponse fournie.
// Dans notre exemple de calculateur par lots, nous pouvons utiliser ce moyen, car nous maîtrisons bien les données de test utilisées :
//      --> Le flux d'opérations sous forme de chaînes de caractères.
// Donc, si l'on a le flux de données suivant :
//                  final Stream<String> operations = Arrays.asList("2 + 2", "5 - 4", "6 x 8", "9 / 3").stream();
// Alors le mock pourra être configuré ainsi :
//                  when(calculatorService.calculate(any(CalculationModel.class)))
//                      .thenReturn(new CalculationModel(CalculationType.ADDITION, 2, 2, 4))
//                      .thenReturn(new CalculationModel(CalculationType.SUBTRACTION, 5, 4, 1))
//                      .thenReturn(new CalculationModel(CalculationType.MULTIPLICATION, 6, 8, 48))
//                      .thenReturn(new CalculationModel(CalculationType.DIVISION, 9, 3, 3));
// Il suffit de chaîner les méthodes 'thenReturn()' ! Si on avait glissé une division par zéro, on aurait pu aussi chaîner avec 'thenThrow()'.
// Le test complet devient :
//                  @Test
//                  public void givenOperationsList_whenbatchCalculate_thenCallsServiceAndReturnsAnswer2()
//                          throws IOException, URISyntaxException {
//                      // GIVEN
//                      final Stream<String> operations =
//                          Arrays.asList("2 + 2", "5 - 4", "6 x 8", "9 / 3").stream();
//                      when(calculatorService.calculate(any(CalculationModel.class)))
//                              .thenReturn(new CalculationModel(CalculationType.ADDITION, 2, 2, 4))
//                              .thenReturn(new CalculationModel(CalculationType.SUBTRACTION, 5, 4, 1))
//                              .thenReturn(new CalculationModel(CalculationType.MULTIPLICATION, 6, 8, 48))
//                              .thenReturn(new CalculationModel(CalculationType.DIVISION, 9, 3, 3));
//                      // WHEN
//                      final List<CalculationModel> results =
//                          batchCalculatorService.batchCalculate(operations);
//                      // THEN
//                      verify(calculatorService, times(4)).calculate(any(CalculationModel.class));
//                      assertThat(results).extracting("solution").containsExactly(4, 1, 48, 3);
//                  }
// Évidemment, le mock a un comportement moins général, mais ce qu'on cherche ici, c'est tester selon des scénarios précis et répétables.
// -----------
//  - Espionnez du code réel que vous ne pouvez pas simuler :
// Les mocks peuvent faire beaucoup de choses, mais Mockito ne peut pas gérer certaines situations.
//      --> Il est en particulier limité par les contraintes du langage Java.
// Ainsi, une méthode déclarée avec le modificateur 'final' ne peut pas être simulée par un mock de Mockito.
// Voici un extrait de la classe 'IntSummaryStatistics', fourni par le langage Java et qui ne peut pas être simulée par un mock :
//                  public class IntSummaryStatistics implements IntConsumer {
//                      ...
//                      @Override
//                      public void accept(int value) {
//                          ++count;
//                          sum += value;
//                          min = Math.min(min, value);
//                          max = Math.max(max, value);
//                      }
//                      ...
//                      public final double getAverage() {
//                          return getCount() > 0 ? (double) getSum() / getCount() : 0.0d;
//                      }
//                      ...
//                  }
// Imaginons un service de calcul statistique utilisant cette classe 'IntSummaryStatistics'.
//      --> Le comportement de 'getAverage()' ne pourra pas être simulé à cause du mot clé final.
// La solution consiste à utiliser une autre forme de doublure de test, la classe espion ou Spy pour Mockito.
// C'est une classe réelle qui peut être vue comme un mock partiel :
//      --> Par défaut, c'est le comportement réel qui est utilisé.
//      --> Mais l'on peut espionner les appels.
//      --> Voire modifier le comportement des méthodes qui n'ont pas le mot clé final dans leur déclaration.
// Ici la méthode 'accept', par exemple.
// Voici une brève comparaison entre espions et mocks :
// Situation                                                                Mock                                    Espion
// Créer avec l’annotation.                                                 @Mock                                   @Spy
// Créer avec une méthode.                                                  mock(RealClass.class)                   spy(RealClass.class)
// Appeler 'someMethod' après                                               Renvoie la réponse fournie.             Renvoie la réponse fournie.
//      when(someMethod)
//          .thenReturn(response)
// Appeler someMethod() que vous n’avez pas définie avec ‘when’.            Le mock renvoie un null.                La méthode originale est appelée dans la RealClass pour un résultat.
// Capturer des arguments avec ArgumentCaptor.                              verify(mock)                            verify(mock)
//                                                                              .someMethod(captor)                     .someMethod(captor)
// Simuler une méthode ou classe finale.                                    Erreur de Mockito.                      Erreur de Mockito.
// Voici un exemple concret d'utilisation. Vous souhaitez tester une classe de calcul statistique 'StatisticsCalculator', ayant cette forme :
//                  public class StatisticsCalculator {
//                      private final IntSummaryStatistics summaryStatistics;
//                      public StatisticsCalculator(IntSummaryStatistics summaryStatistics) {
//                          this.summaryStatistics = summaryStatistics;
//                      }
//                      public Integer average(List<Integer> samples) {
//                          samples.forEach(summaryStatistics::accept);
//                          // Extraire la moyenne
//                          Double average = summaryStatistics.getAverage();
//                          return average.intValue();
//                      }
//                  }
// Le test consisterait à vérifier que le calculateur prend bien en compte tous les nombres à fournir à 'IntSummaryStatistics', via la méthode 'accept'.
// Nous allons donc mocker la méthode 'accept' mais laisser la méthode 'final getAverage' telle quelle.
// Voici la syntaxe du test :
//                  @ExtendWith(MockitoExtension.class)
//                  public class StatisticsCalculatorTest {
//                      @Spy
//                      IntSummaryStatistics summaryStatistics = new IntSummaryStatistics();
//                      StatisticsCalculator underTest;
//                      @BeforeEach
//                      public void setUp() {
//                          underTest = new StatisticsCalculator(summaryStatistics);
//                      }
//                      @Test
//                      public void average_shouldSample_allIntegersProvided() {
//                          final ArgumentCaptor<Integer> sampleCaptor = ArgumentCaptor.forClass(Integer.class);
//                          final List<Integer> samples = Arrays.asList(2, 8, 5, 3, 7);
//                          underTest.average(samples);
//                          verify(summaryStatistics, times(samples.size())).accept(sampleCaptor.capture());
//                          final List<Integer> capturedList = sampleCaptor.getAllValues();
//                          assertThat(capturedList).containsExactly(samples.toArray(new Integer[0]));
//                      }
//                  }
// Dans ce test, nous avons :
//      --> Utilisé l'annotation '@Spy' au lieu de '@Mock'.
//      --> Utilisé 'ArgumentCaptor' pour capturer et vérifier les paramètres d'appel de la méthode 'accept'.
// Nous pouvons ajouter un autre test, sans mock pour vérifier que le calcul de moyenne est correct :
//                  @Test
//                  public void average_shouldReturnTheMean_ofAListOfIntegers() {
//                      final List<Integer> samples = Arrays.asList(2, 8, 5, 3, 7);
//                      final Integer result = underTest.average(samples);
//                      assertThat(result).isEqualTo(5);
//                  }
// Ce deuxième test est moins 'unitaire', dans le sens où le test couvre à la fois le calculateur statistique et la classe 'IntSummaryStatistics'.
//      --> Mais nous ne pouvons pas faire autrement à cause du modificateur final.
// Donc, les classes espions permettent de trouver des solutions lorsque le mocking n'est pas possible, mais veillez à ne pas généraliser l'utilisation des annotations @Spy !
// -----------
//  - En résumé :
//      --> Utilisez ArgumentCaptor pour capturer les arguments réels avec lesquels votre mock est appelé.
//              Cela vous permet de vérifier la conformité des appels aux mocks.
//              Et ce, en particulier lorsque votre classe de test utilise des arguments sur lesquels vous n’avez pas de visibilité directe.
//      --> Utilisez les fonctions de réponse sous forme de lambdas ou les réponses multiples avec 'when()', pour obtenir des comportements plus sophistiqués de vos mocks.
//      --> '@Spy' et 'spy()' vous permettent d’utiliser des instances réelles d’une classe, mais sur lesquelles vous pouvez utiliser 'when()' et 'verify()'.
//              Ce sont des mocks partiels. Cela se révèle nécessaire lorsque vos classes contiennent des méthodes avec le modificateur final.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Écrivez les tests d'intégration et de bout en bout ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découvrez les tests d'intégration et les tests fonctionnels ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Gravissez la pyramide : les tests d'intégration et les tests fonctionnels (ou end-to-end) :
//      --> Jusqu’ici, nous avons vérifié des composants individuels.
// Mais cela signifie que nous avons émis beaucoup de suppositions sur la façon dont ces éléments fonctionnent ensemble.
// Surtout en utilisant des mocks dès que la classe à tester avait besoin d'un autre composant.
// Nous devons maintenant nous assurer que le comportement de l'application est toujours aussi conforme, à mesure que nous assemblons les unités de code.
// Pour cela, nous allons utiliser les tests qui se trouvent au milieu de la pyramide, les tests d'intégration, et les tests au sommet de la pyramide, c'est-à-dire les tests fonctionnels.
// Sachez qu'il existe deux types de tests d'intégration : les tests d'intégration composants et les tests d'intégration système :
//      --> Les tests d'intégration composants : ils permettent de vérifier si plusieurs unités de code fonctionnent bien ensemble.
//              Dans un environnement de test assez proche du test unitaire, c'est-à-dire de manière isolée.
//              Donc sans lien avec des composants extérieurs et ne permettant pas le démarrage d'une vraie application.
//      --> Les tests d'intégration système : ils permettent de vérifier le fonctionnement de plusieurs unités de code au sein d'une configuration d'application.
//              Et ce, avec éventuellement des liens avec des composants extérieurs comme une base de données, des fichiers, ou des API en réseau.
// Passons aux tests fonctionnels de bout en bout. Ce sont des tests qui partent de l'interface utilisateur pour obtenir un résultat selon un scénario prédéfini.
// Ils imitent l'utilisateur final de l'application. Un démarrage complet de l'application est donc nécessaire.
// Ce tableau ci-dessous donne quelques exemples de chaque type de test, afin de vous aider à mieux les distinguer.
//      - Milieu :
//          --> Tests d’intégration composants.
//                  --> Est-ce que les classes que nous avons soumises aux tests unitaires fonctionnent vraiment bien ensemble ?
//                          - Nous écrivons un test JUnit qui vérifie que 'BatchCalculatorService' peut appeler des méthodes sur 'CalculatorService' et 'Calculator'.
//                              Ainsi, pour vérifier des bons et mauvais chemins représentatifs entre ces deux classes.
//      - Milieu :
//          --> Tests d’intégration système (SIT pour « System Integration Tests »).
//                  --> Comment pouvons-nous rapidement tester que notre application en fonctionnement collaborerait avec le monde extérieur ?
//                          - Un test qui utilise un de nos services pour écrire à une base de données réelle.
//                          - Un test pour une classe qui parle à un autre service, comme l’API de Google Search.
//                              Pour le rendre rapide, nous parlerions à un faux service, ou un "bouchon" avec des réponses réalistes.
//                          - Un test qui vérifie que notre configuration Spring fonctionne et que notre application pourra se lancer.
//                          - Des tests des contrôleurs de notre service web avec des requêtes simulées mais semblant réelles.
//      - Sommet :
//          --> Tests du parcours utilisateur de bout en bout.
//                  --> Comment pouvons-nous vérifier qu'un utilisateur final utilisera une application conforme et cohérente de bout en bout ?
//                          - Tester qu’un utilisateur peut se loguer dans notre système, sélectionner un type de calcul, entrer des valeurs, et les convertir correctement.
// À chaque usage un type de test. Posez-vous la question suivante : de quel test ai-je vraiment besoin dans mon cas ?
// Dans les quelques chapitres à venir, nous verrons comment écrire et implémenter chacun de ces tests à tour de rôle.
// Souvenez-vous que plus vous assemblez les unités de code, plus vous avez de composants fonctionnels à parcourir.
// Aussi, plus vos tests ralentissent et peuvent devenir fragiles face aux évolutions de code, mais ils deviennent de plus en plus réalistes globalement.
// -----------
//  - Découvrez les tests d’acceptation durant votre ascension :
// En complément des tests d'intégration et des tests fonctionnels, vous pouvez effectuer des tests d'acceptation.
//      --> Ils abordent un autre point de vue : il s'agit de vérifier directement une exigence métier, exprimée par le client, un expert fonctionnel le représentant.
// Traditionnellement, les tests d’acceptation manuels étaient les derniers à être testés, et toujours au sommet de la pyramide sur un système qui fonctionne.
// Certains pensent que leur place est toujours là dans le monde automatisé, mais les tests manuels effectués à la fin sont extrêmement lents.
// C'est pour cette raison que de nombreuses équipes choisissent d'écrire des tests d'acceptation qui se trouvent au même niveau de la pyramide que les tests d'intégration.
//      --> Les frameworks modernes, tels que Spring et Cucumber, facilitent leur écriture dans cette configuration.
// Sachez que les tests d’acceptation sont une grande source de confusion pour de nombreux développeurs.
//      --> Est-ce que ce sont des tests d’intégration système ? Oui.
//      --> Est-ce que ce sont des tests de bout en bout ? Oui.
//      --> Et qu’en est-il des tests unitaires ? Il y a de nombreuses opinions fondées sur les modèles différents que vous verrez dans différentes équipes de développement.
// Cela signifie que nous en sommes encore à émettre des suppositions sur l’utilisateur. Ne devrions-nous pas utiliser uniquement des tests de bout en bout ?
// À la base, les tests d’acceptation peuvent être implémentés de plus d’une façon. Vous n’avez pas besoin d’utiliser exclusivement des tests de bout en bout.
// De fait, il est peu probable que vous le fassiez.
// Martin Fowler, l’un des fondateurs du mouvement Agile et qui soutient l'approche de la pyramide de test, décrit les tests d’acceptation de façon transversale à la pyramide de test :
//      --> « Il est bon de comprendre qu’il n’y a pas de nécessité technique à écrire les tests d’acceptation au sommet de la pyramide de test.
//              Si la conception de votre application et le scénario en cours vous permettent d’écrire un test d’acceptation à un niveau inférieur, allez-y.
//              Il est préférable de disposer d’un test de bas niveau plutôt que d’un test de haut niveau. »
//      --> Autrement dit, vos tests d'acceptation doivent se dérouler aussi vite que possible, et vous devez utiliser des tests automatisés au niveau le plus bas possible de la pyramide.
// Ainsi, vous obtiendrez un feedback rapide et fiable. Ces tests ne sont peut-être pas au même niveau de la pyramide.
// Ils auront peut-être un lit superposé entre deux niveaux. Nous pouvons compléter le tableau précédent comme suit :
//      --> Mais comment décider où et quand nous avons réellement besoin de tests d’acceptation ?
// Voici comment je vous recommande de prendre votre décision :
//      --> Demandez-vous si le comportement métier est déjà couvert par un test fonctionnel de bout en bout.
//          Qui utilisera les méthodes et classes dont vous aurez besoin pour livrer votre test d’acceptation.
//      --> Si la réponse est non, vous aurez peut-être besoin d’en écrire un.
// Après cela, écrivez tous vos tests d’acceptation métier le plus possible avec des tests d'intégration système.
// L'expérience semble indiquer que c'est le niveau le plus équilibré en général pour les tests d'acceptation.
// Assurez-vous que vos tests d’acceptation peuvent être exécutés ensemble. Utilisez '@Tag', par exemple !
// Voici un exemple pour une application web :
//      --> « Les utilisateurs authentifiés doivent pouvoir supprimer leurs profils pour se désinscrire de notre site ».
// Cela implique de tester qu’un utilisateur peut s'authentifier et utiliser l’application pour se désinscrire.
// Ensuite, nous devons vérifier qu’ils ne sont plus des utilisateurs inscrits.
// Cela ne teste pas directement un composant, mais plutôt nos attentes métiers.
// Les tests d’acceptation sont écrits en français sous forme de scénario de test, mais pour les automatiser, vous allez les implémenter en utilisant les types de tests automatiques.
// -----------
//  - Qu’y a-t-il au-delà du sommet de la pyramide ?
// Si vous sortiez votre télescope pour regarder au-dessus du sommet de votre pyramide, vous seriez aveuglés par le chaos du monde réel.
// Pour la majeure partie, la pyramide teste des scénarios prévisibles. Quand vous arrivez au sommet, ce n’est que là que vous savez réellement comment votre produit se comporte.
// Alors, que pouvez-vous continuer à tester, apprendre, et percevoir dans le monde ? Regardez ces différents types de tests :
//      --> Bêta : Que se passe-t-il quand je présente une version de mon application à des utilisateurs réels ?
//              --> Si je publie mon calculateur pour des élèves réels de l’école locale, est-ce qu’il est performant et utilisable ?
//      --> A/B testing : J’ai deux idées géniales pour cette interface utilisateur ou un bout de code compliqué. Laquelle devrais-je utiliser ?
//              --> Vous pourriez sortir deux versions de votre application. L’une enverrait tous les calculs à Google, et l’autre les résoudrait elle-même.
//                      Comparez laquelle est meilleure et préférée par vos utilisateurs.
//      --> Smoke testing : L’intégration entre votre application en marche (tout le code) et la plateforme sur laquelle elle fonctionne.
//              --> L’application fonctionne sur votre plateforme de production. Les tests rapides vérifient que ses configurations sont correctes et qu’elle semble gérer un ou deux bons chemins.
// Pourquoi faire des tests après la sortie de votre application ?
//      --> Le fait de construire une partie d’un système est votre contribution à la résolution d’un problème plus vaste.
// Une question que vous devez vous poser continuellement est :
//      --> Quel problème est-ce que je résous ?
// Lorsque vous résolvez ce problème, vous devez continuer à vous demander si vous développez les bonnes choses.
// C’est-à-dire, est-ce que vous résolvez correctement ce problème d’une façon qui fonctionne pour vos utilisateurs et votre client dans le monde réel ?
// -----------
//  - Alors, qu’est-ce que tout cela signifie pour notre pyramide ?
// Voici la pyramide finale. Elle n’a pas vraiment changé. Vous devriez simplement avoir une meilleure idée des types de tests, en particulier sur la partie supérieure.
// En parallèle de cette pyramide, il existe aussi d'autres tests, plutôt à vocation technique
// En voici quelques exemples, avec un outil conseillé, que je vous laisse découvrir au-delà de ce cours :
//      --> Les tests de performance, pour vérifier que votre application est assez rapide, avec JMeter.
//      --> Les tests de charge, qui s’assurent que votre application ne s’écroule pas quand de nombreuses personnes l’utilisent en même temps, avec Gatling.
//      --> les tests de sécurité, qui vérifient si quelqu’un peut exploiter votre logiciel et accéder à des données qu’il ne devrait pas pouvoir atteindre, avec ZAP.
// Évidemment, il existe de nombreux types de tests supplémentaires que vous pouvez effectuer.
// Ce que vous décidez de faire dépend de la question suivante : Sur quels éléments avez-vous besoin d’atteindre le niveau d’assurance qualité souhaité pour votre système ?
//      --> En général, la plupart des bons projets devraient disposer au moins de tests unitaires, d’intégration de composants, et de bout en bout.
//      --> Tout ce que vous faites au-delà de ces catégories dépend des besoins spécifiques à votre produit.
// Enfin : les tests ne sont pas gratuits. Rappelez-vous que chaque test est comme un animal de compagnie.
// Vous devez vous engager à en prendre soin et à investir le temps nécessaire pour lui donner l’attention continue dont il aura besoin.
// -----------
//  - En résumé :
//          --> Pour que les tests unitaires soient rapides et approfondis, ils formulent de nombreuses hypothèses, exprimées à travers les mocks.
//          --> Les tests d’intégration des composants valident qu’un petit nombre d’unités de code peuvent collaborer ensemble.
//          --> Les tests d’intégration système valident la capacité de vos unités de code à collaborer dans un système partiellement en fonction, avec des composants extérieurs simulés ou non.
//          --> Avec les tests de bout en bout, vous faites fonctionner le système complet et vous validez vos hypothèses.
//          --> Les tests d’acceptation fonctionnent de façon perpendiculaire à la pyramide et peuvent traverser les niveaux, tout en restant en principe au milieu ou en haut de la pyramide.
// Maintenant que vous avez découvert un peu de théorie sur les types de tests au milieu et en haut de la pyramide, passons à la pratique.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentez les différents types de tests d’intégration ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Découvrez les tests d’intégration composants :
// Vous avez vu de nombreux tests unitaires jusqu’ici. Souvent en utilisant des mocks.
// Les tests d'intégration composants sont à peu près identiques, mais vous n’utiliserez peut-être pas de mock.
// Vous testez l’intégration des unités de code que vous avez développées et testées unitairement.
// Jetons donc un coup d’œil à un exemple de ce type de test ! Nous allons créer un test d’intégration pour 'CalculatorService', et nous assurer qu’il peut être lancé de manière autonome.
// Nous le nommons 'CalculationServiceIT'. Le « IT » dans le nom signifie test d’intégration (« integration test » en anglais).
//      --> Le fait de mettre « IT », ou « integration test » à la fin des tests est une convention Java.
// Elle permet notamment à Maven à séparer les tests unitaires, traités par le plugin 'Surefire', des tests d'intégration, traités par le plugin 'Failsafe'.
// Sans trop entrer dans les détails du fonctionnement de Maven, sachez que la commande : mvn package.
//      --> Permet de lancer la compilation, les tests unitaires, et le packaging des sources.
// Alors que la commande : mvn verify.
//      --> Permet d'effectuer à la fois les tâches couvertes par mvn package, mais aussi les tests d'intégration en plus.
// Le test lui-même ressemble structurellement à un test unitaire, mais sans mock.
// Évitez de coder des tests de manière exhaustive pour la classe à tester, concentrez-vous plutôt sur quelques scénarios représentatifs.
//                  public class CalculatorServiceIT {
//                      // Mettre en place des objets réels non mockés
//                      private final Calculator calculator = new Calculator();
//                      private final SolutionFormatter formatter = new SolutionFormatterImpl();
//                      // Initialiser la classe à tester
//                      private final CalculatorService underTest = new CalculatorServiceImpl(calculator, formatter);
//                      @Test
//                      public void calculatorService_shouldCalculateASolution_whenGivenACalculationModel() {
//                          // GIVEN
//                          // ...
//                          // WHEN
//                          final int result = underTest.calculate(
//                                  new CalculationModel(CalculationType.ADDITION, 1, 2)).getSolution();
//                          // THEN
//                          assertThat(result).isEqualTo(3);
//                      }
//                  }
// Et voilà. Voyez-vous en quoi il diffère des tests unitaires précédents ? Voici le test unitaire pour l'addition :
//                  @ExtendWith(MockitoExtension.class)
//                  public class CalculatorServiceTest {
//                      @Mock
//                      Calculator calculator;
//                      @Mock
//                      SolutionFormatter solutionFormatter;
//                      CalculatorService classUnderTest;
//                      @BeforeEach
//                      public void init() {
//                          classUnderTest = new CalculatorServiceImpl(calculator, solutionFormatter);
//                      }
//                      @Test
//                      public void calculate_shouldUseCalculator_forAddition() {
//                          // GIVEN
//                          when(calculator.add(1, 2)).thenReturn(3);
//                          // WHEN
//                          final int result = classUnderTest.calculate(
//                                  new CalculationModel(CalculationType.ADDITION, 1, 2)).getSolution();
//                          // THEN
//                          verify(calculator).add(1, 2);
//                          assertThat(result).isEqualTo(3);
//                      }
//                  }
// Il n’y a pas beaucoup de différences, n’est-ce pas ? Une chose que vous avez dû remarquer, c'est que nous n’avons pas utilisé de mocks aux lignes 4 et 5 !
// Dans ce type de test, vous aurez peut-être un scénario principal et un scénario d'exception à gérer.
// Vous avez besoin de juste assez de tests pour avoir l’assurance que vos unités collaborent entre elles.
// Ici, la preuve que nous sommes capables de faire de l’arithmétique a déjà été établie par CalculatorTest, donc il n’y aurait pas de valeur ajoutée à répéter ce test ici.
// Si cela fonctionne, vous pouvez faire confiance à vos tests unitaires existants.
// Et aussi à avoir davantage d’assurance sur le bon fonctionnement des méthodes 'add', 'substract', 'multiply' et 'divide' quand elles sont appelées par d’autres classes !
// -----------
//  - Appréhendez les tests d’intégration système :
// Les tests d’intégration système partent d'une démarche similaire, à savoir assembler des composants entre eux.
// Mais de manière plus large, avec plusieurs services, une configuration d'application, et des liens éventuels avec des composants extérieurs à l'application, simulés ou en production.
// Parmi ces tests d'intégration système, il existe certains tests qui permettent de vérifier que votre application web sait gérer la soumission d'un formulaire.
// Donc, sans simuler directement les interactions de l'interface utilisateur (sinon c'est un test fonctionnel de bout en bout, que l'on verra dans des chapitres ultérieurs).
//      --> C'est ce qu'on appelle test sous-cutané.
// Vous pourriez aussi prouver que votre code sera capable d'interagir avec une base de données en lançant une partie de votre application, et en utilisant une base de données réelle ou en mémoire.
// -----------
//  - Écrivez un test d’intégration système pour une application Spring :
// Spring est le framework de référence utilisé par les développeurs Java pour construire leurs applications web.
// Il aide à coller toutes vos classes dans une application qui fonctionne. Les tests d’intégration système aident en testant un système en marche.
// Les frameworks comme Spring aident à rassembler les classes dans ce même système !
//      --> Spring Boot est assez facile à tester, et propose des outils de qualité pour les tests d’intégration système.
// C’est l’une des nombreuses raisons pour lesquelles nous l’utilisons souvent comme base de développement pour de nombreuses applications.
// Notre application Calculator a été modifiée et est devenue une vraie application web basée sur Spring Boot, mais sans tests.
//      --> Pour démarrer l'application, il vous suffit de lancer la commande : mvn spring-boot:run.
// Vous pouvez ensuite le voir dans votre navigateur à http://localhost:8080.
// Et voici comment créer votre premier test d'intégration système :
// J’ai nommé le test 'CalculationControllerSIT' pour montrer clairement que c’est un test d’intégration système.
// Dans la vraie vie, vous trouverez souvent à la fois vos tests d’intégration composants et vos tests d’intégration système groupés ensemble dans votre projet.
// Avec Maven, ils seront gérés par le plugin 'Failsafe' comme les tests d'intégration composants, car leur nom se termine par IT.
// Observons les annotations que nous avons utilisées :
//                  @WebMvcTest(controllers = {CalculatorController.class, CalculatorService.class})
//                  @ExtendWith(SpringExtension.class)
//                  public class CalculatorControllerSIT {
//                      @Inject
//                      private MockMvc mockMvc;
//                      @MockBean
//                      private SolutionFormatter solutionFormatter;
//                      @MockBean
//                      private Calculator calculator;
//                      @Autowired
//                      private CalculatorController calculatorControllerUnderTest;
//                      @Test
//                      public void givenAUser_whenRequestIsMadeToAdd_thenASolutionSouldBeShown() throws Exception {
//                  ...
//                      }
//                  }
//      - @WebMvcTest : @WebMvcTest(controllers = {CalculatorController.class, CalculatorService.class}).
// Spring peut lancer un environnement simulé qui laisse agir les tests comme si vous aviez un serveur web fonctionnel.
// D’abord, utilisez l’annotation '@WebMvcTest' à la ligne 1 et passez-lui en argument les objets réels (avec Spring, on dit souvent "bean") qui seront initialisés par Spring.
// Dans ce cas, nous allons utiliser un CalculatorService réel et un CalculatorController réel.
// Dans une application web, la classe contrôleur possède des méthodes qui dialoguent directement avec le monde extérieur à l'origine d'une requête HTTP.
// Dans notre code, il prend connaissance de ce que vous vouliez calculer, puis donne une réponse à votre navigateur web en HTML.
// Étant donné qu’il s’agit de la classe au bord de notre système à laquelle notre navigateur parle, c’est là que nous allons concentrer nos tests d’intégration système.
//      - @ExtendWith(SpringExtension.class) : @ExtendWith(SpringExtension.class).
// Comme avec Mockito et son extension MockitoExtension, SpringExtension assiste JUnit pour configurer une application de test, configuré avec Spring.
// Cette annotation est nécessaire pour activer toutes les autres annotations que nous voyons dans ce code.
//      - @Inject :
// Sans entrer dans les détails de Spring, ce dernier effectue ce que l'on appelle de l'injection de dépendances (DIP en anglais).
// Si votre classe est un service qui a besoin d'autres composants, Spring s'occupe de les initialiser pour vous !
//      --> Concrètement, vous ne faites plus de  new Calculator().
// Moins vous avez de code de routine à écrire dans vos tests, et plus vous pouvez vous concentrer sur le fait de tester les méthodes publiques.
// @Inject indique à Spring de vous donner une instance d’une classe et de gérer sa création, comme dans les lignes 5, 14 et 17 ci-dessus.
// Par exemple, les lignes ci-dessous donnent une instance réelle d’un CalculatorService prête à être utilisée dans vos tests :
//                  @Inject
//                  private CalculatorService calculatorService;
// La raison pour laquelle vous pouvez faire cela ici est que l'annotation '@Names' a été ajoutée à la classe 'CalculationService'.
// Ceci dit à Spring que vous avez besoin d’une instance de cette classe, et au développeur qu’elle fournit des méthodes que d’autres classes peuvent utiliser.
// Nous nommons ces instances créées par Spring des Spring beans. Le terme bean(ou « haricot », en anglais) est très utilisé en Java ; ne le confondez pas avec ses nombreuses autres significations.
//      --> Dans ce cas, c’est simplement une classe que Spring a créée et configurée pour vous, pour que vous n’ayez pas à le faire.
// Pour que Spring puisse créer une classe pour vous, elle doit habituellement être désignée avec '@Service', '@Component', '@Controller', '@Bean' ou encore '@Named', la plus générique.
// Voici par exemple le code de CalculatorServiceImpl :
//                  import javax.inject.Named;
//                  ...
//                  @Named
//                  public class CalculatorServiceImpl implements CalculatorService {
//                      ...
//                  }
// Regardez par vous-même le nouveau code des autres classes 'CalculatorController' et 'Calculator' pour découvrir ces nouvelles annotations.
// Pour effectuer l'injection, vous pourrez aussi trouver '@Autowired' au lieu de '@Inject'. Pour Spring, c'est la même chose.
// Mais l'annotation '@Inject' est issu d'un standard Java, contrairement à '@Autowired' qui est propre à Spring.
// L'avantage, c'est que votre code est plus générique et pourrait plus facilement être migré, s'il y en avait le besoin, sur un autre framework que Spring !
//      - @MockBean :
// Aux lignes 8 et 11, nous avons utilisé l’annotation '@MockBean' avant les attributs de type Calculator et SolutionFormatter.
// Le fait de placer '@MockBean' avant un champ demande à l’exécuteur de test de Spring de nous créer un mock.
//                  @MockBean
//                  private SolutionFormatter solutionFormatter;
//                  @MockBean
//                  private Calculator calculator;
// Avec ces déclarations, nous obtenons une instance simulée du Calculator à utiliser au sein de ce test.
// C’est la même chose que le '@Mock' de Mockito, sauf que Spring utilise ces objets comme des beans Spring utilisables par d'autres beans Spring (classes annotés @Named).
// Par exemple, l'attribut de type CalculatorService à la ligne 14 nécessite qu’une instance de calculateur soit passée à son constructeur.
//      --> Spring lui injectera le mock de calculateur que nous avons créé ici.
// Dans notre exemple, CalculatorService est une instance réelle, mais il se trouve qu’il utilise le mock de calculateur que nous avons créé ci-dessus.
// Le fait de désigner le constructeur de CalculatorService avec l’annotation '@Autowired' demande à Spring de regarder les arguments qui lui sont passés :
//                  @Autowired
//                  public CalculatorService(Calculator calculator, SolutionFormatter formatter) {
//                      this.calculator = calculator;
//                      this.formatter = formatter;
//                  }
// En gros, Spring trouvera alors une classe d’un type approprié et la mettra en place.
// Dans un test d’intégration Spring, en désignant un attribut comme un MockBean, il devient éligible pour satisfaire à toute dépendance '@Autowired' dans le système sous test.
//      - @Autowired MockMvc mockMvc :
// À la ligne 6, Spring nous permet d’injecter une classe spéciale nommée 'MockMvc' dans notre test.
// Cela se fait exactement comme dans les exemples ci-dessus.
// Mais cela nous donne également un navigateur web spécial basé sur du code que nous pouvons utiliser pour tester une application Spring sans la démarrer.
// La classe MockMvc appellera votre contrôleur comme si l’application avait réellement été démarrée, et vous permet d’inspecter la façon dont elle répond dans vos tests.
// -----------
//  - Jetez un coup d’oeil au test !
//              @Test
//                  public void givenAUser_whenRequestIsMadeToAdd_thenASolutionSouldBeShown() throws Exception {
//                      when(calculator.add(2,3)).thenReturn(5);
//                      mockMvc.perform(post("/calculator")
//                      .param("leftArgument", "2")
//                      .param("rightArgument", "3")
//                      .param("calculationType", "ADDITION")
//                      ).andExpect(status().is2xxSuccessful()).
//                              andExpect(content().string(containsString("id=\"solution\""))).
//                              andExpect(content().string(containsString(">5</span>")));
//                      verify(calculator).add(2, 3);
//                      verify(solutionFormatter).format(5);
//                  }
// Dans ce cas, la ligne 4 utilise le faux navigateur 'MockMvc' pour faire semblant de soumettre un formulaire.
// L'argument '.param("leftArgument", 2)' et les trois lignes suivantes soumettent des champs de formulaire, comme si quelqu’un l’avait fait dans un navigateur.
// Nous avons utilisé la méthode statique post à la ligne 4 pour ce faire.
// La valeur '/calculator' devrait correspondre à une autre annotation dans CalculatorController désignée par '@PostMapping'.
// Voici le code réel avec lequel un navigateur interagirait :
//                  @PostMapping("/calculator")
//                  public String calculate(@Valid Calculation calculation, BindingResult bindingResult, Model model) {
//                          // Arrange
//                          CalculationType type = CalculationType.valueOf(calculation.getCalculationType());
//                          CalculationModel calculationModel = new CalculationModel(
//                                  type,
//                                  calculation.getLeftArgument(),
//                                  calculation.getRightArgument());
//                          // Act
//                          CalculationModel response = calculatorService.calculate(calculationModel);
//                          // Present
//                          model.addAttribute("response", response);
//                          return CALCULATOR_TEMPLATE;
//                  }
// Lorsqu’un test appelle 'mockMvc.perform(post("/calculator"))', il essaye de se connecter à l’une des méthodes de votre contrôleur.
// La méthode 'post()' ressemble à l’action de cliquer sur le bouton 'envoyer' dans un formulaire ou un navigateur.
// La valeur que vous lui donnez s’appelle un chemin, et devrait correspondre à une méthode annotée dans votre contrôleur avec '@PostMapping' et ce chemin.
//      --> Elle correspond à '@PostMapping("/calculator")' à la ligne 1, ci-dessus.
// Le chemin correspond en principe la fin de l'URL de la requête. L'URL complète comprend en plus un préfixe correspondant à l'URL de l'application.
// Par exemple '/calculator' peut correspondre à 'http://localhost:8080/monApplication/calculator'.
// Pour d’autres types de scénarios, vous pouvez avoir '@GetMapping' avec la méthode statique 'get()'. Et '@PutMapping' avec la méthode statique 'put()'.
// Vous pouvez constater que notre contrôleur ressemble aux cas de tests que nous avons écrits précédemment qui appellent 'CalulationService.calculate(calculationModel)'.
// Exactement comme nous l’avons fait à la ligne 10. Cela retourne un autre CalculationModel avec une solution.
// Spring utilise ensuite ce modèle pour montrer une réponse à l’utilisateur. Le code HTML se trouve dans 'resources/templates/calculator.html'.
// Pensez-y comme à une page web utilisée pour récupérer des inputs de l’utilisateur et lui montrer le résultat.
// Le fichier contient l’extrait suivant, qui montre la solution uniquement si une réponse a été calculée à la ligne 2. Elle remplacerait le mot solution à la ligne 4.
//                  <div class="col">
//                      <ul th:if="${response}">
//                          <span id="solution" th:text="${response.getSolution()}" class="badge">
//                          Solution
//                          </span>
//                      </ul>
//                  </div>
// Il s'agit d'un modèle de page HTML écrit avec 'Thymeleaf', configuré avec Spring Boot. Mais revenons à notre test.
//      --> Les lignes 8 à 11 garantissent qu’une bonne réponse serait renvoyée à notre faux navigateur.
//      --> Et aussi qu’elle contiendrait l’extrait ci-dessus avec la solution à 2+3 quand nous avons un span avec l’id de solution.
// Nous avons accompli tout cela sans lancer l’application !
// -----------
//  - En résumé :
//          --> Les tests d’intégration composants valident que les unités de code déjà testées unitairement collaborent réellement comme leurs mocks le faisaient.
//          --> Les tests d’intégration système sont en fait simplement des tests d’intégration composants à plus grande échelle.
//                  Ils testent au sein d’un système partiellement en marche et examinent les intégrations avec d’autres collaborateurs au niveau du système (comme les bases de données).
//          --> Nous avons écrit des tests d’intégration système qui ont validé une application web Spring sans navigateur, en utilisant '@WebMvcTest' et l’extension JUnit SpringExtension.
//                  Cela suppose d'avoir préparé le code de l'application pour qu'il lance une application web construite avec Spring Boot.
// Maintenant que vous savez implémenter vos premiers tests d'intégration, vous pourriez appliquer ces connaissances pour les tests d'acceptation !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Couvrez les besoins utilisateurs avec les tests d’intégration /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous avez abordé jusqu'à présent le TDD comme une bonne pratique pour créer des tests unitaires principalement.
// L'objectif ici est de découvrir une adaptation de cette méthode pour traduire les exigences métiers sous forme de tests d'acceptation puis de tests d'intégration.
//      --> Pour cela, nous allons découvrir le 'TDD de Londres'.
// -----------
//  - Le TDD de Londres : un nouveau type de TDD :
// Au milieu des années 2000, la communauté eXtreme Programming londonienne a commencé à s’inquiéter du manque de prise en considération des besoins de nos utilisateurs.
// Elle a donc inventé un style de TDD qui aidait à garantir que nos tests décrivent réellement les problèmes de nos utilisateurs.
// Avec AssertJ, nous avions déjà tenté de rendre plus lisibles les assertions. Mais là, il s'agit de revoir complètement l'écriture du test !
//      --> Extreme Programming (ou XP) est un framework pour le développement logiciel Agile.
// Il spécifie de nombreuses pratiques d’ingénierie pour livrer des logiciels de haute qualité, centrés sur les utilisateurs, tout en recherchant du feedback régulier.
// Kent Beck, le père du TDD, est aussi le père de XP, où il a introduit pour la première fois la programmation test-first (commençant par les tests).
//      --> En quoi est-ce différent du TDD que nous avons vu jusqu'à présent ?
// Le TDD que nous avons vu se concentre surtout sur les tests au niveau des fonctionnalités unitaires.
// C’est au développeur de s’assurer que ces tests reflètent les exigences du client.
// Ce type de test va de l’intérieur vers l’extérieur, des plus petites unités de code jusqu’à ce avec quoi les utilisateurs interagissent.
// Par opposition, le TDD de Londres commence par les prérequis métiers
// Au lieu de se concentrer sur ce qui est fait dans le code, comme l’ajout d’un utilisateur dans la base de données, le TDD de Londres se concentre sur ce dont l’utilisateur a besoin.
// Le fait de formuler les exigences comme « un utilisateur doit pouvoir s’inscrire » décrit le comportement d’un programme à travers les besoins utilisateur.
// Autrement dit, vous travaillez avec des tests d’acceptation !
// C’est pourquoi on la désigne aussi sous le nom de développement piloté par les tests d’acceptation ATDD pour 'Acceptance Test-Driven Development', ou test de l’extérieur vers l’intérieur.
// Ainsi, vous allez développer uniquement des classes qui doivent faire passer vos tests d’acceptation.
// Cela peut vous aider à développer moins de code inutile.
//      --> Comment est-ce que je commence de l’extérieur pour travailler vers l’intérieur ?
// Comme je l'ai mentionné, votre test d’acceptation est habituellement placé de façon optimale dans vos tests d’intégration ou au-dessus, car il décrit une exigence business.
// De l’extérieur vers l’intérieur signifie que vous commencez par le test d’acceptation puis descendez la pyramide en développant les tests nécessaires.
//      --> Commencez par vous poser les questions suivantes :
//              --> Quel est le test d’acceptation ?
//              --> Avez-vous des tests unitaires qui couvrent ce dont vous avez besoin pour le test d’intégration ?
//              --> Avez-vous un test d’intégration qui couvre ce dont vous avez besoin pour le test de bout en bout ?
//              --> Avez-vous un test de bout en bout qui représente ce test d’acceptation ?
// À chaque non, vous écrivez un test et demandez ce dont vous avez besoin pour réussir ce test.
// La réponse : davantage de tests plus bas dans la pyramide ! La plupart du temps, aucun test ne couvre vraiment le test d'acceptation.
// Donc, il s'agit de partir de l'extérieur (le besoin métier) vers l'intérieur (l'unité de code testée).
// En écrivant chaque test, vous creusez un chemin de l’extérieur de votre code vers l’intérieur, en construisant uniquement les parties dont vous avez besoin.
//      --> Écrivez des tests jusqu’à être sûr d’avoir couvert tous les besoins de votre test d’acceptation.
// Ensuite, vous commencez à écrire le code, en remontant à partir du bas de la pyramide, pour retourner jusqu’au sommet.
// Quand vous construisez ce code fonctionnel, vos tests unitaires, d’intégration et si nécessaire de bout en bout commencent tous à réussir.
// Il y aura toujours quelques ajustements à faire, mais vous écrirez moins de lignes de code, qui seront également plus ciblées.
// Vous écrirez toujours de nombreux tests unitaires, mais ce seront les seuls dont vous aurez besoin.
// -----------
//  - Appliquez le TDD de Londres :
// Le TDD de Londres vous encourage également à travailler en cycles courts, un test à la fois.
// Séquence des actions pour effectuer du TDD de Londres :
//      - Dans les étapes 1 et 2, vous prenez votre test d’acceptation et vous écrivez des cas de test pour lui.
//          Il s’agit de faire échouer les tests d’intégration (et, si nécessaire seulement, des tests fonctionnels de bout en bout) !
//      - Les étapes 3 à 5 indiquent que vous appliqueriez le TDD à une unité de code, ce qui aide à construire le code réel pour satisfaire au test d’acceptation.
//      - Les étapes 6 et 7 sont la boucle de refactoring dont nous avons parlé dans les chapitres précédents, où vous nettoyez votre code sans casser les tests.
//      - À partir de l’étape 8 :
//              - Si vos tests d’acceptation échouent encore, il vous faut continuer à écrire davantage de code et retourner à l’étape 3.
//              - Si vous en avez suffisamment pour que cela ait commencé à réussir, allez à l’étape 8 et remontez le cycle pour commencer un nouveau test d’acceptation !
// C’est encore assez abstrait, nous allons donc construire une application web de calculateur ensemble en utilisant ces cycles.
// Une fois le développement terminé, il doit pouvoir additionner, soustraire, diviser, et multiplier.
// Si vous commencez par l’addition, vous aurez un point de départ gérable.
// Par exemple, vous pouvez créer un test d’acceptation qui dit : "un utilisateur doit pouvoir additionner deux nombres et voir leur somme".
// Quels tests vous attendez-vous à obtenir ? Parcourons les étapes ensemble :
//      --> Etape 1 : commencez par écrire un test de bout en bout rouge.
//              Ce test ne doit pas se préoccuper de l’aspect de la page web, mais peut automatiser la visite d’une page web, la sélection de deux nombres, et le clic sur un bouton '='.
//              Par exemple : « un utilisateur doit pouvoir additionner deux nombres et voir leur somme ».
//      --> Etape 2 : exécutez le test rouge ci-dessous, et il échouera car vous n’avez pas construit votre serveur web :
//              TYPE DE TEST               NOM DU TEST                                                                 CE QUI EST TESTÉ
//          Test d’acceptation.     Un utilisateur doit pouvoir additionner deux nombres et voir leur somme.    Un utilisateur visite une page, entre deux nombres, clique sur « = » et voit un résultat.
//      --> Etape 3 : écrivez un test d’intégration pour un serveur web auquel vous pouvez envoyer deux nombres :
//              TYPE DE TEST                NOM DU TEST                                                                 CE QUI EST TESTÉ
//          Intégration.            GivenTwoNumbers.                                                            Le serveur peut démarrer, et a un contrôleur qui acceptera deux nombres.
//                                  WhenAdded.                                                                  Il les donnera à une classe de calculateur pour les additionner.
//                                  ThenTheyShouldBeSummed.
//      --> Etape 4 : choisissez votre framework favori (comme Spring Boot) pour construire un contrôleur auquel vous pouvez envoyer deux nombres.
//      --> Etape 5 : exécutez vos tests de bout en bout et d’intégration rouge : le serveur ne fait toujours rien de vos nombres.
//      --> Etape 6 : maintenant, écrivez un cas de test unitaire rouge pour de nouvelles classe et méthode : Calculator.add(Integer a, Integer b).
//      --> Etape 7 : créez Calculator.add, et vos tests sont rouges :
//              TYPE DE TEST                NOM DU TEST                             CE QUI EST TESTÉ
//          UNITAIRE.                   add_Sums_PositiveAndPositive            Calculator.add(1, 1)
//          UNITAIRE.                   add_Sums_NegativeAndPositive            Calculator.add(-1, 1)
//          UNITAIRE.                   add_Sums_NegativeAndNegative            Calculator.add(-1, -1)
//          UNITAIRE.                   add_Sums_PositiveIntegerAndZero         Calculator.add(1, 0)
//          UNITAIRE.                   add_Sums_ZeroAndZero                    Calculator.add(0, 0)
//      --> Etape 8 : faites fonctionner Calculator.add et tous vos tests passent au vert.
//      --> Etape 9 : vous pouvez maintenant nettoyer (refactorer) votre code et vous assurer que le test reste vert.
//      --> Etape 10 : passez à l’écriture d'autres cas de test unitaire pour la même fonctionnalité, en prenant en compte les scénarios alternatifs/limites.
//      --> Etape 11 : et maintenant, écrivez un autre test d’intégration, et répétez les étapes 3 à 10 !
//          INTÉGRATION.                GivenBadValues _WhenAdded               Le serveur démarre, le contrôleur valide l’input et fournit une erreur.
//                                      ThenAnErrorIsReturned
//          UNITAIRE.                   add_ThrowsException_AddingToNull        Calculator.add(null, 1)
//          UNITAIRE.                   add_ThrowsException_AddingNull          Calculator.add(1, null)
// -----------
//  - Découvrez le développement piloté par le comportement (BDD) :
//      - Quelques définitions :
//          Vous avez la méthodologie pour vous concentrer sur les besoins métiers, mais comment réussir à parler le même langage avec le client et les utilisateurs.
//          Plus généralement des non-informaticiens ? Pour une meilleure collaboration entre intervenants d'un projet, réussir à construire une compréhension partagée des cas de test.
//          Ceci, grâce au langage courant, est une des clés de la réussite.
//          Cette approche va de pair avec les pratiques agiles : réunissez-vous et définissez ces besoins dans le langage qu’utilise votre client.
//          Vous pourriez proposer ce qui suit au tableau blanc :
//                  LA FONCTIONNALITÉ QUE NOUS DÉVELOPPONS : Additionner deux nombres.
//                  QUE VEUT L’ÉTUDIANT ?
//                  En tant qu’étudiant, je veux additionner deux nombres pour pouvoir résoudre des calculs compliqués.
//                  PAR EXEMPLE :
//                  En supposant qu’un élève utilise le Calculateur quand 2 et 5 sont additionnés, on devrait montrer 7 à l’élève.
//          --> La phrase commençant par "En tant que..." est ce qu'on appelle, en agilité, un récit utilisateur.
//          Il décrit une fonctionnalité en n'oubliant pas qui est la cible ni la finalité de la fonctionnalité.
//          En donnant un exemple, on fabrique naturellement un test d'acceptation en langage naturel.
//          Vous pouvez utiliser un outil populaire nommé 'Cucumber' pour automatiser le développement dans le style BDD.
//              --> Il vous aide à décrire vos scénarios en langage naturel, et surtout à faire le lien avec vos tests fonctionnels ou d'intégration.
//      - Comment fonctionne Cucumber ?
//          Cucumber décrit une fonctionnalité que vous allez développer en utilisant un fichier de fonctionnalité.
//          C’est l’équivalent d’une partie de votre application que vous allez construire de façon incrémentale.
//              --> Par exemple, « gérer l’addition » pourrait être une fonctionnalité de votre calculateur.
//          'Gherkin' est le nom donné au langage que Cucumber utilise pour les tests.
//              --> Il s’agit d’une structure pour décrire le comportement attendu de votre logiciel dans différentes situations.
//          Le langage Gherkin décrit un scénario de test avec une phrase de structure suivante :
//              - Given some preconditions / Étant donné les conditions préalables.
//              - When some action / Quand une action.
//              - Then what expectations to assert / Alors les attentes à affirmer.
//          Par défaut, Gherkin propose ses mots clés en anglais, mais il est tout à fait possible d'utiliser des plugins pour utiliser la langue de votre choix, comme le français.
//          De plus, il y a plusieurs mots clés possibles en français pour Given/When/Then.
//              --> Reportez-vous sur la documentation de Gherkin si vous souhaitez connaître toutes les possibilités.
//          Voici un exemple de fichier de fonctionnalité pour le calculateur, avec un choix de langage en français :
//                  # language: fr.
//                  Fonctionnalité: Additionner deux nombres.
//                  En tant qu'élève, je veux additionner deux nombres pour pouvoir résoudre des calculs compliqués.
//                  Scénario: Additionner deux nombres positifs.
//                  Étant donné un élève utilise le Calculateur.
//                  Quand 2 et 5 sont additionnés.
//                  Alors on montre 7 à l'élève.
//              - Ligne 1 : on spécifie la langue.
//              - Lignes 3-4 :  on explicite une fonctionnalité sous forme de titre (ligne 3) et de description en dessous (ligne 4).
//              - Lignes 6-9 : on détaille un scénario avec un titre (ligne 6), l'étape Given (ligne 7), l'étape When (ligne 8) et l'étape Then (ligne 9).
//      - Écrivez un test d’acceptation Cucumber :
//          Tout d’abord, voyons comment ajouter Cucumber à votre projet et le mettre en place pour les tests avec Spring.
//          Puis créons un premier test d'intégration en lien avec le test d'acceptation issu du fichier texte.
//          - Ajout de Cucumber dans la configuration Maven
//              Modifiez le fichier pom.xml pour y intégrer Cucumber.
//              On définit une property pour indiquer la version de Cucumber (rendez-vous sur mvnrepository.com !), et ajouter les dépendances nécessaires.
//              Vous devrez aussi ajouter une dépendance spéciale de JUnit : junit-vintage-engine.
//              Ce composant permet de lancer des tests JUnit 4 dans un système JUnit 5.
//                  --> À ce jour, Cucumber n'est pas compatible avec JUnit 5.
//              Voici les modifications à faire dans le fichier pom.xml :
//                  <properties>
//                          ...
//                          <dep.cucumber.version>4.8.0</dep.cucumber.version>
//                  </properties>
//                  <dependencies>
//                      ...
//                              <dependency>
//                              <groupId>org.junit.vintage</groupId>
//                              <artifactId>junit-vintage-engine</artifactId>
//                              <scope>test</scope>
//                          </dependency>
//                          <dependency>
//                              <groupId>io.cucumber</groupId>
//                              <artifactId>cucumber-jvm</artifactId>
//                              <version>${dep.cucumber.version}</version>
//                              <scope>test</scope>
//                              <type>pom</type>
//                          </dependency>
//                          <dependency>
//                              <groupId>io.cucumber</groupId>
//                              <artifactId>cucumber-spring</artifactId>
//                              <version>${dep.cucumber.version}</version>
//                              <scope>test</scope>
//                          </dependency>
//                          <dependency>
//                              <groupId>io.cucumber</groupId>
//                              <artifactId>cucumber-junit</artifactId>
//                              <version>${dep.cucumber.version}</version>
//                              <scope>test</scope>
//                          </dependency>
//                  </dependencies>
//          - Ajout du fichier de fonctionnalité :
//              Ensuite, copiez-collez le fichier de fonctionnalité rappelé en exemple ci-dessous, dans un nouveau fichier 'src/test/resources/features/calcul-addition.feature' :
//                  # language: fr
//                  Fonctionnalité:  Additionner deux nombres
//                  En tant qu'élève, je veux additionner deux nombres pour pouvoir résoudre des calculs compliqués.
//                  Scénario: Additionner deux nombres positifs
//                  Étant donné un élève utilise le Calculateur
//                  Quand 2 et 5 sont additionnés
//                  Alors on montre 7 à l'élève
//          - Création du test d'acceptation Cucumber :
//              Vous allez ensuite créer le lanceur de tests d'acceptation Cucumber.
//              En fait, ce lanceur va être reconnu comme un test JUnit, mais il peut y avoir autant de tests que de fonctionnalités définies dans les fichiers texte.
//              Pour qu'il soit exécutable par Maven en tant que test d'intégration, vous pouvez créer une classe 'CucumberAIT' (pour Acceptance Integration Test).
//              Ceci, dans un nouveau paquetage 'org.openclassrooms.testing.cacul.acceptance'.
//              Cette classe ne contient pas directement les tests mais simplement des indications au lanceur, comme, par exemple, le chemin vers les fichiers de fonctionnalité :
//                  @RunWith(Cucumber.class)
//                  @CucumberOptions(features = "src/test/resources/features", plugin = { "pretty", "html:target/html-cucumber-report" })
//                  public class CucumberAIT {
//                  }
//          - Création des étapes Given/When/Then sous forme de test d'intégration système :
//              Les étapes Given/When/Then vont être implémentées comme des méthodes d'une classe de test d'intégration.
//              Donc, au lieu d'avoir une méthode de test intégrant les 3 étapes :
//                  @Test
//                  public void givenA_whenB_thenC() {
//                      // GIVEN
//                      ...
//                      // WHEN
//                      ...
//                      // THEN
//                      ...
//                  }
//              Vous allez implémenter :
//                  @Given("A")
//                  public void givenA() {
//                      ...
//                  }
//                  @When("B")
//                  public void whenB() {
//                      ...
//                  }
//                  @Then("C")
//                  public void thenC() {
//                      ...
//                  }
//              Les annotations '@Given', '@When' et '@Then' viennent de Cucumber.
//              Le contenu textuel des annotations doit alors correspondre au contenu textuel des fichiers de fonctionnalités !
//              Et là où c'est intéressant, c'est que vous pouvez paramétrer les contenus textuels dans vos méthodes !
//              Votre fichier de fonctionnalité donne des scénarios d'exemples. Ici : tester 2 + 5 = 7.
//              Vous pouvez récupérer ces arguments d'exemple en arguments de méthode. Voilà ce que ça donne pour le fichier de fonctionnalité d'addition :
//                  @Given("un élève utilise le Calculateur")
//                  public void a_student_is_using_the_Calculator() {
//                      ...
//                  }
//                  @When("{int} et {int} sont additionnés")
//                  public void and_are_added(Integer leftArgument, Integer rightArgument) {
//                      ...
//                  }
//                  @Then("on montre {int} à l'élève")
//                  public void the_student_is_shown(Integer expectedResult) {
//                      ...
//                  }
//              Le contenu textuel est paramétré par {int} et les méthodes concernées :
//                  - A la méthode annotée '@When', on récupère les deux arguments de l'addition (2 et 5).
//                  - A la méthode annotée '@Then', on récupère l'argument de résultat attendu (7).
//              Cela signifie que l'on pourrait rédiger d'autres exemples d'additions dans les fichiers de fonctionnalités, et réutiliser les mêmes méthodes d'étapes !
//              Il ne nous reste plus qu'à implémenter ces étapes. Nous allons le faire dans une nouvelle classe CalculatorSteps.
//              Nous allons réaliser un test d'intégration système basé sur Spring Boot, comme on l'a vu au chapitre précédent, mais sans mocks.
//                  --> En effet, Cucumber n'est pas compatible avec @MockBean.
//              On utilise alors deux annotations pour configurer Spring Boot avec tous les services : '@SpringBootTest' et '@AutoConfigureMockMvc'.
//              Nous ne rentrerons pas dans les détails de ces annotations.
//              Ensuite, nous implémentons les étapes Given/When/Then d'une façon similaire à CalculatorControllerSIT du chapitre précédent, mais avec un scénario encore plus proche de l'utilisateur :
//                  --> Au 'Given', on crée une requête GET pour vérifier que le formulaire est disponible à l'utilisateur.
//                  --> Au 'When', on initialise les variables en fonction du contenu textuel du fichier de fonctionnalité.
//                  --> Au 'Then', on soumet le formulaire POST et on vérifie la réponse comme au chapitre précédent.
//              Je vous laisse prendre le temps de regarder le code complet de la classe CalculatorSteps :
//                  @SpringBootTest
//                  @AutoConfigureMockMvc
//                  public class CalculatorSteps {
//                      @Inject
//                      MockMvc mockMvc;
//                      private Integer lastLeftArgument;
//                      private Integer lastRightArgument;
//                      private String calculationType;
//                      @Given("un élève utilise le Calculateur")
//                      public void a_student_is_using_the_Calculator() throws Exception {
//                          mockMvc.perform(MockMvcRequestBuilders.get("/calculator"))
//                                  .andExpect(MockMvcResultMatchers.status().is2xxSuccessful());
//                      }
//                      @When("{int} et {int} sont additionnés")
//                      public void and_are_added(Integer leftArgument, Integer rightArgument) throws Exception {
//                          lastLeftArgument = leftArgument;
//                          lastRightArgument = rightArgument;
//                          calculationType = "ADDITION";
//                      }
//                      @Then("on montre {int} à l'élève")
//                      public void the_student_is_shown(Integer expectedResult) throws Exception {
//                          final MvcResult result = mockMvc
//                                  .perform(MockMvcRequestBuilders.post("/calculator").param("leftArgument", lastLeftArgument.toString())
//                                          .param("rightArgument", lastRightArgument.toString()).param("calculationType", calculationType))
//                                  .andExpect(MockMvcResultMatchers.status().is2xxSuccessful())
//                                  .andReturn();
//                          assertThat(result.getResponse().getContentAsString()).contains(">" + expectedResult + "<");
//                      }
//                  }
// -----------
//  - En résumé :
//          --> Le développement piloté par le comportement (ou BDD) implique de collaborer avec votre équipe, les product owners, et d’autres décideurs.
//                  Collaborer pour écrire des tests d’acceptation business en utilisant un langage métier. Ils deviennent vos premiers tests qui échouent.
//          --> Le TDD de Londres ou test de l’extérieur vers l’intérieur implique de prendre ces tests d’acceptation et d’appliquer le rouge-vert-refactor des tests d’intégration système.
//                  Mais de les effectuer vers l’intérieur, vers les tests unitaires et les classes nécessaires à les satisfaire.
//          --> Cucumber utilise un fichier de fonctionnalité non technique contenant des scénarios de tests d’acceptation.
//                  Ces scénarios testent automatiquement en écrivant des définitions d’étape pour correspondre au code.
// Si l'on a pu comprendre les tests d'acceptation et implémenter un exemple avec un test d'intégration système, il reste encore un bout d'ascension à faire sur la pyramide des tests.
// Et ceci dans le but d'atteindre les tests fonctionnels de bout en bout !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Testez les parcours utilisateur avec les tests de bout en bout ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous arrivons peu à peu au sommet de la pyramide !
// L'objectif est à présent de vérifier le bon fonctionnement de l'application complète, et installée dans un environnement suffisamment proche de l'environnement de production.
// Pour cela, nous allons simuler le comportement d'un utilisateur selon des scénarios de bout en bout représentatifs. En agilité, on appelle ces scénarios des parcours utilisateur.
// Mais ne faudrait-il pas un utilisateur qui parcoure le site manuellement pour tester cela ?
// En fait, vous pouvez aussi utiliser l’automatisation ici. Si votre utilisateur utilise une application mobile, vous automatiserez une interface mobile.
// Si votre utilisateur utilise un navigateur, vous automatiserez un navigateur.
// OK, mais comment peut-on automatiser une personne qui clique dans un navigateur ?
// Il existe un robot très populaire qui peut tester les navigateurs. Et vous pouvez le faire entrer dans votre projet en tant que dépendance Maven.
//      --> Il s’appelle 'WebDriver', issu du produit libre 'Selenium'.
// Vous pouvez vérifier un parcours à travers une gamme de navigateurs (sans les télécharger) grâce à un autre composant nommé 'WebDriverManager'.
// Apprendre à automatiser les tests de sites web vous permettra de réaliser la validation de bout en bout de nombreux projets.
// Pour ceux d’entre vous qui s’intéressent aux tests des appareils mobiles, regardez 'Appium', qui est similaire à WebDriver pour les applications mobiles !
// -----------
//  - Testez votre calculateur de bout en bout !
// Notre application Calculator a maintenant une interface web, et nous n’avons pas encore prouvé qu’un élève peut utiliser notre calculateur pour résoudre un calcul basique.
// Importons tout de suite toutes les dépendances Maven nécessaires et créons un premier test de bout en bout !
// Grâce à WebDriver, ce test va ouvrir un vrai navigateur et, tel un robot, va effectuer des actions de saisie et de clics dans ce navigateur !
// Reprenons les étapes principales de ce screencast. Partez de la branche p3ch4 du dépôt de code : git checkout -f p3ch4.
// Créons ensuite un test fonctionnel en le nommant par exemple 'StudentMultiplicationJourneyE2E'.
// En haut du test, nous avons utilisé l’extension JUnit 5 de Spring avec '@ExtendWith(SpringExtension.class)'.
// Ceci nous a ensuite permis d’utiliser l’annotation '@SpringBootTest' pour démarrer notre application en entier.
// Et cela, en utilisant ce qui suit pour rendre notre application joignable par un navigateur durant le test : '@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)'.
// Cela place aussi la partie de l’adresse web de notre serveur plus bas dans le code, là où nous plaçons le champ port :
//                  @LocalServerPort
//                  private Integer port;
// Lorsque le test a été exécuté, avez-vous remarqué qu'il a ouvert un navigateur Firefox en marche ?
// Nous avons utilisé WebDriverManager pour mettre en place notre test, afin qu’il utilise un navigateur spécifique.
// WebDriverManager permet de mettre en place des instances de navigateurs variés à utiliser dans vos tests. Vous pouvez consulter sa documentation pour en savoir plus.
// Dans notre test de bout en bout (E2E), nous avons simplement requis qu’un driver pour le navigateur Firefox soit mis en place dans une méthode annotée avec '@BeforeAll' :
//                  @BeforeAll
//                  public static void setUpFirefoxDriver() {
//                      WebDriverManager.firefoxdriver().setup();
//                  }
// Dans la méthode 'setUpFirefoxDriver()' annotée '@BeforeEach', nous avons ensuite créé une instance de FirefoxDriver en utilisant :
//                  @BeforeEach
//                  public void setUpWebDriver() {
//                      webDriver = new FirefoxDriver();
//                      baseUrl = "http://localhost:" + port + "/calculator";
//                  }
// Étant donné que notre application fonctionne en local, nous avons installé baseUrl avec une URL, comme celles que vous entrez dans votre navigateur, qui pointe vers votre machine locale.
// Plus tard dans le '@AfterEach' nous avons vérifié si WebDriver a été réglé et ferme le navigateur avec 'webDriver.quit()' s’il est ouvert. Ainsi, chacun de nos tests restera indépendant.
//                  @AfterEach
//                  public void quitWebDriver() {
//                      if (webDriver != null) {
//                          webDriver.quit();
//                      }
//                  }
// Vous pouvez même regarder les tests se dérouler tandis qu’ils vérifient et cliquent dans votre navigateur !
// Maintenant, il est temps de tester que notre calculateur peut multiplier 2 par 16.
// Notre test commence par un nom significatif à propos de l’objectif de l’élève, et, comme avec nos tests unitaires, commence par un bloc pour organiser les choses pour notre test.
// Ceci, est fait naturellement, durant l'étape Arrange/Given.
//                  @Test
//                  public void aStudentUsesTheCalculatorToMultiplyTwoBySixteen() {
//                      // GIVEN
//                      webDriver.get(baseUrl);
//                      final WebElement leftField = webDriver.findElement(By.id("left"));
//                      final WebElement typeDropdown = webDriver.findElement(By.id("type"));
//                      final WebElement rightField = webDriver.findElement(By.id("right"));
//                      final WebElement submitButton = webDriver.findElement(By.id("submit"));
//                      ...
//                  }
// À la ligne 4, nous avons utilisé 'webDriver.get(baseUrl)' pour amener notre navigateur jusqu’au formulaire du calculateur.
// C’est exactement comme de taper quelque chose comme 'http://localhost:8081/calculator' dans votre navigateur.
// Les lignes 5 à 8 ont utilisé 'webDriver.findElement()' pour accéder à une partie du formulaire dans le test.
// Nous lui avons passé la méthode 'By.id()' avec une valeur d’un id dans le formulaire HTML, telle que '<input type="text" id="left">'.
// La méthode findElement de WebDriver peut recevoir une instance de la classe By, qu’elle utilise pour localiser des parties d’une page web.
// 'By' fournit un grand nombre d’options pour extraire des éléments depuis un site web selon différents critères. Consultez sa javadoc pour en savoir plus.
// La ligne 6 donne le contrôle du champ formulaire de gauche désigné par« Première Valeur » dans notre navigateur.
// Les champs du formulaire et le bouton « submit » sont représentés chacun comme une instance de la classe WebElement de WebDriver, que le "robot" saura manipuler dans nos tests.
// Notre test remplit ensuite ces champs formulaire, naturellement durant l'étape Act/When.
//                  @Test
//                  public void aStudentUsesTheCalculatorToMultiplyTwoBySixteen() {
//                      ...
//                      // WHEN
//                      leftField.sendKeys("2");
//                      typeDropdown.sendKeys("x");
//                      rightField.sendKeys("16");
//                      submitButton.click();
//                      ...
//                  }
// Ceci remplit notre formulaire et l’envoie ! Par exemple, 'leftField.sendKey("2")' tape le caractère « 2 » dans le champ formulaire pour la valeur de gauche.
// 'submitButton.click()' clique sur le bouton "submit" dans le navigateur, comme vous le feriez en remplissant le formulaire vous-même.
// Eh oui, notre navigateur se fait contrôler, et tout cela à partir d’un test JUnit ordinaire !
// Nous devons attendre que notre application nous donne une réponse, qui sera placée à côté du '=' dans un espace signalé avec l’id solution.
// Nous devons attendre que la solution apparaisse sur notre page, puis affirmer qu’elle correspond à la valeur attendue :
//                  @Test
//                  public void aStudentUsesTheCalculatorToMultiplyTwoBySixteen() {
//                      ...
//                      // THEN
//                      final WebDriverWait waiter = new WebDriverWait(webDriver, 5);
//                      final WebElement solutionElement = waiter.until(
//                              ExpectedConditions.presenceOfElementLocated(By.id("solution")));
//                      final String solution = solutionElement.getText();
//                      assertThat(solution).isEqualTo("32"); // 2 x 16
//                  }
// Effectuez cela en utilisant la classe 'WebDriverWait' de 'WebDriver' qui attend un élément.
// À la ligne 5, nous avons créé une instance de WebDriverWait et lui avons donné le WebDriver et une valeur de 5 pour la faire attendre 5 secondes.
// Pour faire attendre notre test 5 secondes jusqu’à l’apparition d’un élément avec l’id de solution sur la page, nous avons appelé notre méthode 'until()' de 'WebDriverWait'.
// Nous lui avons passé le résultat de la méthode statique 'ExpectedConditions.presenceOfElementedLocated()'.
// A celle-ci, nous avons passé un spécificateur selon lequel nous voulions trouver un élément en utilisant 'By.id("solution")'.
// Cela attendra que notre page affiche une solution, puis retournera un WebElement appelé 'solutionElement' à la ligne 6.
// Ceci contient la valeur de notre page web avec la solution, en utilisant un id de solution.
// Finalement, nous avons vérifié le résultat de notre test en obtenant la valeur 32 en retour.
// À la ligne 8, 'solutionElement.getText()' a renvoyé la valeur 32 comme un String. À la ligne 9, nous avons utilisé AssertJ pour vérifier que nous obtenons 32 en retour.
// -----------
//      --> Test Selenium avec Opera :
//                  package com.openclassrooms.testing.calcul.e2e;
//                  import static org.assertj.core.api.Assertions.assertThat;
//                  import org.junit.jupiter.api.AfterEach;
//                  import org.junit.jupiter.api.BeforeAll;
//                  import org.junit.jupiter.api.BeforeEach;
//                  import org.junit.jupiter.api.Test;
//                  import org.junit.jupiter.api.extension.ExtendWith;
//                  import org.openqa.selenium.By;
//                  import org.openqa.selenium.WebDriver;
//                  import org.openqa.selenium.WebElement;
//                  import org.openqa.selenium.opera.OperaDriver;
//                  import org.openqa.selenium.support.ui.ExpectedConditions;
//                  import org.openqa.selenium.support.ui.WebDriverWait;
//                  import org.springframework.boot.test.context.SpringBootTest;
//                  import org.springframework.boot.web.server.LocalServerPort;
//                  import org.springframework.test.context.junit.jupiter.SpringExtension;
//                  import io.github.bonigarcia.wdm.WebDriverManager;
//                  @ExtendWith(SpringExtension.class)
//                  @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
//                  public class StudentMutliplicationJourneyE2E {
//                      @LocalServerPort
//                      private Integer port;
//                      private WebDriver webDriver;
//                      private String baseUrl;
//                      @BeforeAll
//                      public static void setUpFirefoxDriver() {
// 	                 WebDriverManager.operadriver();
//                      }
//                      @BeforeEach
//                      public void setUpWebDriver() {
// 	                 webDriver = new OperaDriver();
// 	                 baseUrl = "http://localhost:" + port + "/calculator";
//                      }
//                      @AfterEach
//                      public void quitWebDriver() {
// 	                 if (webDriver != null) {
// 	                     webDriver.quit();
// 	                 }
//                      }
//                      @Test
//                      public void aStudentUsesTheCalculatorToMultiplyTwoBySixteen() {
// 	                 // GIVEN
// 	                 webDriver.get(baseUrl);
// 	                 WebElement leftField = webDriver.findElement(By.id("left"));
// 	                 WebElement rightField = webDriver.findElement(By.id("right"));
// 	                 WebElement typeDropDown = webDriver.findElement(By.id("type"));
// 	                 WebElement submitButton = webDriver.findElement(By.id("submit"));
// 	                 // WHEN
// 	                 leftField.sendKeys("2");
//                  	rightField.sendKeys("16");
// 	                 typeDropDown.sendKeys("x");
// 	                 submitButton.click();
// 	                 // THEN
// 	                 final WebDriverWait waiter = new WebDriverWait(webDriver, 5);
// 	                 WebElement solutionElement = waiter.until(
// 	                 	ExpectedConditions.presenceOfElementLocated(By.id("solution"))
// 	                 );
// 	                 String solution = solutionElement.getText();
// 	                 assertThat(solution).isEqualTo("32");
//                      }
//                  }
// -----------
//  - En résumé :
//          --> Vous pouvez utiliser WebDriver pour écrire des tests qui vérifient votre navigateur à distance.
//          --> WebDriverManager aide à sélectionner de façon déclarative sur quel navigateur vous voulez tester.
//                  Sans lui, il vous faudra beaucoup plus de mise en place, et télécharger manuellement des navigateurs.
//          --> Vous pouvez récupérer des parties d’une page web comme instances WebElement en utilisant 'webDriver.findElement()'.
//          --> Vous pouvez utiliser des méthodes telles que 'sendKeys()' et 'click()' pour interagir avec les WebElements dans votre navigateur.
// Vous avez réussi à implémenter votre premier test fonctionnel de bout en bout.
// Mais savez-vous que vous pouvez améliorer la conception de ces tests grâce aux objets de page ?
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Améliorez la maintenabilité des tests fonctionnels avec les objets de page ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans ce chapitre, nous allons consolider notre ascension au sommet de la pyramide des tests !
// En effet, les tests fonctionnels sont les plus fragiles. Et le moindre changement dans une page web peut rendre votre test obsolète.
//      --> Voyons comment nous pouvons améliorer la maintenabilité des tests fonctionnels de bout en bout, notamment grâce aux objets de page.
// -----------
//  - Évitez le piège des tests de bout en bout fragiles :
// Il existe un principe populaire dans le logiciel que vous devez toujours essayer de respecter.
//      --> Cela s’appelle la règle DRY, pour "don’t repeat yourself". Cela signifie que vous ne devez pas écrire le même code deux fois.
// Si vous le faites, c’est un bon moment pour nettoyer votre code avec le refactoring. Vous vous rappelez l'indicateur SonarCloud sur la duplication de code ?
// C'est le même refactoring qui est utilisé dans le cycle rouge-vert-refactor !
// Chaque répétition représente davantage de code que vous devez modifier si le comportement de votre application change. C’est aussi plus de code qui peut mal tourner.
// Assez fréquemment lors de l’écriture des tests de bout en bout, vous avez besoin d'aller sur la même page à travers de multiples tests.
// Parfois, il vous faut cliquer sur un bouton ou remplir un champ. Quand il s’agit de déclarations d’une ligne, souvent dans un ordre différent.
// Regardez ce bout de code :
//                  @Test
//                  public void aStudentUsesTheCalculatorToMultiplyTwoBySixteen() {
//                      // GIVEN
//                      webDriver.get(baseUrl);
//                      final WebElement leftField = webDriver.findElement(By.id("left"));
//                      final WebElement typeDropdown = webDriver.findElement(By.id("type"));
//                      final WebElement rightField = webDriver.findElement(By.id("right"));
//                      final WebElement submitButton = webDriver.findElement(By.id("submit"));
//                      // WHEN
//                      leftField.sendKeys("2");
//                      typeDropdown.sendKeys("x");
//                      rightField.sendKeys("16");
//                      submitButton.click();
//                      // THEN
//                      final WebDriverWait waiter = new WebDriverWait(webDriver, 5);
//                      final WebElement solutionElement = waiter.until(
//                              ExpectedConditions.presenceOfElementLocated(By.id("solution")));
//                      final String solution = solutionElement.getText();
//                      assertThat(solution).isEqualTo("32"); // 2 x 16
//                  }
// Ce parcours utilisateur devait tester la multiplication. Imaginez que vous ayez d’autres tests pour valider les parcours pour différents types de calculs.
// Ce test pourrait inclure le code pour trouver des éléments de page et interagir avec eux pour effectuer la multiplication.
// Si vous écriviez plus de tests, vous pourriez rapidement vous retrouver avec une logique similaire dans beaucoup de tests !
// Regardons la partie de notre formulaire où nous avons sélectionné le calculationType (le type de calcul) :
//                  <form action="#" th:action="@{/calculator}" th:object="${calculation}" method="post">
//                           ...
//                                  <div class="col">
//                                      <select id="type" th:field="*{calculationType}" class="form-control form-control-lg">
//                                          <option value="ADDITION" selected="true"> + </option>
//                                          <option value="SUBTRACTION" selected="true"> - </option>
//                                          <option value="MULTIPLICATION"> x </option>
//                                          <option value="DIVISION"> / </option>
//                                      </select>
//                                  </div>
//                           ...
//                              </div>
//                              <div class="row">
//                                  <div class="col">
//                                      <button id="submit" type="submit" class="btn btn-primary">=</button>
//                                  </div>
//                           ...
// Maintenant, imaginez ce qui se produirait si nous le transformions d’un menu déroulant en des cases à cocher ?
// Ou si un designer voulait restructurer et modifier le style de notre site, en créant de nouvelles pages HTML ?
// Nous verrions nos tests se casser et nous devrions trouver tous les tests qui pensent savoir comment fonctionne notre page, et les modifier !
//      --> Martin Fowler, l’un des fondateurs du mouvement Agile, a introduit le modèle 'PageObject'.
// Il applique la programmation orientée objet à la façon dont nous concevons une page web.
// En remplacement du code ci-dessus, il s’agit de rassembler toutes ces méthodes et ces sélecteurs spécifiques à une page au même endroit.
// Un sélecteur, c’est ce 'By.Id("left")' du code ci-dessus, qui demande à notre test de rechercher '<input id=”left">'.
// Les tests précédents étaient fragiles car de petits changements dans le HTML pouvaient les casser.
//      --> Créons une classe PageObject pour notre calculateur ensemble pour éviter ces problèmes !
// Partez de la branche p3ch5 du dépôt de code de ce cours : git checkout -f p3ch5.
// Créez un nouveau paquetage com.openclassrooms.testoing.calcul.e2e.page et créez une nouvelle classe CalculatorPage.
// Déclarons les attributs de cette classe correspondant aux éléments que l'on peut trouver sur la page du Calculator :
//                  public class CalculatorPage {
//                      @FindBy(id = "submit")
//                      private WebElement submitButton;
//                      @FindBy(id = "left")
//                      private WebElement leftArgument;
//                      @FindBy(id = "right")
//                      private WebElement rightArgument;
//                      @FindBy(id = "type")
//                      private WebElement calculationType;
//                      @FindBy(id = "solution")
//                      private WebElement solution;
//                      ...
//                  }
// Chaque attribut est une instance de class WebElement, et l'annotation '@FindBy' permettra au WebDriver d'associer cet élément avec l'élément HTML ayant l'id indiqué.
//      --> Ensuite, on code une méthode pour soumettre un calcul depuis cette page :
//                  private String calculate(String calculationTypeValue, String leftValue, String rightValue) {
//                          leftArgument.sendKeys(leftValue);
//                          calculationType.sendKeys(calculationTypeValue);
//                          rightArgument.sendKeys(rightValue);
//                          submitButton.click();
//                          final WebDriverWait waiter = new WebDriverWait(webDriver, 5);
//                          waiter.until(ExpectedConditions.visibilityOf(solution));
//                          return solution.getText();
//                      }
// On y ajoute 4 méthodes pour faciliter les utilisateurs de cette classe pour les 4 opérations courantes.
// Elles appelleront toutes la méthode calculate. La classe finale CalculatorPage aura donc le code suivant :
//                  public class CalculatorPage {
//                      public static final String ADDITION_SYMBOL = "+";
//                      public static final String SUBTRACTION_SYMBOL = "-";
//                      public static final String DIVISION_SYMBOL = "/";
//                      public static final String MULTIPLICATION_SYMBOL = "x";
//                      @FindBy(id = "submit")
//                      private WebElement submitButton;
//                      @FindBy(id = "left")
//                      private WebElement leftArgument;
//                      @FindBy(id = "right")
//                      private WebElement rightArgument;
//                      @FindBy(id = "type")
//                      private WebElement calculationType;
//                      @FindBy(id = "solution")
//                      private WebElement solution;
//                      private final WebDriver webDriver;
//                      public CalculatorPage(WebDriver webDriver) {
//                          this.webDriver = webDriver;
//                          PageFactory.initElements(webDriver, calculatorPage);
//                      }
//                      public String add(String leftValue, String rightValue) {
//                          return calculate(ADDITION_SYMBOL, leftValue, rightValue);
//                      }
//                      public String subtract(String leftValue, String rightValue) {
//                          return calculate(SUBTRACTION_SYMBOL, leftValue, rightValue);
//                      }
//                      public String divide(String leftValue, String rightValue) {
//                          return calculate(DIVISION_SYMBOL, leftValue, rightValue);
//                      }
//                      public String multiply(String leftValue, String rightValue) {
//                          return calculate(MULTIPLICATION_SYMBOL, leftValue, rightValue);
//                      }
//                      private String calculate(String calculationTypeValue, String leftValue, String rightValue) {
//                          leftArgument.sendKeys(leftValue);
//                          calculationType.sendKeys(calculationTypeValue);
//                          rightArgument.sendKeys(rightValue);
//                          submitButton.click();
//                          final WebDriverWait waiter = new WebDriverWait(webDriver, 5);
//                          waiter.until(ExpectedConditions.visibilityOf(solution));
//                          return solution.getText();
//                      }
//                  }
// Je vous invite à regarder la ligne 27 de plus près : c'est grâce à cet appel de PageFactory, une classe de Selenium, que les attributs annotés '@FindBy' sont initialisés.
// Voilà, nous avons créé notre premier objet de page ! Il ne reste plus qu'à l'utiliser ! Allons dans la classe de test StudentMultiplicationJourneyE2E et modifions le code du test  aStudentUsesTheCalculatorToMultiplyTwoBySixteen()  pour utiliser l'objet de page :
//                      @Test
//                      public void aStudentUsesTheCalculatorToMultiplyTwoBySixteen() {
//                          // GIVEN
//                          webDriver.get(baseUrl);
//                          final CalculatorPage calculatorPage = new CalculatorPage(webDriver);
//                          // WHEN
//                          final String solution = calculatorPage.multiply("2", "16");
//                          // THEN
//                          assertThat(solution).isEqualTo("32"); // 2 x 16
//                      }
// C'est plus synthétique, non ? À l'étape GIVEN, on initie l'objet de page.
// Et les étapes WHEN et THEN sont clairement simplifiées, car une partie du code est traitée par CalculatorPage.
// Nous avons donc pu appeler 'calculatorPage.multiply(2, 16)' et laisser la responsabilité de remplir les champs de formulaire appropriés au PageObject !
//      --> Vous pouvez alors coder d'autres tests simplement, par exemple un test d'addition :
//                      @Test
//                      public void aStudentUsesTheCalculatorToAddTwoToSixteen() throws InterruptedException {
//                          // GIVEN
//                          webDriver.get(baseUrl);
//                          final CalculatorPage calculatorPage = new CalculatorPage(webDriver);
//                                          // WHEN
//                          final String solution = calculatorPage.add("2", "16");
//                          // THEN
//                          assertThat(solution).isEqualTo("18"); // 2 + 16
//                      }
// Cela vous protège aussi de la dispersion de dépendances sur la structure de votre page web à travers de nombreux tests.
//      --> Il n’y a qu’une dépendance sur la structure de toute page, il s’agit de l’objet de page que vous avez modelé d’après elle.
// Imaginez que dans 'calculator.html', l'identifiant du champ de type de calcul change (ligne 34 du fichier calculator.html).
// Le champ :           <select id="type" th:field="*{calculationType}" class="form-control form-control-lg">.
// Devient :            <select id="typeOperation" th:field="*{calculationType}" class="form-control form-control-lg">.
// Vos deux tests vont échouer ! Mais pour les refaire passer en succès, il vous suffit de changer juste la ligne adaptée dans CalculatorPage :
//                      @FindBy(id = "type")
//                      private WebElement calculationType;
// Devient :
//                      @FindBy(id = "typeOperation")
//                      private WebElement calculationType;
// Le code complet pour ce chapitre se trouve sur la branche p3ch5-fin : git checkout -f p3ch5-fin.
// -----------
//  - Évitez la pyramide inversée :
// Vous êtes désormais armé de tous les outils nécessaires pour tester chaque niveau de la pyramide, mais méfiez-vous.
// Il est facile de se laisser séduire par le côté obscur du test.
// Plutôt que de choisir ce qui semble facile aujourd’hui, envisagez une approche qui vous permettra d’avoir une confiance continue en vos tests automatisés.
// Il est facile de vous écarter de l’équilibre entre le feedback opportun et rapide et la confiance, en écrivant plus de tests vers le sommet de la pyramide.
// Et ainsi en glissant ainsi vers un anti-pattern connu sous le nom de pyramide inversée.
// Lorsque nous parlons d’une nouvelle fonctionnalité dans une application, nous nous projetons directement dans l'interface utilisateur : "Afficher un message d’erreur en lecture seule à l’utilisateur".
// Ceci pourrait vous conduire à choisir le mauvais test : la plupart des codeurs penseront immédiatement à écrire un test de bout en bout.
//      --> Mais si vous avez un test d’intégration existant qui prouve que vous pouvez afficher des erreurs à l’utilisateur, un simple test d'intégration, voire unitaire, suffirait.
// Plus vous avancez dans une application, plus il est facile de se tourner par défaut vers des tests situés plus haut dans la pyramide.
// Mais plus vous écrivez de tests de bout en bout, plus votre feedback est lent, et plus il faut de temps aux développeurs pour savoir s’ils sont sur la bonne voie.
// Vous pourriez même vous convaincre que ça va plus vite de faire des tests manuels !
//      --> Voici quelques signaux représentatifs que vous pouvez guetter, qui indiquent que votre pyramide commence à s’inverser :
//              --> Vos tests se cassent souvent, et il est normal de devoir les réexécuter jusqu’à ce qu’ils réussissent.
//              --> Vos tests sont si peu fiables qu’il vous faut des tests manuels, juste pour être sûr.
//              --> Vos tests d’intégration et de bout en bout sont si lents que vous devez les exécuter séparément.
//                      Vous le faites peut-être pour une bonne raison, mais s’ils prennent des heures, vous devez vous demander ce que vous pouvez redescendre dans vos tests unitaires.
//              --> Votre équipe ne s’intéresse plus à ce que tous les tests fonctionnent.
//              --> On n’écrit plus de nouveaux tests unitaires, ou ils ont seulement quelques tests de bons chemins.
//              --> De nombreux bugs sont détectés par test manuel, ou par les utilisateurs peu après une sortie.
// -----------
//  - En résumé :
//          --> Les modèles PageObject vous permettent d’englober les sélecteurs d’une page et de fournir des méthodes nommées de façon sémantique pour effectuer des actions sur cette page web.
//          --> L’utilisation du modèle PageObject vous protège de la dispersion des dépendances sur la structure de vos pages web.
//          --> Méfiez-vous de la pyramide inversée. Il est facile d’être entraîné à tout tester avec des tests fonctionnels de bout en bout.
//                  Ces tests ralentissent rapidement, et peuvent devenir peu fiables.
// Ce chapitre achève cette troisième et dernière partie sur les tests d'intégration et fonctionnels.
// Et si nous récapitulions tout ce que vous avez appris ? Rendez-vous au prochain et dernier chapitre !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Résumé du cours ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous êtes parvenu à la fin de ce cours. Vous avez à présent toutes les clés en main pour écrire un code testé de qualité, selon les meilleures pratiques du moment.
// Vous disposez maintenant de toutes les connaissances nécessaires pour :
//      - Pratiquer le TDD avec les tests unitaires et le TDD de Londres avec les tests d'acceptation.
//      - Utiliser JUnit 5 et la bibliothèque d'assertions AssertJ.
//      - Structurer un test unitaire selon les 3 étapes AAA ou Given/When/Then.
//      - Vérifier la couverture de vos tests et la qualité de votre code avec SonarCloud.
//      - Utiliser Mockito pour créer des mocks et obtenir des tests bien isolés (le principe F.I.R.S.T. !).
//      - Ecrire différents types de tests d'intégration.
//      - crire les tests fonctionnels de bout en bout et exploiter le pattern des PageObject.
// Il ne vous reste plus qu’à utiliser vos nouvelles compétences en continuant à écrire d’excellents tests pour vos applications !
// Le monde des tests, et plus généralement de l’automatisation, évolue très rapidement.
// Je vous invite à pratiquer d’abord, à échanger avec d’autres développeurs, et à continuer à vous tenir informé !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Débuggez votre application Java ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bien que vous essayiez toujours d’éliminer les bugs, ils apparaissent dans pratiquement tous les projets de développement, pour diverses raisons.
//      --> Alors, comment réagir lorsque votre logiciel cesse de se comporter comme vous l’attendez ?
//      --> Quel process suivre pour signaler un bug et le réparer ?
//      --> Comment s'attaquer à sa cause initiale, pour de bon ?
// Le debug, lorsqu’il est bien effectué, est un process scientifique piloté par des tests qui vous aide à comprendre un bug et à éviter qu’il se reproduise.
// Ce cours vous emmènera en voyage en partant du rapport de bug, et à travers une myriade d’outils, y compris un débugger Java, VisualVM, et JConsole.
// Vous utiliserez un débugger Java pour investiguer et examiner une JVM en exécution jusqu’à avoir trouvé la cause d’un bug complexe.
// Vous apprendrez à mettre en place des points d’arrêt conditionnels, à faire progresser et inverser le flux d’exécution, et à inspecter les valeurs changeantes.
// Vous apprendrez aussi à tester des théories pour résoudre le mystère d’un bug difficile à comprendre.
//      --> Vous utiliserez VisualVM pour répondre à un rapport portant sur une application lente et identifier le point sensible de votre code qui la ralentit.
//      --> Vous utiliserez JConsole pour inspecter les métriques JMX d’une application Spring, afin d’examiner une application de production en exécution.
//              --> Vous rendrez même ses rapports plus communicatifs sans la relancer.
// Avez-vous déjà enquêté sur un problème au sein de votre code en utilisant des déclarations print ?
// Eh bien, vous allez apprendre comment éviter cette pratique et obtenir un résultat similaire, mais plus efficient, en utilisant la log SLF4J et en mettant en place des niveaux de log significatifs.
//      --> Objectifs pédagogiques :
//              - Identifier des méthodologies, des outils, et le vocabulaire clés du débug.
//              - Enquêter sur un bug avec un débugger Java.
//              - Réparer des bugs avec VisualVM, JConsole, et des techniques de log.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découvrez la méthodologie du débug ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découvrez l’origine des bugs //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Identifiez la source des bugs :
// Avez-vous déjà imaginé un plan parfait, pour vous rendre compte plus tard qu’il ne convenait pas au monde réel ?
// Peut-être aviez-vous oublié un détail clé ou ne vous étiez-vous pas rendu compte qu’un élément poserait problème avant qu’il ne soit trop tard ?
//      --> C’est arrivé à la plupart des gens ! Cela fait partie de la condition humaine.
// La même vérité s’applique à l’écriture de code. Quand vous écrivez un programme Java, vous construisez un plan qu’un ordinateur peut suivre pour résoudre un problème.
// Vous définissez les besoins de vos clients, les interprétez sous forme de règles métiers, puis les traduisez en Java.
// Ce travail s’effectue avec des cerveaux, des mains et des claviers. Autrement dit, des instruments de l’erreur humaine !
// Les coquilles, les manquements à la logique, et les erreurs sont des choses qui arrivent.
// Un bug est une erreur dans votre logiciel (qui fait que votre programme fait autre chose que ce à quoi vous vous attendiez).
// Le terme bug a été inventé par la vice-amirale Grace Hopper, pionnière de l’ingénierie informatique. Un jour, son super ordinateur a rencontré un problème bizarre.
//      --> Quand elle l’a ouvert, elle s’est aperçue que des mites s’y étaient installées !
// Cette anecdote nous incite à nous rappeler humblement qu’il existe beaucoup trop de défauts possibles pour que nous puissions penser à tout.
// Les bugs doivent être réparés, mais nul besoin de paniquer. Votre logiciel est un réseau complexe de code, d’idées, et d’architecture logicielle.
// Donc si vous essayez frénétiquement d’assommer un bug, vous risquez de casser autre chose.
// Une approche plus structurée vous permettra de découvrir ce qui est à l’origine du bug et de réparer sa cause première.
// Bien que les bugs puissent être stressants, ils constituent également une excellente manière d’acquérir de nouvelles connaissances sur votre logiciel.
// Le fait de les traquer représente une opportunité de comprendre ce qu’il s’est passé, de le rectifier, et d’éviter que cela ne se reproduise. C’est une bonne chose !
// Gardez un état d’esprit d’apprentissage, c’est important. Cela devrait même faire partie de la façon dont fonctionnent les équipes.
// -----------
//  - Types de bugs :
// Mieux comprendre les bugs constitue une première étape pour que vous puissiez prioriser ceux qui méritent votre temps.
// Il existe deux types de bugs principaux, les pannes et les défauts.
//      - Panne :
//          De temps en temps, un bug troublera le flux de votre application à tel point qu’une erreur apparaîtra aux utilisateurs.
//              --> Il pourrait provoquer l’arrêt de leur programme, ou leur donner un résultat incorrect !
//          Dans des circonstances extrêmes, cela pourrait occasionner des cris. Vous ne voulez pas faire crier vos utilisateurs.
//          Les erreurs qui impactent directement vos utilisateurs sont connues sous le nom de pannes.
//          Qu’il s’agisse d’une exception ou d’une application qui plante, lorsque votre utilisateur est impacté de façon négative, le bug devient une priorité.
//          Des développeurs qui ont été trop paresseux par le passé pour utiliser try et catch ont donné une mauvaise réputation aux applications Java.
//          En effet, ces derni-resqui spammeraient les utilisateurs avec des exceptions d’aspect technique et de longues stack traces.
//          L’information indique une panne logicielle. Elle est utile aux développeurs, mais non aux utilisateurs, car ils ne peuvent rien y faire.
//              --> La leçon à retenir est de toujours utiliser catch et de gérer vos exceptions, afin que vos utilisateurs n’aient pas à le faire !
//              --> Une stack trace est une liste des méthodes appelées avant que l’exception ne soit levée.
//      - Défauts :
//          Tous les bugs ne gâchent pas la journée de vos utilisateurs.
//          Les défauts sont des bugs qui pourraient exister silencieusement, sans se faire remarquer par les personnes utilisant votre logiciel.
//              --> Ils provoquent des comportements inattendus dans le code, mais pas suffisamment pour gêner visiblement l’utilisateur.
//          Par exemple, un message d’erreur pourrait être mal formulé ou affiché avec la mauvaise couleur.
//          Des valeurs monétaires pourraient être arrondies à cinq décimales au lieu de deux, alors que les utilisateurs ne s’intéressent pas à ces valeurs de toute façon.
//          Dans bien des cas, les tests détecteront ces erreurs, la spécification n’étant pas respectée : néanmoins, ces bugs se glissent en production occasionnellement.
//          Pourquoi cela arrive-t-il ? Tout simplement parce que ces cas n’ont pas été testés, car personne n’a pensé à écrire un test pour ce scénario en particulier, avec toutes ses nuances.
//              --> Les défauts seraient donc simplement des pannes moins graves ?
//          Oui. Les pannes sont les points culminants des défauts.
//              --> Les défauts créent un effet boule de neige jusqu’à arriver à un problème qui empêche l’utilisation de votre application – autrement dit, une panne !
//          Souvenez-vous que, quel que soit le nom que vous utilisez, c’est quelque chose que votre logiciel fait alors qu’il ne devrait pas.
//          Une remarque : parfois, une erreur peut devenir une solution acceptable sur le long terme si elle n’impacte pas votre capacité à résoudre le bon problème utilisateur.
//          Les utilisateurs pourraient même avoir adoré des défauts. J’ai vu ce cas en utilisant accidentellement la mauvaise feuille de style dans une application web !
//          Les utilisateurs pourraient se plaindre si vous rectifiez cela !
// -----------
//  - En résumé :
//          --> Les défauts sont des erreurs dans le logiciel qui peuvent rester en sommeil et ne sont pas toujours apparentes.
//          --> Les pannes sont causées par des défauts dans le logiciel et empêchent les utilisateurs d’utiliser votre logiciel.
// Vous vous demandez comment résoudre ces défauts et ces pannes ? Découvrez la méthodologie du débug dans le prochain chapitre !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez une méthodologie efficace de débug ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Méthodologie de débug :
//      - Observer.
//      - Reproduire.
//      - Théoriser.
//      - Inspecter.
//      - Corriger.
// -----------
//  - Débarrassez-vous des bugs avec un process scientifique : le débug !
// La réparation des bugs de logiciel ressemble à la relecture d’un article.
// Vous devez tous les trouver, apporter des corrections, et vous assurer que ce sont des améliorations par rapport à l’original.
// Ce process basique s’appelle le débug. Pour débugger un logiciel de manière efficace, vous devez utiliser une approche méthodique pour identifier et résoudre chaque problème.
// Spécifiquement, pour chaque bug que vous voyez, vous devez respecter les étapes suivantes.
// -----------
//  - Étape 1 : Observez le bug :
// Avant de supposer que vous êtes face à un bug, assurez-vous qu’il est bien réel !
// Avez-vous déjà vu un logiciel échouer puis se mettre soudainement à fonctionner à nouveau ?
// Votre connexion réseau a pu être interrompue pendant deux minutes.
// Votre ordinateur effectuait peut-être une mise à jour au moment où votre application a redémarré spontanément.
// Vous ne reverrez peut-être jamais ce problème particulier, car il était dû à un pépin et à une convergence de facteurs peu probables.
// Ce n’était peut-être même pas un problème à la base !
// -----------
//  - Étape 2 : Écrivez un test répétable pour le comportement correct attendu :
// Pour commencer le travail sur un bug, vous devez être capable de vérifier que c’est quelque chose que vous pouvez reproduire, comprendre, corriger, et dont vous pouvez prouver la réparation.
// Cela signifie que vous avez besoin d’un moyen de reproduire le problème, afin que vous puissiez enquêter à son sujet et vérifier son comportement.
// Quel serait un moyen fiable de mettre en place votre logiciel de manière prévisible pour que (a) il fasse quelque chose et (b) que vous vérifiez le résultat ?
//      --> Cela ressemble à une tâche pour un test automatique !
// Pour ce faire, créez un test pour le comportement attendu de votre logiciel sans le bug.
//      --> Il échouera à sa première exécution, car vous avez un bug !
// Ainsi, quand vous pensez avoir résolu le problème, vous pouvez lancer le test.
//      --> S’il réussit, vous saurez que vous avez corrigé le problème avec succès ! De plus, avec un test, vous verrez si quelqu’un réintroduit ce bug un jour.
// Le fait de réparer un bug qui ne peut pas être reproduit c’est un peu comme rechercher un objet chez soi que l’on ne possède peut être même pas.
// Résistez à l’envie de vous lancer sans prendre le temps de comprendre le problème !
// -----------
//  - Étape 3 : Proposez une théorie sur la raison de l’apparition du bug :
// Quand vous commencez par un test, vous pouvez enquêter pour déterminer quel élément dans le code fait échouer le test.
//      --> En étudiant le code alors que votre test échoue, vous trouverez une ou plusieurs idées sur les causes possibles du problème.
// Chacune de ces idées peut être listée et soumise à enquête en testant votre solution.
// Devinez quoi ? Ces excellentes idées que vous avez trouvées sont des théories !
//      --> Et si j’arrive à voir immédiatement quelle est l’erreur dans le code ? Je dois toujours écrire un test et imaginer des théories ?
// Certaines erreurs sembleront évidentes. En voyant le message d’erreur, vous pourriez penser intuitivement que vous savez ce qu’il se passe.
// Imaginons que vous remarquez qu’une exception ait été levée depuis une classe que vous venez de modifier. Cela semble être une solution évidente pour ce bug.
// Est-ce qu’il ne serait pas tentant de lancer votre IDE, vous plonger dans le code, et trouver le chemin le plus rapide pour contourner le problème ?
//      --> Mais êtes-vous sûr de déjà savoir quel est le problème ?
// Même si vous supprimez le symptôme (l’exception) pour l’instant, vous n’aurez peut-être pas traité les causes profondes.
// En ne prenant pas le temps d’examiner les causes premières possibles, le risque existe toujours qu’un problème sous-jacent provoque le chaos dans votre programme d’une autre façon.
// De plus, le fait de contourner un bug signifie généralement que vous ajoutez un cas spécial à votre logiciel, qui est contraire à son comportement normalement attendu.
// En parlant de cas spécial, je veux parler de manipulation de la logique de votre programme d’une façon qui n’est pas cohérente avec le design original du code.
//      --> Ceci compliquera votre logiciel, et vous devrez envisager des situations inhabituelles dès que vous ferez une modification.
// Si l’erreur est évidente, vous avez une théorie à valider, et l’écriture du test la confirmera.
// Je sais qu’il est difficile de ne pas se lancer immédiatement, mais il vous faut déterminer précisément pourquoi le bug a été déclenché, et non uniquement comment l’éliminer.
// En commençant par une théorie et un test automatique pour la vérifier, vous pouvez cibler un problème spécifique et être sûr que vous l’avez réparé !
//      --> Les bugs s’infiltrent généralement dans votre code car ils n’ont pas été envisagés quand le logiciel a été écrit.
// Si le bug que vous avez vu était si facile à voir, comment a-t-il échappé au premier passage des développeurs ?
// Il n’a peut-être pas toujours été si visible.
//      --> Le faire taire en cachant un message d’erreur pourrait vouloir dire que vous ratez une erreur plus importante qui se développe dans votre code.
// -----------
//  - Étape 4 : Confirmez ou infirmez la théorie :
// Et maintenant, essayez de confirmer votre théorie en menant l’enquête dans votre code.
//      --> Votre but est de réparer le test qui échoue.
// Avec votre théorie, nous espérons que vous réparerez le bug, ainsi qu’une série d’autres problèmes similaires.
//      --> Si ce n’est pas le cas, revenez à l’étape 2 et recommencez avec une nouvelle théorie, jusqu’à avoir trouvé une réponse.
// -----------
//  - Étape 5 : Résolvez le bug :
// Rappelez-vous que les bugs arrivent souvent à plusieurs. Une seule erreur peut se manifester par une série de bugs similaires.
// Il m’est arrivé à de multiples reprises d’avoir réparé un bug et de le voir fermer une série d’autres bugs similaires.
// Encore une fois, une bonne façon de résoudre cela est d’effectuer davantage de tests.
//      --> Comment appliquer ces étapes à l’investigation d’un bug réel ?
// Imaginons que vous ayez construit une application d’e-commerce.
// Vous avez reçu un rapport de bug indiquant que, lorsqu’une utilisatrice essaye d’enlever un seul élément de son panier, elle se retrouve avec un élément de plus plutôt qu’un élément de moins.
//      --> Comment aborderiez-vous ce cas en utilisant la structure ci-dessus ?
// Parcourons les étapes ensemble :
//      - Étape 1 : Reproduisez ! Tout d’abord, il vous faut vous assurer qu’il s’agit d’un bug réel.
//          Il existe différentes façons dont vous pouvez le reproduire dans une application en exécution :
//          Demandez à l’utilisateur de vous montrer ce qu’il s’est passé, ce qui pourrait confirmer la réalité du bug.
//          Consultez tous les logs que vous avez pour comprendre ce qu’il s’est passé dans le logiciel à ce moment-là (en supposant que vous ayez de bons logs). Si ce n’est pas le cas, enrichissez-les et réessayez.
//      - Étape 2 : Écrivez un test ! Vous savez peut-être ce que vous devez réparer à ce stade. Il y a peut-être un + à la place d’un -.
//          Plutôt que de vous précipiter, une manière méthodique de vous assurer que vous ne commettez pas d’autres erreurs serait d’écrire un test.
//          Vous pourriez écrire un test voué à l’échec qui s’attend à ce que le panier soit vide lorsque vous enlevez le seul élément qui s’y trouve. Il devrait échouer.
//      - Étape 3 : Générez des théories ! Regardez le code et essayez de définir pourquoi le test échoue.
//      - Étape 4 : Testez vos théories ! Utilisez le test qui échoue pour reproduire le bug.
//          Ensiuite, sur la base de vos théories, testez différentes réparations jusqu’à ce qu’il soit résolu (c’est-à-dire, que les éléments soient supprimés du panier).
//          Le test restera dans votre code et aidera d’autres développeurs à s’assurer qu’il ne se casse pas à nouveau.
//      - Étape 5 : Résolvez votre bug ! Vous aurez peut-être besoin de tests supplémentaires si vous avez découvert plus de bugs.
// On dirait que ce process peut prendre pas mal de temps. Et si je suis sous pression et que le bug doit être réparé le plus vite possible ?
// Nous avons tous connu cela. Mais le fait de réparer quelque chose le plus vite possible ne signifie pas qu’il ne faut pas le reproduire, comprendre, et tester.
// Il le faut si l’on veut avoir une chance de la réparer vraiment.
// Imaginez que vous décidiez de réparer quelque chose sans respecter la procédure ci-dessus.
// Votre première impulsion sera peut-être de tester manuellement (ou de tâtonner), mais cela peut prendre plus longtemps que vous ne le pensez.
//      --> Arrêtez-vous et repensez votre approche. Les tests manuels peuvent être lents et peu fiables comparés aux tests automatiques.
// Si vous décidez de sortir une réparation effectuée à la va-vite, vous devez tout de même nettoyer derrière vous.
// Ne voudriez-vous pas être sûr que vous avez résolu le véritable problème et que vous n’en avez pas causé d’autres ?
// Voudriez-vous pouvoir savoir si le bug sera réintroduit accidentellement à l’avenir ? Moi oui !
// Ne répétez pas la même négligence qui s’est produite lors de l’écriture initiale de votre code. Prenez le temps de réparer votre bug de façon fiable.
// -----------
//  - Vivre dans un monde de bugs :
// En tant qu’ingénieur logiciel, vous avez autant de chances d’éliminer les bugs de votre logiciel que les jardiniers en ont d’éliminer les insectes de leurs jardins.
// Les bugs sont un résultat de l’erreur humaine. C’est-à-dire qu’ils font partie de la nature.
//      --> Nous essayons de les éliminer depuis toujours, mais vous pouvez au mieux réduire la probabilité qu’ils apparaissent. Un logiciel n’est jamais parfait.
// Vous pouvez au mieux essayer de les éviter en utilisant les pesticides suivants :
//      --> Testez largement pour prouver que vous répondez à vos exigences métiers et techniques connues.
//      --> Écrivez le logiciel pour qu’il soit aussi résistant à l’échec que possible à l’aide des bonnes pratiques de développement.
//      --> Abordez les rapports de bug calmement.
//      --> Prenez un bug comme une opportunité de comprendre quelque chose que vous n’avez pas vu la première fois, et de prouver méthodiquement qu’elle a été réparée.
// Dans ce cours, nous nous concentrerons sur les deux derniers points.
//      --> Nous apprendrons comment utiliser des outils pour nous familiariser avec les bugs qui se faufilent entre les lignes de code !
// -----------
//  - En résumé :
//          --> Les tests peuvent réduire la probabilité d’apparition des bugs, mais ils n’ont que la qualité des scénarios qui ont été imaginés au départ.
//          --> Pour résoudre un bug de façon fiable, utilisez la méthode scientifique et une série d’expérimentations avec des tests répétables :
//                  - Écrivez un test répétable pour le comportement correct attendu.
//                  - Investiguez la raison de l’échec de ce test et imaginez des théories.
//                  - Testez les théories et les solutions pour rectifier le test qui échoue.
//                  - Faites réussir le test qui échoue et résolvez le bug.
// Envie d'appliquer cette méthodologie ? Commencez par installer votre environnement de débug, en suivant le prochain chapitre !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Installez votre environnement de débug ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Qu’est-ce qu’un débugger ?
// Avez-vous déjà rencontré un bug étrange qui vous a laissé perplexe ? Si seulement vous aviez pu reproduire la scène du crime.
// Peut-être une machine à remonter le temps qui vous emmène dans votre ordinateur juste avant l’apparition du bug ?
//      --> Imaginez si vous aviez été capable de voir tout ce que faisait votre code et de le regarder échouer au ralenti.
// Un outil qui a exactement ce pouvoir existe. Il peut voyager dans le temps et vous aider à examiner pourquoi votre logiciel échoue. Cela s’appelle un débugger.
//      --> Où est-ce que je peux obtenir un débugger ? Et comment fonctionne-t-il ?
// Si vous avez une installation Java ou un IDE, vous avez déjà un débugger ! Les différents IDE de Java comprennent d’excellentes interfaces de débug.
// Elles vous permettent d’exécuter vos programmes comme vous le feriez normalement, mais avec une différence importante :
//      --> Vous pouvez mettre le programme en pause et regarder dans la JVM pour inspecter les variables qui s’y trouvent.
// La JVM exécute le bytecode compilé depuis votre logiciel.
// Elle est responsable du contrôle de l’exécution et de la surveillance des variables et objets de votre code.
// Les débuggers permettent aux développeurs de se connecter à la JVM et de lui dire quoi faire ensuite.
// Vous pouvez vérifier quelles variables sont mises en place et examiner les méthodes appelées pour parvenir à un point précis.
// Vous pouvez même intervenir dans le comportement du programme pour essayer des choses !
// Cela peut être utile lorsque vous essayez de comprendre pourquoi votre logiciel échoue et lorsque vous traquez un bug dans votre code.
// Un débugger vous fournit une télécommande bien utile pour votre JVM.
// Dans le cadre du haut du diagramme ci-dessous, vous pouvez voir comment il vous permet de contrôler votre JVM et d’inspecter ce qu’elle fait.
// Pendant le reste du cours, vous allez vous familiariser avec ces commandes et les maîtriser !
//      --> En utilisant JPDA, votre debugger peut contrôler votre JVM à distance.
// Avez-vous remarqué le sigle JPDA dans le coin en bas à gauche ?
// Les créateurs de Java ont défini la Java Platform Debugging Architecture (JPDA, ou architecture de débug de la plateforme Java).
//      --> Elle correspond à un ensemble de lignes directrices permettant à tout un chacun de créer un débugger.
// La JPDA inclut le JDWP (Java Debugger Wire Protocol, ou protocole de communication du débugger Java), qui définit comment les débuggers communiquent avec les JVM.
// Le JDWP fonctionne par un réseau, même si vous êtes juste en train de débugger quelque chose sur votre machine locale.
// Par conséquent, le débug d’une application sur une JVM de l’autre côté de la planète est tout à fait identique à la même action effectuée localement.
//      --> Je ne peux pas exécuter mon programme et afficher les variables ?
// Vous pouvez, bien sûr. Mais si vous l’avez déjà fait, vous savez que c’est un cycle lent, et vous ne verrez que les valeurs que vous choisissez d’afficher.
// Cela correspond à recréer une scène de crime, mais en incluant uniquement les suspects dont vous avez deviné la présence.
// Vous pourriez rater quelqu’un et ne jamais le savoir !
// Néanmoins, si vous pouviez revenir à ce moment-là du passé, toutes les preuves seraient devant vous, y compris les variables visibles par le périmètre de votre code à cet instant-là.
// -----------
//  - Installez IntelliJ Community Edition :
// Je vais utiliser la version Community Edition d’IntelliJ pour vous montrer comment vous pouvez débugger en Java.
// IntelliJ est un environnement de développement puissant et extrêmement courant en Java.
// Vous pouvez suivre avec votre IDE favori, mais l’UI pourrait avoir un aspect différent et utiliser des noms légèrement différents.
// -----------
//  - En résumé :
//          --> Vous pouvez utiliser un débugger pour contrôler l’exécution d’un programme et inspecter les variables utilisées pendant l’exécution du programme.
//                  Cela peut être utile lors de la reconstitution de la scène de crime d’un bug logiciel.
//          --> La version Community Edition d’IntelliJ inclut un débugger que nous utiliserons dans ce cours.
// Vous avez terminé la première partie de ce cours, qui vous a permis d'explorer la méthodologie du débug.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Enquêtez sur un bug avec le débugger Java /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Localisez un bug grâce à un rapport de bug ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Game of Throws : qu’est-ce qu’un rapport de bug ?
// Quand un logiciel échoue, les utilisateurs impactés peuvent se plaindre.
//      --> Pour définir ce qui a mal fonctionné et le réparer, recueillez autant d’informations que possible sur la panne. C’est un rapport de bug.
// Par exemple, imaginez que vous prêtiez main-forte aux personnes maintenant une application qui aide les équipes commerciales à calculer les tailles de selle de dragon en fonction de leur âge.
// Voici une brève description du produit :
// Comme chacun le sait, les dragons sont des créatures mythiques qui n’existent pas. Pas naturellement, en fait.
// C’est un fait peu connu qu’en l’an 1 après J.-C., le sage alchimiste Lou Tan Dey-ta a créé un petit groupe de dragons grâce à des moyens contre-nature et quelques potions effervescentes.
// Ces dragons sillonnent encore les cieux aujourd’hui.
// Les dragons ont une espérance de vie extrêmement longue et grandissent à un rythme constant, mais lent.
// L’achat de la bonne selle est une affaire compliquée.
// Pour aider ceux qui seront assez chanceux pour monter sur un dragon un jour, Lou Tan a publié un algorithme pour calculer la taille d’une selle en fonction de l’âge du dragon.
// Des siècles plus tard, cet algorithme a été réécrit en toute hâte en Java pour aider ceux qui ont la bonne fortune d’avoir besoin de selles de dragon.
// Le calculateur de taille de selle de dragon est devenu un improbable accessoire favori des soirées réussies !
// Le code laisse beaucoup à désirer. Malheureusement, un utilisateur a suscité un rapport de bug sur l’application.
// L’équipe commerciale a récemment perdu une cliente importante, la princesse Drag’on, qui a acheté une selle trop petite en raison d’estimations défaillantes de l’application.
// Un rapport de bug est l’endroit où vous mettez les informations dont vous disposez sur une panne, afin de pouvoir définir ce qui est allé de travers et le réparer !
// Regardez le rapport de bug :
//      Reporter de bug : Sander des équipes commerciales.
//      Date : 18 mai 2020.
//      Titre du bug : Estimations de selles de dragon non valides à partir de l’application.
//      Description :
//          L’exécution de l’application “Taille de selle de dragon” sans aucun argument résulte en une panne que je ne comprends pas !
//          Cela impacte nos Chevaucheurs de dragon premium, car je ne peux pas recommander de selles adaptées en ce moment.
//      Étapes pour reproduire : L’exécution de la run task de Gradle (./gradlew run) résulte en l’erreur suivante.
//      Gravité :
//          Impacte le flux de travail des équipes commerciales ! Nous avons déjà perdu un client qui a choisi de chevaucher les dragons à cru.
//          Car notre contournement manuel pour "deviner" a résulté en une selle trop petite.
//          Réparez le plus vite possible, s’il vous plaît !
// Un bon rapport de bug doit inclure :
//      --> La personne qui a signalé le bug : le reporter de bug.
//              Vous avez besoin d’un contact pour vous aider à reproduire le bug et répondre à toute question supplémentaire.
//              La personne qui l’a signalé peut aussi aider à vérifier qu’il est réparé.
//      --> La date (quand le bug s’est produit).
//              Le fait de connaître le moment où un bug a été signalé peut vous aider à vérifier s’il est lié à d’autres problèmes connus.
//              --> Par exemple, il a pu se produire une interruption du réseau ce jour-là.
//      --> Une description ou une explication du bug.
//              Jusqu’à ce que vous parliez à l’utilisateur, encouragez-le à fournir autant d’informations pertinentes que possible dans le rapport de bug.
//              Par exemple, cela ne fait pas de mal que l’utilisateur fournisse également la version du logiciel ou le numéro de build (s’il a accès à cette information).
//              Encouragez-le à vous fournir autant de détails que possible, afin que vous puissiez reproduire et comprendre le problème.
//      --> Une série d’étapes pour reproduire le bug.
//              Pour vous aider à reproduire le bug, demandez à l’utilisateur de détailler les étapes impliquées.
//              Il peut décrire exactement ce qu’il a fait et faire une capture d’écran du résultat.
//              Cela l’encourage aussi à s’assurer qu’il n’a pas commis d’erreur en documentant le process précédant le bug.
//      --> Gravité et impact du bug.
//              Le bug impacte-t-il les utilisateurs ? Les affecte-t-il directement ? Coûte-t-il de l’argent ? Nuit-il à votre marque ?
//              Les conséquences d’un bug vous aideront à déterminer son importance et sa priorité.
//              Le fait de travailler sur un bug prend du temps qui pourrait être consacré à l’amélioration du code, l’ajout de fonctionnalités, et la réponse à d’autres problèmes.
// -----------
//  - Comment dois-je répondre à un rapport de bug ?
// Dans cet exemple, l’équipe commerciale veut que le bug soit réparé le plus vite possible, ce doit être urgent ! Bougez-vous !
// Attendez ! Stop ! Tout d’abord, pour être sûr que cela vaut la peine d’y consacrer plus de temps, vérifiez le champ de gravité dans votre rapport de bug.
// Si vous travaillez au sein d’une équipe avec un product owner et d’autres personnes qui s’intéressent au logiciel, demandez-leur toujours si c’est plus important que d’autres tâches.
// Ensuite, ralentissez un peu pour comprendre le bug. Ainsi, vous pourrez le réparer méthodiquement et aller vite à nouveau.
// Même le fait de réparer le problème le plus simple peut accidentellement résulter en une réparation incomplète, ou causer l’apparition d’un autre problème ailleurs.
// Souvenez-vous, si la solution était évidente, vous (ou un autre développeur) ne l’auriez peut-être pas cassée au départ.
// J’ai souvent vu des développeurs enthousiastes répondre à un bug avec réactivité et frénésie. Je l’ai fait moi-même !
// Il est tentant de sauter dans le code, d’essayer de trouver où il est cassé et de le réparer.
// Cela ne se passe jamais bien et peut prendre plus longtemps, car vous n’avez pas pris le temps de comprendre le problème et ses subtilités.
// Pour reproduire méthodiquement ce bug, vous devez :
//      --> Comprendre le rapport de bug (ce que vous devez observer).
//      --> Parler à l’utilisateur.
//      --> Trouver une version adaptée de l’application pour procéder au test.
//      --> Reproduire le bug.
// Heureusement, l’utilisateur vous a montré comment reproduire le bug dans le rapport ci-dessus, donc la dernière partie sera un peu plus simple. Passons à l’étape 1 !
// -----------
//      --> Étape 1 : Comprenez le rapport de bug :
// Tout d’abord, lisez le rapport de bug et essayez de comprendre ce que vous dit chaque section.
// Dans le rapport ci-dessus, vous voyez qu’ils ont perdu un client, et que les estimations de selles ne fonctionnent pas correctement.
// Cela signifie qu’il y a des défauts et des pannes qui impactent directement les utilisateurs, y compris l’équipe commerciale !
// Le bug a été signalé en 2020, et le résultat suggère que le programme a échoué en raison d’une taille de selle négative et inattendue.
// Nous verrons de manière plus détaillée comment lire le reste de cette exception plus tard, en enquêtant de façon plus approfondie sur le problème.
//      --> Tout d’abord, nous devons nous assurer que nous pouvons reproduire le problème – car il pourrait ne pas être réel !
// Qu’entendez-vous par "pas réel" ?
// C’est une bonne question, et nous allons y répondre dans la section suivante !
// -----------
//  - Étape 2 : Parlez à l’utilisateur :
// Un rapport de bug peut provenir d’utilisateurs réels, de testeurs, ou de qui que ce soit d’autre ayant utilisé votre code.
// Ce sont des personnes réelles, et il est bon de commencer par parler avec elles pour comprendre le bug.
// La personne qui a signalé le bug a fait un rapport sur ce qui a déclenché le bug. Pour l’aider, vous devez pouvoir reproduire le problème.
// C’est souvent une bonne idée d’aller voir l’utilisateur en personne et de voir s’il peut vous faire une démonstration du problème.
// De nombreux bugs de logiciel sont causés par le PEBKAC (Problem Exists Between Keyboard and Chair, ou  "le problème est situé entre la chaise et le clavier").
//      --> En d’autres termes, une erreur manuelle.
// Vous savez à quel point il est facile d’être frustré et contrarié de manière irrationnelle par un programme qui ne se comporte pas bien.
// Comment être sûr que ce n’est pas un cas de PEBKAC ? Une brève conversation permet généralement de vérifier s’il s’agit d’un problème réel.
// L’utilisateur vous sera reconnaissant si vous pouvez lui montrer que le problème a disparu comme par magie, sans aucun effort.
// Peut-être que l’utilisateur avait un câble réseau débranché, ou exécutait la mauvaise version du logiciel.
//      --> Le fait de discuter avec l’utilisateur peut fournir d’autres informations à utiliser dans votre enquête.
// Il peut également être utile d’avoir quelqu’un à qui montrer votre solution quand vous aurez fini, et qui réponde à vos questions.
// Et si je n’ai pas accès à mes utilisateurs ?
// Si l’utilisateur n’est pas accessible, demandez-lui un court enregistrement d’écran du problème !
// Vous pouvez alors regarder le comportement de l’utilisateur et reproduire exactement ce qu’il fait.
// Si possible, vous devriez aussi faire cela lorsque vous allez le voir en personne.
//      --> Les nuances du moment peuvent se perdre, et les étapes décrites ne capturent pas toujours chaque détail.
//      --> Des logiciels d’enregistrement d’écran comme QuickTime (Mac), Windows Game Bar (Windows) et Kazam (Linux) peuvent être utilisés pour capturer rapidement ce que fait votre utilisateur.
// Imaginez que l’utilisateur vous ait montré le bug, et qu’il se déroule exactement comme dans le ticket. C’est un problème de logiciel.
// Cet utilisateur doit travailler sur d’autres tâches, vous aurez donc besoin d’un autre environnement pour reproduire le bug et creuser davantage.
//      --> Il est temps d’enquêter jusqu’à trouver la cause première du problème. C’est-à-dire la raison pour laquelle il se produit.
// -----------
//  - Étape 3 : Mettez en place un environnement représentatif :
// Il vous faut une version de ce code à exécuter et tester.
//      --> La première chose à faire est d’effectuer git clone sur le répertoire et git checkout master sur sa branche produit.
// Cela variera en fonction du projet, mais commencez par répondre à cette question : "Comment puis-je exécuter une version de notre code de production localement ?".
// Pour vérifier le code et le réparer, vous devez cloner le répertoire, l’importer dans votre IDE, et vous assurer que tout cela a bien fonctionné en exécutant les tests dans le projet.
// Comme vous l’avez vu, nous venons d’obtenir quelques informations au sujet du bug :
//      - L’utilisateur peut le reproduire.
//      - L’utilisateur utilisait la dernière version du code.
//      - L’utilisateur se contente de suivre des instructions simples pour consulter le code de Git et l’exécuter avec gradlew run.
// Voici un récapitulatif :
//      --> Clonez le répertoire.
//              Nous avons cloné le répertoire de https://github.com/OpenClassrooms-Student-Center/openclassrooms-dragon-saddlesize-checker.
//              Cela nous donne le code source Java du projet que nous débuggons afin que nous puissions le construire, le modifier, et l’exécuter localement.
//                  - Ce projet utilise sa branche master pour représenter le logiciel qui est sorti en production.
//                      C’est la branche sur laquelle nous allons enquêter.
//                  - Même si nous avons utilisé IntelliJ pour cela, vous pouvez également le faire depuis la ligne de commande si vous préférez.
//                      Pensez à importer votre projet dans IntelliJ avant de commencer le débug.
//                          --> git clone https://github.com/OpenClassrooms-Student-Center/openclassrooms-dragon-saddlesize-checker.
//      --> Exécutez les tests.
//              Nous avons utilisé Gradle et IntelliJ pour exécuter les tests unitaires existants dans le projet.
//              Exécutez-les avant de commencer pour vous assurer qu’il n’y a aucun problème connu dans le code qui causerait son échec.
//                  - Si le code ne se construit pas, cela signifie que vous ne regardez pas la version correcte pour ce bug.
//                      Étant donné que l’utilisateur utilise actuellement une copie en exécution de ce code, même s’il comporte des bugs, il a été compilé un jour.
//                  - Vous pouvez éliminer tout build cassé de votre investigation initiale.
//                      Évitez de descendre dans un tunnel sans fin d’inconnues, et assurez-vous de commencer avec la version du code source qui représente celle qui est utilisée par l’utilisateur.
// -----------
//  - Étape 4 : Reproduisez le bug :
// Si vous regardez à nouveau le rapport de bug, vous verrez que les étapes pour reproduire le bug impliquent de taper : './gradlew run'.
// Faisons cela et voyons ce qu’il se passe ! Je vous montrerai comment le faire de la même façon que l’utilisateur l’a fait, et également avec l’intégration Gradle d’IntelliJ :
// Comme vous l’avez vu, nous avons validé le fait que le bug est réel.
// En le reproduisant, nous savons qu’il y a un problème sous-jacent qu’il faut traiter, et qu’il n’avait rien à voir avec la machine locale de l’utilisateur qui l’a signalé.
//      --> Nous savons que le bug est réel. Une exception est montrée à l’utilisateur. Mais qu’est-ce que le code devrait vraiment faire ?
// Si vous allez réparer un bug, il est important de savoir comment le code devrait se comporter.
// Le fait de revoir le ticket ne nous donne pas cette information. Prochaine étape, regardez les tests.
// Regardez les tests de ce projet dans le dossier src/test/java et ouvrez le com.openclassrooms.debugging.DragonSaddleSizeEstimatorTest.
// Il contient des tests avec des valeurs attendues pour une sélection d’années différentes.
// Le test pour l’an 2 après J.-C. (*n’oubliez pas de lire l’histoire dans le README du projet) porte le titre de 'estimateSaddleSize_shouldReturnASizeOfOne_forEarlyEraTwoAD' et ressemble à ceci :
//                  @DisplayName("Given we have a saddle size estimatorUnderTest spell")
//                  @ExtendWith(MockitoExtension.class)
//                  class DragonSaddleSizeEstimatorTest {
//                      ...
//                      @DisplayName("When estimating for a saddle size in the year 2 AD then the size is 1 centimeter")
//                      @Test
//                      public void estimateSaddleSize_shouldReturnASizeOfOne_forEarlyEraTwoAD() throws Exception {
//                          double estimatedSaddleSize = estimatorUnderTest.estimateSaddleSizeInCentiMeters(2);
//                          // A one year old dragon has a 1 cm saddle size
//                          assertThat(estimatedSaddleSize, is(equalTo(1.0)));
//                      }
//                      ...
//                  }
// Comme vous l’avez vu précédemment, les tests ont réussi. Cela signifie que la taille de selle pour l’an 1 après J.-C. est correctement calculée, du moins dans nos tests.
// Nous savons également qu’il y a une classe 'DragonSaddleSizeEstimator' avec une méthode 'estimateSaddleSizeInCentiMeters(Int year)'.
// Elle est utilisée pour estimer la taille d’une selle quand on lui fournit une année.
// La ligne 9 appelle la méthode 'estimateSaddleSizeInCentiMeters', et la ligne 11 valide que le résultat attendu est de 1 cm.
// Il y a aussi un autre test, qui vérifie la taille des selles des dragons vivant en l’an 2021.
//      --> Si vous regardez le 'DragonSaddleSizeEstimatorTest', vous verrez qu’il y a deux valeurs attendues dans les tests :
//              Année                       Estimation de taille de selle
//              2                               1,0 cm
//              2021                            2020,0 cm
// Vous pouvez supposer que le test est correct, étant donné qu’il représente un comportement avec lequel les experts métier et les sorciers qui prédisent les tailles des dragons seraient d’accord.
// Il existe un autre indice concernant la façon dont le programme devrait se comporter.
// Si vous creusez un peu plus et consultez le fichier README, il vous dit que nous pouvons exécuter l’application pour calculer la taille des dragons pour n’importe quelle année.
// C’est exactement ce que nous allons faire. Voici ci-dessous les instructions du README :
//                  Exécutez cette application.
//                  Calculez la taille de selle d’un dragon pour l’année en cours.
//                  ./gradlew run.
//                  Cela ira par défaut à l’année en cours et vous fournira une estimation adaptée.
//                  Calculez la taille de selle d’un dragon pour N’IMPORTE QUELLE année.
//                  Vous pouvez passer n’importe quelle année à la commande gradlew avec '--args'.
//                  ./gradlew run --args 2020.
//                  Cela renverra la taille de selle pour l’année 2020.
// -----------
//  - Essayez par vous-même !
// Voyez si vous pouvez exécuter l’application pour définir la taille de selle pour 2020, en spécifiant l’année.
// Sous Linux et OS-X, utilisez la commande suivante : ./gradlew run --args 2020.
// Sous Windows, elle devrait être : gradlew.bat run --args 2020.
//      --> Est-ce que cela a échoué, ou avez-vous récupéré une valeur ?
//      --> Que se passe-t-il si vous l’exécutez pour les années 2021 et 2022 ?
//      --> Recevez-vous les mêmes valeurs que celles qu’attendait le test ?
// Pour faire cela, modifiez simplement l’année donnée après '--args' dans l’exemple ci-dessus.
// Souvenez-vous, le programme fournit la taille de selle en mètres.
// Elle ne ressemblera donc pas forcément exactement à ce que vous avez vu dans le test, qui présentait ces tailles en centimètres.
// Il y a 100 cm dans chaque mètre. Je suis sûr que Google peut vous aider à ce sujet si nécessaire.
// -----------
//  - Écrivez un test qui échoue pour vérifier votre théorie :
// En tant qu’ingénieur responsable, vous contactez l’utilisateur qui a soulevé le bug et expliquez qu’il peut passer une valeur pour l’année 2020.
// L’utilisateur est ravi qu’il y ait un contournement, mais préférerait ne pas spécifier l’année.
// C’est une distraction du flux de travail habituel. Il a confirmé que 2020,0 est la valeur correcte pour 2021. De la même manière, 2021,0 est la valeur pour 2022.
// Vous êtes prêt à écrire un test qui échoue ! Soyez prudent.
// Le bug s’est déjà introduit en production une fois par le passé. Comme vous l’avez vu, tous les tests existants réussissent.
//      --> Vous devez dupliquer la façon dont le programme fonctionne dans le monde réel pour bien concevoir ce cas de test !
// Regardons la méthode 'main(String[] args)' de la classe 'DragonSaddleSizeGuesser', le point d’entrée de Java pour tout programme.
//                  public static void main(String[] args) throws Exception {
//                      DragonSaddleSizeEstimator estimator = DragonSaddleSizeEstimator.INSTANCE;
//                      // Loop needlessly to replicate and ancient ritual
//                      for (int i=0; i<Integer.MAX_VALUE; i++) {
//                      }
//                      // Estimate the saddle size of a dragon,
//                      // relative to the year One when all extent dragons were born.
//                      int targetYear = Calendar.getInstance().get(Calendar.YEAR);
//                      // Take the year from the command line arguments
//                      if (args.length != 0) {
//                          targetYear = Integer.parseInt(args[0]);
//                          estimator.setCopyOfUniversalConstant(42); // The universal constant
//                          estimator.setYearOfBirth(1); // All dragon's were spawned in 1 AD
//                      }
//                      System.out.println("Calculating saddle size for a dragon in the year " + targetYear);
//                      // Calculate Saddle Size
//                      double saddleSize = DragonSaddleSizeEstimator.INSTANCE.estimateSaddleSizeInCentiMeters(targetYear);
//                      // Report
//                      new SaddleSizeReporter(targetYear, saddleSize).report();
//                  }
// Réfléchissons à tout cela !
//      --> Ligne 2 : cette classe principale obtient une instance d’une classe DragonSaddleSizeEstimator à la ligne 2 depuis une variable statique nommée INSTANCE.
//      --> Lignes 4 à 5 : d’étranges rituels recommandés par les spécialistes mystiques, qui n’affectent pas l’exécution. Ils ressemblent un peu à des exigences métiers.
//      --> Ligne 8 : l’année en cours est obtenue avec 'Calendar.getInstance()' de Java.
//      --> Lignes 10 à 14 : permettez à l’utilisateur de passer une année spécifique en utilisant des arguments depuis la ligne de commande.
//      --> Ligne 19 : estimez la taille de selle pour une année donnée.
//      --> Ligne 22 : faites un rapport sur la taille de selle.
// Regardons ce code. Si vous ignorez les lignes 10 à 14, le code restant est tout ce qui serait nécessaire pour exécuter l’application sans que l’utilisateur ne lui passe une date.
// Et si nous transformions cela en test ? Pourquoi écrire un test ?
// Pour rappel, les tests fournissent un moyen rapide de reproduire un bug de façon répétée.
// Si le test s’attend au comportement correct, il continuera à échouer jusqu’à ce que vous intégriez la première réparation qui corrige le bug.
// La méthode scientifique suggère d’effectuer de multiples expérimentations pour confirmer les théories.
// Pendant que vous essayez de réparer le problème, utilisez le test pour confirmer les théories.
//      --> De plus, le fait de reproduire le bug fidèlement à chaque exécution vous aide à examiner ce que fait le logiciel.
// Quelle est notre première théorie ?
// Voici quelques questions pour vous :
//      --> Comment le code s’est-il comporté quand une année lui a été passée sur la ligne de commande ?
//      --> Comment peut-on comparer cela à l’exécution de l’application sans lui avoir passé une année ?
// La première théorie est que vous pouvez écrire un test qui échoue démontrant que, si vous exécutez l’application sans passer de date, cela lèvera l’exception soulevée dans le rapport de bug.
// Si vous regardez l’exception dans le rapport de bug, vous pouvez suivre la chaîne de lignes commençant par 'at com.openclassrooms.debugging' à la ligne 3, jusqu’à la dernière occurrence de ce type.
//                  Calculating saddle size for a dragon in the year 2020
//                  Exception in thread "main" com.openclassrooms.debugging.exception.InvalidSaddleSizeException: Unexpected saddle size:-49.0
//                      at com.openclassrooms.debugging.DragonSaddleSizeVerifier.verify(DragonSaddleSizeVerifier.java:13)
//                      at com.openclassrooms.debugging.DragonSaddleSizeEstimator.estimateSaddleSizeInCentiMeters(DragonSaddleSizeEstimator.java:60)
//                      at com.openclassrooms.debugging.DragonSaddleSizeGuesser.main(DragonSaddleSizeGuesser.java:34)
// Pouvez-vous voir que cela se situe dans 'com.openclassrooms.debugging.DragonSaddleSizeGuesser' ?
// Cela se produit juste après un appel à 'estimateSaddleSizeInCentiMeters(..)'.
// Regardez l’exemple de notre méthode principale ci-dessus. Il correspond à la ligne 19, où nous avons appelé 'estimateSaddleSizeInCentiMeters()'.
// Le bug a quelque chose à voir avec la façon dont 'DragonSaddleSizeEstimator' est appelé quand vous ne fournissez pas de valeur pour l’année dans la ligne de commande.
// Le test va dupliquer la façon dont la classe principale appelle le 'DragonSaddleSizeEstimator'.
// Le test unitaire existant pour 'le DragonSaddleSizeEstimator' utilise des mocks, ou simulations, pour le 'DragonSaddleSizeVerifier'.
// C’est-à-dire qu’il utilise de fausses versions de cette classe pour accélérer les tests et les rendre plus prévisibles. C’est une pratique de test normale.
// Étant donné que 'DragonSaddleSizeVerifier' est la classe qui lève l’exception dans l’extrait ci-dessus (ligne 2), il vous faudra utiliser une version réelle de cela dans le nouveau test.
// En piochant directement dans la méthode main, ou méthode principale, créez un nouveau 'DragonSaddleSizeEstimatorIntegrationTest'.
// Ce test créera une nouvelle instance du vérificateur, ainsi que de toute autre classe avec laquelle il aurait besoin de collaborer.
// Cela prouvera qu’elles s’intègrent correctement, donc cela signifie que c’est un test d’intégration.
//      --> Comment transformer ce que fait notre code en cas de test qui échoue ?
// J’ai pu créer un test qui duplique le comportement de la méthode main ci-dessus.
// Ne reproduisez pas toutes les lignes de la méthode principale, mais son flux normal.
// Étant donné que c’est un test, j’ai fait l’impasse sur les déclarations print et la mise en place des paramètres passés au programme.
//      --> Voici notre test :
//                  @DisplayName("Given that we have a DragonSaddleSizeEstimator")
//                  public class DragonSaddleSizeEstimatorIntegrationTest {
//                      @DisplayName("When the year is 2020 Then the saddle size should be 20.19 meters")
//                      @Test
//                      public void estimateSaddleSizeInCentiMeters_shouldReturnTwentyPointNineteen_whenCalculatingTheSizeIn2020() throws Exception {
//                          // ARRANGE
//                          DragonSaddleSizeEstimator estimator = DragonSaddleSizeEstimator.INSTANCE;
//                          // Act
//                          Double expectedSaddleSize = DragonSaddleSizeEstimator.INSTANCE.estimateSaddleSizeInCentiMeters(2020);
//                          // Assert
//                          assertThat(expectedSaddleSize, is(equalTo(2019.0)));
//                      }
//                  }
// Le test a été écrit en trois étapes :
//      --> Ligne 9 : Implémenter l’utilisation d’une instance du 'DragonSaddleSizeEstimator'. Cela se fait exactement comme dans la méthode principale.
//      --> Ligne 12 : Utiliser cette instance en appelant la méthode 'estimateSaddleSizeInCentiMeters()' avec la valeur 2020.
//      --> Ligne 15 : Affirmer que l’estimation correcte attendue est 2019,0.
// Vous pouvez récupérer ce code avec la branche 'integration-test' et la commande CLI : git checkout integration-test.
// Contrairement à la méthode main, 'Calendar.getInstance()' n’est pas utilisé pour obtenir la valeur passée à la ligne 12. L’exception levée a été reproduite avec succès.
// Mais cela échoue toujours. Sur quoi pouvons-nous enquêter maintenant ?
// Lisez toujours l’exception. Les quelques premières lignes sont les suivantes :
//                  com.openclassrooms.debugging.exception.InvalidSaddleSizeException: Unexpected saddle size:-49.0
//                      at com.openclassrooms.debugging.DragonSaddleSizeVerifier.verify(DragonSaddleSizeVerifier.java:13)
//                      at com.openclassrooms.debugging.DragonSaddleSizeEstimator.estimateSaddleSizeInCentiMeters(DragonSaddleSizeEstimator.java:60)
// Si vous exécutez le test avec l’option débug, cela vous permet de demander à la JVM de marquer une pause quand elle lève une exception.
// La ligne supérieure montre sa localisation, et l'endroit d’où elle a été levée.
// Vous pouvez alors appeler des méthodes sur l’exception et interagir avec elle pour voir des détails là où elle a été levée.
// Je vais exécuter le test encore une fois en utilisant le débugger et dire à l’application de s’arrêter quand l’exception est levée, et nous la regarderons alors de plus près.
// Félicitations, vous venez de voir le débugger en action. Essayez vous-même avec le répertoire que vous avez déjà cloné.
// -----------
//  - En résumé :
//          --> Un rapport de bug fournit des détails sur un bug, tels que : qui l’a signalé, son impact, et comment le reproduire.
//          --> Vous écrivez un test pour une application qui montre ce qui devrait se produire en l’absence du bug. Cela s’appelle un test qui échoue, car il échouera en présence du bug.
//          --> Avec un débugger, vous pouvez exécuter un test et suspendre la JVM quand une exception spécifique est levée.
// Dans le chapitre suivant, nous allons enquêter sur la première ligne de notre trace d’appels !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définissez des points d’arrêt /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Faites un arrêt sur image avant une exception :
// Est-ce que vous avez déjà regardé un film et pensé que vous aviez repéré un acteur faisant une apparition spéciale ?
// Les films ont généralement un rythme rapide, passant de scène en scène, alors il est difficile d’en être sûr.
// Quand cela arrive, votre cerveau pense : "Qu’est-ce qui vient d’interrompre mon immersion dans l’univers du film ?".
// Que faites-vous quand cela se produit ? Vous rembobinez probablement pour regarder la scène à nouveau.
// Vous effectuez peut-être un arrêt sur image pour examiner le détail.
//      --> Parfois vous confirmez ce que vous avez vu, et parfois vous vous rendez compte que "non, ce n’est pas Elvis !".
// Votre code ressemble un peu à cela. Les instructions individuelles sont exécutées comme des images d’un film.
// Quand vous dézoomez sur le code, vous voyez différents niveaux d’abstraction.
// Plus vous vous éloignez, plus les instructions individuelles commencent à constituer des parties de méthodes, de classes, de paquets, et à la fin de l’application complète.
//      --> Si un bug fait une apparition, il sera plus difficile de distinguer l’arbre de la forêt.
// Lorsque vous recherchez un bug, vous avez besoin de voir les subtilités entre chaque déclaration de votre code, pour mieux comprendre ce qui échoue.
//      --> Mais notre code s’exécute à une telle vitesse, comment pourrions-nous suivre ce qu’il fait ?
// C’est vrai. Les applications courent d’instruction en instruction. Pour suivre ce qu’il se passe, il est utile de se concentrer sur une partie spécifique du logiciel.
// Il vous faut donner un coup de frein et faire une pause lorsque la JVM voit une ligne de code intéressante.
//      --> Vous pouvez alors la regarder se dérouler étape par étape !
// Heureusement, les débuggers vous permettent d’arrêter le code n’importe où.
// Vous allez voir comment utiliser le débugger pour exécuter votre application jusqu’au moment juste avant qu’elle ne s’écroule.
// Ainsi, vous pouvez inspecter les preuves qui amènent à votre exception levée et commencer à formuler une théorie sur sa cause.
// Lorsque nous avons exécuté le test qui échoue, vous avez vu une stack trace commençant par :
//                  com.openclassrooms.debugging.exception.InvalidSaddleSizeException: Unexpected saddle size:-49.0
//                  at com.openclassrooms.debugging.DragonSaddleSizeVerifier.verify(DragonSaddleSizeVerifier.java:13)
// Si vous attrapez une exception et que vous voulez la voir, vous pouvez soit la passer à un logger, soit utiliser la méthode 'printStackTrace()' pour extraire davantage de détails.
// Utilisez-la avec parcimonie, tout de même.
// Il n’y a rien de plus nuisible à la concentration que d’afficher des stack traces non pertinentes d’exceptions personnalisées qui ont été interceptées.
// Particulièrement celles auxquelles on a proprement répondu dans des blocs catch{}.
// L’erreur montre que le code lève une exception Java personnalisée de type 'com.openclassrooms.debugging.exception.InvalidSaddleSizeException' depuis la méthode 'verify()'.
//      --> La stack trace donne également le numéro de ligne dans le fichier source. Regardons la ligne 13 :
//                  package com.openclassrooms.debugging;
//                  import com.openclassrooms.debugging.exception.InvalidSaddleSizeException;
//                  public class DragonSaddleSizeVerifier {
//                      public void verify(Double saddleSize) {
//                          if (null == saddleSize) {
//                              throw new InvalidSaddleSizeException("Unexpected saddle size of null");
//                          }
//                          if (saddleSize <= 0) {
//                              throw new InvalidSaddleSizeException("Unexpected saddle size:" + saddleSize);
//                          }
//                      }
//                  }
// La ligne 13 prend la valeur de saddleSize passée à la ligne 7, et lève une exception en utilisant 'throw new validSaddleSizeException("Unexpected saddle size:" + saddleSize);'.
// Installons un point d’arrêt à cette ligne et lançons le test à nouveau !
// Un point d’arrêt est comme une pause dans le programme qui vous permet d’inspecter ce qu’il se passe, étape par étape.
// Pour en mettre un en place, trouvez la ligne de votre code sur laquelle vous voulez vous arrêter et cliquez sur la marge à côté.
//      --> Elle devrait virer au rouge. Cela dira au débugger de lancer le programme et de faire une pause à cette ligne.
// Vous pouvez maintenant exécuter le test dans votre débugger pour qu’il fasse une pause avant le point d’arrêt.
// Le débugger a affiché une ligne de code surlignée en haut de l’éditeur. Il affiche aussi un volet de débug dans la partie basse de l’écran. Regardons cela de plus près :
//      --> La fenêtre d’explorateur du projet affiche les fichiers du projet, tels que le code Java.
//      --> Le point d’arrêt actuel est surligné dans le volet éditeur, vous montrant la ligne de code sur laquelle la JVM a été mise en pause.
//      --> L’outil de débug apparaît en bas de votre IDE lorsque vous commencez à débugger une application. Il contient des composants pour vous aider dans le débug.
//      --> Le volet Frame affiche la stack trace de votre application, c’est-à-dire la série d’appels de méthodes et les numéros de lignes qui ont conduit au point d’arrêt actuel.
//      --> Le volet Variables affiche toutes les variables actuellement délimitées visibles par le code au point d’arrêt actuel.
//      --> Les boutons de contrôle d’exécution peuvent être utilisés pour contrôler le flux de votre application.
//              Ce sont les boutons de contrôle à distance et ils déterminent si vous continuez à inspecter votre code au ralenti ou si vous accélérez jusqu’à un autre point.
// À gauche du volet Débug, IntelliJ fournit également plusieurs autres outils pratiques pour arrêter et démarrer le débugger.
// Vous pouvez mettre fin à la session de débug en cliquant sur le bouton Stop (carré rouge).
// En utilisant ces commandes, vous pouvez :
//      --> Redémarrer la session de débug en cours.
//      --> Exécuter à nouveau tous vos tests les plus récents ayant échoué.
//      --> Faire en sorte que vos tests s’auto-exécutent lorsqu’ils sont modifiés.
//      --> Reprendre l’exécution et cesser la suspension du point d’arrêt actuel.
//      --> Mettre en pause une JVM dont la suspension a été stoppée à son point actuel d’exécution.
//      --> Stopper totalement le process de débug actuel.
//      --> Activer et désactiver différents points d’arrêts à travers votre application.
// Ces éléments  peuvent être utiles lorsque vous exécutez vos tests avec le débugger. Vous verrez comment utiliser certains d’entre eux plus tard.
// -----------
//  - Ajoutez des points d’arrêt supplémentaires :
// Avez-vous déjà exploré une ville que vous ne connaissiez pas bien en vous souvenant d’endroits relatifs à des points de repère comme un cinéma, un restaurant, ou un café ?
// Lorsque vous exécutez votre test qui échoue, il crée un parcours, exactement comme un chemin à travers la ville.
//      --> Mais plutôt que de voyager d’étape en étape, vous allez de déclaration en déclaration, entrant dans d’autres méthodes qui se voient appelées.
// Dans notre exemple de rapport de bug, l’utilisateur vérifiait la taille de selle d’un dragon en 2020.
// Comme vous l’avez vu dans nos stack traces, cela implique un voyage à travers plusieurs méthodes :
//      --> Soit la méthode, soit le test d’intégration 'main()' est habituellement notre premier code à être exécuté.
//      --> 'main()' et notre test peuvent alors tous deux appeler 'DragonSaddleSizeEstimator.estimateSaddleSizeInCentiMeters(2020)'.
//      --> Ceci appelle 'com.openclassrooms.debugging.DragonSaddleSizeVerifier.verify(...)'.
// Est-ce que ce ne serait pas génial si vous pouviez aussi stopper le code à plusieurs endroits pour observer le mystère se dérouler ?
// Vous pourriez d’abord l’arrêter dans votre test, puis dans la méthode 'estimateSaddleSizeInCentiMeters()', et enfin, dans la méthode 'verify()'.
// En d’autres termes, vous mettez en place plusieurs points d’arrêt.
// C’est le même process que précédemment, sauf que vous l’effectuez à plus d’un endroit.
//      --> Par exemple, vous pouvez cliquer sur la marge à côté de plusieurs lignes dans plusieurs fichiers.
// Supposons que l’année que nous avons passée à notre programme soit modifiée à notre insu.
// L’année est passée entre plusieurs méthodes et il pourrait être logique de vérifier que c’est exactement conforme à ce que nous attendions à chaque pas.
// Cela vous permet de débugger à nouveau votre code et de stopper immédiatement au premier point d’arrêt atteint par la JVM.
// Une fois là, vous pouvez inspecter si vous avez passé vos valeurs correctement dans le code.
// En cliquant sur "resume" dans le volet de contrôles d’exécution, vous pouvez permettre à votre application de continuer l’exécution jusqu’au point d’arrêt suivant.
// Encore une fois, votre code est suspendu. Vous pouvez continuer à cliquer sur resume jusqu’à ce le programme se termine.
//      --> Et maintenant, regardons comment se déplacer entre des points d’arrêt multiples.
// En vous déplaçant entre des points d’arrêt, vous pouvez examiner comment les valeurs sont passées entre les méthodes.
// Qu’avez-vous appris au cours de cette phase de l’enquête ?
//      --> Dans ce cas, il semble clair que l’année ne change pas du tout.
//              'targetYear' était toujours réglé sur "2020" au point où 'estimateSaddleSizeInCentiMeters()' a appelé 'verifier.verify(double saddleSize)'.
//      --> De plus, la méthode 'verifier.verify(double saddleSize)' se voit passer une valeur de "-49" par la méthode 'estimateSaddleSizeInCentiMeters(int targetYear)'.
//              Ceci implique que nous avons calculé une taille de selle négative bien avant que l’exception ne soit levée.
// C’était une investigation de qualité ! Notre théorie selon laquelle la date était modifiée est fausse.
// Néanmoins, nous avons maintenant les outils nécessaires pour nous arrêter à de multiples endroits pendant que nous enquêtons sur le problème.
// Le fait de vous déplacer dans le code étape par étape vous a permis de voir les valeurs contenues par les variables à différentes étapes de la vie du programme.
// -----------
//  - Gérez les points d’arrêt :
// À mesure que vous ajoutez davantage de points d’arrêt à votre code, il peut devenir difficile de se souvenir où ils se trouvent.
// Il est particulièrement important de s’en souvenir lorsque vous avez besoin d’enlever ceux qui ne sont plus utiles.
// Vous pouvez utiliser IntelliJ pour gérer tous vos points d’arrêt du même endroit, nommé le Breakpoints View (vue des points d’arrêt) :
//      - Cliquez droit sur le point d’arrêt rouge et cliquez sur More (plus).
//      - OU cliquez sur le double point rouge pour voir les points d’arrêt depuis l’outil de débug.
//      - Vous pouvez maintenant cocher et décocher les points d’arrêt.
// Comme vous le voyez, j’ai décoché le test d’intégration, pour empêcher le débugger de s’y arrêter.
//      --> J’ai fait cela car le bug semble se situer entre le test et le vérificateur.
// -----------
//  - En résumé :
//          --> Un point d’arrêt représente une ligne de code jusqu’à laquelle vous avez dit à la JVM de dérouler l’exécution et ensuite de la suspendre pour que vous puissiez enquêter.
//          --> Le débugger peut vous montrer les variables actuellement visibles par et dans le périmètre d’un point d’arrêt où vous êtes arrêté.
//          --> Pour vérifier comment les valeurs sont modifiées entre les appels de méthode, placez des points d’arrêt multiples à travers votre code source.
//          --> Le débugger vous permet de reprendre à partir de n’importe quel point d’arrêt et suspendra l’activité au prochain point d’arrêt qu’il rencontrera.
//          --> La stack trace d’une exception peut vous montrer la chaîne d’appels de méthode menant à votre panne. Utilisez-la pour décider où vous arrêter.
// Dans le chapitre suivant, nous allons observer un autre type de point d’arrêt : les points d’arrêt conditionnels.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez les points d’arrêt conditionnels /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Trouvez une théorie nouvelle et testable :
// Maintenant que nous avons éliminé la théorie précédente, nous devons en trouver une nouvelle.
// Pour commencer, regardons à nouveau la méthode 'DragonSaddleSizeEstimator::estimateSaddleSizeInCentiMeters(int targetYear)'. Observez la 'méthodeestimateSaddleSizeInCentiMeters(int targetYear)' :
//                  public Double estimateSaddleSizeInCentiMeters(int targetYear) throws Exception {
//                      double roundedSaddleSize = calculateSaddleSizeFromYear(targetYear);
//                      // slow down the magic
//                      try {
//                          Thread.sleep(200);
//                      } catch (InterruptedException e) {
//                          e.printStackTrace();
//                          throw e;
//                      }
//                      // Verify that we have a valid saddle size
//                      verifier.verify(roundedSaddleSize);
//                      return roundedSaddleSize;
//                  }
// À présent, sur cette base, nous pouvons dire que :
//      --> Nous avons éliminé la théorie selon laquelle l’année cible était modifiée.
//              Elle était toujours définie comme 2020 au point où nous avons appelé la méthode levant notre exception observée à la ligne 13.
//      --> Nous savons également que la valeur de la taille de selle passée à cette méthode est déjà un nombre négatif.
//              Ceci implique que le bug existe quelque part dans la classe où la taille de la selle est calculée 'DragonSaddleSizeEstimator'.
//              Cela semble se produire dans la méthode privée 'calculateSaddleSizeFromYear()' à la ligne 2.
// Si vous regardez cette méthode privée, vous voyez une série d’étapes assez étrange. La méthode prend une année comme information entrante et renvoie une estimation de taille de selle :
//                  private double calculateSaddleSizeFromYear(int targetYear) {
//                      // ((42-1)/41.0)
//                      double universalLuckyNumber = new Double(UNIVERSAL_LUCKY_NUMBER);
//                      double mysticalMultiplier = (copyOfUniversalConstant - yearOfBirth)/ universalLuckyNumber;
//                      // Start by setting the saddle size to the dragon's current age
//                      int saddleSizeFactor = 0;
//                      // Count down how many years it's been alive
//                      for (int i = targetYear; i>DRAGON_SPAWN_YEAR; i--) {
//                          saddleSizeFactor++;
//                          if (i < UNIVERSAL_CONSTANT) {
//                              int modifier = enchant();
//                              saddleSizeFactor += modifier;
//                          }
//                      }
//                      // calculate the final saddle size
//                      double exactSaddleSize = (saddleSizeFactor * mysticalMultiplier) - mysticalMultiplier /10;
//                      return (double) Math.round(exactSaddleSize);
//                  }
//      - Lignes 3 à 4 : on dirait du charabia, mais ce sont des constantes métier que nous multiplions par la taille de selle. Pensez-y comme faisant partie des règles métier.
//      - Lignes 6 à 13 : nous comptons les années depuis 'DRAGON_SPAWN_YEAR' (ce qui, selon l’histoire du README.md, doit être l’an 1 après J.-C.).
//      - Lignes 11 à 12 : il y a aussi une variable modifier particulière ajoutée à notre estimation.
//          Cela se produit quand la variable compteur, 'i' est inférieure à 'UNIVERSAL_CONSTANT', que le code initialise à 42.
//      - Lignes 16 à 17 : le chiffre est agréablement mystifié, converti en centimètres et arrondi.
// Jusqu’à ce que nous ayons étudié la science du calcul des tailles de selle, un grand nombre de ces règles métier resteront un mystère.
// Néanmoins, nous pouvons nous concentrer sur le flux général en tant que développeurs Java :
//      --> Une valeur est passée à une méthode.
//      --> Calcul de certaines valeurs d’entiers en utilisant des variables statiques et des champs de l’objet actuel.
//      --> Boucle et exécution d’un peu d’arithmétique pour incrémenter la variable 'saddleSizeFactor'.
//      --> Applique une formule à 'saddleSizeFactor'.
//      --> Caste le résultat en un double et le renvoie !
// Tout ceci est utile, mais quelle est notre prochaine théorie ?
// En regardant les lignes 6 à 13 ci-dessus, nous pouvons supposer que si nous comptons en descendant de l’année 2020 à l’an 1 après J.-C., nous devrions obtenir une taille de selle de 2019 au minimum.
// Nous avons vu que nous avions un nombre négatif au point d’appel de 'DragonSaddleSizeVerifier::verif y', donc quelque chose le rend négatif.
// Étant donné qu’il y a peu de visibilité sur ce que fait le modificateur à la ligne 12, nous allons supposer qu’il ajoute un nombre négatif à notre taille de selle.
// C’est ce qui pourrait causer le changement de notre valeur positive en valeur négative et, ensuite, faire que le vérificateur lève une 'InvalidSaddleSizeException'.
// Plongeons-nous dans cette boucle for et enquêtons !
// -----------
//  - Débuggez dans une boucle en utilisant des points d’arrêt conditionnels :
// Comment débugger dans une boucle for ? Réfléchissons de façon logique.
// Lorsque vous faites vos courses alimentaires, est-ce que vous parcourez toutes les allées et examinez chaque élément avant de trouver ce que vous voulez ?
// J’imagine que cela rendrait vos courses inutilement longues, et que vous vous retrouveriez avec des tas d’achats spontanés de choses que vous n’utiliseriez jamais.
// Alors, que faites-vous ? Vous avez habituellement une idée de ce que vous cherchez et vous allez directement dans les allées ou les sections appropriées.
// Si vous ne voulez que des lasagnes, vous n’avez pas besoin d’inspecter toutes les marques de riz !
// Cette situation au supermarché n’est pas si éloignée de ce qui se produit dans le code.
//      --> Par exemple, dans une boucle for, le même bloc est revisité encore et encore, mais avec des données différentes.
//              Si vous placez un point d’arrêt dans une boucle for, il sera suspendu de nombreuses fois.
//              Cela signifie que lorsque vous enquêtez sur un problème, vous devrez passer au crible manuellement des tas de suspensions, qui ne sont peut-être même pas nécessaires à votre enquête.
//              Cela ressemble d’un peu trop près au cas des lasagnes et du riz ci-dessus.
//              Une des façons d’éviter cela consiste à utiliser des points d’arrêt conditionnels, des points d’arrêt intelligents qui s’arrêtent quand les bonnes données sont visibles à votre code.
// Si vous n’êtes pas convaincu que c’est fastidieux, regardons un exemple de notre code.
// Pour voir si notre taille de selle était modifiée de façon incorrecte dans notre boucle for, nous allons placer un point d’arrêt à la ligne 11 dans la boucle for sur l’affirmation :
//                  if (i < UNIVERSAL_CONSTANT)
//      --> Voyons si nous pouvons débugger cela en plaçant un point d’arrêt dans cette boucle for !
// Le débugger a essayé de nous aider en s’arrêtant à chacune des itérations sur la condition 'if (i < UNIVERSAL_CONSTANT)'.
// C’est très bien, mais cela ajoute peu de valeur et beaucoup de travail, si nous devons le vérifier 2019 fois.
// Est-ce que ce ne serait pas génial si nous pouvions uniquement l’inspecter à la 2019e boucle ?
//      --> Mais ce code est tout simplement faux. Pourquoi devons-nous même boucler ? Ne devrions-nous pas simplement le réparer ?
// C’est vrai, le code pourrait être amélioré. Peut-être pourrions-nous le réécrire pour éviter complètement la boucle for.
// Malheureusement, il est rare que vous puissiez choisir l’état du code que l’on vous confie.
// En supposant que la personne qui vous a précédé a fait de son mieux, résistez à la tentation de réécrire le code avant de savoir ce qui ne va pas.
// La réécriture du code pour le rendre plus lisible est une bonne chose, mais pas tant qu’il est peut-être cassé.
// Vous pourriez introduire des problèmes supplémentaires. De plus, comme vous savez qu’il est cassé, vous pourriez avoir à modifier le code que vous réécrivez maintenant.
// C’est pour que la réparation de ce code ne devienne pas un jeu de réécriture de l’application complète.
// J’ai vu des développeurs faire cela en se trouvant face à du code qu’ils n’avaient pas pris le temps de comprendre.
// En attendant, ce que vous pouvez faire, c’est ajouter des commentaires 'FIXME' et 'TODO' au code pour vous rappeler les choses que vous devez nettoyer et refactorer.
// Comme cette variable i mal nommée dans notre boucle for !
// Alors, revenons à notre code. Comment pouvons-nous le débugger sans être obligés de cliquer sur « resume » 2 019 fois ?
// Les points d’arrêt conditionnels sont des points d’arrêt intelligents qui s’arrêtent quand les bonnes données sont visibles par votre code.
// Avec les points d’arrêt conditionnels, vous pouvez créer un point d’arrêt qui s’arrêtera uniquement (c’est-à-dire que le débugger s’arrêtera) quand une affirmation Java sera évaluée comme vraie.
//      --> Par exemple, dans le cas de cette boucle, nous pourrions nous arrêter suri==42 ou i<UNIVERSAL_CONSTANT. Utilisons cela pour nous aider à débugger l’application !
// Comme vous l’avez vu avec notre point d’arrêt non conditionnel dans la boucle for, il peut être peu pratique de définir un point d’arrêt uniquement nécessaire à certaines requêtes.
//      --> Nous pouvons définir un point d’arrêt conditionnel ici par un clic droit sur le point d’arrêt existant et en spécifiant une expression booléenne.
//              --> La condition est une expression Java : 'i<UNIVEESAL_CONSTANT'.
// En définissant ce point d’arrêt conditionnel, la JVM s’arrêtera toujours quand l’expression sera évaluée comme vraie.
// Vous pouvez y penser comme à l’ajout d’une déclaration if dans votre code juste avant le point d’arrêt signifié, qui fait quelque chose comme 'if(conditional_expression) { suspendTheJVM! }'.
// Maintenant que nous avons défini un point d’arrêt conditionnel avant la déclaration if dans notre boucle for, débuggons le test et poursuivons l’enquête !
// Comme vous le voyez, en spécifiant un point d’arrêt conditionnel, nous avons pu éviter d’avoir à suspendre et reprendre des milliers de fois !
// La première fois que notre débugger s’est arrêté a été quand i a eu une valeur de 41.
// Nous avons même pu changer le point d’arrêt conditionnel en plein débug et passer directement à la suite, en changeant notre condition en  i < 3.
//      --> Alors, est-ce que c’était la variable modifier qui était la cause de notre bug ?
// Pour examiner l’impact de la valeur modifier, nous avons utilisé le bouton de contrôle d’exécution 'Step Over' pour reprendre l’exécution, mais immédiatement suspendre la JVM à la ligne suivante.
//      --> Le bouton Step Over est caractérisé par une icône et par F8.
// Cela nous a permis de descendre dans le code et d’inspecter la valeur retour de la variable modifier. De façon intéressante, elle ne renvoie jamais que zéro. Cela n’a donc pas d’impact.
//      --> Un détail que nous avons remarqué est que la variable 'mysticalMultiplier' a un nombre négatif :
//              --> La variable mysticalMultiplier a pour valeur -0.02439024.
// Bizarrement, elle est utilisée pour estimer la taille de la selle en la multipliant avec le 'compteursaddleSizeFactor' que nous avons incrémenté dans notre boucle for.
// La formule finale pour notre taille de selle est définie dans le code comme suit :
//                  double exactSaddleSize = (saddleSizeFactor * mysticalMultiplier) - mysticalMultiplier /10;
// En substituant par les valeurs de notre volet Variables :
//                  (2019*-0.024390243902439025)
//                  -0.024390243902439025 / 10
//                  = 49.24146341463415
// Regardons à nouveau notre exception qui bugge :
//                  com.openclassrooms.debugging.exception.InvalidSaddleSizeException: Unexpected saddle size:-49.0
//      --> Il y a une ressemblance surprenante ici. L’une est -49 et l’autre 49,24146... Nous avons une nouvelle piste sur laquelle enquêter.
// -----------
// En résumé :
// Les points d’arrêt conditionnels vous permettent de suspendre la JVM (par le biais de votre débugger) à une ligne donnée, si une condition est remplie.
// Les points d’arrêts conditionnels sont spécifiés en définissant une expression booléenne en Java, qui est évaluée en utilisant des variables visibles par, ou dans le périmètre du code à ce point d’arrêt.
// Les points d’arrêt conditionnels sont particulièrement utiles lorsque l’on débugge du code qui est revisité de nombreuses fois, comme avec une boucle for.
// Dans le chapitre suivant, nous allons regarder certaines façons plus spécialisées de réparer des bugs !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez les watches, watchpoints et le contrôle du flux d’exécution //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Naviguez dans le code avec le flux d’exécution :
// Est-ce que vous avez déjà suivi une recette de cuisine pas à pas ? Après chaque étape, on s’arrête généralement jusqu’à être prêt à effectuer l’étape suivante.
// Parfois, on repère une occasion d’improviser et de changer la recette, mais, dans l’ensemble, on suit la recette et on obtient un gâteau !
// Lorsque vous parcourez pas à pas les lignes de votre programme dans un débugger, c’est tout à fait pareil.
// Vous suivez une recette déterminée pas à pas. La recette est votre code original.
// Néanmoins, lorsque vous choisissez 'step over' et inspectez chaque ligne en action, vous pouvez le changer un peu, modifier les variables, et appeler des instructions.
// La modification des variables pendant que votre programme s’exécute peut vous aider à tester des théories et à cibler votre bug plus précisément !
//      --> Comment puis-je contrôler l’exécution de mon programme avec une telle précision ?
// Vous utilisez le volet du débugger pour contrôler le flux d’exécution. Explorons-le plus en détail et voyons la palette d’options disponibles.
// De droite à gauche, on trouve les boutons suivants :
//      - 1. Evaluate Expression.
//      - 2. Run to Cursor.
//      - 3. Drop Frame.
//      - 4. Step Out.
//      - 5. Force Step Into.
//      - 6. Step Into.
//      - 7. Step Over.
//      - 8. Show Execution Point.
// Détaillons cela :
//      --> 'Evaluate Expression' vous permet d’exécuter tout extrait arbitraire de code Java depuis le débugger, fonctionnant comme s’il précédait votre point d’arrêt actuel.
//              Cela vous sera utile lorsque vous voudrez essayer des modifications de votre code à un point d’arrêt, car la source n’est pas modifiée.
//      --> 'Run To Cursor' fait cesser la suspension du débugger et s’arrête à la ligne où se trouve actuellement votre curseur.
//              Cela correspond à ajouter un point d’arrêt pour la ligne en cours et cliquer sur 'Resume'.
//              Lorsque vous êtes arrêté à un point d’arrêt et que vous lisez votre code, c’est une très bonne façon de crier "par ici !" et de faire en sorte que le débugger vous rattrape.
//              Cela évite de créer de nouveaux points d’arrêt que vous devrez gérer par la suite !
//      --> 'Drop Frame' rembobine votre programme jusqu’au point avant l’appel de la méthode en cours.
//              Cela vous donne le pouvoir de voyager dans le temps lorsque vous vous êtes arrêté à un point d’arrêt et que vous avez manqué un détail.
//              Ou si vous décidez que vous avez envie de repasser l’incident après avoir repositionné vos preuves avec 'Evaluate Expression'.
//      --> 'Step Out' reprend l’exécution et revient jusqu’à l’appel pour continuer.
//              Si vous enquêtez sur une méthode et que vous avez fini d’explorer tout ce qui est pertinent pour votre enquête, cela vous permet de revenir à l’appel.
//              Et par conséquent de continuer à débugger à partir du point après la complétion de la méthode, vous évitant l’inconvénient de devoir aller plus loin.
//      --> 'Force Step Into' est comme 'Step Into. Il reprend l’exécution et la suspend immédiatement dans une méthode que vous n’avez normalement pas besoin de débugger.
//              Comme par exemple les classes, les constructeurs, les getters et setters du langage Java.
//              Cela vous permet d’entrer dans le JDK lui-même. Habituellement, nous faisons confiance à Java et nous n’avons pas besoin de débugger le JDK.
//              Néanmoins, il y a des moments où vous pourriez avoir mal compris la Javadoc ou émis des suppositions erronées sur le rôle d’une partie du framework.
//              Cela peut être inestimable et vous en apprendre plus sur les bibliothèques centrales de Java.
//      --> 'Step Into' reprend l’exécution depuis un point d’arrêt sur un appel de méthode. Il suspend à nouveau à la première ligne de la méthode.
//              Cela vous permet de vous déplacer directement dans cette méthode pour enquêter sur ce qu’elle fait et comment elle gère les arguments que vous lui passez.
//      --> 'Step Over' reprend l’exécution du point d’arrêt en cours, et suspend à nouveau à la prochaine déclaration dans le fichier en cours (autrement dit, à la prochaine ligne valide).
//              Une fois que vous avez suspendu à une ligne particulière, cela vous permet de continuer à suspendre à chaque ligne qui suit.
//              Sans 'Step Over', votre IDE serait plein de points d’arrêt toutes les deux lignes. Vous pouvez utiliser ceci pour comprendre le flux de votre code, pas à pas !
//      --> 'Show Execution Point' ramène l’éditeur de code au point d’arrêt actuel. Cela peut être utile si vous commencez à explorer votre code et avez oublié où le débugger s’est arrêté.
//              Il est très facile de se perdre dans votre IDE lorsque vous lisez un code complexe !
//              Pensez-y comme à un moyen de vous téléporter en arrière jusqu’à la ligne de code où vous avez suspendu l’exécution !
// Nous allons maintenant utiliser ce contrôle comme une télécommande de notre machine à remonter le temps, pour mieux comprendre pourquoi nous obtenons une taille de selle négative.
// Mais est-ce que je ne pourrais pas simplement spécifier tout un tas de points d’arrêt et cliquer sur 'Reprendre' ?
// Bien que rien ne vous empêche de placer des points d’arrêt sur toutes les lignes intéressantes d’un fichier source, cela peut être lent à mettre en place.
// Et cela peut aussi vous forcer à inspecter inutilement des déclarations dans votre code.
// Vous pourriez vous retrouver à devoir examiner des appels de méthodes et des déclarations qui n’ont rien à voir avec votre bug. Des examens que vous pourriez facilement éviter.
// Lorsque vous ne connaissez pas la cause d’un bug, cela peut ressembler à l’exploration d’une nouvelle ville.
// L’utilisation des contrôles de flux d’exécution vous permet de vous promener dans votre code.
// Exactement comme lorsque, en vous promenant dans une ville, vous vous arrêtez lorsque vous voyez quelque chose d’intéressant !
// C’est généralement votre meilleure piste lorsque vous marchez dans des rues inconnues sans avoir de plan.
// Voyons comment nous pouvons utiliser les flux de contrôle pour enquêter encore davantage sur notre bug.
// -----------
//  - Utilisez les flux de contrôle pour enquêter sur un bug :
// Notre enquête nous a aidés à éliminer les causes suivantes :
//      --> Un problème avec le calcul de la date quand aucune date n’est passée.
//      --> Une modification erronée du paramètre de la date.
//      --> Un problème dans la classeDragonSaddleSizeVerifierlevant l’exception.
//      --> Une condition dans la boucle for qui ajuste la taille de selle de façon négative pendant qu’elle est calculée.
// La dernière preuve que nous ayons vue est que la méthode 'DragonSaddleSizeEstimator::calculateSaddleSizeFromYear' calcule une variable nommée 'mysticalMultiplier'.
//      --> Cette dernière possède une valeur négative singulière.
// Quand nous utilisons cette valeur pour calculer la taille de la selle, l’estimation qui en résulte est la même que celle que nous avons vue dans notre exception qui bugge : -49.
// Donc, notre prochaine théorie est que le 'mysticalMultiplier' est calculé différemment quand une date cible est passée depuis la ligne de commande.
// Et cela, contrairement à ce qui se passe quand elle est définie explicitement dans notre test. Utilisons nos outils pour comprendre comment le 'mysticalMultiplier' est calculé :
//      - 'UNIVERSAL_LUCKY_NUMBER' est une constante qui semble être définie sans aspect suspect.
//      - 'mysticalMultiplier' est calculé en utilisant 'copyOfUniversalConstant', 'yearOfBirth', et 'UNIVERSAL_LUCKY_NUMBER'.
//      - 'copyOfUniversalConstant' semble être défini à zéro avant d’être utilisé dans une multiplication. Cela semble suspect, car cela rend la multiplication redondante.
// Le calcul de mysticalMultiplier a lieu dans la méthode 'calculateSaddleSizeFromYear(int targetYear)' :
//                  private double calculateSaddleSizeFromYear(int targetYear) {
//                      // ((42-1)/41.0)
//                      double universalLuckyNumber = new Double(UNIVERSAL_LUCKY_NUMBER);
//                      double mysticalMultiplier = (copyOfUniversalConstant - yearOfBirth)/ universalLuckyNumber;
//                      ...
//                  }
// Étant donné que nous avons déjà des tests unitaires et d’intégration pour vérifier que nous pouvons calculer une taille de selle correcte, nous pouvons comparer les deux tests.
// Faisons-le en explorant l’un des tests unitaires existants qui réussissent et qui sont en rapport avec notre test d’intégration qui échoue.
// Si vous repensez au début de notre enquête, nous avons déjà plusieurs tests unitaires qui semblent passer. Nous n’avons jamais établi pourquoi ces tests réussissent !
// Encore autre chose : qu’est-ce que cette 'copyOfUniversalConstantest' censée être ?
// Heureusement, nous avons l’exemple d’un test que nous pouvons débugger et qui nous montre ce que 'copyOfUniversalConstant' devrait être.
// Nous allons débugger un test JUnit qui réussit, qui calcule une taille de selle en 2021, mais nous allons utiliser la fonctionnalité 'Evaluate Expression'.
// Et ceci, pour changer la définition de l’année cible de 2021 à 2020, pendant l’exécution.
// Nous allons aussi nous promener dans le code et utiliserRun to Cursorpour casser le code à des endroits arbitraires. Notre but est de découvrir :
//      --> Quelle est la valeur de 'copyOfUniversalConstant' quand elle fonctionne.
//      --> Ce qui se passe si nous définissons 'copyOfUniversalConstant' à 0, comme c’était le cas quand nous avons débuggé le test d’intégration qui échouait.
// Lançons-nous et fouillons dans notre code. Nous avons pris un test existant et l’avons utilisé pour qu’il nous amène à une instance de 'DragonSaddleSizeEstimator' bien configurée !
// Une fois dans la méthode 'estimateSaddleSizeInCentiMeters(targetYear)', nous avons utilisé les contrôles du débugger pour modifier le comportement du code.
// Ainsi, nous avons pu tester nos méthodes avec différents paramètres et différentes valeurs définis dans les champs du 'DragonSaddleSizeEstimator'.
// Nous avons utilisé 'Drop Frame' pour annuler notre appel à 'calculateSaddleSizeFromYear(targetYear)', pour pouvoir recommencer du début.
// Nous étions essentiellement en train de voyager dans le temps vers le passé et vers l’avenir dans notre code, et essayions de voir comment différents états de départ affectaient l’avenir.
//      --> Qu’est-ce que cela nous dit au sujet de notre bug ?
// Nous avons appris que la différence clé entre une exécution valide du calculateur de taille de selle et une exécution cassée est la suivante :
//      --> Dans une exécution cassée, nous avons le champ de la constante 'copyOfUniversalConstant' du 'DragonSaddleSizeEstimator' défini à 0, plutôt qu’à 42.
// Découvrons davantage d’outils de débug que vous pouvez utiliser pour déterminer d’où vient cette différence.
// -----------
//  - Observez des valeurs qui changent avec des watches et des watchpoints :
// Est-ce que vous avez déjà suivi quelqu’un sur un média social ? Les gros sites de médias sociaux hébergent des millions et des milliards de comptes des quatre coins du monde.
// Avec un tel nombre de personnes partageant des mises à jour quotidiennes, comment suivre les personnes qui vous intéressent ?
// Qu’il s’agisse d’une célébrité ou de votre grand-tante, cela reste la mise à jour d’une seule personne parmi un flux incroyablement vaste.
// Si vous êtes un utilisateur averti, vous savez que vous n’avez qu’à simplement suivre quelqu’un.
// Votre code est rempli de nombreuses variables que vous utilisez pour vous aider à façonner le monde qu’il contient.
// À mesure que votre code satisfait à différents résultats, certaines de ces variables changent ou évoluent.
// Si vous essayez de trouver la cause d’un bug, il peut être utile de suivre des mises à jour de variables clés, comme vous le feriez pour votre grand-tante, cette célébrité Instagram.
//      --> Ceci peut vous aider à vérifier si une mise à jour non intentionnelle a introduit un défaut dans votre logiciel.
// Heureusement, votre débugger vous permet de surveiller des variables spécifiques dans votre code, et de les observer pendant leur évolution.
//      --> Comment décider quelles variables je devrais suivre ?
// Cette décision doit venir de votre enquête, étant donné que les variables changeantes font partie de la façon dont fonctionne le logiciel.
// Vous devez cibler votre enquête sur les variables qui impactent visiblement le comportement dans votre bug.
// Par exemple, la variable 'copyOfUniversalConstant' mentionnée précédemment serait une bonne candidate.
// Elle impacte directement notre résultat, et nous avons vu qu’elle a une valeur suspecte. Une valeur qui pourrait contribuer à notre bug !
// En Java, vous pouvez indiquer final  sur des variables pour indiquer que ce sont des constantes.
// Si vous déclarez qu’un élément est une constante, il ne peut pas changer une fois défini.
// Les types primitifs comme les doubles, chaînes, entiers, booléens, ou longs n’ont généralement pas besoin d’être surveillés.
// En effet, le compilateur Java explosera gentiment pour vous si quoi que ce soit essaie d’en modifier un.
// Néanmoins, si la valeur est un objet, alors final ne garantit pas que les propriétés au sein de l’objet référencé ne changeront pas.
// Ainsi, il vous faudra peut-être surveiller de tels objets s’ils sont liés à votre enquête.
// -----------
//  - Watches :
//      --> Alors, comment surveiller une variable ?
// Lorsque vous êtes dans la boîte à outils de débug, sélectionnez n’importe quelle variable dans votre volet "Variables", cliquez droit, et cliquez sur "Add to Watches".
// Vous pouvez également supprimer tous les watches en utilisant l’élément tout en haut de ce menu.
// Après avoir ajouté une variable à vos watches, vous la verrez toujours dans votre volet Variables avec une paire de lunettes à côté d’elle.
// Ainsi, vous pouvez garder à l’œil tous les changements qui lui sont apportés.
// Un panneau de variables affichant les variables surveillées avec une paire de lunettes à côté.
// Notez que 'targetYear' a des lunettes à côté.
// -----------
//  - Watchpoints :
//      --> Est-ce que je peux mettre le débugger sur pause quand une variable change ?
// Si la variable que vous surveillez est un champ dans une classe, vous pouvez y ajouter un watchpoint, et le débugger stoppera et s’arrêtera automatiquement sur toute ligne qui modifie ce champ.
// Vous pouvez ajouter un watchpoint avec votre IDE en cliquant sur la marge à côté d’une déclaration de champ, comme vous le feriez pour ajouter un point d’arrêt à tout autre endroit.
//      --> Cela affichera un oeil rouge, contrairement au cercle rouge que vous avez vu jusqu’à présent !
// Pour ajouter un watchpoint, faites un clic droit sur l'oeil rouge.
// Le clic droit là-dessus ouvre un dialogue similaire à celui utilisé pour les points d’arrêt.
// Cela vous permet de cocher la case si vous voulez vous arrêter sur 'Field access' (lecture du champ), 'Field modification' (évolution du champ), ou les deux.
// Testons une théorie. Si nous pensons qu’il y a un problème avec le champ 'copyOfUniversalConstant' dans la classe 'DragonSaddleSizeEstimator'.
// Comment pourrions-nous garder un œil sur les changements à 'copyOfUniversalConstant' ? Nous allons y placer un watchpoint et découvrir ce qui le modifie.
// Vous avez vu la façon dont nous avons utilisé un watchpoint pour nous arrêter sur toute déclaration Java qui modifiait la valeur du 'champcopyOfUniversalConstant' ?
// Et maintenant, regardons les preuves ensemble.
// En plaçant un watchpoint sur 'copyofUniversalConstant', nous avons appris que :
//      --> 'copyOfUniversalConstant' est initialement définie dans le constructeur de 'DragonSaddleSizeEstimator'.
//      --> Elle est définie depuis une variable statique, une constante, nommée 'UNIVERSAL_CONSTANT'.
//      --> Au point de définition de 'copyOfUniversalConstant', 'UNIVERSAL_CONSTANT' a une valeur de 0.
//      --> 'UNIVERSAL_CONSTANT' est la deuxième déclaration dans 'DragonSaddleSizeEstimator' et est codée en dur à 42.
//      --> La variable statique 'INSTANCE' est déterminée juste avant la déclaration de 'UNIVERSAL_CONSTANT'.
//      --> 'UNIVERSAL_CONSTANT' était utilisée dans le constructeur avant qu’on ne lui attribue la valeur de 42.
// Élémentaire. Il semble logique qu’en raison d’un problème d’ordre, 'UNIVERSAL_CONSTANT' soit utilisée dans une invocation du constructeur avant d’être définie.
//      --> Conclusion, une variable statique est utilisée avant d’être définie.
// Et maintenant, testons notre nouvelle théorie. Les quelques premières lignes de notre 'DragonSaddleSizeEstimator' ressemblent à ceci :
//                  public class DragonSaddleSizeEstimator {
//                      // Singleton instance of the Dragon Size Estimator
//                      public static final DragonSaddleSizeEstimator INSTANCE = new DragonSaddleSizeEstimator();
//                      /**
//                      * The universal constant which is 42.
//                      */
//                      public static int UNIVERSAL_CONSTANT = 42;
//                      // The year when dragons were first spawned on Earth in 1 AD
//                      public static final int DRAGON_SPAWN_YEAR = 1;
//                      // Private fields
//                      private int copyOfUniversalConstant;
//                      private int yearOfBirth;
//                      private DragonSaddleSizeVerifier verifier;
//                      /**
//                      * Constructor
//                      **/
//                      public DragonSaddleSizeEstimator() {
//                          copyOfUniversalConstant = UNIVERSAL_CONSTANT;
//                          yearOfBirth = DRAGON_SPAWN_YEAR;
//                          ...
//                      }
//                      ....
//                  }
//      - Ligne 4 : l’attribution d’instance appelle le constructeur à la ligne 22.
//      - Ligne 9 : 'UNIVERSAL_CONSTANT' est définie à 42 après la création d’une instance.
//      - Ligne 12 : 'DRAGON_SPAWN_YEAR' est défini à 1 après la création de l’instance.
//      - Ligne 23 : la première fois que le constructeur a été appelé à la ligne 4, 'UNIVERSAL_CONSTANT' n’avait même pas été définie. Java initialise par défaut ce type de valeur d’entier à 0.
//      - Ligne 24 : la première fois que le constructeur a été appelé à la ligne 4, 'DRAGON_SPAWN_YEAR' n’avait pas encore été défini. À nouveau, Java a attribué 0 par défaut. Même si c’était un 0 !
// Vous voulez dire que la variable finale à la ligne 12 a été utilisée avant d’être définie ? Les finales ne peuvent pas être modifiées !
// Bien observé. Vous avez raison. C’est généralement le cas, mais en raison du flux de contrôle Java pour les entités statiques, ce n’est pas le cas lorsqu’il s’agit de champs statiques.
// Java commence par scanner pour trouver tous les champs statiques et les crée avec des valeurs par défaut. Dans ce cas, int a été mis à 0 par défaut.
// Ensuite, il les attribue et les exécute dans leur ordre d’occurrence dans le code. Cela signifie que la ligne 4 est attribuée en premier.
// L’attribution initiale de 'copyOfUniversalConstant=UNIVERSAL_CONSTANT' est effectuée avant que nous ayons l’occasion de redéfinir 'UNIVERSAL_CONSTANT' du 0 par défaut à 42.
// Oui, Java exploserait et se plaindrait dans un monde idéal. Mais il ne le fait pas dans celui-ci.
// C’est une particularité du langage, qui, comme vous l’avez vu ici, peut facilement apparaître et vous surprendre. Elle ne fait pas ce à quoi vous vous attendez !
//      --> Quelle est la solution ?
// Déplacez simplement la ligne 4 après les lignes 9 et 12. Ainsi, les variables statiques auront été définies avant d’être utilisées.
// Mais comment prouver cette théorie ? Comme toute autre théorie, nous devons la tester. Regardons à nouveau le début de la 'classeDragonSaddleSizeEstimator', avec les commentaires un peu nettoyés :
//                  public class DragonSaddleSizeEstimator {
//                      /**
//                      * Singleton instance of the Dragon Size Estimator
//                      **/
//                      // Makes use of the next two defined static variables
//                      public static final DragonSaddleSizeEstimator INSTANCE new DragonSaddleSizeEstimator();
//                      /**
//                      * The universal constant which is 42.
//                      */
//                      // FIXME this isn't a constant until you add final
//                      public static int UNIVERSAL_CONSTANT = 42;
//                      /**
//                      * The year when dragons were first spawned on Earth in 1 AD
//                      **/
//                      public static final int DRAGON_SPAWN_YEAR = 1;
//                      ...
//                  }
// Étant donné que la première variable statique dans le code dépend des deux qui la suivent, la solution impliquera un remaniement, la déplaçant sous la variable à la ligne 18.
// Ce remaniement est fait car le constructeur actuellement appelé à la ligne 7 appellera ces deux valeurs.
// Si vous avez remarqué le mot singleton à la ligne 4 et que vous vous êtes demandé ce que c’était, laissez-moi vous éclairer à ce sujet.
// Le patron de conception singleton est un choix de design effectué en écrivant votre logiciel.
// Il privilégie la présence d’une seule instance d’une classe qui est utilisée encore et encore, plutôt que d’en créer un grand nombre.
//      --> Cela s’appelle une instance singleton. Comme vous l’avez vu, le code utilise une déclaration statique pour garantir qu’il n’existe qu’une seule variable dans le périmètre de classe.
// Ce n’était pas nécessairement le meilleur choix de design ici, particulièrement car les singletons peuvent être difficiles à tester !
// Souvenez-vous que, lorsque vous débuggez du code, votre but est de rester empirique et de comprendre le flux menant à un bug, avant de réécrire le code.
//      --> Si vous appliquez la bonne solution, votre test d’intégration devrait commencer à réussir. Effectuons-le ensemble.
// -----------
//  - Réparez le bug :
// Nous allons exécuter le test d’intégration en premier et nous rafraîchir la mémoire quant au bug original dans le programme.
// Nous voulons aussi découvrir pourquoi il y a cet étrange moyen de contournement qui consiste à passer une année comme argument au programme.
// Nous pourrons ensuite cibler la cause sous-jacente et la réparer. Réunissons tous les suspects dans la bibliothèque et identifions ce bug !
// Vous avez remarqué la façon dont la méthode principale avait été forcée de fonctionner quand on lui passait un argument ?
// Cela s’appelle un setter, qui a redéfini 'copyOfUniversalConstant'. Les constantes ne sont pas censées changer, cette copie n’existe que pour être redéfinie.
// L’utilisation de ce type de réparation revient à mettre du scotch sur votre code.
// Ce n’est pas une solution à long terme, en particulier car elle ne répare pas la classe 'DragonSaddleSizeEstimator'.
// Si nous écrivions une autre classe qui avait besoin d’utiliser le 'DragonSaddleSizeEstimator', nous aurions à appliquer le même scotch partout.
// Le problème sous-jacent continuerait d’exister dans le code.
//      --> À la place, nous avons résolu le problème en déplaçant la déclaration d’instance vers le bas, là où nous avons défini les variables dont elle dépend.
// Notre débugger nous a donné une loupe sous stéroïdes, avec laquelle nous avons pu résoudre ce mystère.
// Le code doit être nettoyé, et heureusement, cela fonctionne, avec des tests. Qui que ce soit qui nettoie le code aura l’assurance qu’il ne le casse pas davantage.
// Essayez par vous-même ! La réparation est sur la branche nommée bug-fix-1 :
// Regardez cette branche et exécutez le programme par vous-même.
// Regardez bug-fix-1 dans Git, ou dans IntelliJ VCS -> git -> branches -> origin/bug-fix-1 -> Checkout As.
// Essayez de définir un watchpoint 'surcopyOfUniversalConstant' et voyez d’où on y accède et la modifie.
// Astuce : Reproduisez les étapes de débug que je vous ai montrées dans le screencast. Vous verrez peut-être une estimation plus crédible, qui n’est pas négative !
// Est-ce qu’on dirait que nous l’avons réparé ?
// -----------
//  - En résumé :
//          --> Les contrôles de flux d’exécution de votre débugger vous permettent de :
//                  - Show Execution Point : Rafraîchir l'éditeur pour afficher votre point d’arrêt actuel.
//                  - Step Over : Exécuter la commande au point d’arrêt actuel et suspendre la ligne suivante.
//                  - Step In : Entrer dans la méthode sur laquelle vous avez un point d’arrêt et vous arrêter dedans.
//                  - Force Step In : Entrer dans une méthode du JDK comme 'new Double()'.
//                  - Step Out : Aller jusqu’au bout de la méthode en cours et suspendre tout de suite après l’élément qui appelle.
//                  - Drop Frame : Revenir à l’élément qui appelle cette méthode, comme si cette méthode n’avait jamais été appelée, annuler tout changement.
//                  - Run to Cursor : Reprendre depuis ce point d’arrêt et exécuter toutes les déclarations.
//                      Ainsi, vous vous arrêterez à nouveau lorsque vous atteignez la ligne sur laquelle se trouve actuellement le curseur.
//                  - Evaluate Expression : Exécuter toute affirmation Java que vous souhaitez. Vous pouvez voir des valeurs et tester de potentiels changements au code sans changer le code source !
//          --> Watches est une liste de variables utile à épingler à votre volet Variables. Cela vous permet de garder un œil sur tout changement.
//          --> Les watchpoints sont des variables que non seulement vous surveillez, mais que vous avez également configurées pour déclencher des points d’arrêt.
//                  Ces points d'arrêts se stoppent sur toute déclaration qui tente d’y accéder ou de les modifier.
//                  Vous pouvez utiliser ceci pour trouver la partie du code qui ne définit pas correctement l’une d’entre elles.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Réparez les bugs avec VisualVM, JConsole et les techniques de log /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Profilez un programme avec VisualVM ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Comprenez la dégradation de la performance :
// Imaginez qu’un utilisateur soulève un rapport de bug déclarant que le calculateur de taille de selle de dragon prenait trop de temps pour estimer la taille de selle correcte.
// Les dompteurs de dragons sont des personnes occupées, et un tel délai est inacceptable au souverain régnant sur les Huit Royaumes.
// Même si vous n’avez pas peur de la colère de ce souverain, il est important de demander : "Pourquoi est-ce que notre logiciel se mettrait tout à coup à ralentir ?".
// De nombreux facteurs peuvent avoir un impact sur les temps de trajet. Avez-vous déjà pris les transports publics et eu le choix entre différents itinéraires ?
// Le choix du mauvais itinéraire peut vous faire perdre une heure !
// Les applications qui déterminent les itinéraires sont efficaces pour vous donner des options sur la durée que nécessiteraient les différents chemins.
// Pensez maintenant à votre code en exécution sur la JVM avec toutes les branches ou méthodes différentes qu’il pourrait prendre en fonction des données et arguments que vous lui donnez.
// Votre logiciel est également vulnérable à la dégradation des performances à chaque fois que vous ajoutez une nouvelle méthode ou branche où le code pourrait devoir se rendre.
// Pourquoi cela ? Lorsque votre code est en exécution, la JVM effectue généralement un voyage de classe en classe, de méthode en méthode, et essaie d’atteindre son but.
// De façon interne, elle fait de son mieux pour rendre l’exécution de votre code la plus rapide possible, un peu comme ces applications qui trouvent des itinéraires.
// Java est un excellent langage de programmation en ce qui concerne la vélocité, et est vite devenu l’un des langages de programmation les plus rapides.
// Il est même préféré à d’autres langages pour des applications comme le trading en temps réel et le calcul scientifique haute performance, qui nécessitent des logiciels rapides et réactifs.
//      --> Sa machine virtuelle Graal-VM est actuellement en train de le rendre encore plus rapide !
// Les problèmes liés à la performance de Java sont généralement causés par des développeurs.
// Nous concevons souvent des logiciels que même la JVM ne peut pas accélérer, car soit les algorithmes résolvent les problèmes de la manière la plus lente possible, soit ils comportent une autre erreur.
// Lorsque vous rencontrez un problème de performance dans votre code, essayez de le résoudre en :
//      --> Mesurant votre code pour déterminer quelle action le ralentit et où cela se produit dans le code.
//      --> Enquêtant sur le code non performant et questionnant ce qu’il essaie d’accomplir et pourquoi.
//      --> Supprimant ou simplifiant le code si cela peut être fait immédiatement.
//      --> Mesurant votre code à nouveau pour voir si vous l’avez amélioré !
// Est-ce que vous êtes en train de dire que je ralentis peut-être mon application ? Comment cela est-il possible ?
// Vous pouvez faire de nombreuses choses pour ralentir votre logiciel sans vous en rendre compte.
// Les causes les plus courantes impliquent l’écriture d’algorithmes inefficaces et de code qui empêche un autre code de s’exécuter aussitôt qu’il le pourrait.
// Assurez-vous de parler avec les product owners et autres parties prenantes.
// En effet, vous implémentez peut-être quelque chose de plus complexe que ce qui est requis par le business et ses utilisateurs !
// En essayant d’écrire du code de qualité généralisé, il est facile de sacrifier la performance.
// Par exemple, le fait d’écrire du code qui modélise de nombreux types d’informations entrantes, et possède une logique complexe, peut résulter en un algorithme lent.
// A la place, vous devriez utiliser plusieurs algorithmes rapides avec des modèles plus simples.
// Regardons plusieurs causes à tour de rôle !
// -----------
//  - Cause de dégradation de performance n° 1 : algorithmes inefficaces :
// Pour rappel, un algorithme est une série d’étapes qui vous permettent de définir la façon dont vous traiterez les données entrantes et arriverez au résultat escompté.
// Lorsque vous écrivez des méthodes et des fonctions, vous liez généralement une série de déclarations les unes aux autres dans votre langage de programmation.
// Ces déclarations résolvent certains problèmes en inspectant vos données et en appliquant des règles que vous jugez utiles pour résoudre une partie spécifique de votre problème.
// En décidant comment implémenter ces règles en tant que code, vous définissez un algorithme ou une série d’étapes que votre code devra exécuter.
// En fonction de l’algorithme, vous implémenterez du code différent qui impactera la vitesse à laquelle il gère différentes informations entrantes.
// Par exemple, si vous aviez une rangée de girafes en ordre de taille, comment détermineriez-vous laquelle est la plus grande ?
// Vous pourriez commencer avec la première de la série et mesurer chaque girafe. Cela pourrait aller vite s’il y en a deux, mais ralentirait avec un troupeau plus important.
// Le fait de mesurer trente girafes prendrait beaucoup plus longtemps, et les perturberait probablement.
// Étant donné qu’elles sont déjà placées en ordre, il serait plus efficace de se rendre à la fin de la rangée. Cet algorithme ne ralentira jamais !
// Prendre le temps de réfléchir à la façon dont votre code se met à l’échelle pour gérer efficacement différentes données entrantes peut le maintenir performant.
// Ce n’est pas toujours évident ou facile, surtout si vous pensez que vous ne verrez jamais plus de deux girafes !
// Le pire cas de la vitesse d’un algorithme est désigné par sa complexité temporelle.
// Par exemple, votre algorithme pour transformer une liste d’entiers en leur somme pourrait être : "À tour de rôle, inspecte chaque élément de la liste et ajoute-le au dernier".
// Comme il va à chaque élément de la liste, nous savons que cet algorithme sera au moins aussi lent que le temps requis pour examiner autant de chiffres que le permet la taille de la liste, nommée n.
//      --> Nous disons que cet algorithme a une complexité temporelle d’O.(n) (Prononcez « Ordre N »).
// -----------
//  - Cause de dégradation de performance n° 2 : blocage du code :
// La majorité de ce que vous écrivez en tant que développeur est du code séquentiel.
// C’est-à-dire que vous écrivez des algorithmes qui prennent une étape à la fois, dans l’ordre.
// Pour qu’une étape démarre, la précédente doit être terminée. Toute déclaration que d’autres déclarations attendent est appelée une déclaration bloquante.
// Les logiciels sont tellement rapides que cela ne pose pas de problèmes en général.
// Néanmoins, imaginez ce qui pourrait se produire si votre déclaration bloquante impliquait une opération lente.
// Comme l’ouverture d’un fichier ou l’exécution d’un algorithme inefficace, qui prend plusieurs secondes. Eh bien, la prochaine déclaration devrait attendre que ce soit terminé.
// Attendez, est-ce que chaque étape ne dépend pas de la précédente ? Comment éviter cela ?
// Dans de nombreux cas, une déclaration dépend d’une déclaration précédente, mais pas toujours.
// Par exemple, pensez à l’équation de Pythagore pour calculer la surface d’un triangle, a² + b² = c².
// Devez-vous attendre de calculer le côté a au carré avant de calculer le côté b au carré ?
// Si les calculs de a² et b² étaient des opérations lentes, vous pourriez même les effectuer en même temps, c’est ce qu’on appelle une solution concurrente (ou parallèle).
// Le modèle de threading et les bibliothèques de concurrences Java vous permettent d’écrire de telles solutions parallèles.
// Consultez le cours OpenClassrooms sur la concurrence en Java.
// Et maintenant, comment savoir si une méthode a été si mal écrite qu’elle a ralenti votre application entière ?
// Imaginez que vous ne pouvez pas utiliser d’application de calcul d’itinéraire pour naviguer dans les portions moins performantes de votre code.
// vous pouvez surveiller la façon dont il s’exécute pour trouver quels algorithmes le ralentissent.
// Un peu comme si vous regardiez différents indicateurs de circulation qui montrent les bouchons sur des trajets spécifiques. Vous utilisez un outil de profilage de code.
//      --> Qu’est-ce que le profilage ?
// Le profilage correspond à tenir un chronomètre devant vos méthodes et à mesurer le temps qu’elles prennent à renvoyer un résultat.
//      --> Il vous permet de trouver les méthodes lentes dans votre code en mesurant et comparant vos appels pour trouver les moins performants.
//      --> Il peut aussi capturer d’autres métriques concernant votre application.
// Il vous permet de trouver des problèmes affectant la vitesse à laquelle votre application se comporte et avec quelle efficacité elle utilise sa mémoire disponible.
// Tout comme vous avez réduit la probabilité de bugs normaux en écrivant des tests, vous pouvez également réduire la probabilité de problèmes de performance en écrivant des tests de performance !
// Ce sont des cas de test que vous pouvez automatiser pour exécuter de larges volumes de données ou charges de travail à travers des parties de votre système.
// Ou pour mesurer la performance de votre logiciel dans de telles situations.
// Ils peuvent vous aider à trouver toutes les dégradations de performance dès leur introduction.
// Essayez de tester la performance de votre code pour éviter à vos utilisateurs de vous dire que votre logiciel n’est pas au niveau !
// -----------
//  - Utilisez VisualVM pour profiler votre code :
// Pour profiler votre application, vous pouvez utiliser VisualVM, un outil de profilage Java développé par Oracle (les constructeurs de Java), et fourni avec leur JDK.
// Entre autres, il vous permet de mesurer les méthodes de vos applications Java et leur temps d’exécution.
// Vous pouvez utiliser VisualVM pour vous connecter à toute application Java en marche.
// Tout comme JPDA rend possible le débug d’une application exécutée sur la JVM, le profilage est rendu possible grâce à un autre standard connu sous le nom de  JVM Tooling Interface (JVM-TI).
// Les implémentations JVM doivent gérer ce protocole pour permettre aux outils tels que les profileurs de recueillir des informations sur vos applications en exécution.
// -----------
//  - Téléchargez VisualVM :
// Vous pouvez télécharger la dernière version de VisualVM depuis ce lien, ou vous pouvez utiliser celle qui est fournie avec le JDK.
// Essayez de démarrer jvisualvm s’il est déjà installé.
//      - Trouvez vos informations de distribution Java.
//          Vous pouvez généralement trouver jvisualvm en affichant votre variable d’environnement JAVA_HOME et en regardant dans le dossier bin qui y est stocké.
//          Cela varie en fonction de la distribution. Essayez de regarder dans les emplacements suivants :
//              - Sur un Mac avec OS-X, vous trouverez votre distribution Java sous '/Library/Java/JavaVirtualMachines'.
//              - Sous Windows, vous trouverez généralement vos installations Java sous 'c:\Program Files\Java'.
//              - Avec les distributions Debian Linux, vous verrez que votre dpkg a installé JDK sous '/usr/lib/jvm'.
//      - Localisez le fichier.
//          Entrez dans le répertoire JDK et naviguez jusqu’au répertoire bin.
//          Sous celui-ci, vous trouverez un fichier nommé 'jvisualVM'.
//      - Démarrez le fichier en double-cliquant dessus.
// -----------
//  - Profilez un programme avec VisualVM :
// Commençons par vérifier du code qui comporte des bugs.
//      --> Pour regarder la version du projet de calculateur de tour de taille de dragon comportant un bug de performance, vous pouvez utiliser le même répertoire que vous avez cloné en partie 2.
//              --> Cette fois, consultez la branche performance-bug.
// Vous pouvez utiliser le menu VCS d’IntelliJ pour consulter cela ou utiliser la commande Git CLI : 'git checkout performance-bug'.
// Ensuite, exécutez le programme 'DragonSaddleSizeGuesser' et constatez le temps d’exécution de plusieurs secondes.
// Pour enquêter sur les raisons d’une telle lenteur de l’application 'DragonSaddleSizeGuesser', vous devez démarrer VisualVM.
// Le volet Applications sur la gauche affiche les applications Java en exécution que vous pouvez immédiatement commencer à profiler.
// Sur la gauche, apparaît le volet Applications comprenant les applications Java en exécution ou profilables. Parmi elles, se trouve VisualVM.
//      --> Cliquez dessus pour voir toute application Java en exécution sur votre ordinateur.
//      --> En cliquant sur le process VisualVM, vous pouvez explorer les volets fournis.
// Nous rechercherons le code lent, mais je vais tout d’abord vous donner une vue d’ensemble rapide.
// Faisons cela ensemble. VisualVM comporte beaucoup de fonctionnalités, et nous nous concentrerons uniquement sur la surveillance du temps pris par nos méthodes.
// Pour vous donner une vue d’ensemble rapide, j’utiliserai VisualVM pour qu’il se connecte à lui-même, car il s’agit simplement d’un autre process Java.
// Nous n’utiliserons pas la plupart de ces fonctionnalités, étant donné que notre point de concentration est de déterminer la vitesse de nos méthodes.
// Néanmoins, si vous voulez en apprendre davantage, consultez l’excellente documentation fournie avec VisualVM.
// Vous avez vu la façon dont cliquer sur CPU sous la vue du moniteur a affiché le temps total passé dans chaque méthode ? Nous allons utiliser ceci pour trouver notre méthode lente.
// Voici un défi : pouvez-vous démarrer votre 'DragonSaddleSizeGuesser' et vous y connecter avec VisualVM ?
// Avez-vous déjà abandonné ? Je parie que vous vous demandez pourquoi le 'DragonSaddleSizeGuesser' n’arrête pas de disparaître.
// Le problème de notre programme, c’est qu'il s’agit d’une application rapide qui calcule une taille de selle et arrête de s’exécuter, en général en moins de 15 secondes.
// C’est peut-être trop lent pour nous, mais cela rend difficile de le trouver et s’y connecter dans VisualVM.
// Heureusement pour vous, il existe un plug-in dans VisualVM qui vous permet de profiler une application à partir du moment où elle démarre. Laissez-moi vous montrer comment l’installer :
// Comme vous l’avez vu, nous avons suivi le process suivant :
//      - Premièrement, cliquez sur Tools et sélectionnez l’option Plugins.
//      - Maintenant, défilez vers le bas et sélectionnez le plug-in Startup Time Profiler.
//      - Défilez vers le bas et acceptez les modalités et conditions.
//      - Cliquez sur Installer !
//          --> Cela a maintenant ajouté une icône supplémentaire dans VisualVM avec un petit chronomètre.
// Le petit chronomètre correspond à l'icône du profiler Startup Time.
// Comment utiliser ceci pour trouver la méthode qui ralentit mon application ?
// Pour trouver la méthode qui a ralenti notre 'DragonSaddleSizeGuesser', nous devons l’exécuter avec VisualVM.
// Contrairement à l’exemple précédent, nous allons paramétrer VisualVM pour qu’il attende notre programme, afin qu’il puisse commencer le profilage dès le moment où il démarre.
// Nous savons désormais quelle méthode est notre coupable, mais comment l’avons-nous découvert ? Détaillons ce qu’il s’est passé ici.
// Nous avons cliqué sur l’icône chronomètre de notre profileur startup et sélectionné la bonne JVM pour notre application.
// Nous utilisons JDK 8, car c’est la version utilisée par 'DragonSaddleSizeGuesser'.
// Nous avons sélectionné un port de 5130, qui aide notre JVM à envoyer des données à VisualVM.
// Sous Start profiling from classes, nous avons entré le nom de paquet 'com.openclassrooms.debugging.**'.
// Le double « * » fait que VisualVM profile toutes les méthodes des classes et sous-classes de ce paquet.
// VisualVM nous a alors donné quelques commandes à copier en utilisant le bouton Copy to Clipboard (Copier vers le presse-papiers).
// Nous avons ensuite ouvert une console et nous nous sommes placés à le répertoire 'build/libs' de notre projet (si le répertoire n’existe pas, exécuter la commande gradlew build).
// Ainsi, nous pouvions exécuter notre application via le JAR qui est généré grâce à la commande : 'java <option copiée de VisualVM> -noverify -jar dragon-saddle-size-checker-1.0-SNAPSHOT.jar'.
// VisualVM nous a prévenus que l’application avait déjà terminé et a demandé si nous voulions voir le résultat.
// En sélectionnant Oui, nous avons pu prendre notre temps pour enquêter sur le problème.
// Nous avons appris que la méthode que nous recherchons est : 'com.openclassrooms.debugging.DragonSaddleSizeEstimator.enterAProgrammaticTrance()'.
//      --> Comment savons-nous que c’est bien la cause ?
// Dans VisualVM, nous avons cliqué sur  Hot Spots, et cela nous a montré une vue contenant ce qui suit :
// Il y a plusieurs colonnes, de gauche à droite : Hot Spots Method, Self Time, Total Time, Invocations.
// La vue  Hot Spots  montre une liste ordonnée de méthodes, classées selon la quantité de temps passé dans la méthode.
// Comme un présentateur météo qui vous dit qu’il fait 40° C à Tenerife ☀, regardez la ligne supérieure du tableau ci-dessus et regardez sous Self Time (Temps personnel).
//      --> Vous pouvez voir que nous avons un point critique (ou hot spot) de performance de 10 531 millisecondes.
// La première colonne vous montre qu’il s’agit du temps total passé dans la méthode 'enterAProgrammaticTrance()'.
// Si vous regardez la valeur entre parenthèses, elle montre que 99,8 % du temps de notre programme a été consacré à cette méthode.
// La dernière colonne, Invocations, montre qu’elle n’a été appelée qu’une fois.
// L’avant-dernière colonne, Total Time (temps total), inclut Self Time, ainsi que le temps passé dans d’autres méthodes appelées par celle-ci.
// Il est généralement préférable d’utiliser self time lorsque l’on essaye d’identifier quelle méthode est lente.
// Comme vous pouvez le voir dans le cas 'demain(String arg[])', à la deuxième ligne ci-dessus, le fait de regarder le temps total d’une méthode peut vous induire en erreur.
// Il inclut tous les appels de méthodes amenant jusqu’à un appel du coupable réel.
//  La méthode 'main(String arg[])' a le temps total le plus lent, car il s’agit de la première méthode appelée lorsque l’application démarre.
// Ce n’est pas la méthode qui a en fait introduit notre bug de performance, mais celle qui est à l’origine lointaine de son appel !
// Et maintenant, qu’est-ce que cette méthode pourrait être en train de faire ? Souvenez-vous que ce programme a été interprété à partir de sorts anciens d’alchimistes.
// En bref, n’attendez pas trop de logique derrière certaines de nos règles business. Lisons les commentaires et regardons le code.
//                  private void enterAProgrammaticTrance() {
//                      // Slows down the magic
//                      Instant before = Instant.now();
//                      Instant end = before.plus(Duration.ofSeconds(10));
//                      while (Instant.now().isBefore(end)) {
//                          for (int j = 0; j < Integer.MAX_VALUE; j++) {
//                              for (int i = 0; i < Integer.MAX_VALUE; i++) {
//                                  // TODO - implement
//                              }
//                          }
//                      }
//                  }
//      --> Vous voyez ce qu’il fait ? Ou plutôt, ce qu’il ne fait pas ?
// Le code a une boucle while à la ligne 6, qui vérifie constamment si 10 secondes se sont écoulées depuis le calcul de Instant end à la ligne 4.
// Il y a deux grandes boucles for imbriquées après cela aux lignes 7 et 8, mais elles ne font rien ! Il y a un commentaire TODO inutile à la ligne 9.
//      --> Fondamentalement, cela tourne juste en boucle pendant 10 secondes !
// En demandant à nos experts au sujet des dragons (SME pour « subject matter experts »), on nous dit qu’ils n’ont pas besoin d’une règle business comme celle-ci.
// Nous pouvons retirer ce code sans nuire à l’application. Il vaut mieux obtenir des estimations de selle en moins de 10 secondes que d’entrer dans une transe programmatique.
// -----------
//  - Essayez par vous-même !
// Nous avons besoin d’une solution !
// Essayez de reproduire nos étapes ci-dessus. Vous devriez voir le  enterAProgrammaticTrance  dans la vue  Hot Spots.
// Retirez cette méthode et son appel.
// Une fois ceci effectué, vous pouvez essayer de profiler vous-même, comme nous l’avons fait ci-dessus.
// Lorsque vous vous trouvez dans la vue Hot Spots, vous devriez remarquer que 'enterAProgrammaticTrance()' ne se trouve plus dans la partie supérieure.
// Consultez la 'brancheperformance-bug-fix' pour voir la solution : 'git checkout performance-bug-fix'.
// Lorsque j’exécute l’application avec la vue Hot Spots de VisualVM, la méthode lente a visiblement été retirée et la méthode principale est la nouvelle méthode la plus lente avec environ 19 ms.
// -----------
//  - En résumé :
//          --> Le profilage vous permet de recueillir et d’examiner des métriques sur la performance des classes et des méthodes dans votre programme.
//          --> En utilisant VisualVM, vous pouvez profiler vos applications et capturer des vues classées de hot spots de performance dans votre code.
//          --> Avec le plug-in Startup Profiler, vous pouvez inspecter des programmes de courte durée.
// Dans le chapitre suivant, nous allons explorer un autre excellent outil : JConsole !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Explorez des indicateurs clés avec JConsole ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Gérez la santé de votre code avec JMX :
// Êtes-vous déjà allé chez le médecin, faire prendre votre température, mesurer votre pouls et votre pression sanguine ?
// Votre médecin examine généralement votre état de santé en vérifiant quelques indicateurs clés faciles à mesurer.
// Ces mesures peuvent aider à résumer votre état de santé général sans avoir à vous ouvrir de façon chirurgicale !
// Quand des utilisateurs réels utilisent votre application, vous voulez savoir que tout fonctionne comme prévu, sans surprises.
// Vous voulez aussi vous en assurer sans être intrusif, afin de ne pas ralentir, arrêter, modifier, ou redémarrer votre application pendant que vous vérifiez qu’elle fonctionne.
// C’est là que Java Management Extensions (gestion des extensions Java), plus couramment connu sous le nom de JMX, vient à votre secours !
// JMX fournit une interface standard pour que les applications fassent un retour sur leur propre santé (en d’autres termes, sur la qualité de leur fonctionnement).
//      --> Avez-vous déjà utilisé une bibliothèque tierce dans votre code ?
// Dans ce cas, sans même le savoir, vous avez probablement autorisé des extensions JMX, qui vous donnent des informations sur la santé de l’application.
// Y compris des métriques liées à des éléments tels que votre système d’opération et votre utilisation de la mémoire. Ces informations aident à diagnostiquer et traiter les bugs.
//      --> Comment est-ce que cela fonctionne, exactement ?
// Pour comprendre JMX, vous devez savoir ce qui le constitue : des attributs et des opérations.
// -----------
//  - Utilisez des attributs avec JMX :
// JMX permet aux applications de coder des endpoints spéciaux qui rendent disponible l’information de différentes valeurs.
// Ceux-ci s’appellent des attributs et ils décrivent la façon dont votre application fonctionne - comme les vérifications de santé et l’historique médical utilisés par le médecin.
// En termes très simples, les endpoints sont des moyens d’accéder aux informations dont vous avez besoin, un peu comme la porte d’un placard rempli de choses utiles.
// Si vous êtes curieux au sujet des endpoints dans Spring Boot, allez voir le cours Create web applications efficiently with the Spring Boot MVC framework.
// Java vous fournit des informations. Par exemple, il peut vous dire combien de mémoire libre est disponible sur l’ordinateur qui exécute la JVM de votre application.
// La valeur peut comprendre un changement de mémoire au fil du temps, à mesure que votre ordinateur grandit et a besoin de davantage de mémoire pour résoudre ses problèmes.
//      --> Vous pouvez suivre cette croissance dans le temps, avec des métriques que vous pouvez voir sur un graphique.
// D’autres attributs peuvent être fixes et immuables, comme le nom du système d’opération.
// Ce sont des métadonnées, qui aident à décrire votre système en termes plus larges et donnent du contexte aux métriques.
// Les informations fixes, comme la JVM utilisée, pourraient être utiles lorsque vous suivez les différences dans l’utilisation de la mémoire et d’autres ressources entre différentes versions de JVM.
// -----------
//  - Utilisez des opérations avec JMX :
// JMX permet également aux endpoints d’application de rendre disponibles des méthodes spéciales.
// Ceci vous permet d’utiliser les mêmes outils qui inspectent les métriques de votre application pour appeler des méthodes spéciales qui peuvent modifier votre application sans la redémarrer.
// Par exemple, vous pourriez demander à votre application d’être plus bavarde dans ses rapports sur ses activités.
// Vous voulez dire que mon application pourrait déjà avoir des métriques de santé ? Comment puis-je les voir ?
// JConsole est un outil fourni à la fois avec l’OpenJDK et les JDK Oracle.
// Vous pouvez l’utiliser pour vous connecter à une JVM exécutant votre application et examiner les métriques de santé via les opérations et les attributs.
// VisualVM peut également vous montrer les statistiques JMX. JConsole est néanmoins conçu en premier lieu pour cela.
// -----------
//  - Connectez-vous à JConsole et inspectez une application :
//      - Étape 1 : Démarrez une application
//          Vous pouvez généralement trouver JConsole en affichant votre variable d’environnement 'JAVA_HOME' et en regardant dans le dossier bin qui s’y trouve.
//          Cela varie en fonction des distributions. Essayez de regarder aux emplacements suivants :
//              --> Sur un Mac avec OS-X, vous trouverez votre distribution Java sous '/Library/Java/JavaVirtualMachines'.
//              --> Sous Windows, vous trouverez généralement vos installations Java sous 'c:\Program Files\Java'.
//              --> Avec les distributions Debian Linux, vous verrez que votre dpkg a installé JDK sous '/usr/lib/jvm'.
// Regardez sous le répertoire bin de votre installation JDK pour trouver la binaire d’application JConsole.
// Le calculateur de taille de selle de dragon fonctionne avec JDK 8.
// Essayez d’exécuter JConsole et de le faire se connecter à lui-même. Explorez un peu après qu’il se soit connecté.
// Comme avec VisualVM, c’est amusant de connecter JConsole à lui-même, mais l’outil brille vraiment lorsque vous pouvez commencer à l’utiliser pour inspecter votre application.
// Nous allons exécuter une version de notre calculateur de taille de selle de dragon, qui donne un rapport sur la taille de selle estimée pour cette année, pour un dragon né en l’an 1 après J.-C..
// Comme vous allez beaucoup travailler sur Spring Boot en tant que développeur Java, je vous ai fait une application qui fonctionne comme une application web Spring Boot.
// Bien que JConsole puisse être utilisé avec de nombreux outils Java, le fait de travailler dessus avec Spring Boot vous donnera un peu d’entraînement réaliste.
// Spring Boot est un framework Java utilisé par des personnes à travers le monde pour construire des applications d’entreprise.
// Spring Boot construit en particulier des applications qui comportent une interface web.
//      --> Il peut être utilisé pour construire toutes sortes d’applications et faciliter leur configuration, tout en renforçant les bonnes pratiques d’ingénierie.
// Regardons la branche avec notre application web et démarrons-la !
// Revenez au calculateur de taille de selle de dragons, et consultez la branche 'spring-application-with-actuator', dans IntelliJ : 'git checkout spring-application-with-actuator'.
// Comme vous l’avez vu :
//      --> Nous avons “check out” la branche, puis utilisé le menu Gradle pour démarrer l’application en cliquant sur bootRun.
//      --> Nous avons ensuite pu aller à  http://localhost:9999/dragon/size dans notre navigateur web pour obtenir une estimation pour l’année en cours.
// Si vous avez des difficultés à démarrer l’application, éditez le fichier 'src/main/resources/application.properties', et changez la valeur en 'server.port=9999'.
// Par exemple, la changer en 'server.port=8080' signifierait que vous visiteriez l’URL 'http://localhost:8080/dragon/size' à la place.
//      --> Qu’est-ce que cette version de l’application a de particulier ?
// Dans cette branche, votre application de calculateur de taille de selle de dragon a été convertie en une simple application web.
// Vous pouvez donc aller à une URL dans un navigateur et obtenir une estimation de taille de selle.
// Le projet n’est pas seulement une application Spring, mais il a aussi une dépendance ajoutée de 'org.springframework.boot:spring-boot-starter-actuator'.
// Cette dépendance, est connue sous le nom de Spring Actuator, dans son fichier 'build.gradle'.
//      --> L’inclusion de cette dépendance dans un projet Spring introduit des rapports sur votre application web. C’est ce que nous allons regarder avec JConsole.
// -----------
//  - Étape 2 : Utilisez JConsole pour inspecter les métriques de votre application :
// Pour consulter les métriques d’une application, démarrez JConsole et sélectionnez Connexion et New Connection (nouvelle connexion).
// Cela vous montre une liste de process Java auxquels vous pouvez vous connecter. Trouvons la 'DragonSaddleSizeGuesserApp', connectons-nous à elle, et examinons l’écran qui nous est présenté :
//      --> En haut, les programmes Java exécutés sur votre PC. Parmi eux se trouve notre application.
//      --> En bas, les informations à compléter pour connecter le programme Java sur un autre ordinateur.
// Détaillons cela :
//      - La section 'Local Processes' montre tous les process Java exécutés sur le PC où vous avez démarré JConsole.
//      - Après le démarrage de notre application, vous verrez notre 'DragonSaddleSizeGuesserApp' sous 'Local Processes', le nom de la classe principale de notre application.
//          --> Puis, double-cliquez dessus pour vous connecter.
//      - En bas, sous Remote Process, vous pouvez vous connecter à la partie JMX de tout programme Java sur tout ordinateur que vous pouvez atteindre par un réseau sans firewalls en travers du chemin.
//          --> Vous pouvez en apprendre plus à ce sujet ici.
// Utilisons ceci pour nous connecter à notre calculateur de taille de selle de dragon et voir certaines des métriques et données de référence que cela dévoile.
//      --> Le plus intéressant lorsque nous utilisons JConsole est l’onglet 'MBeans'.
// C’est là où les classes Java publient les métriques qui vous donnent des informations sur ce qu’il se passe dans la JVM.
// Les MBeans sont des classes Java spéciales qui respectent le standard JMX et permettent aux applications de dévoiler des attributs et opérations aux outils comme JConsole.
// Même si nous allons les regarder, l’écriture de MBeans est en-dehors du périmètre de ce cours.
// Néanmoins, vous pouvez en apprendre plus à leur sujet dans le cours Create Web Applications Efficiently with the Spring Boot MVC Framework, ainsi que dans la documentation officielle ici.
// Comme vous l’avez vu, il existe de nombreuses métriques différentes mises à disposition par Spring Actuator, ainsi qu’une myriade d’autres bibliothèques dont votre application dépend.
// Elles sont groupées par clés significatives nommées ObjectNames.
// Voyons ce que JConsole vous montre sous MBeans. En haut, les dossiers jaunes correspondent aux JMX Domains. Chaque type a un nom. En cliquant sur un type, on voit les attributs et les valeurs.
// Comme vous pouvez le voir, le formulaire ObjectName est structuré en dossiers dans lesquels vous pouvez naviguer.
// Explorons-les :
//      - Les dossiers jaunes constituent la partie Domaine de l’ObjectName et vous aident à regrouper différents attributs.
//          Comme vous pouvez le voir, Java publie une quantité d’attributs utiles sous le domaine java.lang.
//      - Les clés spéciales regroupent les attributs et les opérations sous un type plus spécifique. Ce type décrit leur nature plus clairement que le domaine.
//          Par exemple, tous les détails récupérés directement depuis le système d’opération Windows ou OS-X sur lequel votre JVM fonctionne sont regroupés sous le type OperatingSystem.
//      - Si vous regardez les détails du type, vous verrez Attributs et Opérations. Sous Attributs, vous pouvez voir les noms des attributs sur lesquels votre application fait ses rapports.
//          Ils sont aussi connus sous le nom de clés. Par exemple, FreePhysicalMemorySize, que vous pouvez voir ci-dessus, est la clé qui décrit combien de mémoire libre il reste sur votre ordinateur.
//      - À droite de vos attributs, vous pouvez voir des paires de clés avec leurs dernières valeurs rapportées. Dans la plupart des cas, elles seront proches de la valeur actuelle.
// Il y a de nombreux ObjectNames, attributs, et opérations dévoilés par une application typique.
// Ceux que je vous ai montrés dans la démonstration constituent un bon début, car ils vous donnent une idée de la manière dont votre application fonctionne, mais il ne s’agit que d’une vue en surface.
// Si vous voulez simplement connaître le niveau de performance de votre application Spring, vous pouvez vous concentrer sur la branche étiquetée 'org.springframework.boot/Endpoint'.
// Cette branche a été donnée par Spring Boot Actuator. Toutes les opérations et tous les attributs sous cette branche sont pensés pour vous donner davantage de visibilité sur une application Spring.
// Le fait de regarder l’endpoint health (santé) devrait vous montrer que votre application a démarré correctement.
// Comme vous l’avez vu, la définition de la propriété a montré que le code correspondait à une version plus ancienne et devait être mis à niveau.
// Dans une situation plus complexe, vous devrez peut-être creuser plus profondément et jouer à nouveau les Sherlock, en utilisant les indices dans votre application.
// Comme par exemple les logs (vous en apprendrez plus à leur sujet dans un chapitre suivant).
// Un autre outil utile pour surveiller les métriques de santé dans les applications Spring Boot est Spring Boot Actuator.
// Apprenez-en plus à ce sujet dans le cours Create Web Applications Efficiently with the Spring Boot MVC Framework.
// -----------
//  - En résumé :
//          --> Java Management Extensions, ou JMX, fournit un protocole que les outils peuvent utiliser pour surveiller et gérer vos applications Java.
//          --> Les MBeans sont des classes spéciales que les applications peuvent fournir pour faire des rapports sur elles-mêmes et permettre le déroulement d’opérations de management spéciales.
//          --> Les attributs sont constitués par une valeur, et une clé qui décrit cette valeur. Les MBeans utilisent les attributs pour effectuer des rapports sur des aspects de votre application.
//          --> Les opérations sont des actions spéciales que vous pouvez effectuer en utilisant les MBeans. Un exemple de ceci pourrait être de changer un niveau de log, ou de vider un cache.
//          --> JConsole est un outil fourni avec le JDK et il est conçu pour vous aider à interagir avec les MBeans sur un process Java local ou à distance.
//          --> Spring Actuator est une bibliothèque qui permet aux applications Spring de gérer les MBeans à travers l’application elle-même sans avoir besoin d’autres outils.
// Dans le chapitre suivant, nous allons nous intéresser à un autre outil puissant : le logging, ou la log !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Faites des rapports avec un logger, des niveaux de log, et l’API SLF4J standard ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Loggez au lieu d’afficher :
// Les éléments que vous soumettez à 'System.out.println' sont visibles à la personne ou au script qui a démarré votre programme, et envoyés à la console qui l’exécute.
// En général, il est souhaitable que toute information venant de l’application en exécution concerne le but de l’application, et son succès ou son échec global.
// Elle devrait être significative pour les personnes exécutant cette application ou suivant ses informations sortantes.
// Si un membre de mon équipe commence à utiliser 'System.out.println()' pour afficher des détails techniques et ésotériques concernant une classe profondément enfouie dans le code.
// Je me retrouve soudainement avec un développeur bruyant qui crie depuis mon application, et je n’ai aucune idée d’où ça vient.
//      --> 'System.out.println()' fait une chose. Il affiche la valeur que vous lui donnez sur la console.
// Il ne me dit pas d’où la valeur a été affichée ni quand elle a été affichée. Il se contente de l’afficher.
// Si vous voulez que votre programme affiche des informations sortantes significatives, n’encombrez pas sa console avec quoi que ce soit de plus que ce vous devez communiquer.
// Par exemple, notre calculateur de taille de selle de dragon original avait uniquement besoin de communiquer l’estimation qu’il avait calculée.
// C’est une bonne chose que nous l’ayons débuggé et que nous ne l’ayons pas encombré de déclarations print.
//      --> Pourquoi est-ce qu’on afficherait des éléments depuis son code ?
// Pour débugger, voilà pourquoi ! Vous avez vu comment utiliser le débugger précédemment dans ce cours.
// Cela implique d’exécuter une version de votre application et de contrôler son flux avec un outil de débug.
// De nombreux développeurs semblent modifier leur code avec des déclarations 'System.out.println()' qui montrent des variables et signalent ce que fait l’application avec des lignes de texte arbitraires.
// C’est quelque chose que l’on fait en grimaçant, car on sait que l’on risque de laisser une nuisance sonore dans le code tout en répondant à la dernière urgence.
// Si vous avez fait cela dans le seul espoir de trouver et réparer un problème sérieux grâce à la chance magique de l’univers, s’il vous plaît, prenez le temps d’utiliser un débugger.
//      --> Je ne devrais jamais débugger en affichant ce que fait mon code ?
// Même si 'System.out.println()' est rarement fructueux, il est incroyablement utile de pouvoir voir ce que faisait votre application lorsqu’un bug est survenu en production.
// Une telle information peut fournir des indices pour aider à formuler des théories, à travers une meilleure compréhension de ce qu’il se passait à l’intérieur de l’application lorsqu’elle a échoué.
// Par exemple, le fait de voir une erreur d’espace disque affichée par votre application avant une 'IOException' pourrait vous donner un indice sur l’existence d’un problème d’espace à ce moment-là.
// Le problème des déclarations 'System.out.println()' est qu’elles peuvent souvent être oubliées dans le code.
// Si vous les y laissez, vous devrez supporter les cris d’une classe précieuse et bien cachée pour l’éternité. Ou au moins jusqu’à ce que vous la bâillonniez avec un logger.
//      --> Qu’est-ce qu’un logger ?
// Les loggers sont des bibliothèques qui vous permettent de créer de façon sécurisée un rapport d’exécution, soit un log ou journal, de ce que fait votre application directement depuis votre code.
// Comme avec les déclarations print, vous pouvez tout logger, et l’usage de phrases bien formulées est encouragé pour vous assurer de la lisibilité de vos lignes de log.
// Contrairement aux déclarations print, les lignes de log sont affichées avec les détails :
//      --> Quand elles ont été affichées.
//      --> Quel est leur emplacement dans le code.
//      --> Et les détails du process et de l’ensemble de threads qui les affiche.
//              --> Cela peut vous aider à déterminer quels autres éléments sont allés de travers au même moment, et même au sein du même thread.
// De plus, vous pouvez faire taire ou réactiver les lignes de log avec la configuration.
// Un logger fournit des méthodes de log qui affichent le texte fourni et l’associent à un niveau d’importance, soit un niveau de log.
//      --> Comment savoir si je dois enquêter sur mon code avec JConsole, VisualVM, ou des déclarations de log ?
// Voici des règles de base rapides pour comprendre les différences :
//      - JConsole et JMX excellent dans les rapports sur les métriques au moment présent.
//          Que se passe-t-il là tout de suite ?! Il y a des attributs auxquels vous avez pensé au début, qui changent en continu.
//          Utilisez-les pour inspecter des métriques de santé choisies, telles que le nombre d’erreurs par minute.
//          Elles peuvent vous aider à établir un diagnostic sur la façon dont votre application accomplit ses tâches.
//                  --> Vous pouvez choisir de stocker également certaines de ces métriques pour obtenir une vision plus approfondie au fil du temps.
//      - VisualVM est également excellent pour observer ce qu’il se passe en ce moment.
//          Il vous permet de voir des métriques sur la qualité de la performance et de l’utilisation de la mémoire en temps réel.
//                  --> Vous pouvez l’utiliser pour profiler la vitesse de votre code. Comme il peut ralentir votre application, évitez de l’utiliser en production.
//      - Les logs, comme les déclarations print, sont des éléments qui nous persistons généralement, ou que nous sauvegardons dans un fichier ou dans un agrégateur de logs.
//          Ils vous permettent de faire des rapports et d’inspecter ce que fait votre application au moment présent, ainsi que de revoir ce qu’elle a fait précédemment.
//                  --> Cela peut être utile lorsque vous enquêtez sur un problème persistant.
// Les logs peuvent être aussi bavards et cohérents que vous le souhaitez, en utilisant un langage clair.
// Ils peuvent également être structurés et concis si cela vous en facilite l’utilisation.
// Fondamentalement, ils vous permettent de capturer toute sorte d’information que vous estimez à même de vous éclairer sur votre application.
// Les logs peuvent même vous aider à déterminer de nouvelles métriques dont vous devriez vous saisir.
// Si vous vous retrouvez à logger un élément qui est effectivement une métrique, alors capturez-la comme telle.
// En pratique, vous vous retrouverez à logger davantage qu’à publier de nouvelles métriques.
// Vous devriez toujours ajouter de la log utile à votre application, là où vous pensez qu’elle peut vous aider à comprendre le flux d’exécution et à diagnostiquer un problème plus rapidement.
// Par exemple, la log d’un call stack pour toutes les 'RuntimeExceptions' non vérifiées vous donnera un endroit où regarder immédiatement si votre application ne se prémunit pas de cela !
//      --> Alors, comment je logge ?
// Il existe de nombreux loggers en Java, et il n’y a pas un bon logger à utiliser. Le JDK comprend le 'java.util.logging' (ou JUL).
// Il possède ses propres niveaux de log. D’autres frameworks de log extrêmement populaires incluent Logback et Log4j2 (notez le 2 à la fin).
// Heureusement, la plupart des projets utilisent SLF4J, la Simple Log Facade for Java, une API courante qui vous permet d’utiliser tous les frameworks ci-dessus, mais avec l’API standard de SLF4J.
//      --> C’est-à-dire que vous utilisez ses méthodes et classes d’une seule façon standard. Elle gère l’appel des méthodes de tout framework que vous avez déjà ajouté à votre projet.
//      --> Comment puis-je utiliser SLF4J et une API de log ?
// Mettons en place notre application de calculateur de taille de selle de dragon originale pour utiliser l’API de log de SLF4J devant Logback.
// Tout d’abord, nous devons ajouter les dépendances à la section dépendance de notre fichier build Gradle :
//                  implementation("org.slf4j:slf4j-api:1.7.26'").
//                  implementation("ch.qos.logback:logback-core:1.2.3").
// Cela ajoute l’API SLF4J et en deuxième l’implémentation 'logback-core'.
// Si vous vouliez utiliser le framework 'java.util.logging' du JDK, utilisez 'slf4j-jdk14' à la place de 'logback-core'.
// Pour log4j2, utilisez la liaison 'log4j2 slf4j' à la place de 'logback-core'.
// Nous pouvons alors ajouter une ligne de log à notre 'DragonSaddleSizeEstimator' en ajoutant les imports de SLFJ, en créant une instance de logger, et en utilisant ce logger pour journaliser.
//                  package com.openclassrooms.debugging.service;
//                  import org.slf4j.Logger;
//                  import org.slf4j.LoggerFactory;
//                  ...
//                  @Service
//                  public class DragonSaddleSizeEstimator {
//                      private static Logger logger = LoggerFactory.getLogger(DragonSaddleSizeEstimator.class);
//                      ...
//                      public Double estimateSaddleSizeInCentiMeters(int targetYear) throws Exception {
//                          logger.info("Estimation d’une taille de selle pour {}", targetYear)
//                          double saddleSizeInCm = calculateSaddleSizeFromYear(targetYear);
//                          // Verify that we have a valid saddle size
//                          verifier.verify(saddleSizeInCm);
//                          return saddleSizeInCm;
//                      }
//                      ...
//                  }
// Détaillons ceci :
//      - Ligne 4 : Nous importons la classe Logger de SLFJ, que nous utiliserons pour logger.
//      - Ligne 5 : Nous importons la classe LoggerFactory de SLFJ, que nous utiliserons pour créer notre logger.
//      - Ligne 10 : Nous créons une instance de Logger en appelant la méthode getLogger(Class clazz) de LoggerFactory.
//      - Ligne 13 : À chaque fois que du code appelle estimateSaddleSizeInCentiMeters(int targetYear), il faut logger l’expression "Estimation d’une taille de selle pour <la valeur de l’année cible>".
//          Et cela, au niveau info. Les méthodes de log remplacent chaque "{}" par les arguments respectifs passés à la méthode de log. Par conséquent, targetYear est évalué et s’y substitue.
// Alors, à quoi cela ressemble-t-il dans nos logs ?
//                  2020-05-18 15:24:24.121 DEBUG 2876 --- [nio-9999-exec-1] c.o.d.service.DragonSaddleSizeEstimator  : Estimation d’une taille de selle pour 2020.
// Notez la façon dont notre logger fait précéder "Estimation d’une taille de selle pour 2020" par :
//      - Le moment où cela a été loggé : 2020-05-18 15:24:24.121.
//      - Le niveau de log : INFO.
//      - L’ID du process du système d’opération : 2876.
//      - L’information du thread : [nio-9999-exec-1].
//      - La classe qui a loggé cette ligne : c.o.d.service.DragonSaddleSizeEstimator.
//      - Le message : Estimation d’une taille de selle pour 2020.
// Nous avons loggé notre message au niveau INFO, car il ne rentre pas trop dans les détails et nous donne l’essentiel de ce que fait l’application.
// Nous avons fait cela en appelant la méthode 'info(message)' sur notre logger.
//      --> Comment est-ce que je saurai quels niveaux de log utiliser ?
// Voyons leurs caractéristiques comparatives, en ordre d’importance :
//      - Error : 'logger.error(message)' – Les erreurs sont les entrées de log les plus importantes. Si vous devez être au courant de quelque chose, ce sont des lignes de log signalées comme erreurs.
//          Il s’agit en général du niveau le moins bavard et il est réservé aux ennuis.
//      - Warn : 'logger.warn(message)' – Ces lignes que vous avez définies comme avertissements sont les deuxièmes en ordre d’importance.
//          Si vous avez demandé à votre code de vous avertir de quelque chose, il devrait le faire.
//          Ceci peut être un peu plus bavard que les erreurs, mais si vous avertissez trop, ce sera comme dans le garçon qui criait au loup, plus personne n’y prêtera attention !
//      - Info : 'logger.info(message)' – Les lignes de log que vous avez définies pour des buts d’information, ou info, sont les suivantes.
//          Vous trouverez peut-être intéressant que votre application vous dise ce qu’elle fait sans entrer trop dans les détails.
//          Vous pouvez fournir des informations utiles ici, mais évitez de devenir trop bavard, ou votre information se transformera en nuisance sonore.
//          Au minimum, ceci pourrait être une ligne qui vous dit qu’elle traite simplement des informations.
//      - Débug : 'logger.debug(message)' – Ce sont des lignes de log assez bavardes, qui vous aident à débugger en informant sur les méthodes et en faisant des rapports sur la valeur des variables.
//          Si vous avez confiance en votre application, elles sont en général uniquement importantes lors de la recherche d’informations de diagnostic utiles.
//          Il est souhaitable qu’elles soient désactivées la plupart du temps, car elles équivalent aux piaillements bavards les plus utiles des déclarations print.
//      - Trace : 'logger.trace(message)' –  Ce sont nos logs les plus bavards. Utilisez Trace lorsque vous ressentez une envie désespérée d’ajouter des déclarations print entre chaque ligne de code.
//          Ou encore d’afficher à peu près toutes les variables jamais vues.
//          Ceci correspond à se tenir debout dans une bibliothèque et à exprimer à voix haute chaque pensée qui vous vient à l’esprit comme si vous chantiez un opéra !
//          Contrairement aux déclarations print, vous pouvez désactiver et réactiver les traces quand vous en avez besoin.
//          Ce sont de grandes bavardes qui ne s’arrêtent jamais de parler ; vous les garderez donc silencieuses la plupart du temps.
//          Ne les ajoutez à des emplacements de votre code que lorsque c’est nécessaire.
//          Par exemple, un incident en production où personne n’a aucun indice après des heures de prise de tête.
//          Une telle situation pourrait justifier la sortie d’une version de votre code pleine de logs Trace.
// Les loggers produisent différents niveaux sonores. En fonction de votre besoin, vous pouvez modifier les niveaux de log auxquels votre application fait ses rapports.
// Par exemple, vous montez le son et observez les messages de log de niveau débug durant une investigation sur la production.
// Comment je monte le son de mon log, exactement ?
// Une fois que vous avez de nombreuses déclarations de log dans votre code, vous pouvez ajuster celles qui sont signalées en définissant des niveaux de log pour les rapports.
// Ils peuvent avoir une granularité large, pour l’application entière, ou une granularité fine, pour les lignes de log par classes individuelles ou paquets spécifiques.
// SLF4J n’est pas un logger en lui-même, mais plutôt une interface de programmation pour d’autres frameworks de log.
// Vous devez utiliser le contrôle du volume du framework de log sous-jacent que vous avez choisi, sous la forme de la configuration appropriée pour votre framework favori.
// Nous avions configuré un niveau de log pour la version Spring Boot de notre 'DragonSaddleSizeApp', nous pouvons ajuster les niveaux de log dans un projet Spring Boot.
// Ceci, simplement en définissant des propriétés Java précédées de 'logging.level'.
// L’un des emplacements par défaut où Spring boot recherche des propriétés se trouve dans 'src/main/resources/application.properties'.
// Jetons un coup d’œil aux parties significatives de notre fichier :
//                  logging.level.root=ERROR
//                  logging.level.org.springframework.web=INFO
//                  logging.level.com.openclassrooms.debugging=TRACE
// Parcourons ceci :
//      - Ligne 1 : Le logger root, ou racine, représente notre logger par défaut à travers l’application. Cette ligne fera taire toute log dans l’application, hormis les appels à 'Logger::error'.
//      - Ligne 2 : Ceci configure la log pour toute classe sous le paquet 'org.springframework.web', et permet tous les appels à 'Logger::info', 'Logger::warn', et 'Logger::error'.
//      - Ligne 3 : Ceci configure la log pour toute classe sous le paquet 'com.openclassrooms.debugging', de façon à ce que notre logger trace tous les appels à toutes les méthodes de log.
//          Y compris 'Logger::trace' et 'Logger::debug'.
// Essayez par vous-même !
// Revenez au calculateur de taille de selle de dragon et consultez la branche 'java-logging-api' : 'git checkout java-logging-api'.
// L’ajout de déclarations de log à votre code est parfois appelé l’instrumentation de votre code.
// C’est parce que, à chaque ligne de log, vous ajoutez un nouvel instrument pour observer ce que fait votre code, comme si vous fixiez un baromètre à côté de votre méthode.
// Nous avons utilisé des lignes de log à différents niveaux pour instrumenter notre code avec des degrés variés d’information ?
// Nous avons également défini les propriétés d’un 'logger root', ou logger racine, pour définir un niveau de log minimal pour notre application.
// Maintenant que notre code a été instrumenté, je pense qu’il est temps de voir comment il se comporte lorsque nous montons et baissons le son !
// Comme vous l’avez vu, il était facile d’augmenter notre log pour obtenir des informations plus profondes sur notre code.
// Nous pourrions même cibler nos contrôles du volume sur un ensemble de loggers plus spécifique. Par exemple, en spécifiant 'logging.level.com.openclassrooms.debugging.service=TRACE'.
// Nous avons pu forcer les classes sous ce paquet à logger au niveau trace !
// En augmentant notre log jusqu’à trace, nous avons graduellement obtenu des informations plus profondes sur ce que faisait notre application.
//      --> Pourquoi est-ce que je ne peux pas toujours garder ma log réglée au niveau trace ?
// Vous pouvez conserver votre log au niveau trace, mais il y a plusieurs conséquences.
//      - Premièrement, cela ne vaut pas mieux que les déclarations print.
//      - Deuxièmement, il vous faut sauvegarder vos logs régulièrement pour que vous puissiez les voir une fois que vos programmes ont terminé.
//          Cela signifie qu’il faudra un jour les écrire sur disque.
//          Les frameworks de log utilisent des appenders, pour envoyer les logs à des disques ou à d’autres systèmes, qui peuvent à leur tour écrire sur disque.
//          L’écriture sur disque est lente, et même s’il existe des moyens de contournement, il ne faut pas que la log devienne la raison pour laquelle votre application ralentit.
//              --> Le plus important, c’est que plus votre application produit du bruit inutile, plus il devient difficile de repérer des problèmes réels.
// -----------
//  - Changez les niveaux de log sans redémarrer votre application :
// Repensons à l’application web Calculateur de taille de selles de dragons du dernier chapitre.
// Imaginez que des milliers d’utilisateurs se rendent sur votre application chaque minute et que vous vouliez que votre application vous dise ce qu’elle fait.
// Mais que faire si vous avez subitement besoin de commencer à journaliser au niveau erreur, alors que votre application a été démarrée au niveau info ?
// Normalement, faire en sorte que ces lignes s’affichent lorsque vous en avez besoin nécessiterait de reconstruire votre application et de la redémarrer.
// Cela devient plus difficile si elle est déjà déployée dans un environnement de production, car vous devriez suivre votre process de mise à jour de l’application.
// La classe 'DragonSaddleSizeController' exécute la méthode 'Double handleSaddleSizeRequest(Integer targetYear)' dès que votre navigateur web requête une nouvelle estimation de taille de selle.
// Cette méthode est toute prête à effectuer quelques rapports. Observons-la :
//                  package com.openclassrooms.debugging.controller;
//                  public class DragonSaddleSizeController {
//                      // Setup a logger
//                      private Logger logger = LoggerFactory.getLogger(DragonSaddleSizeController.class);
//                      ...
//                      /**
//                      * Called by methods which respond to web requests
//                      **/
//                      private Double handleSaddleSizeRequest(Integer targetYear) throws Exception {
//                          // Calculate the estimate
//                          Double saddleSizeEstimate = dragonSaddleSizeEstimator.estimateSaddleSizeInCentiMeters(targetYear);
//                          String response = saddleSizeReporter.report(targetYear, saddleSizeEstimate);
//                          // log it
//                          logger.info("Taille de selle calculée:" + response);
//                          return saddleSizeEstimate;
//                      }
//                  }
// Que se passe-t-il ici ?
//      - Ligne 5 : Nous avons défini un objet spécial nommé logger, qui nous permet de créer un rapport mis à jour en continu, ou un log, sur ce que fait notre application.
//      - Ligne 18 : Nous appelons 'logger.info()' et lui passons une ligne de texte à signaler dans nos logs.
//          Cette méthode sera appelée par toutes les méthodes de notre code qui reçoivent une requête pour calculer une estimation.
// Cela signifie que, dès que vous rafraîchissez votre navigateur, vous devriez voir une nouvelle ligne dans votre log, qui affiche le message "Taille de selle calculée".
// Malheureusement, l’application possède un fichier de propriétés avec des paramètres qui empêchent cette ligne de log d’être affichée.
// Notre fichier sous 'src/main/resources/application.properties' contient le paramètre :
//                  logging.level.com.openclassrooms.debugging=ERROR
// Pour que notre application trace cette ligne de log, nous devrions changer cette valeur de 'ERROR' à 'INFO' pour correspondre au '.info()' de notre ligne 18.
// Néanmoins, des changements sur nos fichiers pourraient nécessiter que nous fassions des modifications, reconstruisions notre application, et ensuite que nous la redémarrions.
// Si vous cherchiez des solutions à un problème en production, imaginez la quantité de travail supplémentaire que cela représenterait.
// Par exemple si vous deviez également la retester et la sortir dans un environnement de production !
// Heureusement, vous pouvez utiliser JConsole (ou un autre client JMX) pour changer le niveau de log pendant que l’application est toujours en exécution.
// Comme vous le verrez, l’un des MBeans du projet Spring fournit une opération que vous pouvez effectuer pour changer le niveau de log.
// C’est utile lorsque vous débuggez un problème en production, car cela vous permet de commencer à recueillir des informations plus détaillées sur ce que fait votre application.
// Comme vous l’avez vu, nous pouvons cibler une partie de la configuration de notre application et la modifier.
// Dans ce cas, nous avons changé le niveau de log sans redémarrer notre application.
// Cela peut être pratique si vous enquêtez sur un problème en production et avez besoin d’observer quelque chose pendant qu’elle se produit, pour mieux la comprendre.
//      --> Qu’est-il arrivé à l’idée de recréer le problème localement pour que je puisse le débugger ?
// Absolument, faites-le, s’il vous plaît. Pour reproduire un problème en production, vous voudrez probablement comprendre comment définir un scénario similaire.
//      --> L’utilisation de JConsole peut vous aider. Elle vous permet aussi d’observer un problème plus difficile à reproduire, qui ne survient qu’en production.
// Vous n’avez peut-être pas réussi à recréer ce problème localement, comme nous l’avons fait en partie 2.
// La recherche de la cause des défauts et des pannes représente le moment où les ingénieurs logiciel ressemblent le plus à des détectives.
// Les logs et le JMX sont simplement d’autres outils dans votre boîte à outils d’enquêteur.
// Il y aura toujours des problèmes, et plus vous disposez de moyens de les inspecter, plus vos chances de rassembler toutes les pièces et de trouver le coupable sont grandes !
// Comme vous l’avez vu, la définition de la propriété nous a indiqué que c’était une version ancienne du code, et que nous devions la mettre à niveau.
// Dans une situation plus complexe, vous devrez peut-être creuser plus profondément.
//      --> Et cela en utilisant les indices dans votre application, qui n’apparaissent que lorsque vous réglez le niveau de log à débug.
// -----------
//  - En résumé :
//          --> Les résultats de votre programme ne doivent pas contenir de nuisances sonores de débug techniques, qui ont peu de sens pour les personnes responsables de l’exécution de votre programme.
//          --> Un framework de log vous permet de créer un rapport continu, ou un log, dans lequel vos classes peuvent s’afficher.
//          --> Java possède plusieurs frameworks de log, mais SLF4J fournit une API unique pour logger vers tous les frameworks principaux.
//                  Son utilisation facilite le changement pour adopter des frameworks de log plus nouveaux ou plus puissants sans changer votre code.
//          --> Les frameworks de log utilisent des niveaux de log pour mettre en lumière et filtrer les événements de log selon leur importance.
//                  Les niveaux de log de SLF4J sont, en ordre d’importance :
//                      - 'error'.
//                      - 'warn'.
//                      - 'info'.
//                      - 'debug'.
//                      - 'trace'.
//          --> Pour réduire le bruit provenant de votre application, essayez d’utiliser des niveaux de log prudents comme 'error' et 'warn'.
// Félicitations ! Vous êtes parvenu à la fin de ce cours. Vous disposez maintenant de toutes les connaissances nécessaires pour :
//      --> Identifier des méthodologies, des outils, et le vocabulaire clés du débug.
//      --> Enquêter sur un bug avec un débugger Java.
//      --> Réparer des bugs avec VisualVM, JConsole, et des techniques de log.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Neuvième partie : Maitrisez Java //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Cette partie du parcours va vous permettre de maitriser Java dans son ensemble :
// - Le web avec Java EE :
//      Servlets, JSPs, JSTL, application web, BDD.
// - Architecture SOA :
//      Architecture orientée Services : SOAP, WSDL et REST.
// - MVC avancé :
//      - Analyser l’architecture d’une application existante.
//      - Séparer les couches d’application avec le Modèle-Vue-Contrôleur et la refactorisation.
//      - Implémenter la communication entre les couches d’application.
// - Microservices :
//      - Faire communiquer les Microservices entre eux de façon simple et automatisée.
//      - Externaliser les fichiers de configuration.
//      - Rendre votre application scalable.
//      - Sécuriser votre application.
//      - Mettre en place des outils de debuggage et de maintenance (Spring).
// Avertissement : un prérequis de connaissances de la stack Spring est préférable pour compléter cette partie du parcours.
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Développez des sites web avec Java EE /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous êtes étudiant de l’enseignement supérieur dans un cursus scientifique (ingénieur, université)... ?
// Vous souhaitez débuter ou approfondir vos connaissances en Java EE ?
// Vous développez peut-être déjà et vous avez simplement besoin d’une remise à niveau sur cette technologie ?
// Qu’est-ce que Java EE ? Comment installer un environnement de développement ?
// Quelles sont les bonnes pratiques dans l’industrie ? Comment créer des Servlets, des JSPs, travailler avec la JSTL et les bases de données grâce à JDBC et DAO ?
// Ici, vous serez en mesure d’évoluer au sein d’une application Java EE et de développer des fonctionnalités efficacement sur toutes les couches applicatives : modèle, vue et contrôleur.
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Premiers pas avec Java EE /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'est-ce que Java EE ? ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisant le langage Java, Java EE ajoute un ensemble de bibliothèques, ajoutant des fonctionnalités à Java.
// Java EE permet de construire des applications web solides, fiables et bien structurées.
// Java EE est conçu comme une plate-forme de développement d'applications web et nous pouvons le comparer à php, django pour Python, ASP.NET de Microsoft, ou encore à Ruby on Rails.
// Que se passe t-il concrêtement lorsque nous allons visiter un site web codé en Java EE ?
// Le visiteur, donc le 'client' va demander un page web au 'serveur' qui possède normalement la page web.
// Ce serveur possède le code en langage Java, et il génère une page web HTML qu'il retourne au client.
// En rentrant un peu plus dans le détail :
//      - Le client va entrer une url dans son navigateur.
//      - Le navigateur va envoyer une requête HTTP au serveur.
//      - Le serveur va transformer cette requête et générer une page HTML.
//      - Il va retourner une réponse HTTP.
// Que se passe t'il si nous regardons un petit peu plus en détail :
//      - Le client va envoyer une requête HTTP vers le serveur d'application.
//      - Ce serveur d'application est découpé en deux parties :
//          --> Le 'Serveur HTTP' qui reçoit la requête HTTP, la lis, la découpe et l'analyse, pour l'envoyer ensuite au 'Conteneur.'
//          --> Le rôle du Conteneur, lui est d'exécuter notre code Java EE. C'est donc ici que Java EE, vis et exécute la page.
//                  --> Il existe plusieurs modèles de cet ensemble. Nous allons utiliser Apache Tomcat, logiciel open-source et gratuit.
//      - Notre serveur d'application, donc Tomcat, va ensuite envoyer sa réponse HTTP au client.
//
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Le modèle MVC /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java EE n'impose aucun rangement particulier de notre code.
// Pour éviter d'avoir un code non-rangé et mal organisé, nous pouvons utiliser le Design Pattern MVC, Modèle Vue Contrôleur.
// Ceci réorganise notre modèle vu précémment de la manière suivante :
//      - Le client transmet une requête HTTP au serveur d'application.
//      - Celui-ci transmet la requête HTTP au contrôleur, qui a un rôle d'aiguilleur, ou de chef d'orchestre.
//      - En général, le contrôleur va appeler le modèle qui contient les informations structurées de nos données.
//      - Ce modèle peut renvoyer des informations au contrôleur.
//      - Le contrôleur va ensuite générer une page web, donc une vue qui est renvoyée au client.
// Avec Java EE, chacun de ces éléments à un nom :
//      --> Le contrôleur est appelé la 'Servlet'.
//      --> Le modèle est géré en général par des objets Java, donc des Java Beans.
//              Le modèle peut aussi être en contact avec une base de données, pour stocker les informations, donc les persister.
//      --> La vue est gérée par des pages .jsp, qui vont utiliser du code HTML et du code spécifique en Java.
// Pour nous aider à dévellopper avec MVC, il existe de nombreux frameworks Java EE. Ce sont des ensembles de bibliothèques, qui sont déjà structurées en MVC :
//      - JSF : JavaServer Faces.
//      - Struts.
//      - Spring.
//      - Hibernate.
// Dans ce cours, nous allons utiliser uniquement Java EE.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Installer un environnement de développement ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons installer Eclipse et Apache Tomcat.
//  - Eclipse : Une fois Eclipse EE installé, nous pouvons ajuster quelques configurations :
//          --> Window > Preferences > Search : 'encoding' > S'assurer que pour CSS, HTML, JSP et XML, l'encodage soit en UTF-8.
//  - Tomcat : Télécharger le .zip de la dernière version stable de Tomcat et la dézipper dans le dossier souhaité.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer une première application Java EE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons à présent créer notre première application Java EE en utilisant Eclipse et Tomcat.
//      - Dans Eclipse, nous allons créer un nouveau projet : File > New > Dynamic Web Project.
//          Name : 'test', Target Runtime > New Server Runtime Environment > Sélectionner Apache Tomcat et cocher 'Create a new local server.' > Next.
//          Name : 'ce que l'on veux', Dossier d'installation de Tomcat à préciser, ainsi que dossier du JRE > Finish > Finsih --> Notre application est créée.
//      - Dans Eclipse, pour les applications Java EE, nous avons un dossier WebContent > WEB-INF.
//          WebContent est créé automatiquement par Eclipse pour son organisation personnelle.
//          WEB-INF est un dossier indispensable pour une application Java EE, quel que soit l'IDE utilisé.
//              --> Dans le dossier Java Ressources, nous avons un dossier 'src', c'est ici que tout va se passer, là où nous allons écrire nos classes Java.
//              --> Dans le dossier WebContent, nous allons placer tous nos fichiers web, donc de type HTML, CSS & JSP.
//              --> Dans le dossier WEB-INF, nous allons placer tous nos fichiers de configuration.
//              --> Dans le sous-dossier 'lib' du dossier WEB-INF, nous allons placer nos bibliothèques externes.
//      - Dans un premier temps nous allons simplement rajouter un fichier 'index.html' à la racine de WebContent et y mettre un contenu simple.
//      - Pour exécuter notre application : Clic droit dessus > Run As > Run on Server > Nous sélectionnons le serveur Tomcat > Next, notre projet doit se situer dans la colonne de droite > Finish.
//          --> Une page web s'ouvre avec le contenu de notre page index.html.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comprendre les Servlets et les JSPs ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créer un Servlet //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La partie Contrôleur de notre code, qui fait l'aiguilleur est en réalité une Servlet.
//      --> Ce sont en réalité de simples classes Java, avec des méthodes telles que 'doGet()' ou 'doPost()'.
// Ces deux méthodes vont se contenter de recevoir l'information, la requête HTTP, puis de générer une page web et de la renvoyer la réponse HTTP.
//      --> Comment en créer une ?
// Nous effectuons un clic droit sur le dossier 'Java Resources/src' > New > Servlet, et nous l'appelons 'ServletTest'.
//      --> Qu'est-ce qu'une Servlet ?
// C'est une classe qui étends HttpServlet.
//      --> Pourquoi est-ce que les méthodes que cette classe hérite existent ?
// Le protocole HTTP définis plusieurs méthodes de communication avec le serveur.
// Par exemple, quand un client souhaites lire une page, en général, il s'agit d'une requête de type 'GET', d'où la méthode héritée 'doGet()'.
// Lorsqu'un client envoies des données de formulaire, il s'agit d'une requête de type 'POST', d'où la méthode 'doPost()'.
// Maintenant, dans le dossier WEB-INF, nous allons créer un fichier de configuration, indispensable pour les projets Java EE qui s'appelle 'web.xml'.
// Dans ce fichier XML, nous allons effectuer la configuration ci-dessous :
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                          xmlns="http://java.sun.com/xml/ns/javaee"
//                          xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"
//                          version="3.0">
//                      <servlet>
//                          <servlet-name>ServletTest</servlet-name>
//                          <servlet-class>com.octest.servlets.Test</servlet-class>
//                      </servlet>
//                      <servlet-mapping>
//                          <servlet-name>Test</servlet-name>
//                          <url-pattern>/bonjour</url-pattern>
//                      </servlet-mapping>
//                  </web-app>
//      --> La balise '<servlet>' décrit la classe qui contiens la Servlet, son nom et son chemin dans le dossier 'src'.
//      --> La balise '<servlet-mapping>' va indiquer sur quelle url nous allons pouvoir effectuer des requêtes en indiquant bien le même nom que dans la balise '<servlet>'.
//              --> Ici, ce sera la méthode 'doGet()' qui sera appelée sur l'url 'localhost:808à/test/bonjour'.
// -----------
//                  package org.vitu.servlets;
//                  import jakarta.servlet.ServletException;
//                  import jakarta.servlet.annotation.WebServlet;
//                  import jakarta.servlet.http.HttpServlet;
//                  import jakarta.servlet.http.HttpServletRequest;
//                  import jakarta.servlet.http.HttpServletResponse;
//                  import java.io.IOException;
//                  @WebServlet("/test")
//                  public class ServletTest extends HttpServlet {
// 	                 private static final long serialVersionUID = 1L;
//                      public ServletTest() {
//                          super();
//                      }
// 	                 protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
// 	                 	response.getWriter().append("Served at: ").append(request.getContextPath());
// 	                 }
// 	                 protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
// 	                 	doGet(request, response);
// 	                 }
//                  }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Associer une vue à une Servlet ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons à présent voir comment associer une partie 'Vue' à notre Servlet.
// Pour ce faire, nous allons faire en sorte que notre Servlet, renvoies des informations qui permettraient d'afficher une page web.
// Dans la méthode 'doGet()' de notre Servlet, nous allons travailler sur deux objets : 'HttpServletRequest' et 'HttpServletResponse'.
// Dans un premier temps, nous paramétrons l'objet 'response' pour qu'il créé du texte de type HTML code en UTF-8, et que celui-ci imprime un texte simple : "Bonjour !".
//                  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
//                      response.setContentType("text/html");
//                      response.setCharacterEncoding("UTF-8");
//                      PrintWriter out = response.getWriter();
//                      out.println("Bonjour !");
//                  }
// Mais ceci n'est pas du contenu HTML, nous pouvons donc faire :
//                  out.println("<!DOCTYPE html>");
//                  out.println("<html>");
//                  out.println("<head>");
//                  out.println("<meta charset=\"utf-8\" />");
//                  out.println("<title>Test</title>");
//                  out.println("</head>");
//                  out.println("<body>");
//                  out.println("<p>Bonjour !</p>");
//                  out.println("</body>");
//                  out.println("</html>");
// Ainsi, nous avons exactement le même résultat que précédemment, toutefois, cette fois-ci, le code HTML est bien structuré, et c'est bien une page HTML que nous retournons.
// Mais ceci est assez contraignant, car cela fait beaucoup de lignes, pour retourner du HTML basique. En Java EE, nous ne faisons jamais de cette manière.
//      --> Si nous voulons faire les choses correctement, nous allons utiliser la technologie JSP : JavaServer Pages.
// Son principe est de gérer nos vues, notre code HTML dans des fichiers spécifiques qui pourront mélanger un peu de code Java avec du HTML.
// Nous allons créer un fichier .jsp dans le dossier 'WEB-INF' : 'bonjour.jsp'. Et nous allons y mettre un simple message 'Bonjour !'.
// Dans notre Servlet, nous allons devoir créer l'appel à ce fichier depuis l'objet 'response' :
//                  this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
// Nous pouvons remarquer que dans l'arborescence, le dossier "WebContent" n'est pas appelé dans notre méthode, c'est parce qu'il est créé par Eclipse, uniquement de manière cosmétique.
//      --> En réalité, lorsque le serveur est démarré, il n'y a qu'un dossier WEB-INF à la racine.
// Maintenant, le messsage affiché est toujours le même, sauf que notre code est plus propre.
//      --> De plus, ici, notre Servlet rempli mieux son rôle de Contrôleur, elle se contente de renvoyer la Vue au client, comme un chef d'orchestre.
//              --> En effet, maintenant, pour modifier la Vue, nous modifions directement la Vue et non le Contrôleur, en effectuant nos modifications directement dans le fichier . jsp.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Présentation des JSP //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Rentrons plus en détail sur le fonctionnement de notre Vue.
//      --> Les pages JSP nous permettent de générer du code HTML, fixe, qui nous permet ensuite de générer du code JSP à son tour.
//      --> Comment pouvons-nous insérer ce code Java, et quel effet produit-il sur notre page web ?
// Dans un premier temps, nous allons spécifier l'encodage de notre page JSP, même si celui-ci est reprécisé, UNIQUEMENT pour la partie HTML en dessous :
//                  <%@ page pageEncoding="UTF-8" %>
// La particularité des fichiers JSP est que nous pouvons y inclure aussi du code Java.
//      --> Nous allons voir comment nous pouvons, à partir de la Servlet, transmettre une variable à la JSP.
// 	                String message = "Au revoir !";
//                  request.setAttribute("variable", message);
// Ici, nous avons fixé un String à la variable 'variable' en paramètre de notre objet 'request', avant de l'envoyer à la page JSP.
//      --> Ainsi, nous avons maintenant accès à la variable 'variable', qui contient le String 'message' à l'intérieur de notre fichier JSP.
//                  <p>
//                      <%
//                          String variable = (String) request.getAttribute("variable");
//                          out.println(variable);
//                      %>
//                  </p>
// Maintenant, notre variable s'affiche bien sur notre page web.
// Nous pouvons aussi écrire du code Java dans ces balises, par exemple, nous pouvons imprimer 20 lignes supplémentaires à l'aide d'une boucle :
//                  <p>
//                      <%
//                          for (int i = 0; i < 20; i++) {
//                              out.println("Une nouvelle ligne " + i + " !<br/>");
//                          }
//                      %>
//                  </p>
// Imaginons à présent que nous voulons afficher 'Bonjour' si c'est le jour, et 'Bonsoir' si c'est le soir.
//                  <p>
//                      <%
//                          String heure = (String) request.getAttribute("heure");
//                          if (heure.equals("jour")) {
//                              out.println("Bonjour !");
//                          } else {
//                              out.println("Bonsoir !");
//                          }
//                      %>
//                  </p>
// De cette manière, si nous passons la variable 'heure' avec la valeur 'jour', le texte imprimé sera 'Bonjour !', si non ce sera 'Bonsoir !'. Ici, nous l'initialisons à 'jour' :
//                  request.setAttribute("heure", "jour");
// Voila, nous avons utilisé une boucle et une déclaration conditionnelle, ainsi que des variables passées par notre Servlet, donc notre Contrôleur, à notre Vue, ici, la page JSP.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les inclusions de JSP /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// En général, quand nous développons des sites web en Java EE, il y a bien souvent des parties de notre site qui sont toujours les mêmes, comme l'entête, le menu ou le pied de page.
// Plutôt que de dupliquer ce code, et de le retrouver dans toutes nos pages JSP, nous pouvons le centraliser dans des pages spécifiques, comme 'header.jsp', 'menu.jsp', ou 'footer.jsp'.
// Ceci nous permettra d'avoir du code HTML centralisé à un seul endroit, que nous pourrons ainsi modifier le moment venu, à un seul endroit.
//      --> Ainsi, les JSP nous permettent de faire ce que nous appelons des 'inclusions de pages'.
//                  <%@ include file="menu.jsp" %>
// Dans notre nouveau fichier menu.jsp, nous pouvons supprimer tout le template HTML, les balises <!DOCTYPE>, <html>, <head>, <body>, car nous n'en aurons pas besoin.
// En effet, ce fichier sera inclus dans une autre page JSP, ayant déjà son template HTML. A la place, nous pouvons imaginer un menu de ce type :
//                  <ul>
// 	                    <li>Page 1</li>
// 	                    <li>Page 2</li>
// 	                    <li>Page 3</li>
//                  </ul>
// Maintenant, nous allons créer une nouvelle page 'acceuil.jsp'. Donc, nous allons créer une nouvelle Servlet, la configurer dans le fichier web.xml, puis créer la page JSP.
// A présent, si nous ajoutons des ancres 'href' dans notre menu, nous pouvons créer des liens dynamiques qui renvoient sur la page d'accueil et sur la page bonjour.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Communiquer des données entre pages ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour le moment, notre site web n'est pas vraiment dynamique, elle affiche un peu tout le temps la même chose.
// Pourtant, il existe un moyen très simple de récupérer des informations dynamiques, notamment, via l'url de la page web.
//      --> Nous allons à présent voir comment récupérer des paramètres 'get' dans nos url.
// Nous verrons comment nous pouvons afficher des informations différentes, en fonction de la valeur de ces paramètres, avec une url de ce type :
//                  http://localhost:8080/test/bonjour?name=Emile
// Il nous suffit donc de modifier dans la Servlet 'Test', la méthode 'doGet()', de manière à récuperer un paramètre :
//                  String name = request.getParameter("name");
// Puis, nous n'avons qu'à initialiser un nouveau paramètre et l'attacher à notre objet 'request' :
//                  request.setAttribute("name", name);
// Ensuite, nous pouvons récupérer ce paramètre dans notre JSP :
//                  <p>
//                      Bonjour !
//                      <%
//                          String name = (String) request.getAttribute("name");
//                          out.println(name);
//                      %>
//                  </p>
// Ainsi, si nous requêtons : http://localhost:8080/test/bonjour?name=Emile, notre page nous afficheras 'Bonjour Emile'.
// Si nous voulions traiter plusieurs paramètres dans une requête client, nous aurions par exemple :
//                  http://localhost:8080/test/bonjour?name=Emile&age=35&cheveux=blond
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser Expression Language dans les JSP /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Jusuq'à présent, nous avons mélangé du code Java et du code HTML dans nos fichiers JSP.
//      --> Toutefois c'est une mauvaise pratique !
// C'est pour cela qu'aujourd'hui, il existe de nouvelles fonctionnalités nous permettant de l'éviter.
//      --> Notamment 'Expression Language' ou 'EL' que nous allons voir dans ce chapitre.
// Il nous permet d'écrire des conditions beaucoup plus courtes, ou encore d'insérer des variables à l'intérieur de nos pages JSP.
// Nous pouvons à présent directement inclure dans notre code HTML des appels à EL :
//                  <p>Bonjour ${6*30}</p>          --> "Bonjour 180".
// Nous pouvons aussi directement afficher des variables : ${ name }.
// Ou encore effectuer des opérateurs conditionnels ternaires : ${ !empty name ? name : '' }.
// Enfin, nous pouvons aussi passer un tableau :
//                  String[] noms = {"Emile", "Anne-Lyse", "Olympe"};
//                  request.setAttribute("noms", noms);
// Puis le récupérer dans notre page JSP :
//                  ${ noms[0] } et aussi ${ noms[1] } and last but not least ${ noms[2] }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Manipuler des Java Beans dans les JSP /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous savons que Java est un langage de programmation orienté objet.
// Ainsi, dans la partie Modèle de notre application, qui est stucturée en MVC, nous allons pouvoir y stocker nos données, informations, en utilisant les JavaBeans.
// Nous allons voir à présent comment créer des JavaBeans, et en particulier comment les informations vont transiter entre le Modèle, le Contrôleur et la Vue.
//      --> Les JavaBeans, sont en fait de simples classes Java, qui sont publiques, dont les attributs sont privés et qui possèdent des méthodes publiques pour y accéder et les modifier.
// Nous allons commencer par créer notre JavaBean, qui sera un auteur, qui aura un nom, un prénom, et un statut actif ou inactif : 'org.vitu.beans.Auteur'.
// Ensuite, nous pouvons simplement le transmettre à notre JSP comme nous le faisons d'habitude :
//                  Auteur auteur = new Auteur();
//                  auteur.setPrenom("Emile");
//                  auteur.setNom("Vitu");
//                  auteur.isActif(true);
//                  request.setAttribut("auteur", auteur);
// Enfin, nous pouvons facilement appeler notre JavaBean et ses attributs dans notre fichier page JSP :
//                  		<p>
//                              Bonjour ${ auteur.prenom } ${ auteur.nom } est un auteur ${ auteur.isActif() ? "actif" : "inactif" }.
//                          </p>
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Des vues puissantes avec la JSTL //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Qu'est-ce que la JSTL ? ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// La JSTL nous évite d'avoir à écrire du code en langage Java dans nos JSP.
//      --> Ce sont en fait des balises XML que nous pouvons insérer dans nos pages JSP.
// Par exemple, nous pouvons utiliser un boucle JSTL forEach, qui va nous permettre d'afficher plusieurs fois une ligne de code HTML.
// Quels sont les avantages d'un code qui utilise JSTL ?
//      --> C'est un code plus facile à lire.
//      --> C'est plus facile à réutiliser.
//      --> C'est plus facile à maintenir.
// JSTL est une bibliothèque que nous allons rajouter à notre code Java EE.
//      --> JSTL : JavaServer Standard Tag Library.
// Cette bibliothèque est en fait constituée de 5 sous-bibliothèques :
//      - 'core' : qui gère l'affichage des variables, des conditions et des boucles.
//      - 'format' : qui permet de formater les données, et particulièrement d'effectuer l'internationalisation de son site web.
//      - 'xml' : qui gère le flux de données XML.
//      - 'sql' : qui permet d'écrire du code en langage SQL, ce qui en pratique est une mauvaise pratique MVC, et donc non-recommandée.
//      - 'function' : qui permet de traiter des chaînes de caractères.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mettre en place la JSTL ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous aurons besoin d'effectuer un peu de configuration dans nos fichiers JSP, ainsi que dans notre projet Eclipse.
//      - Dans nos fichiers JSP, dans la balise d'ouverture, nous devons ajouter la bibliothèque JSTL, à la suite de '<%@ page pageEncoding="UTF-8" %>', nous ajoutons :
//                  <%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c" %>
//          --> Ici, l'attribut 'prefix="c"' signifie que toutes les balises JSTL devront commencer par 'c'.
// Pour appeler JSTL dans notre fichier JSP, nous pouvons écrire :
//                  <p><c:out value="Bonjour JSTL :) !" /></p>
//      - Maintenant, nous devons inclure deux bibliothèques JSTL dans notre projet, donc nous devons télécharger les JAR de la bibliothèque, puis les coller dans le dossier 'WebContent/WEB-INF/lib' :
//                  - jakarta.servlet.jsp.jstl-api-2.0.0.jar.
//                  - jakarta.servlet.jsp.jstl-2.0.0.jar
// A présent, si nous relançons le serveur, le contenu de l'attribut 'value' de notre balise 'c:out' (donc qui envoies vers l'output) est bien visible :
// Nous allons maintenant faire en sortes que la JSTL soit inclue automatiquement, quel que soit le fichier JSP.
//      --> Dans notre fichier de configuration 'web.xml', nous pouvons ajouter la configuration suivante :
//                  <jsp-config>
//                      <jsp-property-group>
//                          <url-pattern>*.jsp</url-pattern>
//                          <include-prelude>/WEB-INF/taglibs.jsp</include-prelude>
//                      </jsp-property-group>
//                  </jsp-config>
// Il ne nous manque plus qu'à créer ce fichier 'taglibs.jsp' :
//                  <%@ page pageEncoding="UTF-8" %>
//                  <%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c" %>
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// JSTL et variables /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Notre première balise '<c:out value="Bonjour !"/> n'est pas complètement inutile.
//      --> Elle échape les caractères spéciaux HTML et XML, ce qui est très pratique et nous évite d'avoir affaire à la 'faille XSS', qui est une faille célèbre sur le web.
// Imaginons que dans un champs de texte, le client saisisse du HTML ou du JavaScript, nous ne voudrions pas qu'il puisse récupérer des informations sur notre structure de site web.
// Avec cette balise 'c:out', nous échappons à ce risque, ce qui est une bonne chose.
// Ainsi, si au lieu d'écrire le texte en brut, nous écrivions :
//                  <c:out value="${ textVariable }" />
//      --> Si le client entre du texte se retrouvant dans notre variable 'textVariable', ce texte sera protégé par JSTL contre la faille XSS.
// Le second avantage est que nous pouvons tester si notre variable est vide ou non.
//                  <c:out value="{ textVariable }" default="Valeur par défaut" />
//      --> Ainsi, si la variable est vide, c'est la valeur par défaut qui s'affichera.
// Enfin, si nous le souhaitions, nous pourrions désactiver la protection contre les failles XSS :
//                  <c:out value="{ textVariable }" default="Valeur par défaut" escapeXML="false" />
// Dernière chose, nous ne sommes pas obligés de mettre l'attribut 'default' pour inclure notre valeur par défaut, nous pourrions aussi faire de cette manière :
//                  <c:out value="{ textVariable }" escapeXML="false">Valeur par défaut</c:out>
// Le JSTL nous permet aussi de définir des variables à l'intérieur de la page JSP :
//                  <c:set var="pseudo" value="Emile" scope="page" />
//      --> De cette manière, nous avons créé une variable 'pseudo' ayant pour valeur 'Emile' et pour périmètre l'ensemble de la page JSP.
// Les autres périmètres disponibles sont :
//      - 'request' : la variable est disponible pendant toute la requête, donc si nous forwardons la JSP, nous inclurons cette variable avec.
//      - 'session' : la variable sera disponible pendant toute la session du client.
//      - 'application' : la variable sera disponible pour toute l'application, donc pour tous les clients en train d'utiliser notre application.
// Nous pouvons aussi définir la valeur de la variable à l'intérieur de la balise 'c:set' :
//                  <c:set var="pseudo" scope="page">Milk</c:set>
// Si nous voulions modifier une variable déjà définie, il nous suffit de reprendre la même balise :
//                  <c:set var="pseudo" scope="page">Duvall</c:set>
// Si nous travaillons avec des JavaBeans, nous pouvons aussi les modifier avec la syntaxe JSTL :
//                  <c:set target="${ auteur }" property="prenom" value="Gabriel" />
//                  <c:out value="${ auteur.prenom }" />
// Pour finir, si nous voulons supprimer une variable de la mémoire, nous pouvons utiliser :
//                  <c:remove var="pseudo" scope="page" />
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// JSTL et conditions ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour réaliser des sites web vraiment dynamiques, nous avons besoin de réaliser des pages web qui changent en fonction de certaines conditions (l'âge du client, l'heure de la journée...).
// Il va falloir traiter ces informations grâce à des éléments conditionnels dans nos pages JSP :
//                  <c:if test="${ 50 > 10 }" var="variable" scope="session">C'est vrai !</c:if>
// Lorsque le test sera vrai, le contenu des balises s'affichera : 'C'est vrai :'.
// De plus, nous pouvons stocker le résultat du test dans une variable pour pouvoir la réutiliser dans la page.
// Par défaut, cette variable à un périmètre de 'page', mais nous pouvons ajouter aussi un attribut 'scope' pour le modifier.
//      --> Le défaut de cette balise, est que nous ne pouvons pas faire de tests conditionnels multiples, tels qu'un 'else' ou un 'else if'.
// Toutefois, nous avons une autre balise JSTL qui nous le permet, et ce, sur plusieurs tests d'affilée :
//                  <c:choose>
//                      <c:when test="${ variable }">Du texte.</c:when>
//                      <c:when test="${ autreVariable }">Du texte.</c:when>
//                      <c:when test="${ encoreUneAutreVariable }">Du texte.</c:when>
//                      <c:otherwise>Par défaut si les autres tests échouent.</c:otherwise>
//                  </c:choose>
// Par défaut, si les tests '<c:when>' échouent, ce sera le contenu de la balise '<c:otherwise>' qui s'affichera.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// JSTL et boucles ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour répéter une action dans des pages web, avec JSTL, nous allons avoir recours aux boucles.
//      --> La JSTL nous propose plusieurs types de boucles.
// Nous pouvons effectuer plusieurs types de boucles avec JSTL :
//      - Boucle qui s'exécute un certain nombre de fois :
//                  <c:forEach var="i" begin="0" end="10" step="2">
//                      <p>Message n°<c:out value="${ i }"/></p>
//                  </c:forEach>
//          Cette boucle 'forEach', nous permet aussi de parcourir des tableaux, des arrays, des énumérations, des maps, des collections ...
//          Nous pouvons en faire le test en ajoutant dans notre Servlet, un array très simple de chaînes de caractères :
//                  <c:forEach items="${ titres }" var="titre" begin="0" end="1">
//                      <p>Titre : <c:out value="${ titre }"/></p>
//                  </c:forEach>
//          A noter qu'ici, seuls les deux premiers titres de la liste s'afficheront car nous avons ajouter les attributs facultatifs 'begin' et 'end'.
//          Nous pourvons aussi utiliser l'attribut 'varStatus' qui va générer la variable 'status' contenant plusieurs informations sur la boucle en cours.
//                  <c:forEach items="${ titres }" var="titre" varStatus="status">
//                      <p> N° <c:out value="${ status.count }"/> - Titre : <c:out value="${ titre }"/></p>
//                  </c:forEach>
//          Il existe d'autres attributs sur cet objet 'status' :
//              - 'index', qui est un compteur, mais commençant à zéro.
//              - 'current', qui correspond à l'élément en cours.
//              - 'first', qui indique si nous sommes dans le premier élément de la liste.
//              - 'last', qui indique si nous sommes dans le dernier élément de la liste.
//      - Boucle 'for' spécialement dédiée aux chaînes de caractères 'forTokens', prenant les attributs :
//              - 'var', correspondant au morceau de la chaîne de caracères que nous allons découper.
//              - 'items', correspondant à la chaîne de caractères à spliter.
//              - 'delims', correspondant au délimiteur.
//                  <c:forTokens var="morceau" items="Un élément/Encore un autre élément/Un dernier pour la route" delims="/">
//                      <p>${ morceau }</p>
//                  </c:forTokens>
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Développer une application web ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les formulaires avec Java EE //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour réaliser un site web vraiment dynamique, nous allons avoir systématiquement recours à des formulaires.
// Comment faire avec Java EE pour récupérer et traiter les informations entrées par un client dans un formulaire ?
// Dans cette partie, nous allons utiliser non pas la méthode 'doGet()' mais la méthode 'doPost()' de notre Servlet, pour récupérer les informations postées par le client.
//      - Dans un premier temps, nous allons créer le formulaire dans notre page JSP :
//          Classiquement, en HTML, nous utilisons les balises '<form>' avec un attribut 'method' qui précise 'get' ou 'post'.
//              - 'get' est relativement limité en données, et transite les informations par l'url. Nous utiliserons la méthode 'doGet()' de notre Servlet pour cette méthode.
//              - 'post' n'est pas limité en données, et ne transite pas par l'url, ce qui est plus intéressant. Nous utiliserons la méthode 'doPost()' de notre Servlet pour cette méthode.
//          L'attribut 'action' précise l'url appelé pour le post ou le get. Ici, nous utiliserons notre page 'bonjour', donc nous utiliserons la Servlet qui est liée à notre page 'bonjour'.
// 	                <form method="post" action="bonjour">
// 	                    <label for="nom">Nom : </label>
// 	                    <input type="text" id="nom" name="nom" />
// 	                    <input type="submit" />
//                  </form>
//          Nous ajoutons aussi un label associé à l'id 'nom', pour légender notre input. Ainsi que notre bouton submit.
//      - Lorsque nous cliquons sur le bouton submit, rien ne se passe, c'est parce que la méthode 'doPost()' de la Servlet associée à cet url ne contient rien pour le moment.
//                  String nom = request.getParameter("nom");
//          Ici, la chaîne de caractères, passée en paramètre de la méthode 'getParameter()' correspond à l'attribut 'name' de notre balise input.
// 	                request.setAttribute("nom", nom);
//                  this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//          Ensuite, nous initialisons un nouvel attribut à la requête, puis nous transmettons notre nouveau paramètre à notre page JSP, comme nous le faisions avec la méthode 'doGet()'.
//      - Il ne nous reste plus qu'à afficher le nom, si il existe dans notre page JSP, nous pouvons le faire en utilisant une condition de champs nom non-vide :
//                  <c:if test="${ !empty nom }">
//                      <p>
//                          <c:out value="Bonjour, vous vous appelez ${ nom }." />
//                      </p>
//                  </c:if>
// Pour le moment, nous avons juste construit un formulaire vraiment très basique, mais en général, nous aurons plusieurs champs et des traitements à faire, des calculs par exemple.
//      --> Par exemple, nous pourrions vouloir vérifier que l'utilisateur à bien le droit de se connecter.
// C'est à ce moment-là que les choses vont commencer à se compliquer car nous aurons tendance à vouloir faire nos calculs dans la Servlet, par exemple dans la méthode 'doPost()'.
//      --> Nous avons toutefois vu que nous devrions faire ce genre de choses dans le Modèle, donc dans des objets Java, et non dans le Contrôleur.
// Pour illustrer ce phénomène, nous allons construire un 'micro-formulaire de connection' dans notre page JSP :
//                  <form method="post" action="bonjour">
//                      <p>
//                          <label for="login">Login : </label>
//                          <input type="text" id="login" name="login" />
//                      </p>
//                      <p>
//                          <label for="pass">Mot de passe : </label>
//                          <input type="password" id="pass" name="pass" />
//                      </p>
//                      <input type="submit" />
//                  </form>
// Ainsi, nous avons deux input nommés 'login' et 'pass' que nous allons pouvoir utiliser côté serveur dans Java.
// Par conséquent, nous debons préparer un modèle d'objet Java que nous allons construire dans un package séparé pour répondre au besoin de ce formulaire :
//                  package org.vitu.forms;
//                  import jakarta.servlet.http.HttpServletRequest;
//                  public class ConnectionForm {
//                      private String resultat;
//                      public void verifierIdentifiants(HttpServletRequest request) {
// 	                        String login = request.getParameter("login");
// 	                        String password = request.getParameter("pass");
// 	                        if (password.equals(login + "123")) {
// 	                            resultat = "Vous êtes bien connectés !";
// 	                        } else {
// 	                            resultat = "Identifiants incorrects !";
// 	                        }
//                      }
//                      public String getResultat() {
//                          return resultat;
//                      }
//                      public void setResultat(String resultat) {
//                          this.resultat = resultat;
//                      }
//                  }
// Maintenant, nous pouvons l'appeler sous forme d'un objet de type 'ConnectionForm' dans notre méthode 'doPost()' tout comme nous le faisions précédemment dans la méthode 'doGet()' :
//                  protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
//                      ConnectionForm form = new ConnectionForm();
//                      form.verifierIdentifiants(request);
//                      request.setAttribute("form", form);
//                      this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//                  }
// Notre méthode 'verifierIdentifiants()' nous permet de vérifier le login et le password, et de retourner un paramètre de type String à notre objet requête, afin qu'il soit renvoyé à notre page JSP.
// Pour l'instant, notre objet 'request' ne contient que notre attribut 'resultat', mais si il venait à évoluer, nous n'aurions pas à modifier le Contrôleur, ou alors très peu.
// Ainsi, nous pouvons ajouter une condition en début de page JSP pour confirmer ou non l'identification d'un utilisateur :
//                  <c:if test="${ !empty form.resultat }">
//                      <p>
//                          <c:out value="${ form.resultat }." />
//                      </p>
//                  </c:if>
//      --> En conclusion, nous avons bien une Vue séparée, qui ne se contente que d'afficher des messages, c'est notre page JSP.
//      --> Notre modèle, lui aussi est bien défini et séparé, c'est notre classe ConnectionForm.
//      --> Notre Contrôleur est toujours notre Servlet, qui fait le pont entre la Vue et le Modèle.
//      --> Notre formulaire a un attribut de type 'enctype' qui à pour valeur 'multipart/form-data', chose indispensable pour que des fichiers puissent être encodés.
//
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Envoyer des fichiers //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Allons encore plus loin dans l'utilisation de nos formulaires. Nous pouvons par exemple uploader des fichiers.
// Alors, comment gérer l'upload de fichiers dans Java EE ?
//      --> Mauvaise nouvelle, ce n'est pas simple...
// Premièrement, la disposition du formulaire :
//      - Nous avons un champs 'Description du fichier' de texte pour y enregistrer un descriptif du fichier à uploader.
//      - Un champs 'Fichier à envoyer', avec un bouton 'Choisir le fichier'.
//      - Un bouton 'Envoyer', pour envoyer la requête au serveur.
// Tout d'abord, voyons comment traduire cela en HTML, donc en JSP :
//                  <c:if test="${ !empty fichier }">
//                      <p>
//                          <c:out value="Le fichier ${ fichier } (${ description }) a été uploadé." />
//                      </p>
//                  </c:if>
//                  <form method="post" action="bonjour" enctype="multipart/form-data">
//                      <p>
//                          <label for="description">Description du fichier : </label>
//                          <input type="text" id="description" name="description" />
//                      </p>
//                      <p>
//                          <label for="fichier">Fichier à envoyer : </label>
//                          <input type="file" id="fichier" name="fichier" />
//                      </p>
//                      <input type="submit" />
//                  </form>
//      --> Ici, nous avons ajouté une balise de type 'input', mais dont l'attribut 'type' est fixé à 'file', donc 'fichier'.
//      --> Aussi, nous lui avons donné comme attribut 'name', pour que nous puissions le retrouver dans notre Servlet.
// Maintenant, dans notre fichier 'web.xml', nous devons modifier le contenu de la balise '<servlet>' afin de permettre les upload de fichiers, et d'en préciser la taille maximale :
//                  <servlet>
//                      <description></description>
//                      <display-name>Test</display-name>
//                      <servlet-name>Test</servlet-name>
//                      <servlet-class>org.vitu.servlets.Test</servlet-class>
//                      <multipart-config>
//                          <location>C:\Users\Emile\Desktop\JAVA\java-projects\emile-workspace\test\src\resources</location>
//                          <max-file-size>10485760</max-file-size>
//                          <max-request-size>52428800</max-request-size>
//                          <file-size-threshold>1048576</file-size-threshold>
//                      </multipart-config>
//                  </servlet>
//      --> En ajoutant la balise '<multipar-config>' ainsi que ses sous-balises, nous précisons à notre application quel sont les propriétés du flux de données autorisées sur notre servlet.
//      --> La balise '<location>' permet d'indiquer où doivent être stockés temporairement les gros fichiers (chemin local ou chemin vers un serveur).
//      --> La balise '<max-file-size>' indique la taille maximale en octets du fichier que nous pouvons uploader, ici nous avons indiqué 10 Mo.
//      --> La balise '<max-request-size>' nous permet d'indiquer la taille maximale de la requête globale, au cas où nous aurions plusieurs fichiers à envoyer par exemple.
//      --> La balise '<file-size-threshold>' nous permet d'indiquer à partir de quelle taille les fichiers doivent être stockés dans le dossier 'localion'.
// Concernant notre Servlet, nous ajoutons deux constantes :
//                  public static final int TAILLE_TAMPON = 10240;
//                  public static final String CHEMIN_FICHIER = "C:\\Users\\Emile\\Desktop\\JAVA\\java-projects\\emile-workspace\\test\\src\\resources\\final";
//      --> Ceux-ci nous permettrons de faire la copie du fichier et spécifie la taille du tampon utilisé pour la copie.
//      --> La seconde variable nous spécifie ou seront copiés les fichiers finaux.
//                  this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//      --> La méthode 'doGet()' elle fait comme précédemment.
//                  protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
//                      //	    String nom = request.getParameter("nom");
//                      //	    request.setAttribute("nom", nom);
//                      //	    ConnectionForm form = new ConnectionForm();
//                      //	    form.verifierIdentifiants(request);
//                      //	    request.setAttribute("form", form);
//                      // Récupération du champs 'decription'.
//                      String description = request.getParameter("descripton");
//                      request.setAttribute("description", description);
//                      // Récupération du champ du fichier.
//                      Part part = request.getPart("fichier");
//                      // Vérification de la réception du fichier.
//                      String nomFichier = getNomFichier(part);
//                      // Si nous avons bien un fichier.
//                      if (nomFichier != null && !nomFichier.isEmpty()) {
//                          String nomChamps = part.getName();
//                          // Corrige un bug du fonctionnement d'Internet Explorer.
//                          nomFichier = nomFichier.substring(nomFichier.lastIndexOf("/") + 1).substring(nomFichier.lastIndexOf("\\") + 1);
//                          // Ecriture définitive du fichier sur le disque.
//                          ecrireFichier(part, nomFichier, CHEMIN_FICHIERS);
//                          request.setAttribute(nomChamps, nomFichier);
//                      }
//                      this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//                  }
//                  private void ecrireFichier( Part part, String nomFichier, String chemin ) throws IOException {
//                      BufferedInputStream entree = null;
//                      BufferedOutputStream sortie = null;
//                      try {
//                          entree = new BufferedInputStream(part.getInputStream(), TAILLE_TAMPON);
//                          sortie = new BufferedOutputStream(new FileOutputStream(new File(chemin + nomFichier)), TAILLE_TAMPON);
//                          byte[] tampon = new byte[TAILLE_TAMPON];
//                          int longueur;
//                          while ((longueur = entree.read(tampon)) > 0) {
//                              sortie.write(tampon, 0, longueur);
//                          }
//                      } finally {
//                          try {
//                              sortie.close();
//                          } catch (IOException ignore) {
//                          }
//                          try {
//                              entree.close();
//                          } catch (IOException ignore) {
//                          }
//                      }
//                  }
//                  private static String getNomFichier(Part part) {
//                      for (String contentDisposition :  part.getHeader("content-disposition").split(";")) {
//                          if (contentDisposition.trim().startsWith("filename")) {
//                              return contentDisposition.substring(contentDisposition.indexOf("=") + 1).trim().replace("\"","");
//                          }
//                      }
//                  return null;
//                  }
//      --> Ici nous ajoutons deux méthodes, une récupérant le nom du fichier, et l'autre, réalisant la copie à l'aide de buffers.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérer les sessions ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour suivre un client, tout au long de sa navigation sur notre site web, nous allons utiliser le concept de 'session'.
//      --> La norme HTTP ne permet pas, en théorie de retenir des informations longtemps. Nous pouvons dire qu'il n'y a pas d'état, donc de 'state'.
// Commençons par voir notre page JSP, contenant un simple formulaire avec deux champs 'nom' et 'prenom', ainsi qu'un bouton de type 'submit'.
//                  <form method="post" action="bonjour">
//                      <p>
//                          <label for="nom">Nom : </label>
//                          <input type="text" name="nom" id="nom" />
//                      </p>
//                      <p>
//                          <label for="prenom">Prénom : </label>
//                          <input type="text" name="prenom" id="prenom" />
//                      </p>
//                      <input type="submit" />
//                  </form>
// Concernant notre Servlet, elle contient uniquement une méthode 'doGet()' et une méthode 'doPost()' affichant la page JSP.
// Nous allons commencer par récupérer le 'nom' et 'prenom' dans la méthode 'doPost()'.
// Ensuite, nous allons créer un objet de type 'HttpSession', pour récupérer le paramètre 'Session' de notre requête.
// Maintenant, nous pouvons faire appel à notre objet 'HttpSession', et initialiser ses attributs 'nom' et 'prenom'.
//      --> Ainsi, nous avons mis en mémoire le 'nom' et le 'prenom', et ceci, durant toute la visite du client.
//      --> Si jamais le client ferme l'onglet, ou si il reste trop longtemps (timeout), la session sera réinitialisée.
//                  String nom = request.getParameter("nom");
//                  String prenom = request.getParameter("prenom");
//                  HttpSession session = request.getSession();
//                  session.setAttribute("nom", nom);
//                  session.setAttribute("prenom", prenom);
//      --> Comment faire pour récupérer ces informations dans notre page JSP ?
// Nous pouvons ajouter un if et récupérer les informations dans l'objet JSTL 'sessionScope.
//                  <c:if test="${ !empty sessionScope.prenom && !empty sessionScope.nom }">
//                      <p>Vous êtes ${ sessionScope.prenom } ${ sessionScope.nom }</p>
//                  </c:if>
// Pour vérifier que les paramètres de Session sont bien enregistrés même quand nous naviguons dans une autre page, nous allons créer une seconde page JSP.
//                  <%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%>
//                  <%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %>
//                  <!DOCTYPE html>
//                  <html>
// 	                    <head>
// 		                    <meta charset="UTF-8">
// 		                    <title>Insert title here</title>
// 	                    </head>
// 	                    <body>
// 		                    <p>Vous êtes sur 'autre.jsp'</p>
// 		                    <c:if test="${ !empty sessionScope.prenom && !empty sessionScope.nom }">
// 			                    <p>Vous êtes ${ sessionScope.prenom } ${ sessionScope.nom }</p>
// 		                    </c:if>
// 	                    </body>
//                  </html>
// A présent, si nous enregistrons notre session sur la page 'bonjour', et que nous requêtons 'http://localhost:8080/test/autre.jsp', nos attributs de session s'afficherons bien.
//      --> A savoir que nous pouvons récupérer les informations de session directement d'autres Servlet, sans forcément passer par de l'ExpressionLanguage dans une page JSP.
// Pour ce faire, nous devons recréer un objet de type 'HttpSession' dans notre méthode 'doGet()'.
// 	                HttpSession session = request.getSession();
//                  String prenom = (String) session.getAttribute("prenom");
// Ainsi, le 'prenom' est stocké dans la mémoire de la méthode 'doGet()', et nous pouvons ainsi l'utiliser si nous le souhaitons.
// Enfin, pour supprimer toutes les informations de session, il suffit d'appeler la méthode 'invalidate()' sur l'objet session.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Stocker les cookies ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Parfois, nous aurons besoin de retenir des informations sur un visiteur, pour par exemple, éviter d'avoir à saisir son login systématiquement.
//      --> Ainsi, nous aurons recours au mécanisme des cookies. C'est une information que nous stockons sur une petite portion de mémoire de l'appareil du client.
//                  String nom = request.getParameter("nom");
//                  String prenom = request.getParameter("prenom");
//                  response.addCookie(new Cookie("prenom", prenom));
//                  response.addCookie(new Cookie("nom", nom));
// Dans la méthode 'doPost()', nous pouvons créer et stocker des objets de type 'Cookie' dans l'objet 'response'.
// Si nous voulons que le cookie dure plus longtemps, nous pouvons faire ainsi :
//                  Cookie cookie = new Cookie("prenom", prenom);
//                  cookie.setMaxAge(60);
//                  response.addCookie(cookie);
// En accédant a l'âge du cookie, via la méthode 'setMaxAge()', nous paramétrons sa durée de vie, ici pour 60 secondes.
// Nous pouvons voir les paramètres des cookies d'une page web en accédant aux paramètres de développeur, dans l'onglet 'Resources' et la colonne 'Expires'.
//      --> Comment faire pour récupérer ces informations ? Nous allons pouvoir le faire dans la méthode 'doGet()'.
//                  Cookie[] cookies = request.getCookies();
//                  if (cookies != null) {
//                      for (Cookie cookie : cookies) {
//                          if (cookie.getName().equals("prenom")) {
//                              request.setAttribute("prenom", cookie.getValue());
//                          }
//                      }
//                  }
// Maintenant, nous pouvons y accéder dans notre page JSP.
//                  <c:out value="${ prenom }" />
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Enregistrer dans une base de données //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Travailler avec JDBC et une base de données ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans la quasi totalité des applications web, nous avons recours à une base de données pour structurer et enregistrer des informations sur notre site web.
//      --> Pour cela, nous utilisons la bibliothèque JDBC.
// Cette bibliothèque va nous permettre de nous connecter à n'importe quel type de base de données.
// Voyons comment nous devons l'installer. Une fois installé nous pouvons entrer cette ligne de commande pour créer la base de données :
//                  CREATE DATABASE javaee DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;
// Puis, la ligne de commande suivante pour créer la table :
//                  CREATE TABLE  javaee.noms (
//                      id INT( 11 ) NOT NULL AUTO_INCREMENT ,
//                      nom VARCHAR( 200 ) NOT NULL ,
//                      prenom VARCHAR( 200 ) NOT NULL ,
//                      PRIMARY KEY ( id )
//                  ) ENGINE = INNODB;
// Enfin, nous devons télécharger le .jar 'MySQLConnector', puis le coller dans notre dossier 'lib' qui contiens toute les librairies utilisées par notre application.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lire et enregistrer des données en SQL ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Voyons à présent comment écrire des requêtes SQL dans notre application Java EE, qui vont ensuite transiter par JDBC, et qui va enfin communiquer cette requête à notre serveur de base de données.
//                  INSERT INTO javaee.noms(nom, prenom) VALUES("Dupont", "Jean");
// Nous pouvons exécuter cette requête plusieurs fois pour remplir notre table avec différentes valeurs.
// Maintenant, nous allons voir comment lire ces lignes dans notre application Java.
//                  public class Noms {
//                      private Connection connexion;
//                      public List<Utilisateur> recupererUtilisateurs() {
//                          List<Utilisateur> utilisateurs = new ArrayList<Utilisateur>();
//                          Statement statement = null;
//                          ResultSet resultat = null;
//                          loadDatabase();
//                          try {
//                              statement = connexion.createStatement();
//                              // Exécution de la requête
//                              resultat = statement.executeQuery("SELECT nom, prenom FROM noms;");
//                              // Récupération des données
//                              while (resultat.next()) {
//                                  String nom = resultat.getString("nom");
//                                  String prenom = resultat.getString("prenom");
//                                  Utilisateur utilisateur = new Utilisateur();
//                                  utilisateur.setNom(nom);
//                                  utilisateur.setPrenom(prenom);
//                                  utilisateurs.add(utilisateur);
//                              }
//                          } catch (SQLException e) {
//                          } finally {
//                              // Fermeture de la connexion
//                              try {
//                                  if (resultat != null)
//                                     resultat.close();
//                                  if (statement != null)
//                                      statement.close();
//                                  if (connexion != null)
//                                      connexion.close();
//                              } catch (SQLException ignore) {
//                              }
//                          }
//                          return utilisateurs;
//                      }
//                      private void loadDatabase() {
//                          // Chargement du driver
//                          try {
//                              Class.forName("com.mysql.jdbc.Driver");
//                          } catch (ClassNotFoundException e) {
//                          }
//                          try {
//                              connexion = DriverManager.getConnection("jdbc:mysql://localhost:3306/javaee", "root", "");
//                          } catch (SQLException e) {
//                              e.printStackTrace();
//                          }
//                      }
//                      public void ajouterUtilisateur(Utilisateur utilisateur) {
//                          loadDatabase();
//                          try {
//                              PreparedStatement preparedStatement = connexion.prepareStatement("INSERT INTO noms(nom, prenom) VALUES(?, ?);");
//                              preparedStatement.setString(1, utilisateur.getNom());
//                              preparedStatement.setString(2, utilisateur.getPrenom());
//                              preparedStatement.executeUpdate();
//                          } catch (SQLException e) {
//                              e.printStackTrace();
//                          }
//                      }
//                  }
// Notre page JSP :
//                  <form method="post" action="bonjour">
//                      <p>
//                        <label for="nom">Nom : </label>
//                        <input type="text" name="nom" id="nom" />
//                      </p>
//                      <p>
//                        <label for="prenom">Prénom : </label>
//                        <input type="text" name="prenom" id="prenom" />
//                      </p>
//                      <input type="submit" />
//                  </form>
//                  <ul>
//                      <c:forEach var="utilisateur" items="${ utilisateurs }">
//                         <li><c:out value="${ utilisateur.prenom }" /> <c:out value="${ utilisateur.nom }" /></li>
//                          </c:forEach>
//                  </ul>
// Notre Servlet :
//                  protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
//                      Noms tableNoms = new Noms();
//                      request.setAttribute("utilisateurs", tableNoms.recupererUtilisateurs());
//                      this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//                  }
//                  public void doPost( HttpServletRequest request, HttpServletResponse response ) throws ServletException, IOException {
//                      Utilisateur utilisateur = new Utilisateur();
//                      utilisateur.setNom(request.getParameter("nom"));
//                      utilisateur.setPrenom(request.getParameter("prenom"));
//                      Noms tableNoms = new Noms();
//                      tableNoms.ajouterUtilisateur(utilisateur);
//                      request.setAttribute("utilisateurs", tableNoms.recupererUtilisateurs());
//                      this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//                  }
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utiliser le modèle DAO ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Précédemment, nous avons écrit des requêtes SQL, directement dans notre code.
// Mais, en général, nous ne retrouvons pas de requêtes SQL dans nos Contôleurs, donc dans nos Servlets, et encore moins dans nos Vues, donc dans nos pages JSP.
// Pour bien structurer notre code, nous allons avoir recours au modèle DAO. Mais qu'est-ce que le modèle DAO ?
//      --> C'est une très bonne pratique, recommandée par les développeurs expérimentés pour gérer l'accès aux données. C'est un peu comme une extension du modèle MVC.
// Jusqu'à présent, c'est le Modèle qui interagit avec la base de données via JDBC.
//      --> Il est recommandé de séparer les requêtes SQL des calculs métiers, des objets métiers.
//              --> C'est là qu'intervient le Design Pattern DAO. C'est l'intermédiaire entre notre modèle et le système de stockage.
// DAO : Data Access Object.
//      Modèle <--> Interface DAO <--> Implémentation DAO A <--> Système de stockage A.
//                                <--> Implémentation DAO B <--> Système de stockage B.
//                                <--> Implémentation DAO C <--> Système de stockage C.
// L'implémentation de l'interface DAO nous permet de faire de l'abstraction, cela nous permet de gérer plusieurs systèmes de stockage, ici A, B et C, par exemple MySQL, Oracle et XML.
// Par exemple, l'interface DAO pourrait avoir trois méthodes à implémenter, peu importe la base de données ciblée : 'add()', 'get()' & 'remove()'.
//                  @WebServlet("/Test")
//                  public class Test extends HttpServlet {
//                      private static final long serialVersionUID = 1L;
//                      private UtilisateurDao utilisateurDao;
//                      public void init() throws ServletException {
//                          DaoFactory daoFactory = DaoFactory.getInstance();
//                          this.utilisateurDao = daoFactory.getUtilisateurDao();
//                      }
//                      protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
//                          request.setAttribute("utilisateurs", utilisateurDao.lister());
//                          this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//                      }
//                      public void doPost( HttpServletRequest request, HttpServletResponse response ) throws ServletException, IOException {
//                          Utilisateur utilisateur = new Utilisateur();
//                          utilisateur.setNom(request.getParameter("nom"));
//                          utilisateur.setPrenom(request.getParameter("prenom"));
//                          utilisateurDao.ajouter(utilisateur);
//                          request.setAttribute("utilisateurs", utilisateurDao.lister());
//                          this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//                      }
//                  }
// Nous aurons aussi trois objets supplémentaires :
//      --> DaoFactory : qui à pour rôle d'initialiser le DAO, c'est ici que nous allons établir la connection à la base de données, et que nous allons précharger un objet en mémoire.
//                  public class DaoFactory {
//                      private String url;
//                      private String username;
//                      private String password;
//                      DaoFactory(String url, String username, String password) {
//                          this.url = url;
//                          this.username = username;
//                          this.password = password;
//                      }
//                      public static DaoFactory getInstance() {
//                          try {
//                              Class.forName("com.mysql.jdbc.Driver");
//                          } catch (ClassNotFoundException e) {
//                          }
//                          DaoFactory instance = new DaoFactory(
//                                  "jdbc:mysql://localhost:3306/javaee", "root", "");
//                          return instance;
//                      }
//                      public Connection getConnection() throws SQLException {
//                          return DriverManager.getConnection(url, username, password);
//                      }
//                      // Récupération du Dao
//                      public UtilisateurDao getUtilisateurDao() {
//                          return new UtilisateurDaoImpl(this);
//                      }
//                  }
//      --> UtilisateurDao : interface ayant pour rôle de définir les méthodes sans les implémenter.
//                  public interface UtilisateurDao {
//                      void ajouter( Utilisateur utilisateur );
//                      List<Utilisateur> lister();
//                  }
//      --> UtilisateurDaoImpl : classe dans laquelle nous allons retrouver les requêtes SQL.
//                  public class UtilisateurDaoImpl implements UtilisateurDao {
//                      private DaoFactory daoFactory;
//                      UtilisateurDaoImpl(DaoFactory daoFactory) {
//                          this.daoFactory = daoFactory;
//                      }
//                      @Override
//                      public void ajouter(Utilisateur utilisateur) {
//                          Connection connexion = null;
//                          PreparedStatement preparedStatement = null;
//                          try {
//                              connexion = daoFactory.getConnection();
//                              preparedStatement = connexion.prepareStatement("INSERT INTO noms(nom, prenom) VALUES(?, ?);");
//                              preparedStatement.setString(1, utilisateur.getNom());
//                              preparedStatement.setString(2, utilisateur.getPrenom());
//                              preparedStatement.executeUpdate();
//                          } catch (SQLException e) {
//                              e.printStackTrace();
//                          }
//                      }
//                      @Override
//                      public List<Utilisateur> lister() {
//                          List<Utilisateur> utilisateurs = new ArrayList<Utilisateur>();
//                          Connection connexion = null;
//                          Statement statement = null;
//                          ResultSet resultat = null;
//                          try {
//                              connexion = daoFactory.getConnection();
//                              statement = connexion.createStatement();
//                              resultat = statement.executeQuery("SELECT nom, prenom FROM noms;");
//                              while (resultat.next()) {
//                                  String nom = resultat.getString("nom");
//                                  String prenom = resultat.getString("prenom");
//                                  Utilisateur utilisateur = new Utilisateur();
//                                  utilisateur.setNom(nom);
//                                  utilisateur.setPrenom(prenom);
//                                  utilisateurs.add(utilisateur);
//                              }
//                          } catch (SQLException e) {
//                              e.printStackTrace();
//                          }
//                          return utilisateurs;
//                      }
//                  }
// La particularité de notre structure ou modèle, est que notre Servlet ne sait pas qu'elle est en train de faire du SQL, elle tiens bien son rôle de Contrôleur.
// Comme nous passons par une interface, si nous changeons de base de données, il nous suffit de revoir la factory sans toucher au Contrôleur.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérer ses erreurs avec son DAO ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons jusqu'ici implenté un DAO sans faire de gestion des erreurs.
// En production, nous avons souvent des erreurs, et il faut savoir les gérer correctement si nous voulons que notre application fonctionne.
// Tout d'abord, nous créons des exceptions personalisées.
// -----------
//                  public class BeanException extends Exception {
//                      public BeanException(String message) {
//                          super(message);
//                      }
//                  }
// -----------
// Ainsi, dans le contrôleur, nous pouvons répérer que nous avons une erreur provenant soit de la base de données, soit de notre bean.
// Par exemple, nous voulons que si un client essaye d'enregistrer un nom de plus de 10 caractères, une 'BeanException' soit jetée.
// Donc, nous pouvons l'adapter dans notre classe 'Utilisateur'.
// -----------
//                  public class DaoException extends Exception {
//                      public DaoException(String message) {
//                          super(message);
//                      }
//                  }
// -----------
// De la même façon, pour nos 'DaoException', nous allons les jeter dans la classe 'UtilisateurDaoImpl'.
// -----------
//                  public class Utilisateur {
//                      private String nom;
//                      private String prenom;
//                      public String getNom() {
//                          return nom;
//                      }
//                      public void setNom(String nom) throws BeanException {
//                          if (nom.length() > 10) {
//                              throw new BeanException("Le nom est trop grand ! (10 caractères maximum)");
//                          }
//                          else {
//                              this.nom = nom;
//                          }
//                     }
//                      public String getPrenom() {
//                          return prenom;
//                      }
//                      public void setPrenom(String prenom) {
//                          this.prenom = prenom;
//                      }
//                  }
// -----------
//                  public class DaoFactory {
//                      private String url;
//                      private String username;
//                      private String password;
//                      DaoFactory(String url, String username, String password) {
//                          this.url = url;
//                          this.username = username;
//                          this.password = password;
//                      }
//                      public static DaoFactory getInstance() {
//                          try {
//                              Class.forName("com.mysql.jdbc.Driver");
//                          } catch (ClassNotFoundException e) {
//                          }
//                          DaoFactory instance = new DaoFactory(
//                                  "jdbc:mysql://localhost:3306/javaee", "root", "");
//                          return instance;
//                      }
//                      public Connection getConnection() throws SQLException {
//                          Connection connexion = DriverManager.getConnection(url, username, password);
//                          connexion.setAutoCommit(false);
//                          return connexion;
//                      }
//                      // Récupération du Dao
//                      public UtilisateurDao getUtilisateurDao() {
//                          return new UtilisateurDaoImpl(this);
//                      }
//                  }
// -----------
// Enfin, parlons un peu des transactions. Pour utiliser les transactions, il va falloir aller dans notre système DaoFactory.
// Dans le bloc 'catch', nous appelons la méthode 'rollback()' sur l'objet Connection adin d'annuler les modifications si il y a eu une erreur.
// Cela nous permet d'éviter de n'enregistrer qu'une partie de la transaction lorsqu'il y a une SQLException durant la transaction.
// -----------
//                  public class UtilisateurDaoImpl implements UtilisateurDao {
//                      private DaoFactory daoFactory;
//                      UtilisateurDaoImpl(DaoFactory daoFactory) {
//                          this.daoFactory = daoFactory;
//                      }
//                      @Override
//                      public void ajouter(Utilisateur utilisateur) throws DaoException {
//                          Connection connexion = null;
//                          PreparedStatement preparedStatement = null;
//                          try {
//                              connexion = daoFactory.getConnection();
//                              preparedStatement = connexion.prepareStatement("INSERT INTO noms(nom, prenom) VALUES(?, ?);");
//                              preparedStatement.setString(1, utilisateur.getNom());
//                              preparedStatement.setString(2, utilisateur.getPrenom());
//                              preparedStatement.executeUpdate();
//                              connexion.commit();
//                              connexion.commit();
//                          } catch (SQLException e) {
//                              try {
//                                  if (connexion != null) {
//                                      connexion.rollback();
//                                  }
//                              } catch (SQLException e2) {
//                              }
//                              throw new DaoException("Impossible de communiquer avec la base de données");
//                          }
//                          finally {
//                              try {
//                                  if (connexion != null) {
//                                      connexion.close();
//                                  }
//                              } catch (SQLException e) {
//                                  throw new DaoException("Impossible de communiquer avec la base de données");
//                              }
//                          }
//                      }
//                      @Override
//                      public List<Utilisateur> lister() throws DaoException {
//                          List<Utilisateur> utilisateurs = new ArrayList<Utilisateur>();
//                          Connection connexion = null;
//                          Statement statement = null;
//                          ResultSet resultat = null;
//                          try {
//                              connexion = daoFactory.getConnection();
//                              statement = connexion.createStatement();
//                              resultat = statement.executeQuery("SELECT nom, prenom FROM noms;");
//                              while (resultat.next()) {
//                                  String nom = resultat.getString("nom");
//                                  String prenom = resultat.getString("prenom");
//                                  Utilisateur utilisateur = new Utilisateur();
//                                  utilisateur.setNom(nom);
//                                  utilisateur.setPrenom(prenom);
//                                  utilisateurs.add(utilisateur);
//                              }
//                          } catch (SQLException e) {
//                              throw new DaoException("Impossible de communiquer avec la base de données");
//                          } catch (BeanException e) {
//                              throw new DaoException("Les données de la base sont invalides");
//                          }
//                          finally {
//                              try {
//                                  if (connexion != null) {
//                                      connexion.close();
//                                  }
//                              } catch (SQLException e) {
//                                  throw new DaoException("Impossible de communiquer avec la base de données");
//                              }
//                          }
//                          return utilisateurs;
//                      }
//                  }
// -----------
//                  @WebServlet("/Test")
//                  public class Test extends HttpServlet {
//                      private static final long serialVersionUID = 1L;
//                      private UtilisateurDao utilisateurDao;
//                      public void init() throws ServletException {
//                          DaoFactory daoFactory = DaoFactory.getInstance();
//                          this.utilisateurDao = daoFactory.getUtilisateurDao();
//                      }
//                      protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {
//                          try {
//                              request.setAttribute("utilisateurs", utilisateurDao.lister());
//                          }
//                          catch (DaoException e) {
//                              request.setAttribute("erreur", e.getMessage());
//                          }
//                          this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//                      }
//                      public void doPost( HttpServletRequest request, HttpServletResponse response ) throws ServletException, IOException {
//                          try {
//                              Utilisateur utilisateur = new Utilisateur();
//                              utilisateur.setNom(request.getParameter("nom"));
//                              utilisateur.setPrenom(request.getParameter("prenom"));
//                              utilisateurDao.ajouter(utilisateur);
//                              request.setAttribute("utilisateurs", utilisateurDao.lister());
//                          }
//                          catch (Exception e) {
//                              request.setAttribute("erreur", e.getMessage());
//                          }
//                          this.getServletContext().getRequestDispatcher("/WEB-INF/bonjour.jsp").forward(request, response);
//                      }
//                  }
// -----------
//                  <%@ page pageEncoding="UTF-8" %>
//                  <%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c" %>
//                  <!DOCTYPE html>
//                  <html>
//                  <head>
//                  <meta charset="utf-8" />
//                  <title>Test</title>
//                  </head>
//                  <body>
//                      <c:if test="${ !empty erreur }"><p style="color:red;"><c:out value="${ erreur }" /></p></c:if>
//                  	<form method="post" action="bonjour">
//                      	<p>
// 	                     	<label for="nom">Nom : </label>
// 	                     	<input type="text" name="nom" id="nom" />
//                      	</p>
//                      	<p>
// 	                     	<label for="prenom">Prénom : </label>
// 	                     	<input type="text" name="prenom" id="prenom" />
//                      	</p>
//                      	<input type="submit" />
//                      </form>
//                      <ul>
// 	                     <c:forEach var="utilisateur" items="${ utilisateurs }">
// 	                     	<li><c:out value="${ utilisateur.prenom }" /> <c:out value="${ utilisateur.nom }" /></li>
// 	                     </c:forEach>
// 	                 </ul>
//                  </body>
//                  </html>
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentez une Architecture Orientée Services (SOA) en Java //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quand vous développez une application en Java (ou autre) en entreprise, il est rare que vous commenciez dans un système vierge à partir d'une page blanche.
// Et encore plus que vous soyez le seul à travailler dessus.
// Vous arrivez donc en général dans un système composé de dizaines voire de centaines d'applications.
// Elles s'envoient des messages, communiquent et qui peuvent se trouver dans des serveurs locaux, dans des serveurs distant ou dans le cloud.
// Elles sont aussi écrites dans divers langages : Java, C#, C++, Python ou pire encore COBOL et autres hiéroglyphes.
// Se posent alors plusieurs problèmes :
//      - Dans le SI (système d'information) d'une entreprise, chaque application peut avoir son propre protocole de communication, ses propres formats de messages, etc.
//          Se pose alors la question de comment créer votre application de façon à ce qu'elle communique parfaitement avec les autres ?
//          Ou encore mieux, comment concevoir toutes les applications du SI dès le départ pour qu'elles communiquent toutes via un protocole et un format standard et compris de tous ?
//      - Comment éviter de réinventer le roue : savoir si certaines fonctionnalités existent déjà dans d'autres applications ou chercher la possibilité de réutiliser certains composant.
//      - Comment savoir à quelle URL ou IP se situe telle ou telle application avec laquelle vous voulez communiquer ? Pire encore, que se passe-t-il si cette application change d'URL ?
// Ce sont des exemples parmi d'autres de problèmes auxquels les développeurs étaient confrontés avant le développement de l'architecture orientée services (SOA).
// Vous allez voir dans ce cours comment les entreprises organisent leurs SI afin que toutes les applications communiquent très facilement via un protocole unique appelé SOAP.
// Elles se mettent à jour sans interruption de service et redeviennent à taille humaine grâce à un découpage de l'ensemble en petites applications appelées services.
// Vous allez ensuite apprendre à découper une application en services, puis vous apprendrez à créer et tester ces services dans le respect des principes de la SOA.
// Le but ici n'est pas que vous soyez capables de créer une architecture SOA à vous seuls, mais plutôt que vous sachiez créer des services qui s'intègrent dans une SOA existante.
// C'est ce qui vous sera la plupart du temps demandé quand vous intégrerez une entreprise dont le SI est basé sur cette architecture. C'est parti !
//      --> Objectifs pédagogiques :
//              --> Concevoir une application web avec une approche par composants.
//              --> Créer un web service SOAP.
//              --> Isoler et déployer une application dans des conteneurs grâce à Docker.
//              --> Sélectionner les langages de programmation adaptés pour le développement de l’application.
//              --> Interagir avec des composants externes.
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maîtrisez les principes fondamentaux de la SOA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découvrez pourquoi mettre en place une SOA ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour comprendre et assimiler les notions d'architecture orientée services (SOA), nous allons suivre tout au long de cette partie une petite entreprise fictive du nom de BUZZ.
// Cette entreprise fabrique et vend des jouets électroniques.
// Créée au début des années 1990, cette entreprise a connu une croissance continue jusqu’à nos jours.
// Son catalogue a évolué au fil des années et ses clients se sont diversifiés.
// L’entreprise a donc été amenée à faire évoluer son SI afin de s’adapter à cette croissance et aux nouveaux canaux de vente comme Internet.
// -----------
//  - Comment faisions-nous avant ?
// Jusqu’à la fin des années 1990, les entreprises exploitaient dans leurs systèmes d’informations (SI) des mainframes qui s’occupaient de toutes les opérations.
// Ainsi, notre entreprise BUZZ avait commencé par mettre en place un mainframe, une sorte de grand ordinateur central très puissant.
// Celui-ci pouvait traiter un très grand nombre de requêtes, voire faire tourner plusieurs sessions d’un système d’exploitation.
// Les développeurs déployaient alors leurs programmes dans cet ordinateur unique.
// Comme le système était unifié et que tous les programmeurs travaillaient plus ou moins dans le même environnement et avec les mêmes technologies, tout fonctionnait dans une joyeuse harmonie !
// Revenons à notre entreprise. Au début des années 2000, BUZZ a rencontré un problème :
//      --> Les procédés dans l’entreprise s’étant informatisés de plus en plus, il a fallu intégrer au SI de plus en plus de logiciels externes à forte valeur ajoutée.
// Par exemple, les dirigeants souhaitaient :
//      - Intégrer un ERP de gestion du service après vente (SAV).
//      - Mettre en place un e-commerce grâce à un CMS pour vendre les produits en ligne et profiter de l'essor de ce secteur.
//      - Automatiser la gestion des commandes des clients professionnels afin de rester dans la course face à une concurrence de plus en plus performante, rapide et informatisée.
// Chacun de ces systèmes à ajouter avait besoin d’un environnement adapté : système d’exploitation, capacité de stockage et de calcul, configuration spécifique (ports, par-feu, etc.).
// La solution était d’abandonner le bon vieux mainframe, devenu très limitant, et de le remplacer par plusieurs ordinateurs (serveurs) munis d'environnements adaptés à chaque système.
// Ainsi BUZZ se retrouvait alors à exploiter :
//      --> Un serveur pour gérer la boutique en ligne.
//      --> Un serveur pour l’ERP du SAV.
//      --> Un serveur pour les grossistes et la gestion des commandes.
//      --> Un serveur pour un ERP de comptabilité.
// BUZZ se trouvait ainsi confronté à un gros problème : comment faire communiquer tous ces différents systèmes ?
// La réponse semblait simple : faire appel à chaque système dans le format qu’il comprend.
// Ainsi, quand l’ERP, écrit en COBOL, doit appeler la boutique en ligne, écrite en PHP, pour obtenir la dernière commande d’un client, la requête doit être envoyée dans un format X compatible PHP.
/// L'ERP reçoit alors de la boutique une réponse dans un format Y qu’il doit transformer en quelque chose de compatible avec COBOL avant de l’exploiter.
// Ces transformations sont réalisées par des adaptateurs. Chaque logiciel dans le SI doit avoir un adaptateur pour communiquer avec un autre.
// Au final, à mesure que le système grandissait, on se retrouvait avec les problèmes suivants :
//      --> Le système devenait trop complexe : chaque logiciel devait gérer des dizaines d’adaptateurs pour communiquer avec des dizaines d’autres logiciels, ayant eux-mêmes d’autres adaptateurs.
//      --> Flexibilité limitée : changer la moindre fonctionnalité dans un logiciel du SI impliquait des changements en cascade dans tout le SI.
//              Les adaptateurs à mettre à jour, un redéploiement de l’ensemble, etc.
//      --> Scalabilité difficile.
//      --> Coût de maintenance trop élevé dû à la complexité du système et à l'interdépendance forte entre les composants du SI.
// -----------
//  - La solution grâce à la SOA :
// Avec l’arrivée du XML, l'architecture orientée services a fait son apparition.
// L’idée est simple : organiser les SI de façon à ce qu’ils soient composés de briques indépendantes appelées services.
// Chaque service a un nombre de fonctionnalités cohérentes et est indépendant des autres services.
// Ces services vont communiquer entre eux grâce à un protocole standard, connu et compris de tous.
//      --> Le protocole qui s’est largement imposé est le SOAP basé sur le XML. On y reviendra en détail.
// Pour bien comprendre le concept, analysons une implémentation de la SOA sous forme d’un web service.
// Il est important de distinguer l’architecture orientée objet, des web services qui sont eux une implémentation ou une application des concepts théorisés dans une SOA.
// Imaginez que vous développez un web service qui doit permettre de gérer les clients d’une banque.
// Ce web service va avoir les fonctionnalités suivantes :
//      - Récupérer un client grâce à son ID.
//      - Mettre à jour les informations d’un client.
//      - Récupérer ses mouvements de compte.
// Vous développez le service en Java qui ira interagir avec les bases de données de la banque pour accomplir les fonctions citées plus haut.
// Une fois mis en production, votre service va être appelé par un autre service qui s’occupe de l’application mobile.
// Il a besoin de faire appel aux informations que propose votre service pour afficher une page de compte à l’utilisateur final.
//      --> 1er problème :
//              Comment indiquer au service mobile où trouver votre service, les fonctionnalités qu'il propose et comment les appeler ?
//              La réponse est simple : il faut établir un "contrat" entre les services qui explique clairement comment fonctionne chaque service.
//              Ce contrat a le plus souvent le format d’un document XML appelé 'WSDL'. Sa structure est standard et connue de tous les services.
//              Vous rédigerez donc un document WSDL dans lequel vous décrirez l’URL où on peut trouver votre service.
//              Vous décrirerz aussi quelles fonctions vous proposez et quels paramètres sont requis pour chaque fonction.
//              Le service mobile n’a plus qu’à consulter ce document pour pouvoir faire appel à votre service en toute fluidité.
//      --> 2e problème :
//              Comment les autres services peuvent-ils trouver votre document WSDL pour consultation ?
//              La solution est de centraliser tous les documents WSDL dans un serveur qui tient un annuaire de ceux-ci.
//              Les différents services connaissent l’URL de ce registre. Ils le consultent pour découvrir les nouveaux services et lire les WSDL afin de communiquer ensemble.
//              Ils ont ainsi l’URL du service, ses fonctions et le type de réponse qu’il va renvoyer.
//              Ce type d’annuaire est appelé 'UDDI' (Universal Description Discovery and Integration).
//      --> 3e problème :
//              Comment faire communiquer des services écrits dans des langages différents et utilisant des technologies variées ?
//              Le XML est la solution, un langage standardisé, extrêmement flexible et personnalisable.
//              SOAP s’est donc imposé comme un protocole qui fixe les règles et les bonnes pratiques pour l’utilisation du XML dans les échanges de messages entre services.
//              Le service mobile dans notre exemple enverra alors un fichier XML grâce à une requête POST via HTTP vers votre service de gestion des clients.
//              Ce fichier contient des instructions conformes à votre contrat WSDL.
//              Il vous suffit de parser ce fichier et de renvoyer une réponse SOAP.
//      --> 4e problème :
//              Comment faire pour créer des messages SOAP conformes afin d'appeler des services ou y répondre ?
//              Bien que vous devriez comprendre la structure et le fonctionnement des fichiers XML qui répondent aux normes SOAP, vous n’aurez dans les faits jamais à en créer un vous-mêmes !
//              En effet, la plupart des langages disposent de leurs propres librairies pour vous épargner la peine de formater des fichiers XML complexes à la main.
//              En Java, la librairie par défaut est JAX-WS. Elle va vous permettre de :
//                  - Générer les WSDL : décrire les classes spécifiées dans votre service dans un fichier WSDL à publier, comme vu plus haut, dans un serveur UDDI.
//                  - Invoquer un service : il vous permettra de récupérer les fichiers WSDL et d’en générer des Class “proxy” que vous appellerez depuis votre code comme n’importe quelle Class.
//                      Jax-WS générera ensuite les messages SOAP et gérera le parsing des réponses.
// -----------
//  - Résumons :
//      --> La SOA définit les concepts qui permettent de mettre en place des SI articulés autour de services et communiquant de façon standardisée.
//      --> Un contrat WSDL est un document XML qui explique les fonctionnalités d’un service, comment l’appeler, où le trouver et quels types de réponses il renvoie.
//      --> UDDI est un serveur qui centralise tous les contrats des services.
//      --> Les services doivent communiquer via SOAP : un protocol XML standard.
//      --> En Java, on utilise des librairies comme JAX-WS pour générer les documents WSDL et les messages SOAP.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Assimilez les 8 commandements de la SOA ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour vous assurer que votre architecture SOA est fiable et exploiter au maximum son potentiel, voici 8 règles fondamentales à respecter.
// -----------
//  - Un contrat standard vous appliquerez :
// Il est important que les documents WSDL soient standarisés au maximum afin de faciliter les réutilisabilités des services.
// Cette standardisation implique par exemple des conventions de nommage standardisées, des types de données standards (types complexes qu’on verra plus tard, etc.).
// -----------
//  - Un couplage faible vous appliquerez :
// Vos services doivent êtres indépendants et faiblement couplés aux autres composants du SI.
// Ceci se concrétise en veillant à ce que tous les échanges de votre service avec le monde extérieur se fassent uniquement via SOAP.
// Le fait d’aller interroger directement un service, par exemple, crée une dépendance entre ces deux services.
// Ainsi si demain le service que vous appelez directement change d’adresse ou est supprimé, votre service n’est plus utilisable non plus.
// Le seul couplage toléré dans une SOA est celui avec un UDDI contenant vos contrats publiés.
// -----------
//  - Abstraits vos services seront :
// Les contrats que vous publiez doivent indiquer le minimum vital nécessaire à l’invocation de votre service.
//      --> En aucun cas vous ne devez publier des informations sur le fonctionnement interne du service.
// Toute information non utile directement à l’invocation du service peut être utilisée par d’autres services et générer des réponses inattendues.
// Ceci crée également un couplage fort car les autres services du SI seront dépendants de l'implémentation que vous faites.
// Par exemple : imaginez que vous exposez une fonction permettant d’avoir la liste complète des clients.
// Pour avoir cette liste, vous avez une méthode interne qui prend un paramètre “limit” qui fixé à -1 retourne la liste complète de tous les clients.
// Le fait de publier cette fonction interne dans votre WSDL peut tenter d’autres services qui veulent avoir juste les 10 premiers clients à appeler votre fonction interne.
//      --> Problème : 1 mois plus tard, vous vous rendez compte que cette fonction peut bien fonctionner sans le paramètre "limit".
//              En effet, de toute façon, elle sera toujours amenée à retourner la liste complète des clients, et vous changez donc votre fonction.
//              Ceci aura comme conséquence que tous les services appelant votre fonction interne se retrouvent avec une erreur en guise de réponse à leurs requêtes.
//              Ce qui les empêcherait, de ce fait, de fonctionner correctement.
//      --> Solution : publiez toujours le strict minimum à l’invocation de votre service.
// -----------
//  - Des services réutilisables vous développerez :
// La réutilisabilité d’un service se mesure à son indépendance de la logique de son processus métier.
// En d’autres termes, votre service doit retourner les réponses les plus neutres possibles afin que celles-ci soient réutilisables dans différents composants du SI.
// Exemple : votre service retourne une liste de produits avec leurs détails : nom, image, description, prix.
// Vous savez que votre service sera appelé par l’application web qui affichera des promotions pendant la période de Noël.
// Donc vous pouvez être tenté de retourner le prix final du produit déduction faite des ristournes.
// Félicitations, vous venez de manquer au 4e commandement !
// Vous avez laissé la logique métier influencer la logique de votre service. Votre service n’est pas réutilisable.
// Pourquoi ? Imaginez qu’un service s’occupe de la vente des produits en gros aux professionnels qui eux ne bénéficient pas des réductions de Noël réservées aux particuliers.
// Ceux-ci souhaitent avoir les prix des produits. Votre service n’est pas exploitable dans ce cas car le prix retourné est spécifique à la logique de l’application web et son contexte.
//      --> Solution : retournez autant que possible des données neutres.
//              C’est au service appelant d’appliquer sa logique et de manipuler ces données retournées pour les adapter à son cas d’utilisation.
// -----------
//  - Autonomes vos services seront :
// Quand vous développez un service web, faites en sorte qu’il soit le plus autonome possible, c'est-à-dire qu’il dispose de ses propres ressources, libraries, containers, etc.
// Un bon service web est un service web que vous pouvez packager dans un war ou jar par exemple et le faire fonctionner dans n’importe quelle machine de façon indépendante.
// -----------
//  - Sans état (stateless) vos services seront :
// Quand vous développez un service, il faut veiller qu'aucune requête ne dépende de la réponse d’une autre.
// Exemple : Votre service gère le panier dans un e-commerce. Vous pouvez être tenté d’implémenter le fonctionnement suivant :
// Un service externe appelle le vôtre en ajoutant un produit A pour le client Robert, puis fait un autre appel pour ajouter un produit B pour le même client.
// Vous gardez ensuite en mémoire une session qui gère le panier de cet utilisateur de façon à ce que quand le client souhaite passer la commande, le service externe vous passe la requête "commander".
// Comme vous avez tout ce qu’il faut en session, il suffit d’enregistrer la commande.
// Votre service a donc maintenu une session en état pendant une période assez longue, et le service externe comptait sur cet état précis pour passer la commande.
// Un des inconvénients de cette approche est que si vous avez 2000 clients sur la boutique, vous saturez la mémoire vive avec 2000 sessions actives.
// De plus, votre service doit rester actif pour maintenir les sessions ce qui réduit la scalabilité du système :
//      --> En d’autres termes on aimerait pouvoir ajouter des instances de votre service et en supprimer en fonction du trafic.
//              Or, comme votre service a un état, il est difficile de supprimer une de ces instances sans perdre des paniers par exemple.
//      --> Solution : quand un service externe demande à ajouter un produit A au client Robert, il suffit d’enregistrer cette donnée dans le système de gestion des données.
//              Et ensuite de retourner l’id du panier. Quand le service externe souhaite ajouter un autre produit ou passer la commande, il est de sa responsabilité de vous passer l’id du panier.
//              Celui sur lequel il faut faire l’opération. Ainsi n’importe quelle instance de votre service peut répondre à une telle demande, votre service est donc stateless.
// -----------
//  - Découvrabilité :
// Comme on l’a vu plus tôt dans le cours, votre service doit pouvoir être trouvé facilement par les autres services grâce à la publication de son contrat (WSDL) dans un annuaire de type UDDI.
// -----------
//  - Composabilité :
// Ce commandement est l’aboutissement des 7 commandements précédents.
//      --> Vous avez créé un service à couplage faible, abstrait, réutilisable, autonome, stateless et découvrable.
// Il est temps de profiter de votre dur labeur !
// Votre service doit maintenant participer à la composition d’une application ou d’un SI plus large en proposant ses fonctions à différents composants.
// La réutilisabilité du service doit être exploitée au maximum afin d’optimiser le système final.
// Tout cela peut vous paraître un peu abstrait, mais ne vous inquiétez pas.
// Vous allez appliquer tous ces commandements quand vous construirez pas à pas un service web dans la 2e partie et ils prendront plus de sens pour vous !
// Mais avant, dans le prochain chapitre, vous allez aider l’entreprise BUZZ à découper son système en services et dresser le nouveau diagramme du SI flambant neuf sur lequel l’entreprise va reposer!
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez une SOA à partir d’un cas réel //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous voilà embauché par BUZZ pour faire évoluer leur système vieillissant vers une nouvelle architecture SOA moderne.
// Nous n’allons pas faire ici le travail des architectes logiciels mais plutôt essayer de comprendre la logique du découpage d’un système en services.
// Eh bien si vous travaillez sur un SI existant d’une entreprise par exemple, imaginez qu’on vous demande de créer un service de gestion des stocks.
// Il vous revient de déterminer les limites et les fonctionnalités de votre service pour qu’il réponde aux 8 commandements qu’on a vu précédemment et qu’il soit un service web IRA :
//      - I : Interesting.
//      - R : Reusable.
//      - A : Atomic.
// Si vous ne savez pas découper les fonctionnalités qu'on vous demande en services dignes de ce nom, vous n'arriverez jamais à l'étape : coder.
// -----------
//  - Rappel du système de départ :
// Comme vous vous souvenez, BUZZ dispose d’un système vieillissant dans lequel tous les composants communiquent ensemble directement.
// Et ce, grâce à une armada d’adaptateurs pour convertir, traduire et reformater les messages entre chaque application.
// Revenons en détail sur les différents composants.
//      - ERP SAV Il s’agit d’un logiciel clé en main propriétaire acheté par l’entreprise.
// Le protocole de communication de ce logiciel est fixé par le constructeur. Dans ce cas, il s’agit du format JSON via HTTP.
// En d’autres termes, si le composant "boutique en ligne" voudrait récupérer les détails d’un incident relatif à un client afin d’afficher le suivi de son traitement à celui-ci.
// Il faut que la boutique en ligne envoie une requête au format JSON, elle recevra également une réponse au même format qu’elle devra comprendre et traiter.
//      - ERP Comptabilité :
// Ce logiciel est également propriétaire. Le protocole de communication proposé par celui-ci est CSV via FTP.
//      - Boutique en ligne :
// Il s’agit d’un CMS de type Prestashop qui fournit une boutique clé en main. Le protocole de communication ici est XML via HTTP.
//      - Commandes Grossistes :
// Ce module est le nouveau web service que vous allez devoir développer.
// À ce stade, comment allez-vous transformer ce système pour le baser sur une architecture orientée services si aucun des composants ne communique via SOAP.
// Ni ne dispose pas de WSDL et en plus chacun a son propre protocole réseau préféré : FTP, HTTP, etc.
// Ne vous inquiétez pas, nous allons voir comment nous allons pouvoir harmoniser tout cela grâce à un ESB.
// -----------
//  - Définir les web services :
// Vous allez d’emblée éliminer : “la boutique en ligne”, “ERP comptabilité” et “ERP SAV” de la liste des composants à découper car ce sont des systèmes indivisibles voire propriétaires ou fermés.
// Il reste le nouveau venu : le composant des commandes des grossistes.
//      - Étape 1 : Définir les fonctionnalités du composant :
// La première étape consiste à établir clairement une liste des fonctionnalités qu’on attend du composant à développer, celles-ci nous aideront plus tard à les assembler en services.
// Vous serez souvent amené à dresser cette liste de fonctionnalités à partir d’un descriptif du fonctionnement du composant.
// Voici le descriptif du module "Commandes Grossistes" :
//          --> Le composant devra recevoir des fichiers CSV par FTP dans lesquels des grossistes auront dressés la liste des produits à commander et leurs quantités.
//          --> Ce fichier est ensuite stocké dans un répertoire. Les grossistes doivent pouvoir le mettre à jour ou le supprimer tant que la commande n’a pas été traitée.
//          --> Votre module doit passer à des heures fixes (10h et 16h) pour relever les fichiers et passer les ordres des commandes.
//          --> Il doit ensuite créer un fichier CSV de réponse à mettre dans le même répertoire FTP et qui contient le suivi des commandes : acceptée, traitée, expédiée, annulée, etc.
//          --> Les grossistes reçoivent un email quand leurs commandes passent à certains états : traitée, annulée.
// Vous allez maintenant définir une liste de fonctionnalités à partir de ce descriptif :
//          - Fonction d’upload et de suppression de fichiers de commandes CSV via FTP.
//          - Fonction de validation des fichiers CSV (bon format et contenu).
//          - Fonction de récupération à heures fixes des commandes.
//          - Fonction de passage des ordres des commandes.
//          - Fonction de suivi des commandes : vérification du statut et mise à jour du CSV de suivi.
//          - Envoi des emails en fonction des statuts des commandes.
// Maintenant que nos fonctionnalités sont clairement définies, on va pouvoir créer un découpage des web services, le plus optimisé possible.
//      - Étape 2 : Découper le composant en web services :
// Découper un composant logiciel en web services est une tâche bien plus délicate que ce que l’on peut penser.
// Dans notre cas, plusieurs solutions sont possibles. La plus intuitive serait :
//          --> Un service qui s’occupe de tout ce qui est opérations sur les CSV : upload, validation, etc. ;
//          --> Un service qui s’occupe des commandes.
// Ceci paraît clair et propre, mais ce genre de découpage est exactement ce qu’il faut éviter.
// Pour vous aider à découper vos web services de manière à ce qu’ils soient compatibles avec une SOA, il faut respecter les 2 règles suivantes :
//          --> Votre web service doit être IRA.
//          --> Votre web service doit respecter les 8 commandements.
// Qu’est-ce qu’un web services IRA ?
// I : Interesting.
// R : Reusable.
// A : Atomic.
//          - Interesting :
// Les fonctionnalités de votre web service doivent être intéressantes non seulement pour servir la finalité du composant que vous développez mais potentiellement intéressantes.
// Et cela, pour l’ensemble des web services du système.
// Exemple : Un service qui met à jour un champ dans une table de base de données dès qu’une commande est ajoutée est totalement inintéressant.
// En effet, il s’agit d’un service qui traite du fonctionnement interne du processus de commande (par exemple dans la boutique en ligne).
// Aucun autre web service ne sera intéressé par la mise à jour d’un champ obscur dans une table aux tréfonds de la base de données d’un CMS !
//          - Reusable :
// Votre web service doit être réutilisable dans d’autres contextes et scénarios. Il ne doit pas être lié à la logique du processus dans lequel il intervient.
// Exemple : un web service qui renvoie les 10 derniers produits ajoutés au stock n’est intéressant que dans un cadre précis (par exemple pour afficher les nouveautés dans une page de la boutique).
// Alors qu’un web service qui renvoie n’importe quel nombre de produits qu’on lui demande est potentiellement intéressant pour beaucoup d’autres web services.
// Par exemple l’ERP Comptabilité peut faire appel à ce web service pour récupérer l’ensemble des prix des produits dans le catalogue !
//          - Atomic :
// Atomic veut dire indivisible et élémentaire. Évitez les fonctions dans vos web services qui par exemple passent les commandes, gèrent les retours, suppriment les produits et font le café.
// Évitez aussi une trop grande atomicité, on ne va pas créer un web service pour récupérer le nom d’un produit et l’autre sa description par exemple.
// Le tout est que celui-ci soit un bloc naturel et élémentaire.
// Exemple : Un service qui a une fonction qui renvoie toutes les informations sur tous les grossistes et leurs commandes depuis la création de leurs comptes.
// Ce web service n'est clairement pas atomic : il sera composé d'une dizaines de composants qui iront chercher les infos des grossistes.
// Un web service atomic serait plutôt celui qui aura des fonctions séparées : une pour renvoyer la liste des grossistes, une autre la liste des commandes, etc.
// La logique étant que si nous voulons toutes ces informations, il suffit d’appeler chacune de ces fonctions et d'agréger les résultats.
// Maintenant que vous avez pris le temps de réfléchir au problème, voici une proposition de découpage.
//          - Service 1 :
// Reçoit un fichier en entrée et l’upload dans un répertoire. Il peut également supprimer un fichier ou le remplacer.
// Intéressant ? Bien sûr, beaucoup de composants peuvent être intéressés par la récupération et l’upload de fichiers divers et variés.
// Réutilisable ? Absolument. Il n’est lié à aucune logique en particulier ni à aucun format de fichier, n’importe quel composant peut le réutiliser.
// Atomic Oui. Le service ne fait que uploader des fichiers, c’est une fonctionnalité tout à fait fondamentale et indivisible.
//          - Service 2 :
// Reçoit des fichiers dans des formats populaires (CSV, XML, etc.) et les valide.
// Intéressant ? Tout à fait. La plupart des composants sont amenés à utiliser des fichiers de ce type et doivent les valider.
// Réutilisable ? Bien sûr. Un service qui centralise la validation des fichiers selon des critères établis à l’avance, sera appelé par tous les composants au besoin.
// Ceci évitera que chacun réécrive la logique de validation de chaque fichier.
// Atomic Oui. La validation est un processus indivisible.
//          - Service 3 :
// Reçoit en entrée un fichier CSV puis place les ordres de commandes.
// Reçoit en entrée une information de mise à jour de commande, puis met à jour le CSV de suivi des commandes.
// NOTE Ici on a un web service qui offre plusieurs fonctionnalités. C’est souvent ce genre de web service que vous allez rencontrer. Les règles dans ce cas s’appliquent fonction par fonction.
// Intéressant ? Oui. Avoir un moyen de placer des commandes et d'assurer leur suivi via un simple fichier CSV pourrait intéresser plusieurs composants et entrer dans plusieurs cas d’utilisation.
// Réutilisable ? Oui. Fonction 1 : Plusieurs composants pourraient se servir de ce service pour placer des commandes très simplement via CSV.
// Par exemple, un service qui s’occupe des ventes privées ou groupées, pourrait l’utiliser pour passer les commandes.
// Et cela, sans avoir à recréer l’ensemble de ce que nous mettons en place pour les commandes des grossistes.
// Fonction 2 : Absolument ! Tous les composants du système qui entrent dans le traitement de commande feront appel à cette fonction pour mettre à jour le statut des commandes.
// Exemple : les systèmes de paiement, de gestion de stock, d'expéditions, de retours, etc.
// Atomic Oui. Le processus de passage de commande est un processus cohérent, extrêmement interconnecté et qui se fait en un seul bloc.
// Vous aurez donc compris la logique de découpage, je vous donne les 2 derniers services nécessaires et je vous laisse vérifier s’ils sont conformes aux règles.
//          - Service 4 :
// Un service de mailing qui sera appelé par le service de commande pour envoyer des emails aux grossistes pour les notifier de l’évolution de leurs commandes.
// Bien entendu, ce service peut être utilisé par n’importe quel autre composant pour envoyer des emails.
//          - Service 5 :
// Un service qui implémente une fonction de type CRON, qui pourra appeler à intervalles réguliers d’autres services.
// Dans notre cas, il servira à appeler le service 3 pour qu’il récupère les CSV à des heures précises.
// Bravo ! vous venez de découper l'application de gestion des commandes des grossistes en plusieurs services et vous avez justifié votre découpage.
// Cependant, tout cela ne sert à rien si vos services ne peuvent pas communiquer avec les autres composants du SI.
// Comment allez-vous faire si vous voulez passer les détails d'une commande à l'ERP comptabilité pour prise en compte ?
// Ou si vous voulez demander à la boutique en ligne s'il n'y a pas des commandes en attente sur un stock pour pouvoir le vendre de votre côté à un grossiste qui en a fait la demande ?
// Eh oui! Je vous rappelle que vos services ne parlent pas encore la même langue ! Regardons comment remédier à cela.
// -----------
//  - Faire communiquer les composant "Non SOAP" grâce à un ESB :
// Nous allons dans cette section survoler les concepts d'un ESB sans pour autant entrer dans les détails.
// Votre but premier dans ce cours est de savoir créer des services compatibles avec une architecture SOA et les faire communiquer ensemble.
// Le reste relève plus du travail d'un architecte logiciel !
// Si ce qu'on a vu jusque-là vous parait trop théorique, tenez bon quand même, dans la prochaine partie on écrira du code et vous allez voir, ça ira mieux !
//      - Quel est notre problème ?
// Notre problème réside dans le fait que nous avons un système incluant plusieurs composants (logiciels, services, etc.) ne communiquent pas via les mêmes protocoles.
// En effet, ils ne sont pas écrits dans les mêmes langages et qui sont malgré tout extrêmement dépendants les uns des autres.
// Une solution serait d'écrire des bouts de code qui traduisent les messages de chaque composant en quelque chose de compréhensible par le composant à appeler.
// Par exemple, si vous voulez que votre service 3 envoie à l'ERP comptabilité le résumé de chaque commande afin que les mouvements rentrent dans les comptes.
// Il vous faudra communiquer avec lui via CSV/FTP. Or votre service communique uniquement en SOAP (via des fichiers XML).
// Donc la solution évidente est d'écrire du code qu'on appellera "adaptateur" qui générera un format CSV plutôt que XML. Puis vous l'enverrez via FTP à l'ERP en question.
// Malheureusement ce n'est pas si facile que ça. Imaginez maintenant que vous êtes dans un SI plus grand et que vous devez communiquer avec une centaine de logiciels et services.
// Allez-vous écrire une centaines d'adaptateurs ? Les autres logiciels devront en faire autant ? Qu'en est-il des logiciels propriétaires qu'on ne peut pas modifier ?
// Vous allez certainement créer d'autres adaptateurs de votre côté pour comprendre leurS messageS, par exemple pour interpréter une requête via CSV reçue de l'ERP compta.
//      - L'ESB à la rescousse :
// Un Enterprise Service Bus (ESB) est un composant central qui se positionnera comme un interlocuteur unique pour tous les composants du SI.
// Ainsi, quand vous voudrez appeler un composant X, vous n'irez plus jamais lui parler directement. Vous ne saurez même pas quel protocole il accepte, ni son URL !
// Il suffira d'envoyer une requête dans votre protocole préféré (dans notre cas SOAP) à l'ESB.
// Celui-ci s'occupera ensuite de faire le nécessaire pour transformer votre message et l'adapter avant de le transférer au composant demandé.
// Il fera ensuite la même chose pour la réponse avant de vous la servir sur un plateau d'argent, reste plus qu'à déguster !
//      --> Euh... l'ESB n'a pas de pouvoirs magiques, il faudra bien lui fournir des adaptateurs ?
// Vous avez parfaitement raison, il faudra bien écrire des adaptateurs à fournir à l'ESB afin que celui-ci sache comment traduire les messages.
// Sauf que l'énorme avantage ici, c'est qu'on n'aura plus une architecture en plat de spaghetti. Vos adaptateurs seront tous centralisés au même endroit.
// De plus vous n'avez plus besoin de dupliquer vos adaptateurs entre différents composants.
// Par exemple, dans l'exemple précédent, si 10 autres services ont besoin aussi de communiquer avec l'ERP Comptabilité, vous allez tout simplement leur fournir votre adaptateur.
// Vous vous retrouvez avec 10 copies de votre code éparpillées dans le système. Imaginez qu'il y ait un bug à résoudre ? Aïe !
// Il faudra appeler tous les développeurs responsables des différents services pour leur demander de faire les changements.
// Certains d'entres eux seront peut-être obligés d'arrêter le service pour intégrer votre modification, mettant en péril le fonctionnement de tout le SI. Pas joli joli tout ça.
// Maintenant que vous mesurez l'importance d'un ESB, regardons à quoi ressemblera notre SI.
// Maintenant quand vous écrivez un adaptateur, il n'en existera qu'une seule copie placée dans l'ESB. Vous pouvez le modifier et l'améliorer à volonté en toute transparence.
// Pour compléter notre survol de l'ESB, voici les avantages qu'il offre :
//          --> Couplage faible : les composants de votre SI n'ont plus à se connaître pour communiquer. Chaque service ne communique plus qu'avec l'ESB.
//                  Vous pouvez donc remplacer à votre guise un service par un autre, et gagner en liberté dans le choix des langages et des environnements.
//          --> Standardisation : quand vous créez un nouveau service, il n'est plus nécessaire de passer des semaines à l'intégrer et le faire communiquer avec les composants du SI.
//                  L'intégration est très simple et se fait uniquement avec l'ESB. Ceci va aider également l'entreprise à établir des standards dans les développements des services.
//                  En effet, il n'y a plus de contraintes d'intégration.
//                  Tous les services à terme se ressembleront dans leurs structures et modes de fonctionnement, ce qui simplifie grandement la maintenance.
//                  Cela simplifie aussi l'interchangeabilité des postes des développeurs et bien sûr le coût !
//          --> Scalabilité : il est maintenant beaucoup plus facile d'avoir plusieurs instances de votre service pour répondre par exemple à un trop grand nombre de requêtes.
//                  Ainsi, si votre service est en surcharge et ne répond plus, l'ESB pourra rediriger les requêtes vers une autre instance de celui-ci.
//                  Ceci permettant ainsi au système de continuer à fonctionner sans ralentissement ou interruption.
//          --> Routage : l'ESB va vous permettre de rediriger les requêtes très finement en fonction des paramètres de votre choix.
//                  Imaginez que vous avez décidé de créer une V2 de votre service avec des améliorations significatives qui impliquent des changements dans la façon de l'appeler.
//                  Grâce à l'ESB, vous allez rediriger les requêtes arrivant à votre service vers la bonne version de celui-ci selon si elles sont compatibles V1 ou V2.
// L'ESB offre de nombreux autres avantages comme ceux liés au messaging, aux protocoles non standards (autres que HTTP), etc.
// Néanmoins ceux-ci nécessiteront la maîtrise d'autres concepts qui ne font pas partie de ce cours.
// -----------
//  - Résumons :
//      --> Quand vous découpez un composant en service, veillez à ce que chaque service soit IRA et respecte les 8 commandements.
//      --> L'ESB est un composant central qui va se positionner comme un interlocuteur unique pour tous les autres composants.
//              Ainsi, éliminant de fait les problèmes de communication et donnant au système une vraie consistance.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentez une SOA grâce à JAX-WS et SOAP/WSDL ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mettez en place l'environnement de développement //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// IntelliJ :
//      - Create New Maven Project > Create from Archetype > Maven WebApp > Name : lifeleft.
//      - Ensuite, nous pouvons supprimer le fichier 'lifeleft/src/main/webapp/WEB-INF/web.xml'.
//      - Puis, nous pouvons créer le dossier : 'lifeleft/src/main/java'.
//      - Nous devons indiquer à IntelliJ que c'est dans ce dossier que se trouvera notre code : Project Structure > Modules > Sélectionner le dossier 'java', puis cliquer sur le bouton 'Sources'.
//      - Enfin, nous pouvons créer le package 'org.vitu.lifeleft' dans le dossier Java.
// GlassFish :
//      - Ouvrir une invite de commande, et se rendre dans le dossier bin du dossier GlassFish.
//      - Executer la commande : 'asadmin start-domain domain1', 'domain1' étant le domaine par défaut. Le port nous est retourné par l'invite de commande : 'Admin Port: 4848'.
//      - A présent nous pouvons vérifier le fonctionnement du serveur dans un navigateur, en requêtant l'adresse 'localhost:4848'.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez un web service Bottom-up ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Les méthodes Top-down et Bottom-up :
// Il y a deux principales méthodes pour créer un web service.
//      - 1- Top-down :
//          Il s'agit de la méthode la plus utilisée en entreprise. Cette méthode est aussi appelée 'Contract First'.
//              --> Il s'agit d'établir avant tout un contrat qui dit tout sur le fonctionnement du service avant de l'implémenter. Ce contrat n'est rien de plus qu'un fichier WSDL.
//          Vous établissez donc un fichier WSDL qui décrit votre service : les opérations possibles, les paramètres à passer et leurs types, etc.
//          Une fois ce contrat établi, vous créez le code nécessaire à son implémentation.
//          Rassurez-vous, vous n'aurez pas à écrire à la main une Class à partir d'un XML indigeste, il y a heureusement des moyens pour automatiser tout cela.
//              --> En Java, la solution la plus populaire est JAX-WS. Nous y reviendrons en détails.
//      - 2- Bottom-Up :
//          Il s'agit là de la manière la plus intuitive et facile pour créer un service.
//          Vous créez votre code qui fait les opérations que vous voulez : dans notre cas une Class qui calcule le temps restant à vivre en fonction des paramètres passés.
//          Puis vous générez automatiquement un WSDL à partir de cette Class. Là encore, JAX-WS le fera automatiquement.
//          Comme tout bon informaticien qui se respecte, nous allons commencer par le plus facile : Bottom-Up.
// -----------
//  - Qu'est ce que JAX-WS ?
// Java API for XML Web Services (JAX-WS) est une API de Java qui facilite la création de web services.
// Pour bien démystifier ce terme, sachez que JAX-WS est exactement la même chose que d'autres API que vous avez dû déjà utiliser comme java.lang (qui vous fournit justement String, Integer, etc.).
// Ou encore java.io (pour manipuler les fichiers, entre autres) ou java.sql.
//              --> AX-WS va permettre de cacher entièrement la complexité des communications impliquant SOAP et WSDL.
//      - Côté web service : Quand un service externe appellera votre web service, il lui passera un simple fichier XML aux normes SOAP.
//          Sans JAX-WS, vous devriez récupérer ce fichier et le parser pour essayer de comprendre quelles méthodes on cherche à invoquer et quels sont les paramètres passés.
//          Je vous laisse deviner les centaines de lignes de code à écrire pour parser correctement un XML et faire appel aux bonnes méthodes dans les bonnes classes !
//          JAX-WS vous dispense de ce travail. Quand vous recevez un appel à votre web service, il va interpréter le message SOAP et appeler la bonne méthode dans votre code.
//          Et ce, exactement comme n'importe quelle méthode appellera une autre.
//          Mieux encore, quand vous retournerez une réponse, JAX-WS construira une réponse SOAP conforme et l'enverra au client.
//          De votre côté, vous n'y verrez que du feu. Vous vous contenterez de créer une Class comme celle qu'on a vu plus haut et y ajouter une annotation. JAX-WS fera le plus dur.
//      - Côté Client : Vous serez amenés à créer des clients pour appeler des web services dont vous ne connaissez rien.
//          Vous n'aurez qu'un fichier WSDL complexe et long comme le bras pour comprendre comment les appeler, à quelle URL les trouver, quels paramètres passer et quel type de réponse recevoir.
//          Vous imaginez bien qu'écrire du code pour parser un XML à chaque fois pour comprendre le fonctionnement d'un nouveau service est à la fois lent et fastidieux.
//          JAX-WS, là encore, vous dispense de tout ça. L'idée est simple : vous lui donnez l'emplacement du WSDL du nouveau service auquel vous voulez faire appel.
//              --> Il se charge de le parser et de créer des classes Java représentant le service en question.
//          Vous n'avez plus qu'à appeler les classes créées comme vous appellerez n'importe quelle Class. Magique non ? :magicien:
//          Bien sûr, JAX-WS propose d'autres fonctionnalités. Mais ces deux-là sont les principales que nous allons aborder.
//              --> Passons à l'application !
// -----------
//  - Description du web service LifeLeft :
// Votre web service devra donc recevoir les paramètres suivants :
//      - Un prénom de type String.
//      - Un sexe de type String (homme/femme).
//      - Une année de naissance de type Integer.
// Le service retourne une réponse de type String correspondant à prénom et nombre d'années restant à vivre.
// Pour calculer on se base sur l'espérance de vie en France qui est de :
//      - Hommes : 79 ans.
//      - Femmes : 85 ans.
// -----------
// Nous allons écrire un service qui va s'efforcer à calculer le nombre d'années restant à vivre, en fonction de l'âge de la personne et de son sexe.
//      - Une fois notre classe et notre méthode prête, nous n'avons plus qu'à les annoter avec les annotations '@WebService' '@WebMethod'.
//      - A ce moment-là nous pouvons packager notre application avec Maven install, après avoir ajouté le packaging war de maven dans les plugin du pom.xml.
//      - Dans la un console, démarrer le serveur glassfish 'asadmin start-domain domain1', puis se rendre sur 'localhost:8080'.
//      - Maintenant, nous n'avons plus qu'à nous rendre sur GlassFish > Applications > Location : sélectionner le fichier .war > Vérifier que le type est bien 'Web Application' > Ok.
//      - Si l'application n'arrive pas à se déployer, copier puis coller le .war dans le dossier 'C:\Users\Emile\Desktop\JAVA\java-util\glassfish5\glassfish\domains\domain1\autodeploy'.
//      - Ensuite, aller dans GlassFish > Applications > Launch > Une page s'ouvre, cliquer sur le lien écoutant le port 8080 > 'Hello World!' s'affiche, c'est la page par défaut 'index.jsp'.
//      - A la fin de l'url, ajouter le nom donné dans l'annotation '@WebService' puis entrée, cela nous affiche notre service.
//      - Une page d'information s'affiche avec l'url du service, ainsi que le contrat WSDL, en le cliquant, cela nous ouvre le contrat XML généré.
// Maintenant, pour tester notre service, nous allons utiliser une fonctionnallité de GlassFish :
//      - Il nous faut ajouter '?Tester' à la fin de notre url de service.
//      - Nous retrouvons notre méthode, avec des champs pour chacun des paramètres, de sortes à tester notre service.
// Pour arrêter le serveur : asadmin stop-domain domain1.
// -----------
//  - Créer un service Bottom-Up :
//      - Créez l'implémentation du service :
//          Revenez sur le projet vide que nous avons créé précédemment.
//          Vous allez maintenant créer une classe classique qui implémente les fonctionnalités dont on a parlé.
//          Faites un clic droit sue le Package 'com.lifeleft' puis sélectionnez New > java Class. Nommez-la 'LifeLeftService'.
//          Voici une implémentation. Celle-ci n'intègre pas la gestion des erreurs que nous verrons dans un autre chapitre.
//          Néanmoins tout est défini pour que vous puissiez plus tard gérer cela avec un minimum de code.
//                  package com.lifeleft;
//                  import java.time.Year;
//                  public class LifeLeftService {
//                      private static final Integer ESPERANCE_VIE_HOMMES = 79;
//                      private static final Integer ESPERANCE_VIE_FEMMES = 85;
//                      String homme = "homme";
//                      String femme = "femme";
//                      Integer evDeReference = 0;
//                      public String  anneeRestantesAVivre (String prenom, String sexe, Integer anneeNaissance) {
//                          if(sexe.equals(homme)) evDeReference = ESPERANCE_VIE_HOMMES;
//                          else evDeReference = ESPERANCE_VIE_FEMMES;
//                          //Remarque, en cas de problème, vous pouvez changer Year.now().getValue() par Calendar.getInstance().get(Calendar.YEAR)
//                          Integer anneeRestantes = evDeReference -(Year.now().getValue() - anneeNaissance );
//                          return "Bonjour " + prenom + ", il vous reste " + anneeRestantes + " ans à vivre, profitez-en au maximum !";
//                      }
//                  }
//          Cette implémentation ne marchera pas comme attendu si l'utilisateur a un âge supérieur à l'espérance de vie moyenne.
//          Le but ici est d'avoir une méthode la plus basique et simple possible. Si vous vous sentez à l'aise, n'hésitez pas à l'améliorer !
//          Je vous recommande néanmoins pour la suite des exemples du cours de continuer à travailler avec cette version afin de vous concentrer principalement sur les concepts abordés.
//      - Explications du code :
//          En partant de la classe vide que vous avez créée, voici les explications :
//              - Lignes 7 et 8 : On crée ici deux variables statiques et finales qui contiennent nos valeurs constantes à savoir les espérances de vie.
//              - Lignes 10 et 11 : On définit ici les valeurs qu'on accepte pour désigner le sexe.
//                  Bien sûr dans le code à ce stade nous n'avons besoin que d'une seule valeur (homme ou femme) pour déduire par élimination le sexe.
//                  Néanmoins on définit ici les deux pour que nous puissions plus tard retourner une erreur si ce que nous avons reçu ne correspond ni à l'un ni à l'autre.
//              - Ligne 13 : evDeReference est l'espérance de vie (ev) que nous choisirons comme référence selon que l'utilisateur soit une femme ou un homme.
//              - Ligne 15 : on définit une simple fonction public qui accepte les 3 paramètres nécessaires.
//              - Lignes 17 et 18 : on fixe la valeur de evDeReference selon le sexe.
//              - Ligne 21 : on effectue le calcul. (Year.now().getValue() - anneeNaissance ) nous donne l'âge de l'utilisateur. Il suffit ensuite de le soustraire de l'espérance de vie moyenne.
//              - Ligne 23 : On retourne une phrase pour annoncer la nouvelle !
//          À présent, on va devoir exposer cette méthode de cette Class en tant que web service. C'est là que JAX-WS vient à la rescousse.
//          Voici le résultat :
//                  package com.lifeleft;
//                  import javax.jws.WebMethod;
//                  import javax.jws.WebService;
//                  import java.time.Year;
//                  @WebService(serviceName = "LifeLeft")
//                  public class LifeLeftService {
//                      private static final Integer ESPERANCE_VIE_HOMMES = 79;
//                      private static final Integer ESPERANCE_VIE_FEMMES = 85;
//                      String homme = "homme";
//                      String femme = "femme";
//                      Integer evDeReference = 0;
//                      @WebMethod
//                      public String  anneeRestantesAVivre (String prenom, String sexe, Integer anneeNaissance) {
//                          if(sexe.equals(homme)) evDeReference = ESPERANCE_VIE_HOMMES;
//                          else evDeReference = ESPERANCE_VIE_FEMMES;
//                          //Remarque, en cas de problème, vous pouvez changer Year.now().getValue() par Calendar.getInstance().get(Calendar.YEAR)
//                          Integer anneeRestantes = evDeReference -(Year.now().getValue() - anneeNaissance );
//                          return "Bonjour " + prenom + ", il vous reste " + anneeRestantes + " ans à vivre, profitez-en au maximum !";
//                      }
//                  }
//          Vous l'avez remarqué, je n'ai eu à ajouter que 2 annotations :
//              --> @WebService : Cette annotation dit simplement à JAX-WS que cette Class est à exposer en tant que web service.
//                      Elle peut prendre plusieurs paramètres, j'ai choisi de lui en passer un seul ici : serviceNname = "LifeLeft".
//                      Ce nom qu'on vient de donner à ce service servira ensuite pour accéder à notre service via son URL.
//              --> @WebMethod : Cette annotation désigne cette méthode comme une méthode à exposer.
//                      Normalement si on ne précise pas cette annotation, toutes les méthodes de la Class seront exposées.
//                      Néanmoins, je vous recommande d'ajouter cette annotation à chaque méthode que vous voulez exposer.
//                      Ainsi, nous aurons la liberté d'ajouter d'autres méthodes supplémentaires pour notre usage interne.
//                      Et cela, sans que celles-ci puissent être appelées par les services extérieurs.
//      - Modifier le pom.xml :
//          Dernière étape, nous allons ajouter 2 plugins à Maven. Voici le résultat :
//                  <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
//                    <modelVersion>4.0.0</modelVersion>
//                    <groupId>com.lifeleft</groupId>
//                    <artifactId>lifeleft</artifactId>
//                    <packaging>war</packaging>
//                    <version>1.0</version>
//                    <name>lifeleft : combien vous reste-t-il à vivre?</name>
//                    <build>
//                      <finalName>lifeleft</finalName>
//                      <plugins>
//                        <plugin>
//                          <artifactId>maven-war-plugin</artifactId>
//                          <configuration>
//                            <failOnMissingWebXml>false</failOnMissingWebXml>
//                          </configuration>
//                        </plugin>
//                        <plugin>
//                          <groupId>org.apache.maven.plugins</groupId>
//                          <artifactId>maven-compiler-plugin</artifactId>
//                          <version>3.7.0</version>
//                          <configuration>
//                            <source>1.8</source>
//                            <target>1.8</target>
//                          </configuration>
//                        </plugin>
//                      </plugins>
//                    </build>
//                  </project>
//          Vous précisez que le format que vous souhaitez est war grâce à war.
//          Vous ajoutez le plugin 'maven-war-plugin' qui permettra à Maven de déclencher les bonnes opérations qui aboutiront au packaging de votre service en .war.
//          Vous ajoutez le plugin 'maven-compiler-plugin' qui est simplement le compilateur Java de Maven.
//          Vous avez maintenant tout ce qu'il faut pour packager votre application.
//          Vous pouvez bien sûr packager votre application via la ligne de commande suivante :
//                  mvn install
//          Néanmoins, nous allons utiliser IntelliJ pour exécuter cette commande directement depuis l'interface graphique.
//              1. Sélectionnez View > Tool Windows > Maven Projects
//              2. Sélectionnez ensuite à gauche de la fenêtre Maven, puis déroulez Lifecycle et cliquez sur Install.
//          La commande est alors exécutée, et votre application est packagée ! Vous devriez avoir un message Maven indiquant le succès de la commande dans l'onglet Run en bas de la fenêtre.
//          Vous pouvez vérifier la présence de votre service sous le nom lifeleft.war dans le nouveau dossier Target créé dans votre projet.
//              --> Très bien, vous avez maintenant tout ce qu'il vous faut pour lancer votre premier web service SOAP !
//      - Déployer un service sur Glassfish :
//          Normalement votre serveur Glassfish est démarré. Pour le vérifier, rendez-vous à http://localhost:4848.
//          Si tel n'est pas le cas, je vous invite à le démarrer en suivant les étapes précédemment citées.
//              1. Cliquez sur Applications dans le panneau de gauche puis cliquez sur Deploy dans la nouvelle fenêtre.
//              2. Sous Packaged File to Be Uploaded to the Server cliquez sur le bouton puis sélectionnez lifeleft.war sur votre ordinateur.
//                  Assurez-vous ensuite que Type: Web Application est choisi. Vous pouvez laisser tout le reste par défaut, puis cliquez sur OK.
//              3. Dans la nouvelle fenêtre, cliquez sur Launch en face de votre service.
//              4. Une page avec 2 liens s'ouvre : un lien http et l'autre en https. Sélectionnez le premier (http).
//                  Vous devriez tomber sur une page avec le message "Hello World!". Ce message vient du fichier index.jsp généré par défaut avec votre projet Maven.
//              5. Pour accéder à votre service, ajoutez à votre URL LifeLeft. Celle-ci devrait alors ressembler à quelque-chose comme ça :
//                  http://nomDeVotreOrdinateur.local:8080/lifeleft6252936251939052664/LifeLeft
//          Vous pouvez sans problème remplacer nomDeVotreOrdinateur.local par localhost.
//          Vous devriez tomber sur une page qui vous donne diverses informations sur votre service.
//          Glassfish génère automatiquement un WSDL qui décrit votre service à partir de votre code. Pour le consulter, cliquez sur le lien finissant par '?wsdl'.
//      - Testez votre service :
//          Je vais survoler ici rapidement le test du service via les outils Glassfish, avant de revenir en détail sur un test complet d'un service via SoapUI.
//          À présent que votre service tourne sur le serveur, vous allez pouvoir le tester très facilement, grâce encore une fois à Glassfish.
//          Pour ce faire, ajoutez '?Tester' à votre URL. Elle devrait ressembler à ceci :
//                  http://nomOrdinateur.local:8080/lifeleft6252936251939052664/LifeLeft?Tester
//          Vous retrouverez alors votre méthode précédemment créée avec 3 champs correspondant aux trois paramètres que vous avez défini.
//          Renseignez alors un prénom, un sexe et une date de naissance et validez.
//          Vous voilà avec une page présentant différentes informations que je vais commenter en plus de votre réponse.
//          Notez que cette page est générée par Glassfish pour vous permettre de débugger et voir ce qui s'est passé lors de l'invocation de votre service.
//          Pour vous faciliter la compréhension des messages échangés via SOAP, je vous rappelle le début de ce cours, à consulter ici.
//              - Method parameter(s) : Ici on reprend simplement la liste des paramètres passés.
//              - Method returned : Ici vous retrouvez le fruit de votre dur labeur! La réponse retournée par votre service. Assurez-vous que le résultat est correct.
//              - SOAP Request : IKl s'agit de la requête SOAP que Glassfish a généré en se basant sur le WSDL et les paramètres que vous avez renseigné.
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <S:Envelope xmlns:S="http://schemas.xmlsoap.org/soap/envelope/" xmlns:SOAP-ENV="http://schemas.xmlsoap.org/soap/envelope/">
//                      <SOAP-ENV:Header/>
//                      <S:Body xmlns:ns2="http://lifeleft.com/">
//                          <ns2:anneeRestantesAVivre>
//                              <arg0>john</arg0>
//                              <arg1>homme</arg1>
//                              <arg2>1990</arg2>
//                          </ns2:anneeRestantesAVivre>
//                      </S:Body>
//                  </S:Envelope>
//              - Envelope : l'enveloppe du message SOAP qui délimite le début et la fin de celui-ci. Elle définit les namespaces utilisés : 'S' et 'SOAP-ENV'.
//              - Header ici le header optionnel est vide.
//              - Body : qui définit le corps du message, déclare un namespace 'ns2' pour identifier votre méthode 'anneeRestantesAVivre' et les 3 paramètres qu'on lui passe.
//              - SOAP Response :
//                  Ceci est la fameuse réponse générée par JAX-WS. Elle a la même structure que la requête, à la différence qu'ici dans le 'Body' nous avons la réponse obtenue.
//                  Vous remarquerez que l'on a suffixé le nom de votre méthode par 'Response'.
//                  <?xml version="1.0" encoding="UTF-8"?><S:Envelope xmlns:S="http://schemas.xmlsoap.org/soap/envelope/" xmlns:SOAP-ENV="http://schemas.xmlsoap.org/soap/envelope/">
//                      <SOAP-ENV:Header/>
//                      <S:Body xmlns:ns2="http://lifeleft.com/">
//                          <ns2:anneeRestantesAVivreResponse>
//                              <return>Bonjour john, il vous reste 52 ans à vivre, profitez-en au maximum !</return>
//                          </ns2:anneeRestantesAVivreResponse>
//                      </S:Body>
//                  </S:Envelope>
// -----------
//  - Résumons :
// Comme vous avez pu le voir, JAX-WS a fait le plus gros du travail, vous avez seulement dû ajouter 2 annotations.
// Derrière, JAX-WS a interprété la requête SOAP et a invoqué votre méthode puis il a constitué une réponse SOAP en bonne et due forme qu'il a renvoyé au serveur.
// Pour résumer, voici les étapes pour créer un service Bottom-Up :
//      --> Créez vos classes pour implémenter les fonctionnalités voulues comme vous le faites d'habitude.
//      --> Annotez la ou les classes que vous voulez exposer avec l'annotation '@WebService'.
//      --> Annotez les méthodes que vous voulez exposer grâce à l'annotation '@WebMethod'.
//      --> Packagez votre service au format war (faites les modifications au pom.xml si nécessaire).
//      --> Uploadez votre service dans le serveur.
// Maintenant que vous savez créer un service Bottom-Up, essayons de le faire à l'envers grâce à la méthode Top-down.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez un client et un web service Top-down ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous allons nous attaquer ici à la méthode la plus utilisée pour la création de web services en entreprise.
// Cette méthode consiste à créer un contrat avant d'écrire le code.
//      --> Le contrat est bien sûr un fichier WSDL qui décrit en détail votre service.
// Cette approche a l'avantage de vous permettre d'exposer à tous le monde (et donc aux futurs clients) les caractéristiques de votre service pour validation.
// Vous pourrez alors répondre à des questions comme :
//      - Est-ce que mon service correspond à ce qui a été demandé ?
//      - Est-ce que les réponses que mon service renvoie sont satisfaisantes ?
//      - Manque-t-il des opérations ?
//      - Certaines opérations sont-elles déjà proposées par d'autres services ?
//      - Etc.
// Car il faut savoir qu'un web service est en général plus complexe que celui que vous avez créé précédemment.
// Il est donc préférable de valider d'abord, plutôt que de revenir sur un code complexe pour le remanier entièrement.
// Cette méthode est aussi un passage obligé quand vous voudrez créer un client pour votre service.
// Vous n'aurez à ce moment-là rien d'autre qu'un grand WSDL indigeste.
// Hors de question de passer des heures à le décortiquer pour écrire le bon code qui enverra les bonne requêtes au bon format aux bonnes adresses.
// Nous allons voir comment générer automatiquement un client grâce à wsimport à partir d'un WSDL.
// -----------
// A l'inverse de la méthode 'Bottom-Up', la méthode 'Top-Down' consiste à écrire le contrat d'abord, et générer le service ensuite.
// Le but est d'utiliser ce contrat comme base de discussion avec les autres développeurs afin de vérifier la compatibilité et la pertinence des fonctionnalités proposées.
// Le WSDL créé va permettre de simuler un service avant même de l'avoir développé, et ce, grâce à des outils que nous verrons plus tard.
// Cette méthode est très utilisée en entreprise car elle permet de sortir une version assez mature du service dès le départ.
// -----------
//  - Mise en place du web service :
// Les étapes ici sont les mêmes que lorsque vous avez créé le premier web service avec la méthode Bottom-Up dans IntelliJ IDEA.
// Vous allez simplement remplacer le GroupeID et l'artifactId par 'com.age' et 'age'.
// Vous allez aussi nommer le projet age à la dernière étape.
// Une fois votre projet créé, modifiez le pom.xml afin qu'il soit le même que pour le projet précédent.
//                  <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
//                    <modelVersion>4.0.0</modelVersion>
//                    <groupId>com.age</groupId>
//                    <artifactId>age</artifactId>
//                    <packaging>war</packaging>
//                    <version>1.0</version>
//                    <name>Pour connaître ton âge plus besoin d'envoyer "âge" au 8 12 12 ! </name>
//                    <build>
//                      <finalName>age</finalName>
//                      <plugins>
//                        <plugin>
//                          <artifactId>maven-war-plugin</artifactId>
//                          <configuration>
//                            <failOnMissingWebXml>false</failOnMissingWebXml>
//                          </configuration>
//                        </plugin>
//                        <plugin>
//                          <groupId>org.apache.maven.plugins</groupId>
//                          <artifactId>maven-compiler-plugin</artifactId>
//                           <version>3.7.0</version>
//                          <configuration>
//                            <source>1.8</source>
//                            <target>1.8</target>
//                          </configuration>
//                        </plugin>
//                        <plugin>
//                          <groupId>org.codehaus.mojo</groupId>
//                          <artifactId>jaxws-maven-plugin</artifactId>
//                        </plugin>
//                      </plugins>
//                    </build>
//                  </project>
// Pensez à supprimer le fichier web.xml sous WEB-INF.
// N'oubliez pas sur IntelliJ de marquer le dossier java comme source et de créer la Class vide AgeService sous le dossier java.
// -----------
//  - Créer un fichier WSDL :
// La première chose est donc la création d'un fichier WSDL qui décrit notre service.
// Dans la vie réelle, vous n'aurez pratiquement jamais à en créer à la main, des outils graphiques disponibles sur le marché ou dans les IDE permettent d'en créer.
//      --> Par exemple : 'WSDL Editor' d'Eclipse ou encore 'Liquid'.
// Néanmoins, nous allons ici en créer un à la main afin que vous vous familiarisiez avec ce format.
// Sachez aussi que vous aurez, tôt ou tard, affaire à ce fichier car il est nécessaire de le comprendre pour débugger dans certains cas.
//      - Dans le dossier resources, créez un fichier et nommez-le 'age.wsdl'.
//      - Dans le dossier java créez un Package et nommez le 'ageservice'.
//      - Créez ensuite dans le Package ageservice une Class java nommée 'AgeService'.
// Pour rappel, voici la structure d'un document WSDL :
// Dans le fichier 'age.wsdl' :
//      -  Créez la balise < definitions > comme suit :
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <definitions
//                      xmlns:soap="http://schemas.xmlsoap.org/wsdl/soap/"
//                      targetNamespace="http://ageservice/"
//                      xmlns:tns="http://ageservice/"
//                      xmlns="http://schemas.xmlsoap.org/wsdl/"
//                      name="AgeService">
//          La balise definitions est la racine de tout WSDL, c'est-à-dire la balise qui va englober toutes les autres, elle définit les espaces de noms (namespaces) utilisés dans le document.
//          Ici, nous avons déclaré :
//              - soap : définit des conventions dans le nommage et la structure de certains éléments comme body ou operation que nous verrons plus tard.
//                  Si vous voulez voir les éléments concernés, il suffit de vous rendre à l'URL indiquée.
//              - targetNamespace : ceci est votre espace de nom qui fait référence à ce document même.
//                  Il est à noter que dans ce cas, on peut mettre n'importe quelle valeur, vous n'êtes pas obligé de mettre une vraie URL.
//                  Cela peut tout à fait être remplacé par un GUID (générateur GUID) par exemple 'xmlns:tns="cdf382d1-904d-4f7b-ab43-144623206c3a"'.
//                  D'ailleurs vous remarquerez que j'ai choisi un namescpace fictif 'http://ageservice/' qui n'est pas forcement une URL valide.
//              - tns : c'est la même chose que targetNamespace, la différence c'est qu'on attribue un préfixe tns à ce namespace.
//                  Ceci nous permettra plus tard d'y faire référence pour indiquer que tel tag appartient à notre document.
//                  Avec 'targetNamespace' ceci n'est pas possible en absence justement de préfixe. Il est recommandé que 'targetNamespace' et tns soient les mêmes.
//              - xmlns : ceci est le namespace par défaut si jamais il y a un élément qui n'appartient à aucun.
//              - name : un nom que vous donnez à votre service.
//      - Créez la balise < types >
//                  <types>
//                      <xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema"  targetNamespace="http://ageservice/">
//                          <xs:element name="getAge" type="tns:getAge"/>
//                          <xs:element name="getAgeResponse" type="tns:getAgeResponse"/>
//                          <xs:complexType name="getAge">
//                              <xs:sequence>
//                                  <xs:element name="arg0" type="xs:int" minOccurs="0"/>
//                              </xs:sequence>
//                          </xs:complexType>
//                          <xs:complexType name="getAgeResponse">
//                              <xs:sequence>
//                                  <xs:element name="return" type="xs:string" minOccurs="0"/>
//                              </xs:sequence>
//                          </xs:complexType>
//                      </xs:schema>
//                  </types>
//          Ici vous allez définir les types de données qui vont transiter entre le client et votre service.
//          WSDL ne définissant pas un typage limité, libre à vous de créer vos propres types grâce à la balise complexType.
//          Nous définissons un namespace 'xmlns:xs' pour isoler dans celui-ci les balises que nous allons créer.
//          Le but là encore est qu'il n'y ait pas de confusion dans les noms avec d'autres balises qu'on pourrait créer plus tard.
//          Il sert aussi à montrer que notre structure doit correspondre à celle définie dans 'http://www.w3.org/2001/XMLSchema', ce qui permet plus tard la validation de éléments.
//              - xs:element : nous définissons un élément 'getAge' et un autre 'getAgeResponse'.
//              - xs:sequence : cette balise indique que les éléments qui composent ce 'complexType' doivent apparaitre dans l'ordre.
//                  C'est la balise la plus utilisée car souvent quand on souhaite recevoir des paramètres à passer à une fonction, celles-ci doivent être dans l'ordre.
//                  Pour rappel les deux autres possibilités sont :
//                      - xs:all : l'ordre n'est pas important.
//                      - xs:choice : un seul élément parmi une liste proposée est accepté.
//              - xs:complexType nous revenons ici sur chaque élément pour détailler sa structure et son type de contenu.
//                  Ainsi pour 'getAge' il est composé d'un int qu'on appelle 'arg0'. 'minOccurs="0"' (minimum occurrence) indique que cet élément est facultatif.
//          Ici nous n'avons aucun vrai type complexe pour justifier leur création, nous n'avons besoin que d'un int en paramètre d'entrée.
//          Néanmoins j'ai enveloppé ça dans un type complexe car c'est sous ce format que vous trouverez les types dans les WSDL la plupart du temps.
//          Notamment parce qu'ils sont souvent générés automatiquement.
//          Au final ici nous avons un peu réinventé la roue on définissant un élément 'int' qui sera plus tard utilisé en entrée de notre méthode.
//          Celui-ci calculera l'âge et un élément string qui sera la phrase retournée par celle-ci.
//      - Créez la balise < message > :
//                  <message name="getAge">
//                      <part name="parameters" element="tns:getAge"/>
//                  </message>
//                  <message name="getAgeResponse">
//                      <part name="parameters" element="tns:getAgeResponse"/>
//                  </message>
//          Les messages indiquent les paramètres qui seront passés plus tard aux opérations (les opérations étant l'équivalent des méthodes dans notre Class).
//          Ne pas confondre donc message et type : type définit la nature d'un élément qu'on pourra utiliser comme on veut.
//          Et ceci, alors que message fixe réellement lequel de ces éléments déclarés sera passé aux opérations.
//      - Créez la balise < portType > :
//                  <portType name="AgeService">
//                      <operation name="getAge">
//                          <input message="tns:getAge"/>
//                          <output message="tns:getAgeResponse"/>
//                      </operation>
//                  </portType>
//          Ici nous indiquons enfin nos opérations possibles. Cela revient à indiquer quelles méthodes seront disponibles dans notre service et accessibles de l'extérieur.
//          C'est l'équivalent de '@WebMethod' qu'on a vu plus tôt.
//              - operation : nom qu'on souhaite donner à la méthode qui sera générée.
//              - input : paramètre d'entrée de notre méthode, ici nous avons utilisé getAge qu'on a défini plus tôt.
//                  Vous pouvez imaginer le potentiel des complexType, car imaginez que vous ayez besoin d'un type Client qui contient toutes les informations d'un client (nom, adresse, liste d'achats).
//                  Et ceci, pour pouvoir l'ajouter à une base de données. Dans un programme Java classique, vous créerez une Class Client avec tout ce qu'il faut.
//                  Dans notre cas, c'est un service extérieur qui fait appel à vous et il est peut être écrit en C++, Python ou autre.
//                  Grâce au complexType il va pouvoir vous communiquer le type Client que vous avez défini, un peu comme s'il remplissait un formulaire, que vous récupérerez ensuite.
//                  Et cela, sous forme d'une instance d'une Class client grâce à JAX-WS.
//              - output : paramètre de sortie.
//      - Créez la balise < binding > :
//                  <binding name="AgeServicePortBinding" type="tns:AgeService">
//                      <soap:binding transport="http://schemas.xmlsoap.org/soap/http" style="document"/>
//                      <operation name="getAge">
//                          <input>
//                              <soap:body use="literal"/>
//                          </input>
//                          <output>
//                              <soap:body use="literal"/>
//                          </output>
//                      </operation>
//                  </binding>
//          - binding : décrit concrètement comment les opérations définies dans 'portType' seront invoquées sur le réseau.
//          - soap:binding : est utilisée pour indiquer que la communication se fera via le protocole SOAP.
//          - transport="http://schemas.xmlsoap.org/soap/http" : indique que les messages SOAP seront transmis via HTTP.
//          - On indique enfin que pour l'opération getAge qu'on a définie dans portType, les paramètres en input et output seront encodés en literal.
//              C'est-à-dire qu'ils seront mis en forme selon les définitions que nous avons spécifiées pour structurer les messages SOAP qu'on va renvoyer.
//      - Créez la balise < service > :
//                  <service name="getAge">
//                      <port name="AgeServicePort" binding="tns:AgeServicePortBinding">
//                          <soap:address location="http://localhost:8080/Age/getAge"/>
//                      </port>
//                  </service>
//          Cette dernière balise indique littéralement l'URL pour appeler les opérations que nous avons définies.
//          Dans ce cas, nous n'avons qu'une opération qui se trouve à http://localhost:8080/Age/getAge.
//              - age.wsdl final :
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <definitions
//                          xmlns:soap="http://schemas.xmlsoap.org/wsdl/soap/"
//                          targetNamespace="http://ageservice/"
//                          xmlns:tns="http://ageservice/"
//                          xmlns="http://schemas.xmlsoap.org/wsdl/"
//                          name="AgeService">
//                      <types>
//                          <xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema"  targetNamespace="http://ageservice/">
//                              <xs:element name="getAge" type="tns:getAge"/>
//                              <xs:element name="getAgeResponse" type="tns:getAgeResponse"/>
//                              <xs:complexType name="getAge">
//                                  <xs:sequence>
//                                      <xs:element name="arg0" type="xs:int" minOccurs="0"/>
//                                  </xs:sequence>
//                              </xs:complexType>
//                              <xs:complexType name="getAgeResponse">
//                                  <xs:sequence>
//                                      <xs:element name="return" type="xs:string" minOccurs="0"/>
//                                  </xs:sequence>
//                              </xs:complexType>
//                          </xs:schema>
//                      </types>
//                      <message name="getAge">
//                          <part name="parameters" element="tns:getAge"/>
//                      </message>
//                      <message name="getAgeResponse">
//                          <part name="parameters" element="tns:getAgeResponse"/>
//                      </message>
//                      <portType name="AgeService">
//                          <operation name="getAge">
//                              <input message="tns:getAge"/>
//                              <output message="tns:getAgeResponse"/>
//                          </operation>
//                      </portType>
//                      <binding name="AgeServicePortBinding" type="tns:AgeService">
//                          <soap:binding transport="http://schemas.xmlsoap.org/soap/http" style="document"/>
//                          <operation name="getAge">
//                              <input>
//                                  <soap:body use="literal"/>
//                              </input>
//                              <output>
//                                  <soap:body use="literal"/>
//                              </output>
//                          </operation>
//                      </binding>
//                      <service name="getAge">
//                          <port name="AgeServicePort" binding="tns:AgeServicePortBinding">
//                              <soap:address location="http://localhost:8080/Age/getAge"/>
//                          </port>
//                      </service>
//                  </definitions>
// Maintenant que nous avons notre contrat, nous allons pouvoir utiliser l'outil wsimport pour générer toutes les classes nécessaires à l'implémentation de notre service.
// -----------
//  - Générer des artefacts AJAX-WS grâce à wsimport :
// 'wsimport' est un outil inclus dans le JDK qui permet de générer les artefacts JAX-WS nécessaires pour créer un client ou un service à partir d'un WSDL.
// Ces artefacts sont tout simplement des classes et des interfaces qui font le boulot que nous avons fait plus tôt dans la démarche Bottom-up.
//      - Utiliser wsimport :
//          Si Java est installé, alors wsimport est aussi disponible ! Pour le vérifier, il suffit d'entrer la commande suivante : 'wsimport -version'.
//          Résultat : 'wsimport version "2.2.9"'.
//              - Les documents WSDL sont censés être dans un UDDI.
//                  Afin de s'affranchir des problèmes des chemins vers le WSDL, nous allons le placer dans un répertoire Github dont nous allons récupérer l'URL directe.
//              - Commencez par vous placer dans le dossier age du projet : 'cd /Chemin/Vers/Dossier/IdeaProjects/age'.
//              - Générez les artefacts comme suit : 'wsimport -Xnocompile -d ./src/main/java -p generated.ageservice https://raw.githubusercontent.com/AdamSoufiane/age/master/age.wsdl'.
//              - '-Xnocompile' : indique que vous ne souhaitez pas que les Class générées soient compilées. En effet, nous les compilerons nous-mêmes grâce à Maven.
//              - '-d' : indique le dossier dans le projet dans lequel vous souhaitez mettre les Class qui seront générées.
//              - '-p' : indique à quel packet ces Class appartiendront. Dans ce cas, vous créez un packet spécialement pour celles-ci, appelé 'generated.ageservice'.
//          Pour connaître les autres paramètres, rendez vous dans la documentation.
//      - Les fichiers générés :
//          - 'AgeService' : il s'agit ici d'une interface qui représente ce que nous devrions implémenter.
//              En d'autres termes, si vous ouvrez le fichier, vous verrez que cette interface définit une méthode 'getAge' qui accepte comme argument 'arg0' que nous avons défini, retournant un String.
//              Cette interface va nous permettre de créer l'implémentation dans laquelle nous allons définir la logique de notre service (ici, le calcul de l'âge à partir d'une date de naissance).
//          - 'GetAge' et 'GetAgeResponse' : ces Class représentent les 'complexType' que nous avons créés précédemment dans la balise < types >.
//              Ici elles n'ont pas une grande utilité, mais rappelez-vous de l'exemple que je vous ai donné avec la Class Client et nombreux attributs.
//              Si nous avions déclaré un 'complexType' qui définit un client avec tous ses attributs, nous aurions eu alors une Class Client.java avec toutes les méthodes et attributs prêts à l'emploi.
//          - 'GetAge_Service' : je vous parlerai de cette Class quand nous construirons le Client.
//          - 'ObjectFactory' : une Factory pour créer des instances des différentes Class générées à partir des 'complexType'.
//              Dans notre cas il s'agit des Class 'getAge' et 'GetAgeResponse'.
//          - 'package-info.java' : ce fichier permet en général de générer de la documentation pour les Packages en ajoutant des commentaires au-dessus des noms des Packages.
//              Mais dans notre cas sa principale fonction est de créer une association entre le Namespace 'http://ageservice/'' que nous avions défini dans le WDSL.
//              Ainsi que le package auquel il est associé dans les Class générées, à savoir 'generated.ageservice'.
//      - Créer l'implémentation :
//          L'implémentation est très simple, il nous suffira d'implémenter l'Interface AgeService
//                  package ageservice;
//                  import javax.jws.WebMethod;
//                  import javax.jws.WebService;
//                  import java.math.BigInteger;
//                  @WebService(serviceName = "getAge")
//                  public class AgeService implements generated.ageservice.AgeService {
//                      @WebMethod
//                      public String getAge(Integer naissance) {
//                          return "Votre âge est de " + (2017-naissance) + "ans";
//                      }
//                  }
//          C'est tout ! Vous venez de créer un web service en partant d'un WSDL. Évidemment, ici vous ne voyez pas forcement tous les avantages, car le code est court.
//          Mais imaginez que votre service gère des commandes et propose une dizaine de méthodes exposées et une dizaine de Class de type : Client, Commande, Paiement.
//          Dans ce cas-là, la puissance de 'wsimport' apparaît clairement. En partant d'un WSDL, vous aurez toutes ces Class prêtes à l'emploi ainsi qu'un SEI formaté et annoté.
//      - Packagez et changez l'URL de votre web service :
//          Pour packager votre web service, il vous suffit de suivre les mêmes étapes que dans le service LifeLeft créé en Bottom-up.
//          Pour rappel sur IntelliJ, il vous suffit de cliquer sur Install sous Lifecycle du panneau Maven.
//          Uploadez ensuite votre war dans Glassfish.
//          Vous avez dû remarquer que nous avons fixé l'URL sous la balise < service > dans notre WSDL à 'http://localhost:8080/Age/getAge'.
//          Or si vous vous rendez dans Applications sur votre serveur puis Launch vous remarquerez que votre service a une URL de ce type : 'http://localhost:8080/age146146464161484/'.
//          Les chiffres après age sont un identifiant unique généré par Glassfish afin d'éviter que vous ayez deux services avec le même nom.
//          Comme nous ne souhaitons pas de chiffres dans notre URL afin qu'elle soit conforme à notre WSDL, nous allons les supprimer.
//          Rendez-vous dans Applications puis cliquez sur le nom de votre service age dans la colonne Name.
//          Sous Context Root: remplacez le tout par '/Age' puis validez.
//      - Testez votre web service :
//          Pour tester votre web service, vous pouvez procéder de la même manière que pour LeftLife.
//          Si vous avez suivi les mêmes noms que dans les exemples que je vous ai donnés, vous devriez avoir une URL de test comme celle-ci : 'http://localhost:8080/Age/getAge?Tester'.
//          Entrez ensuite une date de naissance.
// -----------
//  - Créer un client à partir d'un WSDL :
// Vous allez à présent créer un client pour votre web service LifeLeft.
// Commencez par créer un autre projet vide exactement comme vous aviez fait avec LifeLeft.
// GroupeId : com.leftlifeclient ArtifactId : leftlifeclient Project name : leftlifeclient
//          --> Ne créez par contre aucune Class.
//      - Récupérez le WSDL de LifeLeft depuis Glassfish. Pour ce faire, allez dans Applications.
//          Puis cliquez sur Launch en face de LifeLeft et cliquez sur le premier lien avec le port 8080.
//          Ajoutez le nom de service que vous aviez défini dans serviceName de '@WebService'. Cela devrait vous donner une URL comme celle-ci :
//                  http://nomDeVotreOrdinateur.local:8080/lifeleft/LifeLeft
//          Remarquez que j'ai changé l'URL de ce service également pour ne garder que lifeleft au lieu de lifeleft45656426146. Je vous invite à faire de même.
//          Dans la page qui s'ouvre, vous avez l'adresse de votre WSDL à droite.
//          C'est cette adresse qui va nous permettre de générer notre client à partir du WSDL.
//              - Comme nous l'avons fait plus tôt, placez-vous dans le dossier lifeleftclient depuis la ligne de commande.
//              - Générez le client : 'wsimport -Xnocompile -d ./src/main/java -p generated.leftlife http://localhost:8080/lifeleft/LifeLeft?wsdl'.
//                   On utilise la même commande que précédemment, mais cette fois nous allons nous intéresser à l'implémentation d'un client à partir des Class générées.
//      - Regardez la Class LifeLeft. Cette classe est appelée une Class 'proxy'. Elle va vous permettre d'appeler le service distant LifeLeft comme s'il était local.
//          JAX-WS vous cache tout ce qui concerne la formulation des requêtes SOAP, leur envoi via le protocole choisi (ici HTTP) et l'interprétation des réponses.
//          L'annotation '@WebServiceClient' est une annotation utilisée par les générateurs comme wsimport pour localiser < service > dans le WSDL.
//          Vous n'aurez pratiquement jamais à utiliser cette annotation.
//          Cette Class hérite de la Class Service qui est une Class capable de fournir une représentation en Java d'un service à partir de son WSDL.
//          S'ensuivent plusieurs définitions de constantes déclarant les URL et Namespaces qu'on a déclaré dans le WSDL.
//          Ce qui nous intéresse ici est principalement la méthode 'getLifeLeftServicePort' qui va nous donner accès à toutes les opérations déclarées dans le WSDL.
//          Dans notre cas il y a une seule opération : anneesRestantesAVivre.
//      - Utiliser le client :
//          Nous allons maintenant invoquer le code généré pour appeler notre service distant LifeLeft comme s'il était un simple package dans notre code.
//          Créez une Class Main sous le dossier java.
//          Invoquez le service :
//                  import generated.leftlife.LifeLeft;
//                  import generated.leftlife.LifeLeftService;
//                  public class Main {
//                      public static void main(String[] args) {
//                      LifeLeft lifeleft = new LifeLeft();
//                      LifeLeftService lifeleftsrv = lifeleft.getLifeLeftServicePort();
//                      String resultat = lifeleftsrv.anneeRestantesAVivre("john", "homme", 1980);
//                      System.out.println(resultat);
//                      }
//                  }
//              - Ligne 8 : On crée une instance de la Class LifeLeft générée.
//              - Ligne 10 : On demande une instance LifeLeftService qui contient l'opération 'anneesRestantesAVivre'.
//              - Ligne 11 : Nous appelons la méthode 'anneesRestantesAVivre' en lui passant les paramètres nécessaires.
//                  C'est à ce moment-là que JAX-WS fera le nécessaire pour formuler une requête SOAP et l'envoyer à votre web service LifeLeft.
//                  Puis il va recevoir la réponse SOAP également et en extraire le résultat sous forme de String.
//              - Ligne 13 : Écrire le résultat dans la sortie standard.
//      - Tester le client :
//          Comme notre lifeleftcient n'est pas forcément un web service, il ne propose aucune interaction avec le monde extérieur.
//          Nous n'avons pas besoin de le déployer dans un serveur comme Glassfish.
//          Nous allons tout simplement le compiler et l'exécuter en local.
//          Pour ce faire, faites un clic droit sur le main, puis cliquez sur Run 'Main.main()'.
//          Vous aurez peut-être dans la sortie sur IntelliJ un message d'erreur comme 'objc[15219]: Class JavaLaunchHelper is implemented in both ... '.
//              --> Sachez que ce n'est qu'un ancien bug spécifique à IntelliJ, il n'a aucun impact sur votre code.
//          Voilà ! Vous venez de recevoir une réponse de votre web service. Vous n'avez eu à écrire aucune ligne de XML ni lire aucun WSDL.
// Tout ça est très bien, mais vous ne trouvez pas que c'est un peu opaque ?
// On aimerait quand même voir ce qui se passe, quel message est envoyé et quel message est reçu, surtout en cas de bug !
//      --> Je vais donc vous apprendre dans la partie suivante à utiliser un outil magique : SoapUI !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Testez votre service grâce à SoapUI ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Réalisez des tests fonctionnels ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Comment tester une architecture SOA :
// Un SI conçu autour d'une architecture SOA nécessite des tests bien différents de ceux qu'on peut voir dans des architectures plus anciennes.
// En effet, le système étant composé de plusieurs services indépendants, il ne suffit pas que chacun fonctionne correctement en interne (tests unitaires).
//      --> En effet, il faut qu'il prouve qu'il est capable de fonctionner parfaitement dans son environnement.
// Il faut donc réaliser les 4 types de tests suivants :
//      --> Tests fonctionnels : test de fonctionnement des services : recevez-vous les bonnes réponses ? Les bons formats ? Recevez-vous toutes les balises attendues ? etc.
//      --> Tests de performances : vos services supportent-ils une montée en charge ? Vos services répondent-ils assez vite ?
//      --> Tests de sécurité : votre service refuse-t-il de répondre quand la stratégie de sécurité n'est pas respectée ? Que se passe-t-il quand on essaye de contourner celle-ci ?
//      --> Tests d'intégration : vos services n'ont de sens que s'ils s'intègrent bien entre eux.
//          Il faut donc tester des scénarios de combinaison de services, les protocoles de communication utilisés et la consistance des données qui transitent dans le système.
// Beaucoup de développeurs se contentent de tester le système dans son intégralité. Par exemple, passer une commande dans une boutique créée en SOA.
// Ce genre de tests n'est absolument pas fiable. Il faut veiller à tester service par service, puis tester l'ensemble des services et leurs interactions grâce à des scénarios de tests.
// Dans cette partie, nous allons nous concentrer sur les tests fonctionnels de nos services et voir comment SoapUI peut les faciliter et les automatiser.
// -----------
//  - Qu'est-ce que SoapUI :
//      --> SoapUI est un logiciel open source écrit en Java qui permet de tester les API qu'elles soient Soap ou RESTful.
//      --> SoapUI offre une panoplie de possibilités qui couvrent tous les tests nécessaires à une SOA.
// Voici les principales fonctionnalités :
//      - Test fonctionnels.
//      - Mocking : simulation de service.
//      - Tests de performances.
//      - Test de sécurité.
//      - Automatisations des tests.
//      - Intégration avec d'autres systèmes, comme ceux de l'intégration continue de type Jenkins.
// SoapUI est populaire grâce à son interface qui permet de commencer à tester un service en quelques minutes et d'élaborer des scénarios complexes très simplement.
// Il est aussi tout à fait possible de créer des scripts avancés de tests grâce à Groovy.
// -----------
//  - Installer SoapUI et créer un premier projet :
//      - Téléchargez la version open source de SoapUI.
//      - Suivez ensuite les instructions basiques pour l'installation du logiciel en gardant toutes les options par défaut.
// Nous allons commencer par créer un projet vide. Cliquez sur l'icône SOAP en haut à gauche, puis renseignez LifeLeft en titre de votre projet et validez.
// Nous allons tester le web service LifeLeft que nous avons créé dans la partie précédente. Assurez-vous que le service est bien déployé sur Glassfish et que celui-ci est en marche.
//      - Retrouvez le lien vers le WSDl de ce service en vous rendant sur l'URL de celui-ci. Votre URL qui devrait alors ressembler à ceci : 'http://localhost:8080/lifeleft/LifeLeft?wsdl'.
//      - Ajoutez le WSDl au projet : clic droit sur le nom du projet à gauche puis 'Add WSDL'.
//      - Ajoutez ensuite l'URL que vous avez récupéré et laissez les choix par défaut.
//      - Vous obtenez alors une arborescence à gauche dans votre projet.
//          - (1) : Le nom de votre projet que vous avez renseigné lors de la création sur SoapUI.
//          - (2) : Le nom de la balise < binding > dans le WSDL dans laquelle sont déclarées les opérations possibles.
//          - (3) : Liste des opérations possibles, dans ce cas il n'y qu'une 'anneesRestantesAVivre'.
//          - (4) : Une requête générée par SoapUI pour tester l'opération en question.
// Vous pouvez double cliquer sur chaque opération ou projet pour avoir une vue détaillée sur les URL, les WSDL, etc.
// -----------
//  - Tester une opération :
// Pour tester une opération, il suffit d'utiliser la requête générée correspondante. Double cliquez sur Request 1 sous 'anneesRestantesAVivre'.
// Vous verrez à gauche la requête générée par SoapUI, vous reconnaîtrez la structure d'un message SOAP, avec 'Envelope' et 'Body'.
// Les trois arguments demandés par votre service sont représentés par 'arg0', 'arg1' et 'arg2'.
// Remplacez les '?' par les arguments nécessaires puis cliquez sur play : bouton vert en haut à gauche.
// La requête est alors envoyée à votre service sur le serveur Glassfish.
//      --> Une réponse SOAP est générée par JAX-WS puis renvoyée vers SoapUI. Cette réponse est celle que vous voyez sur le panneau de droite.
// -----------
//  - Comprendre les concepts Test Suit, Test Case et Test Step :
// Afin de comprendre ces concepts, je vous invite à modifier notre service pour ajouter quelques méthodes.
//                  package com.lifeleft;
//                  import javax.jws.WebMethod;
//                  import javax.jws.WebService;
//                  import java.time.Year;
//                  import java.util.concurrent.ThreadLocalRandom;
//                  @WebService(serviceName = "LifeLeft")
//                  public class LifeLeftService {
//                      private static final Integer ESPERANCE_VIE_HOMMES = 79;
//                      private static final Integer ESPERANCE_VIE_FEMMES = 85;
//                      String homme = "homme";
//                      String femme = "femme";
//                      Integer evDeReference = 0;
//                      @WebMethod
//                      public String  anneesRestantesAVivre (String prenom, String genre, Integer anneeNaissance) {
//                          if(sexe.equals(homme)) evDeReference = ESPERANCE_VIE_HOMMES;
//                          else evDeReference = ESPERANCE_VIE_FEMMES;
//                          //Remarque, en cas de problème, vous pouvez changer Year.now().getValue() par Calendar.getInstance().get(Calendar.YEAR)
//                          Integer anneeRestantes = evDeReference -(Year.now().getValue() - anneeNaissance );
//                          return "Bonjour " + prenom + ", il vous reste " + anneeRestantes + " ans à vivre, profitez-en au maximum !";
//                      }
//                      @WebMethod
//                      public int creerClient(String login, String password) {
//                          /*
//                          Insérer le client dans la base de données et retourner son ID unique
//                           */
//                          return ThreadLocalRandom.current().nextInt(100, 900);
//                      }
//                      @WebMethod
//                      public String commanderCompteARebours(Integer clientId){
//                          /*
//                          Insérer la commande dans la base de données et retourner un message de validation.
//                          */
//                          return "Merci ! Votre commande pour le client : "+ clientId +" de compteur de vie est validée";
//                      }
//                  }
// Ce service dans ce cas est utilisé dans un site qui vous permet de calculer le nombre d'années restant à vivre, puis vous propose de vous vendre un compte à rebours.
// Si vous souhaitez l'acheter, il faut créer un compte.
// J'ai donc ajouté 2 méthodes simples :
//      --> 'creerClient' : qui simule une méthode qui crée un client, l'ajoute à une BDD puis retourne l'ID unique de celui-ci.
//      --> 'commanderCompteARebours' : qui simule la prise en compte de la commande et retourne un message de confirmation.
// Regardons maintenant comment on organise les tests :
//      - Test Step : dans SoapUI, un Test Step est une action qui peut être une requête comme celle qu'on a faite plus tôt.
//          Comme un transfert de résultat d'un Test Step précédent vers le suivant, ou encore comme un appel à une base de données.
//      - Test Case : un Test Case (terme que vous retrouverez en général dans le domaine des tests logiciels) est un ensemble d'entrées, de conditions et de variables.
//          Ensemble auxquel le service ou l'application doit répondre d'une certaine manière précise et attendue.
//          Dans SoapUI ces entrées, variables et conditions, ce sont les Test Steps.
//          Une fois tous ces Tests Steps enchaînés avec succès, le résultat doit correspondre à une sortie précise qu'on attend du service.
//          Par exemple on s'attend à ce que le service nous retourne une phrase qui contient le nombre d'années restantes à vivre, et non pas juste un chiffre.
//      - Test Suite : Un Test Suite est composé d'un ou de plusieurs Test Case.
//          Il vise à exécuter automatiquement plusieurs Test Steps afin de vérifier leur bon fonctionnement dans un scénario d'utilisation.
//          Par exemple : on voudrait tester le scénario dans lequel un utilisateur commande dans notre service un compteur sans avoir calculé auparavant les années lui restant à vivre.
//          Ou encore le scénario dans lequel après avoir calculé le nombre d'années, puis s'être enregistré, l'utilisateur du service passe commande en fournissant un ID client différent du sien.
// -----------
//  - Créer des Test Cases et Test Suites :
// Pour tester ces fonctionnalités, nous allons importer notre nouveau WSDL généré après la mise à jour de notre Class.
//      - Mettez à jour la Class avec le code fourni précédemment.
//      - Packagez puis uploadez sur Glassfish.
//      - Récupérez le WSDL comme fait précédemment.
//      - Supprimez l'ancien projet que nous avons créé : clic droit sur le projet > Remove.
//      - Créez un nouveau projet et appelez le LifeLeft.
//      - Ajoutez le nouveau WSDL comme fait précédemment.
// Nous avons les 3 méthodes que nous avons définies dans notre Class avec, pour chacune, une requête générée.
// Vous allez maintenant mettre 'creerClient' et 'commanderCompteARebours' dans un Test Case.
//      1- Faites un clic droit sur 'Request 1' sous 'commanderCompteARebours' puis 'Add' to 'TestCase'.
//      2- Une fenêtre s'ouvre vous demandant de créer un Test Suite. En effet les Test Case dans SoapUI doivent être regroupés dans un Test Suite. Acceptez le nom par défaut 'TestSuite 1'.
//      3- C'est maintenant qu'on vous propose de créer le Test Case, nommez-le 'TestCase Commande'.
//      4- Une nouvelle fenêtre s'ouvre, vous proposant de donner un nom à cette requête que vous venez d'ajouter. Acceptez le nom par défaut.
//      5- Vous obtenez votre premier Test Suite avec un Test Case dedans qui est composé de Test Steps.
//          Ici il n'y a qu'un Test Step correspondant à la requête vers notre opération 'commanderCompteARebours'.
//      6- Pour ajouter la deuxième requête, faites un clic droit sur 'Request 1' sous 'creerClient' puis 'Add to TestCase'.
//          Une fenêtre s'ouvre avec une liste déroulante vous proposant de choisir sous quel Test Suite et quel Test Case vous voulez ajouter la nouvelle requête.
//          Choisissez celle que nous venons de créer puis validez.
//          Validez ensuite comme précédemment la fenêtre du choix du nom de cette requête.
//              --> Vous avez maintenant une Test Suite qui comporte un seul Test Case composé de 2 étapes.
//      7- Pour finir, nous allons faire exactement la même chose pour la dernière requête en la mettant dans sa propre Test Suite et Test Case.
//          Cliquez droit sur Request 1 sous 'anneesRestantesAVivre' puis 'Add to TestCase'. Choisissez cette fois dans la liste déroulante 'Create new TestSuite'.
// Suivez ensuite les mêmes étapes que plus haut, afin d'obtenir la même arborescence.
// -----------
//  - Les propriétés dans SoapUI :
// Vous êtes presque prêts pour lancer vos tests… mais il y a un hic !
// Si vous allez dans une des requête ajoutées et que vous double cliquez dessus pour voir le contenu, vous obtiendrez quelque chose comme ça :
//                  <soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:lif="http://lifeleft.com/">
//                      <soapenv:Header/>
//                      <soapenv:Body>
//                              <lif:commanderCompteARebours>
//                              <!--Optional:-->
//                              <arg0>30</arg0>
//                          </lif:commanderCompteARebours>
//                      </soapenv:Body>
//                  </soapenv:Envelope>
// 'agr0' aura soit une valeur que vous avez renseigné plus tôt (dans mon cas, c'est 30, mais vous pourriez avoir une autre valeur), soit une valeur par défaut '?'.
// Dans tous les cas cette valeur est écrite en dur dans la requête.
//      --> Or ceci est une mauvaise pratique, d'une part parce que si vous avez 70 requêtes à tester, vous n'allez pas pouvoir aller dans chacune pour changer la valeur selon les tests.
//              De plus, parce que ça ne nous permet pas d'indiquer des paramètres arbitraires pour tester le comportement de votre service.
// Les propriétés sont la solution idéale dans SoapUI. Vous pouvez les voir comme des variables que l'on définit à l'avance et qui seront injectées dans les requêtes que nous allons exécuter.
// Les propriétés peuvent être définies à plusieurs niveaux. Le plus haut niveau étant celui du logciel en soit, un peu comme une variable globale.
//      --> Nous allons ici nous intéresser à ceux qu'on peut définir dans notre projet.
// Si vous cliquez sur le nom du projet LeftLife, vous verrez en bas s'afficher 2 onglets avec 'Projet Properties' et 'Custom Properties'.
//      - L'onglet 'Projet Properties' représente les propriétés du projet comme son nom par exemple.
//      - L'onglet 'Custom Properties' est celui dans lequel vous pouvez définir vos propres propriétés à utiliser plus tard.
// Les mêmes onglets existent pour TestSuite 1 et TestCase 1. C'est dans ce dernier que nous allons définir nos variables.
// Pourquoi autant d'endroits pour définir les propriétés, on ne peut pas juste les définir toutes au niveau du projet ?
// Eh bien là encore il vous faut imaginer un cas réel où vous avez un logiciel dans lequel vous devez tester 12 services et 120 requêtes possibles par exemple.
//      --> Dans ce cas, vous auriez des centaines de variables à gérer.
// Vous allez définir les propriétés nécessaires au niveau de chaque Test Case.
//      1- Cliquez sur Test Case Commande puis en bas dans l'onglet Custom Properties cliquez sur le symbole '+' et créez les variables 'login' et 'password'.
//      2- Nous allons maintenant passer ces propriétés à notre requête creerClient sous 'Test Case Command'.
//          Double cliquez sur celle-ci puis enlevez les valeurs par défaut dans le panneau de droite.
//                  <soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:lif="http://lifeleft.com/">
//                      <soapenv:Header/>
//                      <soapenv:Body>
//                          <lif:creerClient>
//                              <!--Optional:-->
//                              <arg0></arg0>
//                              <!--Optional:-->
//                              <arg1></arg1>
//                          </lif:creerClient>
//                      </soapenv:Body>
//                  </soapenv:Envelope>
//      3- Faites maintenant un clic droit entre les balises et puis sélectionnez en bas 'Get Data' puis 'TestCase Command' et enfin 'Property [login]'' que vous avez défini plus tôt.
//          Un identifiant unique de votre variable est ajouté : '${#TestCase#login}'.
//      4- Faites de même pour arg1 mais cette fois en choisissant password : '${#TestCase#login} ${#TestCase#password}'.
//      5- Cliquez sur le bouton vert 'play' en haut à gauche pour lancer le test, votre service devrait répondre avec un chiffre généré aléatoirement comme prévu.
//          Comment pourrais-je savoir si ce sont bien mes variables qui sont passées effectivement à mon service ?
//          Pour voir ce qui se passe réellement avec nos variables, nous allons exécuter les tests dans notre Test Case.
//      6- Double cliquez sur 'Test Case Command', une fenêtre s'ouvre avec nos deux requêtes.
//      7- Lancez les tests avec le bouton play en haut à gauche.
//          Une barre verte Finished en haut indique que les tests se sont déroulés avec succès.
//      8- En bas de la fenêtre, vous avez les étapes du test. Celle qui nous intéresse est la première creerClient '- Request1', alors double cliquez dessus !
//          --> Vous obtenez une fenêtre qui présente la requête effectivement envoyée.
//          Vous voyez que vos propriétés ont été injectées dans le contenu des balises 'arg0' et 'arg1'.
//          Vous pouvez aussi voir la réponse grâce à l'onglet 'Response Message'.
// Félicitations, vous venez de compléter votre premier test.
// Néanmoins on a un problème : revenez sur la fenêtre d'exécution du test Case et vous double cliquez cette fois sur la 2e requête 'commanderCompteARebours'.
// Vous constaterez que la requête qui a été envoyée est celle-ci :
//                  <soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:lif="http://lifeleft.com/">
//                      <soapenv:Header/>
//                      <soapenv:Body>
//                          <lif:commanderCompteARebours>
//                              <!--Optional:-->
//                              <arg0>?</arg0>
//                          </lif:commanderCompteARebours>
//                      </soapenv:Body>
//              </soapenv:Envelope>
//      --> Aucun argument valide n'a été envoyé via cette requête.
// Or, pour cette requête, ne nous pouvons pas juste établir une variable pour tester, nous devons tester en lui passant l'identifiant client que nous a retourné la requête précédente.
// Je vais vous expliquer comment transférer des propriétés.
// -----------
//  - Transférer des propriétés :
// Comme je l'ai dit précédemment, nous avons besoin de passer le résultat de la requête 'creerClient' comme paramètre à la requête 'commanderCompteARebours'.
// Ceci, afin que celle-ci enregistre la commande pour le bon client.
// Nous allons transférer le résultat de la première requête vers la seconde qui sera envoyée à 'commanderCompteARebours'.
// Pour ce faire, nous créérons une propriété vide au même titre que login et password puis nous allons l'alimenter avec le résultat de la première requête.
//          1- Créez une variable 'clientId' au niveau de 'TestCase Command' qui viendra s'ajouter aux deux autres.
//          2- Faites un clic droit sur 'T'estCase Command' puis cliquez sur 'Add Step' puis 'Preperty Transfer'.
//          3- Nommez-la dans la boite de dialogue suivante : 'Transfert ClientId'.
//          4- Une nouvelle fenêtre s'ouvre. Si ce n'est pas le cas, double cliquez sur 'Property Transfer'.
//          5- Ajoutez un nouveau transfert grâce au bouton '+' en haut à gauche et nommez-le 'clientId'.
//      - Fournir la source :
//          À la droite de la fenêtre, vous avez deux blocs : un Source et un autre Target.
//          Dans le bloc Source, nous allons définir la provenance de notre variable à transférer.
//          Choisissez comme source 'creerClient - Request 1' puis dans le champs 'Property' choisissez 'Response'.
//          Ce champ définit si l'on souhaite transférer une variable depuis la requête elle-même ou plutôt sa réponse voire d'autres sources comme le domaine, etc.
//          Dans notre cas, c'est la réponse qui nous intéresse.
//      - Le XPath :
//          Ici les choses se corsent pour ceux qui ne maîtrisent pas bien le XML.
//          En effet, nous allons devoir déterminer ici un XPath vers la balise dans laquelle se situe la valeur à transférer.
//          Voici un exemple de réponse qu'on obtient de 'creeClient' :
//                  <S:Envelope xmlns:S="http://schemas.xmlsoap.org/soap/envelope/">
//                      <S:Body>
//                          <ns2:creerClientResponse xmlns:ns2="http://lifeleft.com/">
//                              <return>765</return>
//                          </ns2:creerClientResponse>
//                      </S:Body>
//                  </S:Envelope>
//          Il faut voir le XPath un peu comme la barre d'arborescence qu'on retrouve souvent dans les sites web.
//                  Accueil > Vêtements > Hommes > Vestes > Vestes en cuir
//          Par analogie, le chemin vers la balise qui nous intéresse serait : 'Envelope > Body > creerClientResponse > return'.
//          Sauf que voilà… il nous faut indiquer des espaces de nom devant chaque balise afin d'éviter toute confusion.
//          Afin d'intégrer ces namespaces, nous allons utiliser le bouton ns: dans notre fenêtre plutôt que de les copier.
//          Un message d'erreur va apparaître indiquant qu'il n'y a pas encore de Target. Ignorez-le !
//          Dans le champ sous Source vous obtiendrez tous les namespaces déclarés dans la réponse.
//                  declare namespace soap='http://schemas.xmlsoap.org/soap/envelope/';
//                  declare namespace ns1='http://lifeleft.com/';
//          À partir de là, il suffit de combiner notre arborescence avec les namespaces déclarés, cela donne
//                  declare namespace S='http://schemas.xmlsoap.org/soap/envelope/';
//                  declare namespace ns2='http://lifeleft.com/';
//                  /S:Envelope/S:Body/ns2:creerClientResponse/return/text()
//          Devant chaque balise, il y a le préfixe déclaré pour l'espace de nom puis on finit par 'text()' qui indique que nous souhaitons récupérer le contenu de la balise.
//          Bien sûr, dans ce cas c'est très simple, mais quand vous avez une réponse SOAP plus grande, cela va être beaucoup plus compliqué.
//              --> Je vous suggère alors une autre méthode.
//          Créez un fichier test.xml dans le projet LifeLeft sur IntelliJ. Celui-ci a une fonction qui permet de récupérer le XPath très facilement.
//          Faites simplement un clic droit sur le contenu, une pop-up s'affiche avec le XPath : cliquez sur l'icône copier à droite. Vous obtiendrez alors :
//                  /S:Envelope/S:Body/ns2:creerClientResponse/return/text()
//          Veillez à changer les préfixes (S et ns2) en fonction des namespaces que nous avons importés plus tôt avec le bouton 'ns'.
//          De retour dans notre champ source, on obtient ceci :
//                  declare namespace S='http://schemas.xmlsoap.org/soap/envelope/';
//                  declare namespace ns2='http://lifeleft.com/';
//                  /S:Envelope/S:Body/ns2:creerClientResponse/return/text()
//      - Fournir la Target :
//          Nous allons maintenant déterminer vers où nous souhaitons transférer cette valeur qu'on vient de cibler.
//          Vous vous souvenez que nous avons défini une propriété 'clientId' au niveau de 'TestCase Command'. Nous allons diriger cette variable ciblée vers 'TestCase Command'.
//          Dans le champ Target choisissez comme cible 'TestCase Command'. Dans 'Property' vous devriez retrouver 'clientId' précédemment défini.
//      - Tester le transfert :
//          Pour tester si votre transfert fonctionne correctement, il suffit d'appuyer sur le bouton play en haut à gauche.
//          Maintenant, la colonne 'Transfer Name' reprend le nom du transfert que nous avons défini au début dans le panneau de gauche.
//          Dans la colonne 'Transfer Values', vous retrouvez la valeur qui lui sera attribuée.
//          Si vous avez une erreur dans cette dernière colonne, c'est que le plus souvent, votre XPath n'est pas correct.
//          Si vous l'avez écrit à la main, alors je vous recommande d'utiliser la méthode IntelliJ.
//          Fermez ensuite la fenêtre directement, il n'y a pas de validation à faire.
//      - Tester le transfert dans le TestCase :
//          Vous devriez à ce stade avoir cette arborescence dans votre TestCase Commande.
//          Si votre étape '_Property Transfert' est en bas de la liste je vous recommande de la remonter entre les deux étapes précédentes afin que ce soit visuellement plus parlant.
//          On récupère le résultat de la requête en haut pour le transférer vers celle d'en bas.
//          Nous allons donc maintenant indiquer dans la requête 'commanderCompteARebours' que nous souhaitons qu'elle récupère comme paramètre la propriété 'clientId'.
//          Double cliquez sur 'commanderCompteARebours' puis comme on l'a fait pour 'creerClient', puis faites un clic droit sur le contenu de la balise 'arg0' et indiquez la propriété 'clientId'.
//          Vous obtenez :
//                  <soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/" xmlns:lif="http://lifeleft.com/">
//                      <soapenv:Header/>
//                      <soapenv:Body>
//                          <lif:commanderCompteARebours>
//                          <!--Optional:-->
//                              <arg0>${#TestCase#cliendId}</arg0>
//                          </lif:commanderCompteARebours>
//                      </soapenv:Body>
//                  </soapenv:Envelope>
//          Très bien, il ne reste plus qu'à lancer le Test Case. Cliquez sur le bouton play, en bas vous devriez avoir cette fois-ci 3 étapes.
//          Si vous ouvrez l'étape 1 et 3 côte à côte, vous verrez que la réponse reçue par creerClient a été bien transférée à la requête 'commanderCompteARebours'.
// -----------
//  - Scripting :
// Tout ça est bien joli, mais je ne teste rien si c'est pour que j'aille changer la valeur des propriétés manuellement à chaque fois pour tester avec différente valeurs.
// Effectivement quand on veut tester une méthode, une Class ou un service, il est inutile de la tester avec une seule valeur.
//      --> Il faut tester en fournissant des données aléatoires et voir si la fonctionnalité choisie réagit comme prévu.
// Dans SoapUI Pro, il y a la possibilité d'ajouter une étape 'DataGen' au même titre que 'Property Tranfer' et qui générera des données pour vous automatiquement.
// Comme SoapUI Pro est payant, nous allons voir comment générer ces données facilement grâce à une des fonctionnalités les plus puissantes de SoapUI : les 'Groovy Scripts'.
// Pour ceux d'entre vous qui ne le connaissent pas, 'Groovy' est un langage de programmation qui reprend en grande partie la syntaxe de Java.
// Il permet dans SoapUI (mais pas que) de créer de petits scripts facilement.
//      - Objectif :
//          Nous voulons que les propriétés login et password soit alimentées avec des données aléatoires afin de voir si notre opération creerClient répond comme prévu.
//      - Créer le script :
//          Nous allons commencer par ajouter une étape à notre 'TestCase Commande'.
//          Cliquez sur 'Add Step' puis sélectionnez 'Groovy Script', appelez-le : 'ParamAleatoires'. Glissez-le en haut de la liste.
//          Double cliquez sur cette nouvelle étape ajoutée. Nous allons commencer par nous familiariser avec cet outil en récupérant la valeur des propriétés que nous avons définit plus tôt.
//          Entrez ce code dans l'éditeur :
//                  String login = testRunner.testCase.getPropertyValue( "login");
//          Oui on dirait du pur Java, et c'est le cas !
//          Techniquement, c'est un autre langage, mais dans la pratique vous allez utiliser les bibliothèques Java classiques ainsi que sa syntaxe.
//          Groovy vient ajouter d'autres fonctionnalités, qui ne nous seront pas utiles ici.
//          Cette ligne récupère la propriété login grâce à testRunner.
//          Celui-ci est votre ami, car c'est l'objet qui exécute les TestCase, il réitère sur les TestSteps et les exécute l'une après l'autre.
//          Il vous permet donc l'accès à l'ensemble des propriétés et étapes qui entrent dans votre TestCase.
//          Cliquez sur play et une pop-up apparaîtra avec la valeur que vous avez donné précédemment à login.
//          À l'instar de 'getPropertyValue', 'setPropertyValue' vous permet de changer la valeur d'une propriété.
//          Voici le script final pour fournir des données aléatoires à 'login' et 'password' :
//                  import org.apache.commons.lang.RandomStringUtils;
//                  import java.util.concurrent.ThreadLocalRandom;
//                  int longueurParDefaut = 15
//                  String charset = (('a'..'z') + ('A'..'Z') + ('0'..'9')).join()
//                  String loginAleatoire = RandomStringUtils.random(longueurParDefaut, charset.toCharArray());
//                  testRunner.testCase.setPropertyValue( "login", loginAleatoire);
//                  int mdpAleatoire = ThreadLocalRandom.current().nextInt(1000, 9000);
//                  testRunner.testCase.setPropertyValue("password", "${mdpAleatoire}");
//              - Ligne 1 et 2 : on importe la bibliothèque RandomStringUtils qui permet de générer aléatoirement une chaîne de caractères à partir d'une autre.
//                  On importe également 'ThreadLocalRandom' qui nous permettra comme dans la Class LifeLeft de générer des int aléatoires.
//              - Ligne 4 : on définit la longueur des chaînes que nous souhaitons générer.
//              - Ligne 5 : on génère une chaîne de caractères comportant tous les caractères que l'on souhaite utiliser dans la génération de notre chaîne aléatoire.
//              - Ligne 6 : on fournit la longueur souhaitée et les caractères à mélanger à la méthode random de RandomStringUtils, que nous avons importé précédemment.
//              - Ligne 8 : on utilise setPropertyValue pour remplacer la valeur de login par celle qu'on vient de générer.
//              - Ligne 10 : on génère un int aléatoire.
//              - Ligne 12 : on l'affecte à la propriété password.
//                  --> À noter qu'ici nous passons mdpAleatoire sous cette forme '${mdpAleatoire}' car 'setPropertyValue' accepte uniquement des String comme argument.
//          Très bien, vous pouvez maintenant appuyer sur play.
//          Rien ne se passe à l'écran, mais si vous cliquez sur 'TestCase Command' puis 'Custom Properties' en bas, vous verrez que les valeurs changent à chaque fois que vous appuyez sur play.
//      - Tester :
//          Il ne vous reste plus qu'à double cliquer sur votre Test Case et appuyer sur play pour lancer le test.
//          Si vous double cliquez sur la requête en bas 'creerClient' (Step 2 dans l'image ci-dessus), vous verrez que le 'login' et 'mdp' sont effectivement aléatoires.
//          Bien entendu, si vous voulez tester vraiment votre service, vous allez ajouter dans les chaînes aléatoires des caractères spéciaux.
//          Ou encore des espaces et tout un tas de choses pour voir si celui-ci répond correctement.
//          Le composant Groovy Script vous offre énormément de possibilitéS, par exemple la possibilité de faire tourner les étapes d'un Test Case en boucle autant de fois que vous le souhaitez.
//          Je vous invite à consulter la documentation à ce sujet.
// -----------
//  - Assertions :
// Votre test fonctionne, mais vous n'allez tout de même pas aller vérifier par vous-même à chaque fois si le résultat correspond à ce que vous attendez ?
// Imaginez que la réponse soit un message SOAP de 1300 lignes, je crois que vous aurez perdu 2 points d'acuité visuelle avant de l'avoir validé à l'oeil nu !
// SoapUI offre la possibilité de valider automatiquement les réponses aux différentes requêtes, on appelle ça des 'Assertions'.
// Pour chaque requête ou Test Step, vous pouvez ajouter 0 ou plusieurs assertions afin de valider la réponse.
//      --> Sans que vous le sachiez, SoapUI avait déjà placé une assertion par défaut pour valider les réponses reçues.
// Double cliquez sur la requête creerClient puis cliquez en bas sur Assertions.
// Le panneau des assertions apparaît avec une assertion SOAP Response déjà présente. Celle-ci vérifie tout simplement si le message reçu est un message SOAP valide.
// Pour ajouter une assertion, cliquez sur le bouton vert '+' en haut à gauche de ce panneau. Vous obtenez alors une liste des différents types d'assertions à appliquer.
// Vous avez à gauche la catégorie des assertions et à droite les assertions utilisables dans notre requête.
// Cliquez sur 'Property Content'. Parmi les plus utiles dans cette catégorie on retrouve :
//      - Contains : permet de chercher dans l'ensemble de la réponse une valeur en particulier, on peut bien entendu utiliser des expressions régulières.
//      - Not Contains : l'inverse de la précédente .
//      - XPath : vous vous souvenez quand on a ciblé le contenu d'une balise grâce à un XPath ?
//          Eh bien celui-ci peut vous servir encore ici, car vous pouvez avec cette assertion cibler le contenu d'une balise pour vérifier s'il correspond à une valeur que vous déterminez.
// Cliquez à présent sur 'Compliance', 'Status' and 'Standards'. Les fonctionnalités les plus utiles sont :
//      - SOAP Fault : détermine si le message SOAP reçu ne comporte pas la balise fault qui indique qu'une erreur a été retournée (nous verrons cette balise dans le chapitre de gestion des erreurs).
//      - Schema Compliance : celle-ci est extrêmement utile car elle permet de vérifier que la réponse obtenue correspond bien à ce qui a été prévu dans le WSDL.
//          Cela implique la vérification des type de donnés : int ? String ? entre autres.
//      - SOAP Response : très utile également, elle est incluse comme assertion par défaut mais vous pouvez la supprimer.
// Enfin la catégorie 'Script' permet de valider le XML de la réponse manuellement grâce encore une fois à Groovy.
// Nous allons commencer par tester la balise 'Schema Compliance'. Une fois sélectionnée, cliquez sur 'Add'.
// Une fenêtre va vous demander l'adresse du WSDL contre lequel on va valider la réponse. Normalement il est pré-rempli avec celui que vous avez indiqué à la création du projet.
// Cliquez sur OK puis appuyez sur play pour lancer la requête. Vous ne devriez pas recevoir d'erreur car notre réponse est valide.
// Afin de tester si notre assertion vérifie bien que dans notre balise < return > on a un int, remplacez la valeur de celle-ci manuellement dans la réponse par un String comme 'test'.
// Nous allons lancer cette assertion sans relancer la requête, car sinon on recevra de notre serveur une réponse valide.
// Double cliquez tout simplement en bas dans le panneau des assertions sur Schema Compliance et validez le WSDL proposé.
// Une vilaine erreur apparaît en bas nous indiquant que le mot test ne ressemble pas des masses à un chiffre décimal.
//      - Scripting :
//          L'assertion la plus puissante est celle qui permet d'utiliser un script.
//          Nous allons donc ici créer un script Groovy, pour vérifier si l'id client reçu est toujours inférieur à 1000 comme prévu.
//          Ajoutez une nouvelle assertion de type script.
//          Une fenêtre semblable à ce qu'on a vu plus tôt avec les propriétés aléatoires apparaît.
//          Voici le code qui nous permettra d'accomplir cela :
//                  def util = new com.eviware.soapui.support.GroovyUtils(context);
//                  def xml = util.getXmlHolder(messageExchange.responseContent);
//                  xml.namespaces["S"]="http://schemas.xmlsoap.org/soap/envelope/";
//                  xml.namespaces["ns2"] = "http://lifeleft.com/"
//                  String clientId = xml.getNodeValue("/S:Envelope/S:Body/ns2:creerClientResponse/return");
//                  if(clientId != null && !clientId.isEmpty()) {
//                      Integer idClientInt = clientId.toInteger();
//                      assert idClientInt < 1000;
//                  } else {
//                      assert false
//                  }
//          - def : dans Groovy, def sert à définir une variable sans type (eh oui, du Java sans le typage).
//              D'ailleurs le def n'est pas obligatoire , il est surtout là pour limiter la portée de la variable à ce script uniquement.
//          - Ligne 1 : on récupère une instance de GroovyUtils, qui est une Class fournie par SoapUI.
//              Elle permet d'avoir accès à quelques fonctions utiles comme le 'XmlHolder' qui nous permet de manipuler et naviguer dans les réponses XML.
//          - Ligne 2 : on récupère une instance de XmlHolder afin de l'utiliser pour retrouver la valeur que nous cherchons dans la réponse.
//          - Ligne 4 et 5 : on définit les espaces de noms exactement comme on l'a fait pour les propriétés aléatoires.
//          - Ligne 7 : on utilise la méthode 'getNodeValue' de 'XmlHolder' pour accéder à la valeur de la balise < return > exactement de la même manière que précédemment.
//              Ceci, à l'exception qu'ici on n'a pas besoin de finir par 'text()' car 'getNodeValue' récupère justement le contenu de la balise ciblée.
//          - Ligne 9 : on vérifie que l'expression 'clientId' n'est pas égale à 'null' et n'est pas vide.
//          - Ligne 10 : les valeurs récupérées dans un XML sont toujours des String, il faut donc convertir dans notre cas vers un Integer.
//          - Ligne 11 : on utilise assert qui permet dans Groovy d'évaluer une expression et d'indiquer si elle est vraie ou fausse.
//              Si la 'clientId' est supérieure à 1000 alors SoapUI comprendra le retour d'assert et affichera que le test a échoué.
//          - Ligne 14 : on renvoie un false si 'clientId' est vide.
//              Normalement, on ne devrait pas le faire ici, mais plutôt directement dans le WSDL en indiquant que cette balise ne doit pas être vide.
//              Néanmoins pour l'exemple, nous renvoyons ici une erreur dans ce cas.
//          Très bien, pour tester ce script, appuyez sur le bouton play.
//          Vous devriez avoir un message de succès. Afin de tester si notre script marche vraiment, appuyez sur OK pour valider puis fermez cette fenêtre.
//          Remplacez ensuite manuellement la valeur de la balise < return > par un chiffre supérieur à 1000.
//          Double cliquez à nouveau sur le script d'assertion dans le panneau du bas et appuyez sur le bouton play dans la fenêtre de l'éditeur de scripts.
//          Vous obtenez alors une erreur, comme prévu !
//          Vous pouvez faire le même test avec une balise < return > vide ou encore en changeant dans la Class du service la valeur 'clientId' à retourner.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Simulez un service avec les mocks /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Imaginez que vous avez la charge de tester un logiciel. Un service primordial comme l'authentification est toujours en cours de développement.
// Vous êtes donc bloqué pour tester des scénarios qui impliquent l'authentification.
// SoapUI offre la possibilité de simuler un service à partir de son WSDL.
//      --> En quelques clics, vous pouvez avoir un service qui tourne sur un serveur interne de SoapUI et qui simule le fonctionnement du vrai service.
// Allons tester cette magie, nous allons créer un nouveau projet à partir d'un simple WSDL qui accepte en entrée un prénom et affiche 'Bonjour + prénom'.
// Copiez ce WSDL et enregistrez-le sous 'bonjour.wsdl' :
//                  <definitions name = "BonjourService"
//                     targetNamespace = "http://www.exemples.com/wsdl/BonjourService.wsdl"
//                     xmlns = "http://schemas.xmlsoap.org/wsdl/"
//                     xmlns:soap = "http://schemas.xmlsoap.org/wsdl/soap/"
//                     xmlns:tns = "http://www.exemples.com/wsdl/BonjourService.wsdl"
//                     xmlns:xsd = "http://www.w3.org/2001/XMLSchema">
//                     <message name = "AfficherBonjourRequest">
//                        <part name = "prenom" type = "xsd:string"/>
//                     </message>
//                     <message name = "AfficherBonjourResponse">
//                        <part name = "bonjour" type = "xsd:string"/>
//                     </message>
//                     <portType name = "Bonjour_PortType">
//                        <operation name = "afficherBonjour">
//                           <input message = "tns:AfficherBonjourRequest"/>
//                           <output message = "tns:AfficherBonjourResponse"/>
//                        </operation>
//                     </portType>
//                     <binding name = "Bonjour_Binding" type = "tns:Bonjour_PortType">
//                        <soap:binding style = "rpc"
//                           transport = "http://schemas.xmlsoap.org/soap/http"/>
//                        <operation name = "afficherBonjour">
//                           <soap:operation soapAction = "afficherBonjour"/>
//                           <input>
//                              <soap:body
//                                 encodingStyle = "http://schemas.xmlsoap.org/soap/encoding/"
//                                 namespace = "urn:exemples:bonjourservice"
//                                 use = "encoded"/>
//                           </input>
//                           <output>
//                              <soap:body
//                                 encodingStyle = "http://schemas.xmlsoap.org/soap/encoding/"
//                                 namespace = "urn:exemples:bonjourservice"
//                                 use = "encoded"/>
//                           </output>
//                        </operation>
//                     </binding>
//                     <service name = "Bonjour_Service">
//                        <port binding = "tns:Bonjour_Binding" name = "Bonjour_Port">
//                           <soap:address
//                              location = "http://www.exemples.com/AfficherBonjour/" />
//                        </port>
//                     </service>
//                  </definitions>
//      - Créez pour l'occasion un nouveau projet et appelez-le Bonjour.
//      - À l'étape où on vous demande un WSDL, choisissez celui que vous avez enregistré dans votre ordinateur puis validez.
//      - Faites un clic droit sur 'bonjour_binding' puis choisissez Generate SOAP Mock Service.
//      - Vous tombez sur le générateur de mocks qui vous proposera de choisir les opérations à inclure, dans ce cas il n'y en a qu'une.
//          Changez par contre Path pour le simplifier, mettez bonjour tout simplement à la place. Validez.
//      - On vous demandera ensuite de choisir le nom à donner à ce mock, entrez "MockBonjour".
//      - Créez une propriété "name" au niveau du projet. Pour ce faire, cliquez sur le projet et ajoutez la propriété en bas dans le panneau affiché.
//      - Revenez dans le mock créé et double cliquez sur Response 1. Celle-ci représente la réponse que le mock va simuler quand vous l'invoquerez.
//          Nous allons mettre en réponse la propriété name que nous avons fixé plus haut. Fermez ensuite cette fenêtre.
//      - Doublez cliquez sur MockBonjour à gauche afin d'afficher la fenêtre de celui-ci. Celle-ci vous permet de lancer le mock dans le serveur interne de SoapUI.
//          Celui-ci sera alors disponible exactement comme n'importe quel service. Cliquez sur le bouton play pour le lancer.
//      - Vous avez en haut à droite running on port 8088 qui vous indique le port de votre service.
//          Afin de tester que celui-ci marche bel et bien, rendez-vous dans votre navigateur à l'adresse = 'http://localhost:8088/'.
//      - SoapUI vous indique que vous avez un mock qui fonctionne et vous fournit son adresse de WSDL.
//      - Vous allez maintenant faire appel à ce service depuis la requête qu'on avait au départ.
//          Double cliquez sur Request 1 et remplacez là aussi le contenu de la balise < prenom > par la propriété que nous avons définie.
//      - Remplacez l'adresse du service par celui qu'on vient de créer : 'http://localhost:8088/bonjour'.
// Il ne vous reste plus qu'à appuyer sur le bouton play pour lancer le test.
// Vous verrez alors par magie apparaître le résultat attendu, à savoir le prénom que vous avez fixé dans la propriété name.
// Changez ce prénom et testez encore pour vérifier. Si vous préférez qu'il vous affiche "Bonjour Robert", il suffit d'éditer Response 1 en ajoutant le mot "bonjour" avant la propriété.
// Votre requête vient d'interroger votre mock qui s'est comporté comme un vrai service et a répondu avec un message SOAP valide.
// Vous pouvez grâce à cet outil simuler tout une ribambelle de services avant même de commencer à les développer.
// Vous pouvez aussi tester le service que vous comptez développer et l'intégrer dans un système déjà existant afin de vérifier qu'il s'intègre correctement, avant d'écrire la logique.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérez les erreurs /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quand nous avons développé le web service LifeLeft, vous avez remarqué que nous avions soigneusement évité de prendre en compte les cas où des erreurs peuvent apparaître.
// Je pense par exemple au cas ou le service distant fournit à l'opération anneesRestantesAVivre une date de naissance dans le futur par exemple.
// -----------
//  - Comment sont indiquées les erreurs dans un WSDL ?
// Il y a une balise spéciale pour renvoyer une erreur : < fault >. Quand votre service rencontre une exception, il renvoie donc une réponse spéciale de type fault.
// Fault est un complexType qui se compose éventuellement d'un code d'erreur et d'un message d'erreur.
// Nous allons voir comment il est déclaré en détail plus tard quand on aura généré notre WSDL.
// -----------
//  - Générer une exception :
// On pourrait croire qu'il suffit de lancer une exception comme on ferait normalement, et que JAX-WS générera la balise fault correspondante.
//      --> Cela peut marcher mais cela génère beaucoup de problèmes du côté client.
// Pour gérer les exceptions correctement, il nous faudra le faire comme le préconisent les spécifications de JAX-WS, c'est-à-dire avec :
//      - Une Class POJO dans laquelle nous allons stocker les messages d'erreur.
//          Si vous ne savez pas ce que une Class POJO, c'est une classe basique, qui contient quelques attributs avec leurs getters et setters pour les manipuler, littéralement : Plain Old Java Class.
//      - Une Class qui représente notre exception et qui hérite de Exception.
// Créez un nouveau package sous le dossier java et appelez-le exceptions.
// Commençons par la POJO, créez une Class et nommez-la LifeLeftFault.
//                  package exceptions;
//                  public class LifeLeftFault {
//                      // code d'erreur
//                      private String faultCode;
//                      //message d'erreur
//                      private String faultString;
//                      //Tous les getters et setters des 2 attributs précédentes
//                      public String getFaultCode() {
//                          return faultCode;
//                      }
//                      public void setFaultCode(String faultCode) {
//                          this.faultCode = faultCode;
//                      }
//                      public String getFaultString() {
//                          return faultString;
//                      }
//                      public void setFaultString(String faultString) {
//                          this.faultString = faultString;
//                      }
//                  }
// C'est une classe toute simple pour contenir les détails de l'erreur que nous allons retourner.
// Astuce : sous IntelliJ vous pouvez générer les getters et setters en appuyant sur 'ctrl + N'.
// Créez une Class et nommez-la 'LeftLifeException', celle-ci contiendra le code de notre exception proprement dite. Cette Class doit répondre à des critères précis :
//      --> Être annotée avec '@WebFault'.
//      --> Hériter de 'Exception'.
//      --> Avoir 2 constructeurs minimum.
//      --> Avoir la méthode 'getFaultInfo' qui retourne la POJO déjà créée.
// On obtient donc ceci :
//                  package exceptions;
//                  import javax.xml.ws.WebFault;
//                  @WebFault(name = "LifeLeftException")
//                  public class LifeLeftException extends Exception {
//                      /*
//                          on déclare une instance de LifeLeftFault qu'on créée précédemment
//                          afin de récupérer ensuite les messages et codes d'erreurs à renvoyer dans cette exception
//                       */
//                      private LifeLeftFault fault;
//                      /*
//                          On crée un constructeur qui prend en paramètre un message d'erreur et un objet LifeLeftFault
//                          avec plus de détails sur l'erreur
//                      */
//                      public LifeLeftException(String message, LifeLeftFault fault) {
//                          super(message);
//                          this.fault = fault;
//                      }
//                      public LifeLeftException(String message, Throwable cause, LifeLeftFault fault) {
//                          super(message, cause);
//                          this.fault = fault;
//                      }
//                      public LifeLeftFault getFaultInfo() {
//                          return fault;
//                      }
//                  }
// Le rôle du deuxième constructeur est de nous permettre de générer des exceptions sans le POJO en passant un 'Throwable' à la place, afin de pouvoir utiliser les exceptions classiques de Java.
// Il ne reste plus qu'à utiliser cette classe pour générer une exception quand le paramètre naissance est supérieur à 2017 par exemple.
//                  @WebMethod
//                  public String  anneesRestantesAVivre (String prenom, String genre, Integer anneeNaissance) throws LifeLeftException {
//                      //vaut mieux remplacer 2017 par Year.now().getValue(), mais pour simplifier on laisse 2017
//                      if(anneeNaissance > 2017) {
//                          //On créer une nouvelle instance de notre POJO
//                          LifeLeftFault fault = new LifeLeftFault();
//                          //On y ajoute le code d'erreur et le détail de l'erreur en question
//                          fault.setFaultCode("1234");
//                          fault.setFaultString("L'année reçu est supérieur l'année actuelle");
//                          //on lance l'exception avec comme premier argument un message général sur l'erreur.
//                          throw new LifeLeftException("Année invalide", fault);
//                      }
//                      if(genre.equals(homme)) evDeReference = ESPERANCE_VIE_HOMMES;
//                      else evDeReference = ESPERANCE_VIE_FEMMES;
//                      //Remarque, en cas de problème, vous pouvez changer Year.now().getValue() par Calendar.getInstance().get(Calendar.YEAR)
//                      Integer anneeRestantes = evDeReference -(Year.now().getValue() - anneeNaissance );
//                      return "Bonjour " + prenom + ", il vous reste " + anneeRestantes + " ans, à vivre, Profitez-en au maximum !";
//                  }
// Comme je l'ai indiqué dans les commentaires, on alimente le POJO avec les messages appropriés puis on le passe en argument à l'exception à retourner.
// C'est fini ! Faites dans le panneau latéral de Maven un 'Clean' puis un 'Install' et uploadez le War sur Glassfish.
// -----------
//  - Tester :
// Retournez à SoapUI dans le projet LifeLeft. Allez cette fois dans TestSuite 2 que nous avons créé précédemment et double cliquez sur 'anneesRestantesAVivre'.
// Remplissez les balises avec les arguments nécessaires en veillent à mettre une année supérieure à 2017 puis cliquez sur play.
// Vous devriez alors avoir une balise fault en réponse avec 'faultstring' contenant le message général qu'on a défini en premier argument de notre exception.
// Vous aurez aussi les détails de l'erreur sous la balise detail.
// -----------
//  - Le WSDL :
// Rendez-vous à l'URL du WSDL de LifeLeft 'http://localhost:8080/lifeleft/LifeLeft?wsdl'.
// Vous constaterez que pour gérer l'exception, les éléments suivants ont été ajoutés :
// Sous < types > si vous allez au lien de schemaLocation qui contient les types complexes, vous verrez alors qu'un nouveau type complexe a été ajouté :
//                  <xs:complexType name="lifeLeftFault">
//                  <xs:sequence>
//                    <xs:element name="faultCode" type="xs:string" minOccurs="0"/>
//                    <xs:element name="faultString" type="xs:string" minOccurs="0"/>
//                  </xs:sequence>
//                  </xs:complexType>
// Sous portType l'opération anneesRestantesAVivre a maintenant, en plus des input et output classiques, une autre possibilité de réponse : 'fault'.
// Cette dernière réponse possible est répercutée comme toutes les autres sous binding.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découplez votre architecture web pour des applications Java robustes //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous voyez ce tiroir dans la cuisine, celui qui est rempli d’un tas de bric-à-brac inutile ? Vous vous demandez comment on en est arrivé là ?
//      --> C’est facile : un élément à la fois.
// Nous pouvons créer le même genre de désordre dans nos applications si on ajoute chaque nouvelle fonctionnalité sans prendre en compte l’architecture globale.
// Pour en finir avec cette approche, on va opter pour une architecture à plusieurs couches, autrement dit découplée :
//      --> Chaque couche se voit attribuer une responsabilité spécifique et un système défini de messages (API).
// Dans ce cours, vous apprendrez à analyser une architecture monolithique existante pour trouver ses faiblesses.
// Ensuite, vous utiliserez de nouvelles opportunités business comme prétextes de refactorisation pour obtenir une architecture découplée.
// Vous utiliserez le design pattern Modèle-Vue-Contrôleur comme ligne directrice pour séparer les couches de votre architecture.
// Vous verrez également diverses solutions de stockage de données et de communication entre les couches.
// -----------
// Objectifs pédagogiques :
//      --> Analyser l’architecture d’une application existante.
//      --> Séparer les couches d’application avec le Modèle-Vue-Contrôleur et la refactorisation.
//      --> Implémenter la communication entre les couches d’application.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Analysez l’architecture d’une application existante ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Examinez les problèmes posés par l’architecture monolithique //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lorsque nous construisons un logiciel, nous pouvons continuer à empiler des fonctionnalités selon les besoins, en prenant le risque que cela finisse par casser.
// Au départ, une application n'est construite que pour faire qu'une seule chose. Mais au fûr et à mesure, nous ajoutons des fonctionnalités par dessus.
//      --> C'est ce que nous appelons une 'Application Monolithique'.
// C'est à dire qu'elle fait tout elle-même, ou pire, elle intéragit avec un autre système monolithique.
// Une telle implémentation n'est pas 'scalable', c'est à dire que la solution telle qu'elle est fonctionne, mais que si nous venons augmenter sa charge de travail par exemple, le système sera débordé.
// -----------
//  - Comprenez les pièges de l’architecture monolithique :
// Que se passe-t-il, sur le long terme, lorsqu'on ne prend jamais en compte l’architecture d’un logiciel pour le modifier ?
//      --> Traditionnellement, les applications sont construites pour remplir un seul objectif.
// Exemple : une application de calculatrice semble être simple à créer : elle doit faire des calculs puis afficher le résultat.
// On serait tenté pour cela de créer une application monolithique.
// Une dans laquelle le code pour l’accès aux données, la logique business, et l’interface graphique seraient tous regroupés en une seule couche interconnectée.
// Une application monolithique est une application qui empile des fonctionnalités les unes par dessus les autres au sein d'un même bloc : tout le code est implémenté dans un seul programme.
// Ce type d'application peut fonctionner jusqu'à un certain point, et ne pourra évoluer que très difficilement :
//      --> Si la charge de travail augmente, le système sera débordé, ralentira et commettra des erreurs.
// Maintenant, revenons à notre exemple d’application de calculatrice. Nous avons tout codé en une application monolithique.
// Mais imaginez que nos clients demandent qu'on ajoute de nouvelles fonctionnalités ?
// Disons que nous voulons fournir une API REST (une interface d’application qui peut être appelée par n’importe qui, de n’importe où).
// Nous voulons sauvegarder les valeurs saisies, les opérations demandées, et les résultats, pour que nous puissions analyser ces informations plus tard (ou en temps réel).
// Nous voulons ajouter de nouvelles opérations pour traiter des calculs métier ou scientifiques, ce qui nécessite davantage de boutons sur l’interface.
// Nous pourrions ajouter des éléments sur les parties existantes en fonction des besoins.
// Mais alors, nous obtiendrons une application difficile à modifier (souvenez-vous des prises sur l’image ci-dessus).
// La logique métier est enfouie profondément quelque part dans le code, ce qui signifie qu’il est difficile de prédire ce qui pourrait se casser lorsqu’on apporte un changement.
// Pourtant nombreux sont ceux qui tombent dans le piège ! Autour de nous, il existent beaucoup de systèmes hérités, qui ont évolué petit à petit jusqu’à atteindre cet état.
// Personne ne commence un projet avec l’intention de créer un casse-tête. Pour autant, c'est le type de problème que peu de développeurs prennent le temps de réparer au fur et à mesure.
//      --> Mais alors, comment faire pour "réparer" une telle application ?
// Nous allons prendre une application monolithique, analyser ses problèmes, la refactoriser en composants séparés, et faciliter la communication entre différentes couches.
// Plongeons-nous dans un exemple précis ! Nous allons travailler dessus ensemble tout au long du cours.
// -----------
//  - Cas d’usage : Réparez une application difficile à modifier et non scalable :
// Le cas d’usage suivant sera utilisé pour illustrer différentes étapes techniques dans ce cours.
// Nous ne travaillerons pas sur une application complète, mais nous soulignerons des exemples clés en utilisant ce cas d’usage comme point de référence.
// Air Business, une petite compagnie aérienne charter, vous a demandé votre aide pour leur application.
// Leur application actuelle est capable de gérer la planification de vols spécialisés, et est exécutée sur un ordinateur à l’aéroport où est basée la compagnie.
// Une personne ouvre l’application et effectue toute la planification nécessaire.
// C’est ce dont la compagnie aérienne avait besoin au moment où elle a pris son envol. Néanmoins, cela ne répond plus aux besoins du client, qui évoluent.
// Plus précisément, la compagnie aérienne a un nouveau client potentiel.
// Un tour opérateur voudrait utiliser leurs services régulièrement pour transporter par avion des voyageurs vers des destinations de rêve.
// Actuellement, la compagnie a uniquement acheminé des particuliers ou de petits groupes vers des réunions professionnelles. Cette nouvelle opportunité est très intéressante pour leur croissance !
// Malheureusement, l’application actuelle a un problème : plusieurs aspects de l'application ne peuvent pas être adaptés, ils ne sont pas "scalables".
//      --> C’est-à-dire que si le système doit répondre à davantage d’exigences, il ralentira — ou ne fonctionnera plus du tout.
// Voyons certaines de ces limites :
//      - Actuellement, il n’est accessible que par une personne. Or il devra être accessible par d’autres agents de la compagnie dans d’autres aéroports.
//          De plus, les agents de réservation du tour opérateur auront besoin d’un accès. À l’avenir, il serait bénéfique que des particuliers puissent eux aussi réserver des vols charters.
//      - La base de données ne supporte pas la connectivité simultanée pour le requêtage et la mise à jour.
//      - La logique business pour trouver les combinaisons d’avions et de pilotes disponibles est enfouie dans du code difficile à trouver, et encore plus à modifier.
// Maintenant, regardons les rouages en détail. L’application est écrite en Java. Les seules classes sont :
//      - Client - représente la personne qui a acheté le voyage charter.
//      - Pilot - une personne qualifiée pour piloter un avion.
//      - Plane - un véhicule qui emmène des passagers d’un endroit à un autre.
//      - Reservation - Détails concernant un voyage.
// L’architecture actuelle est également constituée d’une poignée de classes Java Swing pour le rendu.
// Ainsi que d’une base de données SQLite pour stocker des informations concernant les pilotes, les avions, les réservations, et les clients.
// La gestion des événements et la logique business sont enfouies dans Java.
// Les classes Java Swing sont un ensemble de classes intégrées à Java pour le rendu des objets de l’IHM, et pour générer des événements lorsque l’utilisateur interagit avec eux.
// L'architecture du système de la compagnie aérienne est représentée par un diagramme qui montre les différentes tables de données :
//      --> Avion, Réservation, Client, Pilote. Elles sont reliées aux classes Java Swing et à une base de données SQLite.
// Il y a de nombreuses connexions entre les classes : une situation propice au changement pour aboutir à une architecture web découplée !
//      --> "Découplé" signifie que les différentes parties ne connaissent pas beaucoup de détails sur les autres parties d’un système.
//              Elles communiquent à travers des interfaces bien définies. Par exemple, lorsque vous conduisez une voiture, vous tournez le volant (c’est une interface).
//              Il est relié aux roues. Vous n’avez pas besoin de connaître tous les détails sur les paliers et les connexions pour faire prendre un virage à la voiture.
// Quels sont les avantages du découplage ?
//      --> Une architecture découplée permet à tous les composants d’opérer de manière indépendante.
//              Si on modifie l’implémentation d'un composant, cela n’impacte aucun des autres qui en dépendent.
//              Autrement dit, l’exécution du code dans une couche peut changer sans affecter les autres couches !
// Alors, comment améliorer notre architecture ?
//      --> Pour concevoir l’architecture d’une meilleure solution, nous pouvons appliquer le pattern Modèle-Vue-Contrôleur (MVC).
//              Ce pattern séparera les responsabilités du système en couches et éléments distincts.
// Dans un diagramme, on voit les blocs de couches séparés des uns des autres :
//      --> Couche de connexion, couche de données et couche d'entité. La couche de connexion et reliée à la couche d'entités, la couche de données et à l'interface utilisateur.
// Que font les couches ? C’est ce que l'on va voir dans ce cours. Mais d’abord, quelques définitions :
//      - Interface Utilisateur : Elle interagit avec l’utilisateur, affiche des informations, et récolte des valeurs saisies ou événements déclenchés.
//      - Couche d’entités : Les éléments qui nous intéressent et qui sont affichés, ou manipulés par l’interface utilisateur.
//      - Couche de données : Si l’on doit sauvegarder les informations des entités, elle les stockera et les récupérera via  une solution pérenne de stockage de données.
//      - Couche de connexion : Elle colle toutes les couches les unes aux autres, pour qu’elles n’aient pas à interagir directement entre elles.
// Chaque couche communiquera avec la couche de connexion à travers des interfaces clairement spécifiées.
// Nous pouvons donc remplacer le code derrière l’interface par différentes implémentations, sans affecter ce qui appelle chaque interface.
// Pour déterminer ce que nous devons changer et comment procéder, nous allons passer par les étapes suivantes :
//      --> Exprimer les opportunités business à travers des user stories.
//      --> Étendre les user stories en descriptions de cas d’usage et déterminer quelles entités doivent être ajoutées à notre application.
//      --> Nous poser des questions clés pour déterminer quelle partie de l’application actuelle fait défaut, et ce qui peut être récupéré.
//      --> Prioriser nos user stories en fonction de nos découvertes.
// En analysant nos besoins, en planifiant nos changements, et en les priorisant, nous pourrons tirer le maximum de notre temps et de notre énergie — et nous éviterons de nous retrouver perdus !
// Ensuite, nous appliquerons le pattern MVC étape par étape, en utilisant la refactorisation.
//      --> La refactorisation nous permet d’apporter des changements progressifs tout en s'assurant de l'intégrité et de la stabilité du système.
// Allez c'est parti ! Construisons une meilleure application pour notre client !
// -----------
//  - En résumé :
//      --> Les applications monolithiques sont difficiles à modifier et ne peuvent évoluer de façon pérenne.
//      --> Nous allons découpler notre architecture grâce au pattern MVC et à la refactorisation.
// Pour démarrer, il suffit de faire le premier pas : définir les user stories !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définissez de nouvelles user stories orientées business pour votre application ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lorsque nous travaillons sur un projet depuis longtemps, nous nous retrouvons très vite incapables de prendre du recul.
// Si nous nous apprêtons à ajouter une nouvelle fonctionnalité à notre application, il ne faut pas foncer tête baissée, mais plutôt identifier les opportunités de plus-values pour notre produit.
//      --> A partir de là, nous pourrons générer une liste de User-Stories.
// Ce processus génèrera plus de revenus et permettra de réduire les coûts de production plus rapidement que si nous nous en étions tenus à la user story d'origine.
// -----------
// Une entreprise ne modifie que rarement, voire jamais, l’architecture d’une application pour la beauté du geste.
//      --> Il existe en général une raison sous-jacente, et cette raison, c’est une opportunité business.
// Dans ce chapitre, nous allons amorcer le processus de modification de l’architecture.
//      - Pour ce faire, nous observerons tout d’abord la nouvelle opportunité business présentée et les besoins architecturaux correspondants.
//      - Puis, nous examinerons d’autres opportunités qui peuvent capitaliser sur notre nouvelle architecture.
//      - Enfin, nous exprimerons ces opportunités sous forme de user stories.
// C’est le fait de savoir évaluer les opportunités business qui fait la différence entre un programmeur et un ingénieur logiciel.
// L’ingénierie tient compte des aspects business du développement d’applications, au-delà du fait de faire fonctionner le code.
//      --> C’est pourquoi l’architecture est un composant clé du processus.
// Une bonne architecture s’adapte plus aisément au changement, et est plus facile à tester et à comprendre.
// -----------
//  - Étudiez les opportunités business :
// Air Business veut étendre ses services. Nous avons l’opportunité de répondre à la requête du tour opérateur qui souhaite réserver des vacances régulièrement.
//      --> Comment allons-nous mettre à jour l’application pour répondre à ces besoins ?
// Nous allons commencer par regarder la nouvelle fonctionnalité. Chaque nouvelle fonctionnalité sera traduite en une user story.
// Nous écrirons autant de stories que de fonctionnalités. Plus tard, nous revisiterons les stories en détail pour déterminer ce qui doit être architecturé et codé.
// Une user story consiste en une ou deux phrases simples qui traduisent le besoin des utilisateurs et l’objectif final qui doit être atteint lorsque la fonctionnalité est exécutée.
// Voici notre première user story :
//      --> En tant qu’opérateur d’agence de voyage, je veux réserver un vol pouvant transporter jusqu’à 12 personnes pour qu’elles puissent découvrir un lieu unique.
// Comme nous l’avons indiqué dans le chapitre précédent, le système n’assure pas cette fonctionnalité aujourd’hui.
// L’opérateur devrait donner les détails du voyage qu’il souhaite organiser à la personne au comptoir à l’aéroport.
// Pourquoi ne peut-on pas simplement coder cela et en avoir fini ?
//      --> Nous pourrions nous lancer et essayer de glisser 'de force' cette fonctionnalité dans l’architecture existante.
//              Mais nous savons que c’est une mauvaise stratégie. La solution ?
//                  --> S'orienter vers une application web découplée pour permettre à l’entreprise de réaliser un retour sur investissement significatif.
//                          Et ce, pas uniquement pour cette nouvelle user story là, mais pour une prochaine nouvelle fonctionnalité.
//                          Nous allons nous intéresser à la modification de l’architecture pour qu’elle puisse mieux gérer de plus grosses opérations pour la compagnie aérienne.
//                          Regardons par conséquent d’autres idées de fonctionnalités supplémentaires qu’a eues la compagnie.
// Comment puis-je trouver une opportunité business ?
//      --> Demandez-vous : "Où l'entreprise peut-elle gagner ou économiser plus d’argent ?".
//              Regardons comment celle-ci peut être mieux servie grâce à un changement dans l’architecture.
//              Nous pouvons commencer par poser quelques questions (j’ai fourni les réponses spécifiques à notre scénario) :
//                  --> Quels sont les problèmes orientés utilisateur qui existent actuellement ?
//                          Actuellement, seul un utilisateur unique à un seul emplacement peut utiliser l’application.
//                          La compagnie aérienne veut que l’application soit accessible depuis de nombreux emplacements, par de nombreuses personnes, le tout simultanément.
//                          La transformation en application web résoudra ces problèmes.
//                  --> Quels sont les problèmes orientés données qui existent actuellement ?
//                          La base de données stocke juste assez d’informations pour que l’application réserve des vols.
//                          Le mécanisme de requêtes est dirigé exclusivement vers cette fonctionnalité. Il y a très peu de capacités d’analyse.
//                          L'entreprise est donc incapable de proposer des offres aux voyageurs fréquents, ou de suivre les départs et arrivées en retard ou en avance.
//                          Par exemple, le système actuel affiche une liste de tous les clients d’Air Business, avec des informations qui les concernent, y compris les sommes qu’ils doivent actuellement.
//                          Nous voudrions voir une liste regroupant uniquement les clients qui doivent de l’argent.
//                  --> Quid de ce qui n'est pas informatisé : ce qui est communiqué sur papier, à l'oral ?
//                          - Les pilotes soumettent actuellement les commentaires sur le vol et les demandes de maintenance par des formulaires imprimés.
//                              Avec une architecture découplée, ces données pourraient être saisies via une application mobile, pendant que le pilote fait sa tournée d’inspection avant ou après le vol.
//                          - Les mécaniciens apportent des modifications à l’appareil et, de façon similaire aux pilotes, saisissent ces changements par le biais de rapports papier.
//                              Il serait très utile qu’ils puissent signaler leurs changements en temps réel.
//                  --> Quelles analyses peuvent être réalisées pour prévenir ces problèmes avant leur apparition ?
//                          Les achats de pièces et les dates d’installation peuvent être saisis.
//                          Un système analytique intelligent peut déterminer quelles pièces approchent de leur date de remplacement, et lesquelles peuvent être commandées "juste à temps".
//                          Et ce, avant qu'un dysfonctionnement arrive.
//                          Comme vous pouvez le constater, il existe de nombreuses opportunités de tirer profit de la nouvelle architecture. Voici quelques solutions possibles :
//                              - Convertir le système existant en application web nous donnera beaucoup plus de flexibilité que l’application sur un seul ordinateur.
//                              - Les analyses peuvent être introduites pour proposer des offres spéciales, et suivre les arrivées et les départs en avance et en retard.
//                                  La base de données actuelle n’a aucun moyen de stocker ou de demander ces informations.
//                              - Permettre aux pilotes de saisir des commentaires sur le vol et des demandes de maintenance, possiblement via une application mobile.
//                                  De sortes à ce qu’ils puissentt l'utiliser en effectuant l’inspection de l’avion avant ou après le vol.
//                              - Conserver des archives de maintenance plus avancées, qui pourront être utilisées pour acheter des pièces lorsqu’elles approchent de leur date de remplacement.
//                                  Cela, plutôt qu’une fois qu’elles sont cassées, ce qui oblige à garder l’avion inactif pendant que l’on attend l’arrivée de la pièce.
//                          Toutes ces opportunités n’ont pas besoin d’être mises en place immédiatement.
//                          Néanmoins, le fait de les connaître nous donne de meilleures justifications pour passer à l’architecture découplée.
// Si cela représente autant de travail, pourquoi ne pas simplement recommencer à zéro ?
// Nous pourrions jeter au feu l’application originale et recommencer à zéro.
// Le problème, c'est qu'Air Business est toujours en activité.
// Et puis, le code fonctionne tout de même : il fait ce qu’on attend de lui.
// Nous allons donc intégrer ces changements petit à petit. Cela permet à la compagnie aérienne de poursuivre ses opérations pendant que nous travaillons.
// De plus, nous pouvons récolter du feedback de la part des salariés de la compagnie aérienne sur la façon dont les fonctionnalités devraient marcher.
// Ainsi, ils n’auront pas besoin de se former sur un système totalement nouveau, d’un seul coup.
// -----------
//  - Définissons nos user stories :
// Jusqu’ici, nous avons créé une user story pour la première situation de notre liste :
//      --> Situation :
//              - Actuellement, seul un utilisateur unique à un seul emplacement peut utiliser l’application.
//              - Air Business veut que l’application soit accessible depuis de nombreux emplacements, par de nombreuses personnes, le tout simultanément.
//              - La conversion en application web résoudra ces problèmes.
//      --> User story : En tant qu’opérateur d’agence de voyage, je veux réserver un vol pouvant transporter jusqu’à 12 personnes pour qu’elles puissent découvrir un lieu unique.
// Nous nous concentrerons sur deux user stories supplémentaires pour inclure les situations où des choses se font pour l'instant à l'écrit ou à l'oral, et qui donc, ne sont pas informatisées.
// Essayez de les élaborer vous-même avant de regarder ma réponse ci-dessous :
//      --> Situation :
//              - Les pilotes soumettent actuellement les commentaires sur le vol et les demandes de maintenance par des formulaires imprimés.
//              - Avec une architecture découplée, ces données pourraient être saisies dans une application mobile, pendant que le pilote fait sa tournée d’inspection avant ou après le vol.
//      --> User Story :
//              - En tant que pilote, je veux saisir tout problème de maintenance mineur dès l’atterrissage, pour qu’il puisse être réparé rapidement.
//      --> Situation :
//              - Les mécaniciens apportent des modifications à l’appareil et saisissent ces changements par le biais de rapports papier.
//              - Il serait très utile qu’ils puissent signaler leurs changements en temps réel.
//      --> User Story :
//              - En tant que mécanicien en charge de la maintenance de l’avion, je veux mettre à jour tout problème dès qu’il a été traité, pour que l’avion puisse être comme apte à voler.
// Ces deux questions, ainsi que la user story de l’opérateur, impliquent les questions que nous posions plus haut sur les processus orientés utilisateur, orientés données, et sur papier.
// Il existe une autre user story que nous allons regarder pour illustrer la facilité d’implémentation APRÈS la mise en place de l’architecture (dans la section orientée données) :
//      --> Situation :
//              - Le système actuel affiche une liste de tous les clients d’Air Business, avec des informations qui les concernent, y compris le montant qu’ils doivent.
//              - Nous voudrions voir une liste montrant uniquement les clients qui doivent de l’argent.
//      --> User story :
//              - En tant que responsable financier, je veux voir une liste de tous les clients qui nous doivent de l’argent, afin de pouvoir leur faire un rappel téléphonique.
// -----------
//  - En résumé :
//      --> Résistez à la tentation de coder une fonctionnalité dans une application monolithique et cherchez comment une architecture découplée pourrait plutôt être utilisée.
//      --> Posez vous les bonnes questions pour savoir quels problèmes pourraient être évités.
//      --> Ecrivez une user story pour chaque fonctionnalité de l'application.
//      --> Lorsque vous ajoutez une nouvelle fonctionnalité (user story), pensez aux opportunités business qu'elles représentent.
//              C'est plus facile à justifier auprès du client quand vous lui expliquerez qu'il faut passer à une architecture découplée.
// Maintenant que nous avons nos user stories, décomposons-les et définissons les nouvelles entités dont nous avons besoin dans notre application !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définissez les entités métiers pour votre nouveau modèle d’application ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans le chapitre précédent, nous avons imaginé quelques user stories à implémenter.
// Nous allons maintenant nous intéresser aux classes que nous devons modifier ou créer pour supporter les nouvelles fonctionnalités.
// Pour ce faire, nous allons traduire les user stories en descriptions de cas d’usage.
// Très bien, voyons un peu où nous en sommes :
//      - Nous avons un nouvel ensemble de fonctionnalités à intégrer (grâce à nos user stories).
//      - Nous avons une application existante dans laquelle intégrer les nouvelles fonctionnalités.
//      - Nous avons besoin d’une approche ou d’une méthodologie raisonnée.
// Et maintenant ? Un excellent point de départ sera de trouver les entités, ou les composants architecturaux principaux de l’application.
//      --> Autrement dit, déterminons quels éléments feront le gros du travail.
// Comment allons-nous procéder ? Nous allons suivre plusieurs étapes :
//      --> Nous allons décrire des cas d’usage pour déterminer nos entités.
//      --> Cela nous permettra de savoir quelles entités sont nouvelles et quelles entités existantes ont besoin d’être modifiées.
// Une description de cas d’usage est une liste séquentielle d’interactions entre l’utilisateur et le système, pour atteindre l'objectif du cas d’usage en question.
// -----------
//  - Générez des descriptions de cas d’usage pour définir vos entités :
// Regardons de plus près un cas d’usage et amusons-nous à définir les entités :
// « En tant que pilote, je veux saisir tout problème de maintenance mineur dès l’atterrissage, pour qu’il puisse être réparé rapidement ».
//      --> Le pilote se connecte au système.
//      --> Le système valide le login.
//      --> Le pilote sélectionne nouveau problème de maintenance.
//      --> Le système présente l’écran de sélection de la maintenance.
//      --> Le pilote sélectionne le problème de maintenance mineur.
//      --> Le système présente l’écran de saisie de la maintenance.
//      --> Le pilote sélectionne l’avion qui a le problème.
//      --> Le pilote sélectionne le sous-système concerné.
//      --> Le pilote saisit les détails concernant le sous-système qui ne fonctionne pas correctement.
//      --> Le système enregistre le problème de maintenance mineur associé à l’avion.
// Vous remarquerez que j’ai écrit tous les noms en majuscules. Ces noms vont potentiellement devenir des entités métiers.
// -----------
//  - Déterminez quelles entités sont nouvelles ou ont besoin d’être modifiées :
// Très bien, nous allons maintenant regarder le système actuel pour voir quelles entités métiers existent déjà.
// L'architecture du système de la compagnie aérienne est représentée par un diagramme qui montre les différentes tables de données : Avion, Réservation, Client, Pilote.
//      --> Elles sont reliées aux classes Java Swing et à une base de données SQLite.
// Maintenant, regardons le cas d’usage de plus près. Il fait référence à des problèmes de maintenance mineurs.
// Le terme 'mineur' suppose qu’il existe également un niveau de problème 'majeur' et peut-être un niveau 'modéré'.
//      --> Nous devons donc prendre en compte ces autres niveaux.
// Lorsque vous analysez un cas d’usage, ne vous arrêtez pas à la surface des choses.
// Demandez-vous : que signifie vraiment chacun de ces termes ? Cela vous aidera à identifier les éléments clés à prendre en compte.
// De plus, notre cas d’usage nous montre que les avions possèdent des sous-systèmes qui ont besoin de maintenance.
// Nous devrons également ajouter cette idée. On voit aussi que les archives de maintenance sont associées à des avions précis.
// Le diagramme présenté reprend l'architecture initiale contenant les classes JavaSwing de base (avion, réservation, client et pilote) reliées à la base de données SQLite.
// Mais il y a en plus une nouvelle classe qui dédié au problème de maintenance.
// Si nous poursuivons l’architecture actuelle, nous devons lier ces nouvelles entités à Java Swing et SQLite également.
// Le diagramme présenté reprend l'architecture initiale contenant les classes JavaSwing de base (avion, réservation, client et pilote) reliées à la base de données SQLite.
// Mais il y a en plus une nouvelle classe qui dédié au problème de maintenance.
// C’est pourquoi nous allons le nettoyer dans les chapitres suivants.
// -----------
//  - À vous de jouer : définissez et analysez des entités :
// Tout d’abord, nous allons nous intéresser à notre autre nouvelle user story.
// "En tant que mécanicien en charge de la maintenance de l'avion, je veux mettre à jour tout problème dès qu’il a été traité, pour que l’avion puisse être considéré comme apte à voler".
// Lisez le cas d’usage ci-dessous. Repérez tout nouveau nom qui doit être ajouté à notre système, puis voyez si vous pouvez l’ajouter à notre diagramme existant.
//      --> Le mécanicien de l'avion se connecte au système.
//      --> Le système valide le login.
//      --> Le mécanicien sélectionne “voir tous les problèmes de maintenance avion”.
//      --> Le système présente l’écran des problèmes de maintenance en cours.
//      --> Le mécanicien sélectionne un problème de maintenance en cours.
//      --> Le système présente l’écran de saisie de mise à jour de maintenance.
//      --> Le mécanicien coche l’indicateur de réparation, et confirme la date des mises à jour.
//      --> Le système met à jour le problème de maintenance.
// Réponse :
// Voici les noms que vous devriez avoir repérés : mécanicien de l'avion, login, problèmes de maintenance, réparation, date de mise à jour.
// Avant de consulter ma version, voyez si vous pouvez cartographier les nouvelles entités.
// Le diagramme est mis à jour et contient en plus la classe mécanicien de l'avion.
// Cette classe fait partie des classes JavaSwing et est reliée à la base de données SQLite, au même titre que toutes les classes dans le diagramme,
// Et maintenant, regardez le cas d’usage par lequel tout a commencé :
// "En tant qu’opérateur d’agence de voyage, je veux réserver un vol pouvant transporter jusqu’à 12 personnes pour qu’elles puissent découvrir un lieu unique".
// Encore une fois, lisez le cas d’usage ci-dessous. Repérez tous les nouveaux noms qui doivent être ajoutés à notre système, puis voyez si vous pouvez les ajouter à notre diagramme existant.
//      --> L’opérateur sélectionne l’option "réserver un voyage".
//      --> Le système demande quel est le nombre de touristes.
//      --> L’opérateur saisit le nombre de touristes.
//      --> Le système demande quelle est la destination.
//      --> L’opérateur saisit la destination.
//      --> Le système détermine si un avion a la capacité de gérer ce voyage, en fonction du poids et de la distance estimés.
//      --> Le système répond en indiquant si le voyage peut se faire.
//      --> Le système demande les dates de départ (à destination de) et de retour (retour à la maison).
//      --> Le système enregistre le voyage.
//      --> Le système demande des informations concernant les touristes (étape réitérée).
//      --> Le système recherche un pilote pouvant être disponible.
//      --> Le système réserve l’avion et le pilote.
// Réponse :
// On dirait que nous avons besoin de "voyage" et de "touristes". Nous pouvons maintenant mettre à jour notre système avec les entités pertinentes.
// Étant donné que notre diagramme est en train de devenir trop complexe, à cause de notre mauvaise architecture, je n’en montrerai qu’une partie.
// Ce diagramme reprend un morceau du diagramme inital : il présente l'architecture simplifiée du système.
// Les classes JavaSwing Réservation, Voyage, et Touristes sont reliées à la base de données SQLite.
// Le fait de continuer sur ce chemin architectural nous entraîne vers une application qui deviendra encore plus difficile à tester et à modifier.
// -----------
//  - En résumé :
//      --> On crée généralement une description de cas d’usage pour chaque user story.
//      --> Dans les descriptions, il y a des mots-clés qui ressortent. Ils deviendront des entités.
//      --> Il faut bien déterminer si les entités sont nouvelles, ou s’il y a de possibles modifications d’entités existantes.
// Maintenant que nous savons ce qui doit être ajouté ou modifié, nous pouvons examiner les faiblesses de notre système actuel. En avant !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Identifiez les faiblesses de votre système actuel /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Au chapitre précédent, nous avons généré un nouvel ensemble de classes d'entités, et poursuivi l’approche consistant à les connecter aux classes Java Swing et SQLite.
// Nous voulons maintenant prendre un peu de recul et voir ce qui doit être remplacé ou modifié dans notre système existant pour supporter une meilleure architecture (web découplée).
// -----------
//  - Analysez les problèmes au sein de votre système actuel :
// Avant d’ajouter de nouveaux éléments, regardons ce qui est actuellement en place, en essayant de repérer ce qui posera problème sur le long terme.
// Je l’ai dit, et je le répète : nous ne voulons pas rester dans une situation où nous ajoutons simplement de nouvelles fonctionnalités selon les besoins.
//      --> Quand on ajoute des fonctionnalités les unes par dessus les autres dans une application, ça devient rapidement une usine à gaz.
// Plus on attend avant de commencer à faire un peu d'ordre, plus il devient difficile de modifier des fonctionnalités et de faire évoluer l'application.
//      --> Une situation que nous voulons éviter à tout prix !
// Comment savoir si quelque chose est en désordre ? Nous pouvons nous poser quelques questions sur le logiciel actuel.
// Voici un bon point de départ : est-il simple ? Autrement dit :
//      --> Est-ce que je comprends ce que le logiciel essaye de faire ? Est-ce que je comprends comment il le fait ?
//      --> Est-ce qu’il est facile à maintenir (trouver et réparer les bugs lorsqu’ils se produisent) ?
//      --> Est-ce qu’il est facile d’apporter un changement ? Un changement qui ne provoque pas de bugs dans cette zone, ou ailleurs ?
//      --> Est-ce qu’il est facile à tester ?
// Les classes JavaSwing Mécanicien de l'avion, Problème de maintenance, Avion, Réservation, Client, Voyage, Touristes et Pilote sont chacune reliées à la base de données SQLite.
// -----------
//  - Étape 1 : Posez les bonnes questions :
// Nous avons besoin d’instruments de mesure qui nous disent ce qui est mieux et ce qui ne l’est pas.
// Par exemple, regardons un morceau de code provenant de l’application d’origine de la compagnie aérienne :
//                  class AircraftMechanic {
//                      public List<MaintenanceIssue> getAllUnfixedIssues(JavaSwing component) {
//                          Connection conn = DriverManager.getConnection( "jdbc:sqlite:./db/test.db")) {
//                          if (conn != null) {
//                              // get all the records
//                              String sql = "SELECT id, entered, details, fixed FROM maintenance”;
//                              Statement stmt  = conn.createStatement();
//                              ResultSet rs    = stmt.executeQuery(sql)) {
//                              while (rs.next()) {
//                                  // unfixed (i.e. no date set)
//                                  if (rs.getString(“fixed”).equals(“”)) {
//                                      // show the details for this item
//                                      component.addCheckbox(rs.getString(“details”));
//                                  }
//                              }
//                          }
//                      }
//                  }
// Utilisons nos questions :
//      - Est-ce que je comprends ce que le code essaye de faire ? Comment il le fait ?
//              --> Cette méthode fait tout. Récupérer les archives, parcourir les archives, déterminer quels éléments ne sont pas réparés, et enfin mettre à jour l’affichage.
//      - Est-ce qu’il est facile à maintenir ? À modifier ?
//              --> Vu que le code essaye de tout faire, il n’est pas facile à modifier.
//      - Est-ce qu’il est facile à tester ?
//              --> Il ne peut pas non plus être testé, sauf s’il est connecté à une IHM et une base de données.
// Pourquoi est-ce que l’on écrit du code difficile à comprendre ?
// Il n’était probablement pas difficile à comprendre au moment où il a été écrit (par nous ou par quelqu’un d’autre).
// L’idée était fraîche dans nos esprits. Je vais vous donner un autre type d’exemple.
// J’ai déjà vu du code ayant un émetteur et un récepteur qui fonctionnent en binôme. Les variables sont nommées tx et rx, respectivement :
//                  public void processResponse() {
//                      Receiver rx = new Receiver();
//                      Transmitter tx = new Transmitter();
//                      while (rx.hasData() {
//                          Data data = rx.getData();
//                          tx.sendData(data);
//                      }
//                  }
// Et maintenant, commençons avec notre première question :
//      - Est-ce que je comprends ce que le code essaye de faire ? Comment il le fait ?
//              --> Tant que le récepteur reçoit des données, alors il reçoit ces données et les transmet.
//                      Mais maintenant, cela fait des mois (voire des années ?) que nous (ou quelqu’un d’autre) avons écrit ce code.
//                      Transmettre quoi ? À quoi ? Recevoir quoi ? Oh, attendez, j’ai trouvé, quelque chose qu’on a nommé "données". Super. Quel genre de données ?
// Notre plus gros problème, ici, c’est que nous aurions dû mieux nommer les choses. Et si nous essayions plutôt ce qui suit ?
//                  public void processPrescriptionResponse() {
//                      Receiver patientRxHistory = new Receiver();
//                      Transmitter pharmacySender = new Transmitter();
//                      while (patientRxHistory.hasData() {
//                          Data patientRxRefilled = rx.getData();
//                          pharmacySender.sendData(patientRxRefilled);
//                      }
//                  }
// Le terme "Rx", en anglais, désigne une ordonnance médicale. Ce type de terminologie fait partie de la connaissance du métier secteur.
// Un petit changement rend ce code beaucoup plus facile à comprendre et à travailler.
// -----------
// Étape 2 : Utilisez les principes de conception SOLID :
// Les principes de conception SOLID sont d’excellents instruments de mesure à utiliser.
// Si vous avez besoin d’un rappel sur les principes de conception SOLID, consultez le cours Écrivez du code Java maintenable.
// Un principe facile à enfreindre est celui de la responsabilité unique.
//      --> Lorsqu’une nouvelle fonctionnalité est nécessaire, il est souvent facile d’ajouter du nouveau code à du code existant.
// Comme nous pouvons le constater dans la méthode 'getAllClientsWithTripThisWeeky()', le code enfreint ce principe en faisant trop.
// La classe 'Client' représente quelqu’un dont on attend un paiement pour le voyage et qui doit être un des voyageurs.
//      --> La classe ne doit pas être responsable de savoir comment interagir avec une base de données SQLite, ni avec des composants d’une IHM.
// De plus, le stockage des données doit être géré par une couche de responsabilités qui lui est propre.
// Tout ce qui a besoin de sauvegarder ou de récupérer des informations devra le faire en accédant à cette couche de classes.
// De façon similaire, l’interface utilisateur doit elle-même être gérée dans sa propre couche.
// Si nous voulons abandonner du code sur le critère de la responsabilité unique, notre architecture va subir une modification significative.
// -----------
//  - Étape 3 : Appliquez des design patterns :
// Enfin, il existe un autre groupe d’instruments de mesure : les design patterns.
//      --> Les design patterns sont des solutions déjà existantes à des problèmes courants.
// Pourquoi réinventer les choses alors que nous pouvons tirer profit d’une idée qui a fait ses preuves ?
// Prenons un exemple associé aux langages orientés objet comme Java et C++.
//      --> Nous voulons qu’un objet change de comportement en fonction de certaines circonstances. L’héritage est l’une des façons dont vous pouvez atteindre ce but.
// Traduisez les différentes fonctionnalités par différentes sous-classes.
// Puis, lorsqu’un objet doit changer, créez un nouvel objet du bon type et jetez l’ancien.
// D’accord, mais que se passe-t-il si d’autres parties du système contiennent encore une référence à l’ancien objet ?
// Nous ne pouvons pas remplacer automatiquement l'ancienne référence par la nouvelle sans générer une belle pagaille.
// La référence d’origine devra donc rester en place. Néanmoins, nous voulons obtenir ce changement de comportement.
// En Python ou JavaScript, nous ajouterions simplement une nouvelle fonction/un nouveau comportement à la volée. Ce n’est pas possible avec Java.
// Nous pouvons utiliser le design pattern "object-role". Il s’agit de considérer le nouveau comportement comme une partie d’un rôle joué par l’objet.
//      --> De la sorte, l’objet pourra facilement changer de rôle, mais en restant le même objet.
// Comment appliquer cela à notre application ?
// Notre dernier cas d’usage concerne les clients qui ont des impayés, et ceux qui doivent beaucoup d’argent, plutôt que juste un peu.
// Nous voulons montrer ces types de clients différemment. Mais nous ne voulons pas échanger entièrement les objets.
// Voici un diagramme UML de la façon dont nous pouvons appliquer ce modèle dans notre application.
// Le diagramme montre les différents statuts possibles concernant le client :
//      - Ooption 1 : il a payé le montant entièrement.
//      - Option 2 : il doit de l'argent.
//      - Option 3 : il doit beaucoup d'argent.
// Nous appellerons pour commencer le 'changeStatus()' d’un client avec un objet 'ClientStatusPaidInFull(StatutClientPayéEntièrement)'.
// Puis, si nous déterminons qu’il a un solde impayé, nous le remplacerons par 'ClientStatusOwes(StatutClientDette)' ou  'ClientStatusOwesLots(StatutClientDetteImportante)'.
// Lorsqu’il paye son solde, nous le remettrons à 'PaidInFull'. Mais nous nous en occuperons quand nous en serons là.
// Les design patterns peuvent vous aider à résoudre une multitude de problèmes dans votre application.
// -----------
//  - En résumé :
//      --> Il faut examiner le code existant, et repérer ce qui est difficile à comprendre, à modifier, ou à tester.
//      --> On utilise les principes SOLID pour prendre des décisions de modification de l’architecture.
//      --> Lorsque cela s'y prête, on peut utiliser les design patterns.
// Maintenant que nous savons quels instruments de mesure nous pouvons utiliser pour nos analyses de code, nous allons prioriser nos user stories !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Priorisez vos user stories ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans les chapitres précédents, nous avons établi les bases de ce que nous voulons modifier dans notre architecture.
// La prochaine étape est de déterminer dans quel ordre nous travaillerons sur les changements.
// -----------
//  - Priorisez les user stories :
// Si je regarde dans mon garage et que je vois des cartons pleins d'affaires à trier et à ranger, cela risque de me décourager. Comment savoir par où commencer ?
// La même chose se produit avec notre refonte de logiciel, il y a beaucoup de travail à faire.
// Si nous essayons de tout accomplir en même temps, nous allons nous retrouver débordés et nous prendrons des risques.
//      --> Nous devons trouver une manière de prioriser le travail.
// Regardons l'architecture actuelle :
//      --> Les classes JavaSwing Mécanicien de l'avion, Problème de maintenance, Avion, Réservation, Client, Voyage, Touristes et Pilote sont chacune reliées à la base de données SQLite.
// Les blocs de couches sont séparés des uns des autres : couche de connexion, couche de données et couche d'entité.
// La couche de connexion et reliée à la couche d'entités, la couche de données et à l'interface utilisateur.
// Heureusement, nous pouvons adopter des approches qui ont fait leurs preuves pour prioriser notre travail !
// Commençons par les approches “commerciales”. Nous avons deux formules, mais leurs bases sont les mêmes.
// -----------
//  - Priorisez grâce au retour sur investissement :
// Voyons tout d’abord le retour sur investissement.
//      --> On calcule le montant estimé du revenu généré ou des dépenses évitées, et on le divise par le coût de mise en place de la fonctionnalité.
// La solution qui propose le plus d’argent pour le moindre coût de développement gagne.
//      --> Comment savoir quel montant utiliser dans l’équation ?
// Ici, vous devrez connaître le coût moyen d’une journée de prestation de l’équipe de développeurs.
// Et il n’y a pas de garantie que les chiffres soient totalement exacts. On établit la meilleure estimation possible.
// -----------
//  - Priorisez par “Weighted Shortest Job First” :
// Deuxièmement, nous avons la technique de la "tâche la plus courte et la moins coûteuse d’abord" (ou WSJF, pour "weighted shortest job first" en anglais).
//      --> Comme pour le Retour sur Investissement, on calcule les montants impliqués.
// Quelle est la différence avec cette approche ?
//      --> La tâche la plus rapide à finir est celle qui génère le plus d’argent.
// Mettre en place rapidement plusieurs petites fonctionnalités qui génèrent de l'argent est sans doute une meilleure stratégie sur le plan financier.
// Ensuite, nous avons des techniques qui sont orientées sur le développement.
// -----------
//  - Priorisez par nécessité technique :
// Nous pouvons appliquer une autre option : l’évaluation technique.
//      --> Quelles stories nécessitent le plus de réécriture ?
//      --> Laquelle nous permet de mettre en place plus rapidement une meilleure architecture ?
// Plus nous vivons longtemps avec une mauvaise architecture, plus on accumule de dette technique et plus il devient difficile d’ajouter des fonctionnalités.
// Ces fonctionnalités coûtent donc plus cher à implémenter.
// Il pourrait être plus logique de travailler sur des éléments purement architecturaux, afin que toutes les stories suivantes soient plus faciles à mettre en place.
// -----------
//  - Priorisez par dépendance :
// Dans mon exemple de garage, certaines cartons sont empilées sur d’autres cartons.
// Il existe une dépendance naturelle : je dois commencer par les cartons du dessus et descendre à partir de là.
// Encore une fois, cela fonctionne de la même façon pour notre logiciel.
//      --> Certaines user stories ont des choses en commun. Il faut donc commencer par celle qui établit les fondamentaux.
//      --> Nous choisissons donc celle qui a le plus de dépendances, qui déblaiera le chemin pour les autres stories à compléter.
// Dans notre application de compagnie aérienne, de nombreux secteurs ont des dépendances.
// Nous ne pouvons pas tout changer en une seule fois, mais en classant attentivement nos user stories, nous pouvons construire chacun de ces composants, un par un.
// Les stories que nous traitons en dernier lieu doivent être faciles à mettre en place, car nous aurons construit les bases pour toutes ces dépendances.
// Une chose importante à garder à l’esprit, c’est que les priorisations sont toujours évolutives.
// En raison des circonstances fluctuantes de l’entreprise, les stories qui sont importantes aujourd’hui le seront peut-être moins demain, et vice versa.
// En tant que développeurs, nous devons être réceptifs au changement.
// Quelle option choisir ?
// Étant donné que notre objectif dans ce cours est de modifier l’architecture, nous utiliserons la nécessité technique comme logique de priorisation.
// Nous modifierons l’application pour introduire les quatre user stories que nous avons vues précédemment :
//      - En tant qu’opérateur d’agence de voyage, je veux réserver un vol pouvant transporter jusqu’à 12 personnes, pour qu’elles puissent découvrir un lieu unique.
//      - En tant que pilote, je veux saisir tout problème de maintenance mineur dès l’atterrissage, pour qu’il puisse être réparé rapidement.
//      - En tant que mécanicien en charge de la maintenance de l’avion, je veux mettre à jour tout problème de maintenance dès qu’il a été traité, pour que l’avion puisse être apte à voler.
//      - En tant que responsable financier, je veux voir une liste des clients qui nous doivent de l’argent, afin de pouvoir leur faire un rappel téléphonique.
// -----------
//  - À vous de jouer !
//      - Essayez par vous-même :
//          Et maintenant, sur la base de notre diagramme ci-dessus, de quelle user story vous occuperiez-vous en premier ? Demandez-vous :
//              --> Quels éléments techniques sont requis ?
//              --> Quels éléments techniques elles ont en commun ?
//              --> Quels éléments techniques existent déjà dans le code ?
//          Une fois que vous pensez avoir trouvé une solution, vous pouvez regarder ma réponse :
//      - Réponse :
// Étant donné que ces stories introduisent toutes un accès à l’application via un front end web, nous commencerons par introduire la couche de vue.
// Puis, nous extrairons la couche de données.
// Actuellement, nous avons une classe de réservation existante.
// Elle souffre également de la communication avec les classes SQLite et Java Swing.
// Vu que l’opérateur d’agence de voyage ajoutera et modifiera des réservations, nous commencerons par cette story, car elle touche à tous les aspects dont nous voulons revoir l’architecture.
// Une fois que notre classe de réservation est mise à jour correctement, nous pouvons utiliser ces connaissances pour introduire une nouvelle classe.
// Celle-ci gèrera les problèmes de maintenance pour les deux autres user stories.
// Nous verrons que le fait d’obtenir la liste des clients ayant des impayés sera facile à refactoriser au bon endroit une fois la couche de données établie.
// Les priorités peuvent changer à mesure que votre travail sur le projet avance. N’hésitez pas à les réévaluer sur la base de nouvelles informations.
// -----------
//  - En résumé :
// Il existe de nombreuses stratégies de priorisation :
//      --> Commerciales :
//              - Retour sur investissement (le plus gros montant de revenu généré ou d’économies réalisées pour le plus petit montant de coûts de développement).
//              - La tâche la plus courte et la moins coûteuse d’abord (mettre en place de petites fonctionnalités rapidement).
//      --> Orientées développement :
//              - Nécessité technique.
//              - Dépendances entre stories.
// Maintenant que nous savons par quelles stories nous allons commencer, nous sommes prêts à entamer la refactorisation.
// Avant de vous lancer, n’oubliez pas de répondre au quiz pour tester vos connaissances.
// Puis, rejoignez-moi en partie 2 pour voir comment refactoriser une application.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Séparez les couches de votre application avec le design pattern Modèle-Vue-Contrôleur /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Refactorisez avec le pattern MVC //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons plusieurs options pour modifier notre architecture. Nous pouvons foncer tête baissée et faire des changements de façon erratique.
// Mais cette approche pose problème comme vous le savez car elle a conduit à nos problèmes actuels.
// Intéressons-nous plutôt à une façon plus organisée pour incorporer des changements.
//      --> Cette approche pas à pas s’appelle la refactorisation, ou refactoring en anglais.
// -----------
//  - Refactorisez du code existant :
// La refactorisation implique de faire des changements au code existant pour qu’il continue à faire la même chose, sauf que le code sera de meilleure qualité.
// Avant de nous pencher sur notre application de compagnie aérienne, voyons quelques exemples.
// En voici un provenant d’un système médical sur lequel j’ai travaillé. Est-ce que vous arrivez à comprendre ce qu’il est censé faire ?
//                  public void handlePatientVisit(Patient patient, PatientVisit patientVisitRecord) {
//                      LocalDate today = LocalDate.now();
//                      LocalDate dob = patient.getDateOfBirth();
//                      Period period = Period.between(dob, today);
//                      if (period.getYears() < 18) {
//                          patientVisitRecord.segment[“5.1”].append(patient.parentInfo != null ?
//                          patient.parentInfo : lookupNext(patient));
//                      }
//                  }
// Pas si simple ! La logique est entièrement sur la même ligne, et le programmeur suppose que vous connaissez le format de l’objet 'patientInfo'.
// Voici une façon de refactoriser le code pour qu’il soit plus facile à comprendre. Voyez si vous arrivez à comprendre ce qu’il fait maintenant :
//                  public void handlePatientVisitRefactored(Patient patient) {
//                      if (isPatientAMinor(patient)) {
//                          patientVisitRecord.addNextOfKinInfo(patient);
//                      }
//                  }
// Tout d’abord, le code vérifie si le patient est mineur.
// Si c’est le cas, alors ajoutez une section pour les informations sur le membre de sa famille le plus proche.
// Tous les détails sur le calcul de l’âge du patient, et sur les modifications de la section appropriée du dossier du patient ont été abstraits et placés en appels de fonction, à un haut niveau.
//      --> Attendez, où sont les autres parties ?
// Bien entendu, les détails pour déterminer si un patient est mineur, et pour l’ajout du segment sur le parent le plus proche doivent exister.
// Mais nous allons les déplacer vers des fonctions qui ne remplissent que leur tâche uniquement.
// Regardons le calcul qui détermine si le patient est mineur :
//                  private boolean isPatientAMinor(Patient patient) {
//                      Period period = Period.between(patient.getDateOfBirth(), LocalDate.now());
//                      return period.getYears() < 18;
//                  }
// Le code sert toujours la même fonctionnalité. Néanmoins, nous l’avons modifié pour qu’il soit plus compréhensible et maintenable.
// Il est aussi beaucoup plus facile à tester. Dans la version originale, nous ne pouvons pas tester indépendamment la partie du code portant sur le calcul de l’âge.
// Nous devrions passer un dossier patient, puis vérifier si une section 'nextOfKin' a été ajoutée ou non.
// Dans la version refactorisée, nous pouvons tester la méthode de l’âge du mineur toute seule. La séparation en responsabilités uniques est cruciale.
// Nous pouvons effectuer des changements similaires au niveau architectural également.
// -----------
//  - Refactorisez avec le Modèle-Vue-Contrôleur :
// Notre principale refactorisation architecturale sera la mise en place du pattern Modèle-Vue-Contrôleur.
// Retrouvez l'application initiale que nous allons retravailler sur ce dépôt Github :
//      --> https://github.com/OpenClassrooms-Student-Center/7137741-decouplez-votre-architecture-web-pour-des-app-java-robustes/tree/part1-chap1.
// L’objectif du MVC est d’obtenir des responsabilités très spécifiques pour chaque couche ou section de notre système.
// Nous diviserons le code en trois sections distinctes. L’une sera le modèle, l’autre sera la vue, et la troisième sera le contrôleur.
// Nous aurons aussi une couche de données qui gère la persistance des objets de modèle. Nous verrons les détails de chacun de ces éléments dans les chapitres suivants !
// Le diagramme représente l'architecture du MVC.
//      --> Le Modèle est relié à la couche d'entités, la Vue est reliée à l'interface utilisateur et le Contrôleur est relié à la couche de connexion.
// Ça a l’air de représenter beaucoup de travail. Pourquoi se fatiguer à mettre cela en place ?
// Voici un exemple de bénéfices, issu de la vraie vie :
//      Il y a quelques années, j’ai écrit un programme de quiz de mathématiques. Il fonctionnait sur Palm Pilot.
//      Au fil du temps, j’ai mis à jour ce programme pour qu’il fonctionne sur iPod, iPhone, sur les appareils Android, et même sur PC et Mac.
//      Étant donné que j’avais suivi le MVC, il était facile de générer chaque version. Voici pourquoi.
//      Le modèle représente l’état de notre système. Dans mon jeu de quiz, l’un des objets du modèle était la question du quiz.
//      Un élément doit savoir que nous demandons combien font 5 + 3, et la réponse est 8. Ceci était placé dans une classe  ProblemeDeMaths.
//      Le contrôleur s’assure que le cas d’usage est correctement séquencé. Dans le jeu de maths, quelque chose doit poser la question, puis attendre que l’utilisateur saisisse une réponse.
//      C’est le travail du contrôleur. Une fois saisie, la réponse est vérifiée, et l’emoji adéquat est affiché.
//      Le noyau dur de l’application de maths, à savoir le modèle et le contrôleur, est resté le même.
//      Enfin, la vue est responsable des interactions avec l’utilisateur, pour l’input et pour l’output.
//      Dans mon jeu de quiz, la vue devait changer pour supporter les différents environnements, mais les changements étaient faciles à faire.
//      Cependant, vu que j’avais abstrait cette couche du reste, il était facile de changer l’interface sans toucher au reste du code.
// Voici quelques éléments sur lesquels nous allons nous concentrer :
//      --> De nombreux éléments devraient être des objets du modèle, mais sont condensés dans ces quatre objets : client, réservation, pilote et avion.
//              Nous allons devoir les modifier pour être plus en accord avec les principes de conception SOLID.
//      --> Nous allons voir plusieurs opportunités d’introduire des contrôleurs dans notre application de charter.
//              Ceci coupera la connexion directe entre les composants du modèle et de la vue, et nous permettra d’insérer de la logique business au milieu.
//      --> De plus, en parlant des composants de la vue, nous devrons transformer les composants Java Swing en élément qui affiche des pages HTML accessibles depuis des navigateurs ou mobiles.
// Heureusement, le framework Spring Boot, qui utilise le MVC, peut être utilisé pour nous aider à atteindre notre objectif. Commençons dès le chapitre suivant.
// -----------
//  - En résumé :
//      --> La refactorisation consiste à remplacer le design existant par un design avec une meilleure architecture.
//      --> L’utilisation du MVC nous aide à séparer les responsabilités et à créer une application plus maintenable.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Extrayez la Vue ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les interfaces utilisateurs sont des parties essentielles de toute application, car, de fait, l’utilisateur interagit avec elles.
// Si un utilisateur trouve qu’une interface est difficile à gérer ou à comprendre, il aura un avis négatif sur l’ensemble de l’application.
// De plus, les styles et les fonctionnalités changent avec le temps.
// Faites un tour à bord de la Wayback Machine, tapez un nom de domaine, et regardez les pages web du passé.
// Une expérience amusante : regardez par exemple comment la page Google a changé au fil du temps.
// De plus, les exigences d’aujourd’hui nécessitent que les applications s'adaptent à différentes tailles d'écran (ordinateur, tablette, smartphone…), ce qui exige un design responsive.
// Autrement dit, il faut avoir un moyen de connaître les dimensions mais aussi l’orientation (portrait ou paysage) de l’écran, pour générer la meilleure configuration graphique possible.
// Il est préférable de gérer le design responsive via HTML et le CSS.
// Vous avez raison, les finitions de la mise en page n’entrent pas dans le périmètre de ce cours.
// Cela dit, la séparation de la couche d’interface utilisateur, afin de permettre au CSS et au HTML de changer indépendamment du reste du code, correspond au changement architectural que nous recherchons.
// Pour suivre le rythme des exigences en constante évolution, nous devons placer l’interface dans sa propre couche.
// Nous réparerons ceci dans notre application en :
//      --> Examinant l’architecture et le code existants pour voir où se situent les problèmes (à l'aide de nos instruments de mesure de la première partie).
//      --> Définissant nos solutions pour les appliquer à notre architecture.
//      --> Appliquant notre solution au code.
// -----------
//  - Examinez l’architecture existante pour voir où se situent les problèmes :
// Commençons par regarder l’architecture actuelle du client. Elle est complexe, c'est une usine à gaz :
//      --> Les classes JavaSwing Mécanicien de l'avion, Problème de maintenance, Avion, Réservation, Client, Voyage, Touristes et Pilote sont chacune reliées.
// Nous voyons que tout ce avec quoi l’utilisateur interagit (client, réservation, avion, pilote) a une connexion directe avec un ensemble de composants Java Swing.
// Regardons un extrait de la classe 'com.airbusiness.program.swing.Client' de plus près :
//                  public static void fillTableWithData(JTable table) {
//                      table.setModel(buildTableModel());
//                      }
//                  private static DefaultTableModel buildTableModel() {
//                      ResultSet rs = AirBusinessDb.getResultSet("SELECT * from clients");
//                      try {
//                          ResultSetMetaData metaData = rs.getMetaData();
//                          Vector<String> columnNames = new Vector<String>();
//                          int columnCount = metaData.getColumnCount();
//                          for (int column = 1; column <= columnCount; column++) {
//                              columnNames.add(metaData.getColumnName(column));
//                              System.out.println("columnName: " + metaData.getColumnName(column));
//                          }
//                          // data of the table
//                          Vector<Vector<Object>> data = new Vector<Vector<Object>>();
//                          while (rs.next()) {
//                              Vector<Object> vector = new Vector<Object>();
//                              for (int columnIndex = 1; columnIndex <= columnCount; columnIndex++) {
//                                  vector.add(rs.getObject(columnIndex));
//                                  System.out.println("value [" + columnIndex + "][" + rs.getObject(columnIndex) + "]");
//                              }
//                              data.add(vector);
//                          }
//                          return new DefaultTableModel(data, columnNames);
//                      } catch (SQLException e) {
//                          // TODO Auto-generated catch block
//                          e.printStackTrace();
//                      }
//                          return null;
//                  }
//      --> Quel est le problème ici ?
// Avant de vous lancer et de regarder ma réponse, voyez si vous pouvez utiliser certains instruments de mesure pour analyser le code.
// Essayez d’utiliser les principes SOLID et certaines de nos questions clés. Pour rappel, voici ces questions :
//      --> Est-ce que je comprends ce que le code essaye de faire ? Comment il le fait ?
//      --> Est-il facile à maintenir ? À modifier ?
//      --> Est-il facile à tester ?
// Alors, avez-vous fini votre analyse ?
//      --> Le gros problème de ce code, c’est qu’il enfreint le 'principe de responsabilité unique'.
// La classe client ne contient pas uniquement des données client, elle a également besoin de savoir comment interagir avec un objet Java Swing JTable.
// Elle génère les titres des colonnes, en plus de remplir chaque ligne. Cela fait beaucoup trop de responsabilités.
// Par exemple, que se passe-t-il si nous changeons la façon dont nous voulons montrer l’ensemble des clients ?
// La classe devra être modifiée pour montrer les données différemment.
// De plus, cette méthode est difficile à tester. Un objet JTable doit être construit, alors qu’un test unitaire ne doit pas avoir besoin d’une interface utilisateur.
// Le résultat (c’est-à-dire les lignes remplies) est également contenu dans le JTable.
// Notre test unitaire aurait besoin de requêter les lignes du JTable pour valider que c’est correct.
// Et enfin, si nous voulions changer juste un peu la présentation des données client, nous devrons entrer dans cette classe, et modifier comment elle construit chaque ligne et cellule du tableau.
// Cette fonctionnalité n’a pas sa place ici.
// -----------
//  - Définissez des solutions :
// La première moitié de notre changement d’architecture suivra le principe de responsabilité unique.
// L’interface utilisateur et les classes d’application (client, réservation, avion) doivent être séparées.
// La classe client (réservation et pilote) ne connaîtra plus rien sur JTable.
// Elle sera uniquement responsable de la maintenance de ses propres données.
// Nous commencerons à travailler là-dessus en coupant toutes les connexions directes entre nos classes Java et les classes Java Swing.
// La deuxième moitié de notre changement consistera à placer la vue dans sa propre couche isolée.
// Elle ne sera plus contrôlée par de nombreuses classes différentes.
// Après cette modification, notre architecture fera en sortes que les classes 'Réservation' et 'Client' seront reliées à la base de données SQLite mais pas à la couche HTML.
// Notez qu’il n’y a plus aucune connexion directe entre le client ou la réservation et la vue.
// -----------
//  - Appliquez nos solutions :
// Tout d’abord, nous devons séparer ces classes. Une manière facile de remplacer notre dépendance Java Swing est d’utiliser Spring Boot et la bibliothèque de templates Thymeleaf.
// Avec ces outils, nous allons convertir l’interface Java Swing en interface web.
// Nous pouvons commencer par construire une nouvelle application. Allez sur https://start.spring.io.
// Et maintenant, renseignez les informations suivantes :
//      - Project: Maven Project.
//      - Language: Java.
//      - Spring Boot: 2.4.4.
//      - Group: com.airbusiness.
//      - Artifact: airbusiness-mvc.
//      - Dependencies: Thymeleaf, Spring Web, SpringBoot Dev Tools.
// Spring Boot DevTools offre, entre autres, la possibilité de déployer à chaud votre application (vos modifications seront buildées et déployées automatiquement!).
// Quand vous avez fini, cliquez sur 'Generate'.
// Une fois l’application terminée, ajoutez une interface utilisateur HTML simple.
// Créez le fichier index.html dans le dossier 'src/main/resources/templates'. Le fichier doit contenir ce qui suit :
//                  <!DOCTYPE HTML>
//                  <html>
//                      <head>
//                          <title>AirBusiness</title>
//                          <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
//                          <meta name="viewport" content="width=device-width, initial-scale=1">
//                      </head>
//                      <body>
//                          <a href="/index">
//                              <img th:src="@{/images/AirBusinessLogo.jpg}" height="64" width="64"/>
//                          </a>
//                          <p>Welcome to Air Business</p>
//                      </body>
//                  </html>
// Ensuite, copiez ce fichier dans 'src/main/resources/static/images/AirBusinessLogo.jpg'. Exécutez le projet.
//      --> Connectez-vous avec un navigateur en vous rendant sur http://localhost:8080.
// Nous avons maintenant une application web, qui fait une chose simple mais avec une vue séparée !
// -----------
//  - Séparez vos inputs :
// Les interfaces sont constituées d’un côté input et d’un côté output.
// Du côté input, il est utile de penser à l’interface utilisateur comme générateur d’événements.
// Presque tout ce que fait l’utilisateur avec l’interface doit être un événement qui revient vers le contrôleur.
// Par exemple, dans l’implémentation d’origine, nous avons un bouton d’écoute des événements. Il configure l’objet JTable pour montrer l’ensemble d’items correspondant.
//                  JButton btn = new JButton("Clients");
//                  btn.addActionListener(new ActionListener() {
//                      @Override
//                      public void actionPerformed(ActionEvent e) {
//                          Client.fillTableWithData(table);
//                      }
//                  });
// Ce n’est pas très élégant, mais c’est à prévoir quand on construit une interface avec Swing.
// Spring Boot effectuera la connexion pour nous.
// Mais pour l’instant, nous allons simplement ajouter quelques boutons à l’interface utilisateur, qui nous amèneront vers des pages (qui n’existent pas encore).
// Dans le fichier 'index.html', ajoutez ce qui suit sous la ligne '<p>Welcome to Air Business</p>' :
//                  <p>Choose from the following</p>
//                  <p><a href="/reservations">Reservations</a></p>
//                  <p><a href="/clients">Clients</a></p>
//                  <p><a href="/maintenance">Pilots Submit Maintenance Request</a></p>
//                  <p><a href="/maintenance">Mechanics Update Maintenance Request</a></p>
// Testez l’application à nouveau. Vous remarquerez peut-être que, si vous cliquez sur le logo, ou tout autre bouton, vous obtenez une page d’erreur générée par Spring Boot.
// C’est parce que ces pages n’existent pas encore. Ne vous inquiétez pas, nous les ajouterons bientôt.
// Nous avons maintenant accompli les premières étapes de notre modification MVC !
// Nous avons identifié quel code sera difficile à modifier, tester ou maintenir.
// Nous avons introduit une couche de vue qui n’est pas directement contrôlée par les classes de notre application.
// Nous avons aussi tiré profit d’un framework MVC pour nous simplifier le travail.
// -----------
//  - En résumé :
//      --> Il faut identifier le code qui sera difficile à modifier, tester, ou maintenir.
//      --> On procède à une extraction de la couche de vue par rapport au reste.
//      --> La couche n’est pas directement contrôlée par les classes d’application.
//      --> L’aspect input peut être générateur d’événements.
//      --> Le framework MVC permet de simplifier la refactorisation.
// Maintenant que nous avons extrait la vue, passons au modèle !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Extrayez le Modèle ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Imaginez que vous êtes en train de conduire. A quels éléments faites-vous attention ?
//      --> Probablement votre vitesse, la quantité d’essence dans votre réservoir, la proximité des voitures autour de vous, ou encore les panneaux de signalisation.
// Tous ces éléments constituent l’état de votre système de conduite actuel.
// Nous qualifions toutes ces idées qui représentent l’état de "modèle". Celui-ci correspond à tous les éléments qui sont vus ou manipulés.
// Nous voulons conserver toutes ces idées dans leur propre couche d’entités (tout comme nous avons séparé la couche de vue).
//      --> D’où viennent les objets du modèle ?
// Vous vous souvenez de tout ce temps que nous avons passé à déterminer ce qu’étaient les entités en lisant toutes les descriptions de cas d’usage ?
//      --> Ce seront les classes qui appartiennent au modèle.
// Nous suivrons une série d’étapes similaires à celles que nous avons effectuées pour la vue pour extraire le modèle :
//      --> Examiner l’architecture et le code existants pour voir où se situent les problèmes.
//      --> Définir nos solutions.
//      --> Appliquer nos solutions.
// -----------
//  - Examinez les problèmes de l’architecture actuelle :
// Dans l'application pour notre compagnie aérienne, le modèle est contenu dans les classes Java que nous avons vues dans notre premier chapitre.
// Les classes Réservation et Client sont reliées à la base de données SQLite mais pas à la couche HTML.
// Néanmoins, ces classes ont quelques responsabilités supplémentaires, qui vont au-delà du fait d’être des classes de modèle.
// Par exemple, client, réservation, pilote, et avion créent tous leurs propres objets de connexion SQL, puis exécutent leurs propres requêtes.
// Et, bien que les objets du modèle aient généralement besoin d’être persistés, ce n’est pas le travail des classes du modèle de s’en charger elles-mêmes.
//      --> La responsabilité du stockage de données enfreint le S des principes de conception SOLID. Nous devons y remédier !
// Par exemple, regardons la classe client de plus près :
//      --> Elle a des valeurs de données pour contenir un prénom et un nom de famille, une adresse, un numéro de téléphone, une liste de réservations, et des impayés.
// Toutes ces informations sont essentielles. Si nous n’éteignions jamais notre appareil, un objet client pourrait vivre éternellement en mémoire.
// Cependant, ce n’est pas une attente raisonnable. Nous devons sauvegarder cela (et d’autres objets du modèle) dans un mécanisme de persistance.
// Habituellement, il s’agit d’une base de données. Et il semblerait que c’est SQLite qui est utilisé pour l’application existante.
// Voici du code trouvé dans Client.java qui gère son propre stockage de données :
//                  private static DefaultTableModel buildTableModel() {
//                      ResultSet rs = AirBusinessDb.getResultSet("SELECT * from clients);
//                      try {
//                          // details removed
//                         while (rs.next()) {
//                              // processing this record
//                         }
//                         return new DefaultTableModel(data, columnNames);
//                      } catch (SQLException e) {
//                          e.printStackTrace();
//                      }
//                     return null;
//                 }
// Encore une fois, c’est une classe qui est difficile à modifier, tester, et maintenir.
// Si le type de stockage de données est modifié, alors tout cela doit être modifié.
// L’infrastructure de stockage des données doit exister (ou au moins être simulée) pour tester un objet client.
//      --> Voilà qui représente plus de travail que nécessaire pour changer ou tester la classe.
// -----------
//  - Définissez des solutions :
// D’un point de vue architectural, nous voulons que la persistance constitue une couche de données indépendante.
// Nous voulons couper toute connexion directe entre nos objets du modèle (la couche d’entités) et la façon dont ils sont sauvegardés ou récupérés dans une source de données (la couche de données).
// Mettons à jour le diagramme de classe UML pour couper la connexion entre le client et SQLite.
// Le diagramme représente l'architecture pour laquelle on a coupé les connexions.
// On voit que les classes Réservation et Client ne sont plus reliées à la couche de données, ni à la couche HTML.
// Très bien, nous avons coupé toutes les connexions directes entre nos classes Java (les classes du modèle qui composent notre couche d’entités) et la base de données SQLite (la couche de données).
// Néanmoins, pour que cela fonctionne, nous devons :
//      --> Modifier les classes existantes du modèle pour qu’elles puissent supporter l’intégration dans le framework Spring Boot.
//      --> Faire persister nos objets du modèle.
// -----------
//  - Appliquez les solutions :
// Heureusement, Spring Boot fournit un mécanisme pour faire cela correctement. On peut le faire en seulement quelques étapes.
//      - Étape 1 : Modifiez le fichier POM.xml existant de l’application Spring Boot pour inclure une couche de persistance.
//      - Étape 2 : Copiez les classes du modèle (client, réservation, pilote et avion) dans l’application Spring Boot. Dans celles-ci, nous allons :
//          - Retirer les appels vers la base de données SQLite.
//          - Ajouter des annotations aux variables membres de nos classes. Spring Boot est capable de reconnaître ces annotations comme éléments ayant besoin d’être persistés.
//          - Ajouter des getters et des setters pour chacune des variables membres s’il n’en existe pas.
//      - Étape 3 : Ajoutez une classe Repository correspondante.
// Allons-y.
//      - Étape 1 : Voici les dépendances à ajouter au fichier pom.xml :
//                  <dependency>
//                      <groupId>org.springframework.boot</groupId>
//                      <artifactId>spring-boot-starter-validation</artifactId>
//                  </dependency>
//                  <dependency>
//                      <groupId>org.springframework.boot</groupId>
//                      <artifactId>spring-boot-starter-data-jpa</artifactId>
//                  </dependency>
//                  <dependency>
//                      <groupId>com.h2database</groupId>
//                      <artifactId>h2</artifactId>
//                      <scope>runtime</scope>
//                  </dependency>
//      - Étape 2 : Voici un exemple de la classe client modifiée. Elle va dans un nouveau paquet :
//                  com.airbusiness.airbusinessmvc.entities;
//                  package com.airbusiness.airbusinessmvc.entities;
//                  import javax.persistence.Entity;
//                  import javax.persistence.GeneratedValue;
//                  import javax.persistence.GenerationType;
//                  import javax.persistence.Id;
//                  import javax.validation.constraints.NotBlank;
//                  @Entity   // Added Data Storage Annotation
//                  public class Client {
//                     @Id   // Added Data Storage Annotation
//                     @GeneratedValue(strategy = GenerationType.AUTO)  // Added Data Storage Annotation
//                     private long id;
//                     @NotBlank(message = "First Name is mandatory")  // Added Data Storage Annotation
//                     private String firstName;
//                     @NotBlank(message = "Last Name is mandatory")  // Added Data Storage Annotation
//                     private String lastName;
//                     private String address;
//                     private String telephone;
//                     private double outstandingBalance;
//                     // Added Data Storage Getter and Setter
//                     public void setId(long id) {
//                         this.id = id;
//                     }
//                     public long getId() {
//                         return id;
//                    }
//                     // Added Data Storage Getter and Setter
//                     public String getFirstName() {
//                         return firstName;
//                     }
//                     public void setFirstName(String firstName) {
//                         this.firstName = firstName;
//                     }
//                     // Added Data Storage Getter and Setter
//                     public String getLastName() {
//                         return lastName;
//                     }
//                     public void setLastName(String lastName) {
//                         this.lastName = lastName;
//                     }
//                     // Added Data Storage Getter and Setter
//                     public String getAddress() {
//                         return address;
//                     }
//                     public void setAddress(String address) {
//                         this.address = address;
//                     }
//                     // Added Data Storage Getter and Setter
//                     public String getTelephone() {
//                         return telephone;
//                     }
//                     public void setTelephone(String telephone) {
//                         this.telephone = telephone;
//                     }
//                     // Added Data Storage Getter and Setter
//                     public double getOutstandingBalance() {
//                         return outstandingBalance;
//                     }
//                     public void setOutstandingBalance(double outstandingBalance) {
//                         this.outstandingBalance = outstandingBalance;
//                     }
//                  }
//      - Étape 3 : Enfin, nous devons introduire une classe repository qui connecte les clients à une base de données (que nous n’avons pas encore choisie). Voici cette classe pour client :
//                  @Repository
//                  public interface ClientRepository extends CrudRepository<Client, Long>  {
//                  }
//      --> Eh oui, c’est tout ce qu’il nous faut ! Spring Boot nous a automatiquement créé toutes les opérations CRUD.
// -----------
//  - À vous de jouer :
// Pour vous entraîner à ce que nous venons de faire, lancez-vous et apportez des modifications similaires à d’autres classes du modèle (réservation, pilote, avion).
// La clé ici est de déterminer quelles parties des classes Java existantes sont en effet des parties du modèle (état), et quelles parties doivent aller ailleurs.
// Ensuite, refactorisez à nouveau le code pour que les objets du modèle se reposent sur la couche de persistance pour réaliser le travail de persistance.
//      --> Nous avons mené à bien la deuxième série d’étapes de notre modification MVC.
//      --> Nous avons identifié le code qui sera difficile à modifier, tester, ou maintenir.
//      --> Nous avons introduit les couches de modèle et de persistance. Et nous avons tiré profit du framework Spring Boot pour nous simplifier le travail.
// -----------
//  - En résumé :
//      --> Le modèle contient l’état de l’application.
//      --> Le modèle est composé d’entités.
//      --> Le stockage d’informations du modèle doit être abstrait du reste.
//      --> Extrayez le modèle en introduisant des couches de modèle et de persistance.
//      --> Utilisez un framework MVC pour vous simplifier le travail.
// Maintenant que nous avons extrait notre modèle, nous sommes prêts à travailler sur notre contrôleur  !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Extrayez le Contrôleur ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une application est composée de nombreux éléments qui peuvent changer : les données évoluent, des méthodes sont appelées, certaines interfaces visuelles sont mises à jour.
// Il nous faut un moyen de suivre toute cette activité ! Nous avons besoin de coordination. Nous plaçons donc cette coordination dans un objet du contrôleur.
// Précédemment, nous avons déconnecté les objets du modèle de la vue. Puis, nous avons séparé les objets du modèle de la couche de données.
// Nous avons une couche de plus à retirer. Ensuite, nous recollerons tout cela ensemble. Le contrôleur fera office de colle !
// Nous utiliserons la même approche que dans les chapitres précédents :
//      --> Examinez l’architecture et le code existants pour déterminer où se trouvent les problèmes.
//      --> Identifiez les solutions.
//      --> Appliquez les solutions.
// -----------
//  - Examinez les problèmes posés par l’architecture existante :
// Actuellement, nous avons séparé les couches de la vue et du modèle, et nous avons introduit la couche de données.
// Dans l'architecture pour laquelle on a coupé les connexions, nous voyons que les classes Réservation et Client ne sont pas reliées à la couche de données, ni à la couche HTML.
// Néanmoins, le contrôle (c’est-à-dire ce qui se produit quand l’utilisateur clique sur des éléments de l’interface utilisateur) est toujours imbriqué dans les classes Java Swing.
// Nous n’avons pas copié ce fichier dans notre nouveau projet, mais regardons ce qu’il faisait avant.
// Pour chaque bouton, la logique de ce qu’il devait faire était enfouie à l’intérieur de son gestionnaire d’événements individuel :
//                  JButton btn = new JButton("Clients");
//                  btn.addActionListener(new ActionListener() {
//                      @Override
//                      public void actionPerformed(ActionEvent e) {
//                          Client.fillTableWithData(table);
//                      }
//                  });
// De plus, comme nous l’avons vu précédemment, nous ne pouvons pas tester cette logique de manière isolée
// Et si l’action à effectuer change, ce code sera difficile à modifier.
// -----------
//  - Identifiez des solutions :
// Nous devons plutôt nous assurer que la classe contrôleur s’occupera de la coordination entre la mise à jour des objets du modèle.
// Ainsi qu'entre la mise à jour de la source de données correspondante, et la mise à jour de la vue.
// L'ajout d'un contrôleur va transformer notre diagramme de telle sorte que :
//      - La classe Réservation est reliée à la classe Client qui est reliée au contrôleur.
//      - Le contrôleur est également relié à la couche HTML et à la couche de données.
// Pour faire cela, nous devons :
//      --> Rompre toutes les connexions directes entre nos classes Java Swing et la logique business qui gère les événements.
//      --> Créer des classes du contrôleur pour chaque écran, intégrées dans le framework Spring Boot.
// -----------
//  - Appliquez notre solution :
// Lorsque nous sommes dans une situation complexe, telle que l’assemblage d’un meuble en kit, nous avons besoin de savoir à quelle étape nous en sommes, et quel événement est attendu ensuite.
// Les contrôleurs doivent suivre l’état de l’application.
//      --> Pour rester simple, notre application permettra aux utilisateurs de voir, modifier, ajouter et supprimer des éléments de la liste de clients, réservations, et problèmes de maintenance.
// Tout d’abord, intéressons-nous à un cas d’usage concret : l’ajout d’une réservation dans le système.
// En tant qu’opérateur d’agence de voyage, je veux réserver un vol pouvant transporter jusqu’à 12 personnes, pour qu’elles puissent découvrir un lieu unique.
// Nous avons déjà une classe 'Reservation', qui a déjà toutes les annotations Spring Boot pertinentes, et une classe 'ReservationRepository' qui gère toutes les opérations CRUD.
// Nous devons ajouter un ensemble d’écrans d’interface utilisateur qui nous permettent d’effectuer les opérations CRUD.
// Puis, nous devons ajouter une classe ReservationController qui connectera tous les éléments de réservation.
// Dans le projet GitHub, vous verrez un ensemble de fichiers HTML basés sur la réservation ('add-reservation.html', 'reservations.html', et 'update-reservations.html').
// Ils sont configurés pour que le framework Spring Boot remplisse les données automatiquement.
// Cela semble compliqué, mais cela crée un tableau de données de réservation, avec les boutons pour ajouter, supprimer et modifier les réservations existantes.
// Les boutons indiquent quelle page correspondante doit être la prochaine à apparaître.
// Nous avons maintenant besoin de la classe contrôleur, qui détermine ce qui se passe lorsqu’une page précise est requêtée.
// Une grande partie du code est faite pour récupérer un ensemble de données depuis la couche de données, puis répondre aux requêtes de Spring Boot sur les données à afficher.
// Tout d’abord, nous devons créer un paquet pour contenir nos contrôleurs.
// Créez ce qui suit dans le projet : 'com.airbusiness.airbusinessmvc.controllers'. Puis ajoutez la classe 'ReservationController' au paquet.
//                  package com.airbusiness.mvc.controllers;
//                  import javax.validation.Valid;
//                  import org.springframework.beans.factory.annotation.Autowired;
//                  import org.springframework.stereotype.Controller;
//                  import org.springframework.ui.Model;
//                  import org.springframework.validation.BindingResult;
//                  import org.springframework.web.bind.annotation.GetMapping;
//                  import org.springframework.web.bind.annotation.PathVariable;
//                  import org.springframework.web.bind.annotation.PostMapping;
//                  import org.springframework.web.bind.annotation.RequestMapping;
//                  import com.airbusiness.airbusinessmvc.entities.Reservation;
//                  import com.airbusiness.airbusinessmvc.repositories.ReservationRepository;
//                  @Controller
//                  public class ReservationController {
//                     private final ReservationRepository reservationRepository;
//                     @Autowired
//                     public ReservationController(ReservationRepository reservationRepository) {
//                         this.reservationRepository = reservationRepository;
//                     }
//                     @GetMapping("/new-trip")
//                     public String showNewTripForm(Reservation user) {
//                         return "add-reservation";
//                     }
//                     @PostMapping("/reservation/add")
//                     public String addReservation(@Valid Reservation reservation, BindingResult result, Model model) {
//                         if (result.hasErrors()) {
//                            return "add-reservation";
//                         }
//                         reservationRepository.save(reservation);
//                         model.addAttribute("reservations", reservationRepository.findAll());
//                         return "reservations";
//                     }
//                     @GetMapping("/reservation/edit/{id}")
//                     public String showUpdateReservationForm(@PathVariable("id") long id, Model model) {
//                         Reservation reservation = reservationRepository.findById(id).orElseThrow(() -> new IllegalArgumentException("Invalid reservation Id:" + id));
//                         model.addAttribute("reservation", reservation);
//                         return "update-reservation";
//                     }
//                     @PostMapping("/reservation/update/{id}")
//                     public String updateReservation(@PathVariable("id") long id, @Valid Reservation reservation, BindingResult result, Model model) {
//                         if (result.hasErrors()) {
//                            reservation.setId(id);
//                            return "update-reservation";
//                         }
//                         reservationRepository.save(reservation);
//                         model.addAttribute("reservations", reservationRepository.findAll());
//                         return "reservations";
//                     }
//                     @GetMapping("/reservation/delete/{id}")
//                     public String deleteReservation(@PathVariable("id") long id, Model model) {
//                         Reservation reservation = reservationRepository.findById(id).orElseThrow(() -> new IllegalArgumentException("Invalid reservation Id:" + id));
//                         reservationRepository.delete(reservation);
//                         model.addAttribute("reservations", reservationRepository.findAll());
//                         return "reservations";
//                     }
//                      @RequestMapping("/reservations")
//                      public String reservationsForm(Model model) {
//                         model.addAttribute("reservations", reservationRepository.findAll());
//                         return "reservations";
//                      }
//                  }
// Regardons cela de plus près. Voici l’une des annotations clés :
//                  @Autowired
//                     public ReservationController(ReservationRepository reservationRepository) {
//                         this.reservationRepository = reservationRepository;
//                     }
// Voici comment Spring Boot connectera les données (réservation) appropriées à ce contrôleur :
// '@GetMapping("/some-page-name")' est une autre annotation clé, qui connecte un événement (un clic sur un bouton) à un "gestionnaire" (handler) (une méthode) dans le contrôleur.
// Le contrôleur interroge ensuite la source de données (si nécessaire) et prépare les données, revenant vers Spring Boot. La page correspondante est ensuite affichée.
// -----------
//  - À vous de jouer !
// Pour vous lancer un défi, apportez une série de modifications similaires à la zone client de l’application en ajoutant différents fichiers :
//      - client.html.
//      - add-client.html.
//      - update-client.html.
//      - ClientController.java.
// Et maintenant, ajoutons un peu plus de fonctionnalités à notre contrôleur.
// Souvenez-vous de notre dernière user story de la première partie :
//      --> En tant que responsable financier, je veux voir une liste des clients qui nous doivent de l’argent, afin de pouvoir leur faire un rappel téléphonique.
// Avec tout le travail d’architecture que nous avons déjà accompli, nous pouvons facilement ajouter un bouton qui montre les clients qui ont des impayés.
// Premièrement, ajoutez un bouton à la page clients.html :
//                  <a href="/clients/owe" class="btn btn-primary">Owe</i></a></p>
// Puis, ajoutez une requête à notre ClientRepository :
//                  @Query("SELECT c FROM Client c WHERE c.outstandingBalance > ?1")
//                  List<Client> findByOustandingBalanceGreaterThan(double value);
// Et enfin, un gestionnaire de page à notre classe ClientController  :
//                  @RequestMapping("/clients/owe")
//                  public String clientOwe( Model model) {
//                      model.addAttribute("clients", clientRepository.findByOustandingBalanceGreaterThan(0.0));
//                      return "clients";
//                  }
// Revenons à nos cas d’usage principaux pour notre application de compagnie aérienne.
// Vous vous souvenez que deux des nouveaux cas d’usage que nous traitons sont :
//      - (1) l’ajout d’un problème de maintenance par le pilote :
//              --> En tant que pilote, je veux saisir tout problème de maintenance mineur dès l’atterrissage, pour qu’il puisse être réparé rapidement.
//      - (2), la mise à jour du problème par un mécanicien :
//              --> En tant que mécanicien en charge de la maintenance de l’avion, je veux mettre à jour tout problème de maintenance dès qu’il a été traité.
//                      Et cela, afin que l’avion puisse être considéré comme apte à voler.
// Décomposons leur fonctionnement :
//      --> Alors, premièrement, le pilote saisit la date de détection, la zone qui pose problème, et une description.
//      --> Plus tard, un mécanicien résout le problème.
//      --> Il entre ensuite dans le système, change la date de réparation, et ajoute des informations complémentaires sur le problème.
//              Le contrôleur de problème de maintenance affiche les écrans appropriés et valide les champs.
// -----------
//  - Essayez par vous-même !
// Et maintenant, il est temps pour vous d’ajouter également les différents fichiers :
//      - 'maintenance.html' (vue).
//      - 'MaintenanceIssue.java' (modèle).
//      - 'MaintenanceRepository.java' (couche de données).
//      - 'MaintenanceController.java' (contrôleur).
// Vous remarquerez que nous avons ajouté du CSS et une méthode au contrôleur pour la page d’accueil.
// -----------
//  - En résumé :
//      --> Le contrôleur lie les couches de vue, de modèle, et de données les unes aux autres.
//      --> Créez des classes contrôleur pour chaque écran.
//      --> Utilisez un framework MVC pour vous simplifier le travail.
// Maintenant que vous avez séparé les couches de votre application avec le MVC, vous pouvez tester vos connaissances avec le quiz  !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Implémentez la communication entre les couches de votre application ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Choisissez le bon stockage pour votre couche de données ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Nous avons passé les deux premières parties de ce cours à séparer les couches en utilisant le MVC.
// Maintenant, dans cette partie du cours, nous allons nous pencher sur les différentes options à notre disposition pour implémenter ces couches.
//      --> Dans ce chapitre, nous allons regarder plusieurs options pour la couche de données.
// Lorsque l'on sépare la couche de données, on peut la modifier sans risquer d'impacter le reste du système.
// N’oubliez pas que, dans notre application, les objets du modèle n’appellent plus directement la couche de données. Nous avons maintenant une couche de données qui les appelle.
// Le diagramme représente l'architecture avec la couche de données.
//      --> Elle est reliée à la classe Modèle/Entité et au contrôleur.
//      --> La couche HTML et Modèle/Entité sont également relié au contrôleur.
// Lorsque nous avons commencé à utiliser le framework Spring Boot, la seule chose que nous avions à faire à nos classes de modèle était d’ajouter une annotation (@Entity).
// Ainsi que de paramétrer des getters et setters.
// Lorsqu’un objet est nécessaire, le framework le crée, puis appelle les setters appropriés pour initialiser l’objet.
// Lorsque l’objet est modifié, les getters sont appelés, et les valeurs sont stockées.
// Comment ce stockage est effectué ?
//      --> Simplement en utilisant le framework Spring Boot !
// Nous avons généré automatiquement les opérations de bases de données CRUD standard : create (créer), read (lire), update (mettre à jour) et delete (supprimer).
// C’est un excellent point de départ.
// Mais souvent, nous avons besoin de manipuler les données de manière plus sophistiquée.
// Vous vous souvenez de notre user story "trouver les clients ayant des impayés" ? L’ajout de cette fonctionnalité à notre classe de repository client était facile.
// Nous avons ajouté une méthode qui effectue cette recherche précise. Donc oui, techniquement, il s’agit d’un "read".
// Cela dit, l’appelant de cette méthode n’avait pas besoin de se préoccuper des contraintes SQL pour accomplir sa tâche.
// Il était caché aux yeux de l’élément appelé par le biais de la méthode (c’est-à-dire une API).
//      --> Une API désigne la communication entre deux modules, quels qu’ils soient.
// Dans le cas d’une application monolithique, nous n’avons pas de modules définis, donc notre application se parle intégralement à elle-même, et de façon désordonnée.
// Nous allons explorer les avantages de l’utilisation d’une API pour gérer une architecture web découplée dans la prochaine section.
// -----------
//  - Limitez ce que peuvent faire les autres couches avec une API :
// Le fait de placer la couche de données derrière une API renforce la règle selon laquelle aucune autre couche ne gère de données.
// Si nous permettons à d’autres couches de parler directement à notre source de données, nous allons rencontrer des problèmes. Il n’y a pas de contrôle d’application des règles.
//      --> Qu’entendez-vous par "contrôle d’application des règles"?
// Je vais prendre un exemple pour vous l’expliquer.
// Dans l’application originale, nous avons vu que n’importe quelle classe pouvait ouvrir une connexion SQLite, et écrire des données dans n’importe quelle table.
// La classe Client pouvait accéder à la table PILOT et y apporter un changement.
// Voici une ligne de l’implémentation Client.java d’origine :
//                  ResultSet rs = AirbusinessDb.getResultSet("SELECT * from clients");
// Elle accède bien sûr à la table CLIENTS.
// En revanche, il n’y a aucun contrôle d’application des règles qui garantisse que cette ligne n’accède à aucune des autres tables de notre base de données.
// Cela signifie que nous pouvons facilement nous retrouver avec une valeur stockée illégale ou incorrecte.
// Par exemple, les tables CLIENTS et PILOTS ont tous deux un champ nommé téléphone.
// Sans contrôle d’application des règles, nous pouvons écrire une requête de modification de l’adresse du client comme celle-ci :
//                  "UPDATE pilots SET telephone= 'new telephone' WHERE id = 5";
// Nous avions la tête ailleurs, et nous avons accidentellement écrit 'PILOTS' (pilotes) comme nom de table.
// Bon, mais ce n’est pas bien grave, si ?
//      --> C’est encore pire qu’il n’y paraît !
// À l’avenir, nous souhaiterons contacter ce pilote.
// Lorsque nous récupérerons son numéro de téléphone, nous allons en fait nous retrouver à appeler un client.
// C'est génant et cela va nous prendre du temps avant de comprendre pourquoi nous joignons un client au lieu du pilote.
// Comme le SQL est disséminé partout, nous allons devoir rechercher toutes les fonctions d’insertion (insert) et de mise à jour (update) !
// Ce n’est pas trop catastrophique avec cette petite application, mais imaginez une grosse application avec des centaines de déclarations de ce type.
// Une fois le problème trouvé, nous examinerons probablement nos autres déclarations SQL pour nous assurer que nous n’avons pas commis cette même erreur ailleurs.
//      --> Alors, en quoi une API peut-elle aider ?
// Si nous implémentons la couche de données à travers une API, ces types d’erreurs sont beaucoup plus faciles à traquer.
// Cela représente une sous-partie de code beaucoup plus petite et isolée à examiner.
// Après avoir séparé la couche, et créé les classes de repository, l’erreur ci-dessus ne peut pas se produire. La classe repository du client n’accède qu’à la table CLIENTS.
// Un autre avantage non négligeable : nous pouvons indiquer quelles données sont obligatoires pour une opération de données, et quelles données sont optionnelles.
// Dans les opérations de données que les autres couches appellent, nous pouvons regarder les paramètres entrants.
// Si des champs obligatoires manquent ou sont incorrects, nous pouvons retourner une erreur significative à l’appelant, plutôt que de procéder à un appel qui échouera.
// Pire, il renseignera des champs à des valeurs illégales.
// Nous en voyons un exemple avec les annotations sur certains des champs de nos classes du modèle. Par exemple, dans Client.java, nous avons :
//                  @NotBlank(message = "First Name is mandatory")
//                  private String firstName;
// Maintenant que vous avez vu l’intérêt d’utiliser une API pour gérer votre couche de données, voyons comment l’implémenter.
// -----------
//  - Implémentez une couche de données avec une API :
// Souvenez-vous : nous avions besoin de lister tous les clients avec des impayés. Nous avons donc ajouté ce qui suit au ClientRepository :
//                  @Query("SELECT c FROM Client c WHERE c.outstandingBalance > 0.0";
// Étant donné que les classes du repository ont été séparées des entités qu’elles contrôlent, il est facile d’ajouter de nouvelles recherches et manipulations.
// Elles iront simplement dans les classes repository et contrôleur. Nous ne modifions pas du tout les classes entités du modèle !
// Avec quelques éléments supplémentaires, nous pouvons implémenter des changements à notre API nous permettant de servir toutes sortes de nouvelles user stories.
// Voyons ça de plus près : nous allons ajouter la fonctionnalité pour une user story totalement nouvelle qui est apparue au cours des discussions avec Air Business :
//      --> "En tant que mécanicien en chef, je veux voir tous les problèmes de maintenance non résolus, afin de pouvoir planifier les interventions des mécaniciens."
// De la même façon que nous l'avons fait pour la fonctionnalité qui liste les clients avec des impayés, nous allons ajouter cette nouvelle fonctionnalité en ajoutant :
//          - Un bouton à l’écran de maintenance.
//          - Une requête à la classe MaintenanceRepository.
//          - Un endpoint d’API à la classe MaintenanceController.
//      - Étape 1 : Ajoutez un bouton à l’écran de maintenance :
// Modifiez le fichier 'src/main/resources/maintenance.html' et ajoutez cette ligne sous l’autre déclaration de bouton :
//                  <a href="/maintenance/unfixed" class="btn btn-primary">Not Fixed</i></a></p>
// Exécutez à nouveau l’application pour vous assurer que le bouton apparaît sur l’écran de maintenance.
// Si vous cliquez dessus, cela provoquera une erreur. Pourquoi ? Parce que nous n’avons pas écrit le code "unfixed" dans le contrôleur pour l’instant.
//      - Étape 2 : Ajoutez une requête à la classe MaintenanceRepository :
// Modifiez le fichier 'MaintenanceRepository' et ajoutez la méthode suivante :
//                  List<MaintenanceIssue> findByFixed(String fixed);
// Lorsque nous appelons cette méthode depuis la classe de contrôleur, nous passons une chaîne vide pour trouver les éléments sans valeur pour la date de réparation.
//      - Étape 3 : Ajoutez un endpoint d’API à la classe MaintenanceController :
// Modifiez le fichier MaintenanceController et ajoutez les lignes suivantes :
//                  @RequestMapping("/maintenance/unfixed")
//                  public String unFixed( Model model) {
//                      model.addAttribute("maintenance", maintenanceRepository.findByFixed(""));
//                      return "maintenance";
//                  }
// Et c’est aussi simple que ça : nous avons une nouvelle fonctionnalité dans note API !
// Nous avons ajouté un nouvel endpoint (maintenance/unfixed), qui recherche les problèmes de maintenance sans date de réparation.
// -----------
//  - Choisissez une source de données :
// Le plus gros avantage dont nous bénéficions lorsque nous plaçons les données dans leur propre couche est la flexibilité.
// Toutes les autres couches qui ont besoin de la couche de données ne savent en fait rien sur le stockage concret des données.
// Elles ont uniquement besoin de savoir comment parler à la couche : via l’API. En revanche, nous devons toujours choisir comment stocker nos données.
// Quelles options s’offrent à nous pour les sources de données ?
// Nous avons les bases de données :
//      --> Relationnelles SQL
//      --> Orientées de colonnes.
//      --> Orientées documents.
// Regardons chacune d’entre elles.
//      - Option 1 : Choisissez les bases de données relationnelles et le SQL :
// Si les données à gérer sont très structurées, alors nous pouvons nous reposer sur une base de données SQL, qui est une solution fiable.
// Les bases de données SQL gèrent très bien les données dont la structure change peu au fil du temps.
// Nous pourrions avoir besoin d’ajouter une table ou une colonne à notre modèle de temps en temps, mais globalement le format des données reste le même.
//      --> Si telle est votre situation, choisissez cette technologie qui a fait ses preuves.
// J’ai eu à modéliser une base de données qui allaient devoir stocker des tickets de ventes.
// Un ticket de vente est très structuré et cette structure évolue très peu dans le temps :
// Il y un en-tête avec des informations diverses, et des lignes, qui ont chacune une quantité et une référence à un produit.
// Ici, la donnée est donc bien organisée, peu changeante et il y aura souvent besoin de joindre une donnée en-tête avec ses lignes, voire même de joindre un produit avec toutes ses lignes de vente.
//      --> Le SQL est ici une solution adaptée.
// Les questions liées à la taille comptent parmi les inconvénients des bases de données relationnelles.
// De nombreuses implémentations allouent la même quantité d’espace (mémoire et disque) à une ligne qui a des champs vides, qu’à une ligne remplie de données.
// Par conséquent, si vos données se retrouvent avec de nombreux "espaces vides", il vous faudra peut-être envisager l’option suivante de notre liste.
//      - Option 2 : Utilisez une base de données orientée colonnes :
// Les bases de données orientées colonnes ressemblent au SQL, mais en plus flexibles.
// Les plus courantes sont :
//      --> Cassandra.
//      --> HBase.
//      --> Accumulo.
//      --> DynamoDB.
//      --> Hypertable.
// Si nos données ne sont pas tout à fait propres et nettes, nous pouvons opter pour une approche plus flexible orientée colonnes.
// Elle ressemble à l’approche par colonnes d’une base de données SQL, mais les colonnes ont beaucoup plus de flexibilité dynamique.
// Chaque ligne n’a pas besoin d’avoir la même structure de colonnes que toutes les autres.
// Par exemple, si vous avez un champ vide, une base de données en famille de colonnes sauterait le stockage d’un champ vide ou contenant null.
// Par conséquent, si nos données sont un peu imprévisibles, avec beaucoup de champs qui varient d’une ligne à l’autre, c’est une meilleure option.
// Par exemple, les données de posts de blog ou le flux de données d’un appareil médical fonctionnent bien avec les bases orientées colonnes.
// J’ai eu à développer un site de petites annonces de matériel sportif.
// En fait, non ! Au début, il s’agissait de petites annonces de vélo uniquement.
// Mais ensuite bien-sûr, les annonces se sont élargies aux rollers, trottinettes, monocycles, etc.
// Joindre les données entre elles n'étaient pas forcément nécessaire.
// Par contre, la typologie des annonces s’est avérée très variable et évolutive : un vélo électrique a une puissance, alors qu’un vélo non.
// Des rollers ont une pointure, alors qu’une trotinette non. L’option NoSQL était ici pertinente !
//      - Option 3 : Utilisez une base de données orientée documents :
// Enfin, si nos données ne se conforment à aucune structure, nous pouvons utiliser une base de données orientée documents. En voici certains exemples courants :
//      --> CouchDB.
//      --> MongoDB.
//      --> Marklogic.
//      --> Terrastore.
//      --> OrientDB.
//      --> RavenDB.
//      --> Jackrabbit.
// Une base de données orientée documents est par essence de format libre.
// Nous donnons un identifiant (une clé) aux données, puis une valeur à lui associer.
// L’avantage ? Nous pouvons intégrer des données au format texte, image, audio, vidéo, etc. Les données stockées dans ces bases sont le plus souvent des paires clé/valeur.
// Par exemple, si nous avons un dossier de données médicales, nous pouvons stocker les données en fonction du numéro d’identifiant du patient, faisant office de clé.
// Nous pouvons facilement ajouter des métadonnées supplémentaires :
//      - La date.
//      - L’emplacement du patient au moment de l’enregistrement.
//      - Une série de radios.
//      - Un diagnostic.
//      - Des recommandations de traitement du médecin.
// Ce type d’archives n’a pas de forme à proprement parler que l'on peut saisir facilement dans une base de données relationnelle.
// Par conséquent, si vos données partent dans tous les sens, la base de données orientée documents constitue probablement votre meilleure option.
// -----------
//  - Implémentez une source de données SQLite :
// Nous utilisons actuellement une source de données en mémoire dans notre application Spring Boot.
// Nous allons plutôt utiliser SQLite comme source persistante (option 1), car l’application d’origine l’utilisait.
// Nous pouvons aussi tirer profit de toutes les données héritées qui y sont stockées.
// Nous suivrons ces étapes :
//      - Ajoutez des dépendances SQL à notre fichier POM.
//      - Ajoutez le dialecte spécifique à SQL.
//      - Modifiez le fichier application.properties pour inclure SQLite.
//      - Ajoutez un fichier persistence.xml aux ressources.
//      - Modifiez l’attribut ID de toutes les classes d’entités.
// Allons-y.
//      - Ajoutez des dépendances SQL à notre fichier POM :
// Remplacez la dépendance 'com.h2database' avec ce qui suit dans le fichier 'pom.xml' :
//                  <dependency>
//                      <groupId>org.xerial</groupId>
//                      <artifactId>sqlite-jdbc</artifactId>
//                      <version>3.34.0</version>
//                  </dependency>
//                  <dependency>
//                      <groupId>com.zsoltfabok</groupId>
//                      <artifactId>sqlite-dialect</artifactId>
//                      <version>1.0</version>
//                  </dependency>
//      - Ajoutez des classes spécifiques à SQLite :
// SQL est un langage normé. Cela veut dire que chaque "organisme" qui l’implémente le fait un peu différemment.
// De plus, Spring Boot ne sait pas de lui-même comment interagir spécifiquement avec SQLite.
// Nous avons besoin d’un ou deux fichiers qui lient SQLite, notre modèle, et Spring Boot les uns aux autres.
//          --> Créez un package nommé 'com.airbusiness.airbusinessmvc.sqlite'.
//          --> Créez une classe nommée 'SQLiteDialect.java' qui étend 'org.hibernate.dialect.Dialect' dans le paquet.
//          --> Regardez dans le repo GitHub pour voir ce qui appartient à cette classe. Il s’agit surtout de méthodes de recherches.
//          --> Ajoutez une classe nommée 'SQLiteColumnSupport.java' qui étend 'org.hibernate.dialect.identity.IdentityColumnSupportImpl' dans le package.
//          --> Puis, ajoutez les lignes de code suivantes.
//              Elles disent à Spring Boot comment traiter nos colonnes d’identifiants (qui sont toujours des entiers).
//              Ainsi que comment incrémenter l’identifiant à chaque fois que nous avons une ligne :
//                  @Override
//                  public boolean supportsIdentityColumns() {
//                     return true;
//                  }
//                  @Override
//                  public String getIdentitySelectString(String table, String column, int type) throws MappingException {
//                     return "select last_insert_rowid()";
//                  }
//                  @Override
//                  public String getIdentityColumnString(int type) throws MappingException {
//                     return "integer";
//                  }
//      - Modifiez le fichier application.properties pour inclure SQLite :
// Modifiez le fichier 'src/main/resources/application.properties' pour inclure ce qui suit :
//                  # DB PROPERTIES #
//                  spring.datasource.url = jdbc:sqlite:airbusiness.db
//                  spring.datasource.driver-class-name = org.sqlite.JDBC
//                  # pretty print the sql queries to stdout
//                  spring.jpa.properties.hibernate.format_sql=true
//                  spring.jpa.show-sql=true
//      - Ajoutez un fichier 'persistence.xml' aux ressources :
// Regardez dans le repo GitHub pour voir ce qui doit aller dans le fichier. Il s’agit de paramètres pour SQLite.
//      - Modifiez l’attribut ID de toutes les classes d’entités :
// Modifiez 'Client.java', 'MaintenanceIssue.java', 'Pilot.java', 'Plane.java' et 'Reservation.java'.
// Et ce, de façon à ce que l’annotation de chaque attribut ID puisse être correctement généré automatiquement pour SQLite.
// Changez le type de génération (GenerationType) d’AUTO à IDENTITY. Le code devrait ressembler à ce qui suit :
//                  @Id
//                  // @GeneratedValue(strategy = GenerationType.AUTO)
//                  @GeneratedValue(strategy = GenerationType.IDENTITY)
//                  private long id;
// Voyons comment cela s’applique à l’un de nos extraits d’origine (ci-dessous) :
//                  public class Client {
//                      @Id
//                      @GeneratedValue(strategy = GenerationType.AUTO)
//                      private long id;
// Avec la modification, nous obtenons :
//                  public class Client {
//                      @Id
//                      @GeneratedValue(strategy = GenerationType.IDENTITY)
//                      private long id;
// Et maintenant, notre application sauvegarde et récupère à nouveau des données depuis une base de données SQL !
// -----------
//  - En résumé :
//      --> Les autres couches ne doivent pas contrôler directement la couche de données. Pour éviter cette situation, on écrit une API qui reflète les intentions de la couche de données.
//      --> Il faut choisir une façon adaptée de stocker vos données :
//              --> Une base SQL si les données sont propres et bien organisées.
//              --> Une base NoSQL orientée colonnes si les données sont organisées, mais changeantes.
//              --> Une base de données orientée documents si le format des données est totalement libre.
// Et maintenant, gérons un peu la communication entre nos différentes couches !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérez la communication entre les couches avec une API de données //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comme vous le savez maintenant, une application monolithique pose problème parce qu'il est difficile voire impossible de :
//      --> La modifier ou la maintenir facilement.
//      --> De tester ses composants de manière individuelle.
// La solution c'est donc de diviser l’application en couches séparées.
// Dans ce chapitre, nous allons regarder comment fonctionne la communication entre couches.
// -----------
//  - Construisez vos couches de communication correctement :
// Pour commencer, regardons comment connecter les classes contrôleurs à notre couche de vue et notre couche de données.
// Dans notre cas, Spring Boot établit la communication et effectue les différentes connexions pour nous.
// C'est une approche qui est très utilisée. Voici une partie de 'ClientController.java' :
//                  @RequestMapping("/clients/owe")
//                  public String clientOwe( Model model) {
//                      model.addAttribute("clients", clientRepository.findByOustandingBalanceGreaterThan(0.0));
//                          return "clients";
//                  }
//      --> Ligne 1 : Il s’agit de la connexion entre la page d’affichage (vue) et le contrôleur.
//              Elle dit que, lorsque l’application décide d’afficher la page /clients/owe, la fonction 'clientOwe()' est appelée.
//              Le choix d’afficher cette page est décidé par la référence qui y est faite dans 'clients.html'.
//      --> Ligne 3 : Il s’agit de la connexion entre le contrôleur et la couche de données.
//              Elle dit de trouver le modèle de données du client, puis d’ajouter toutes les données client qui correspondent à la requête du repository.
//              Il y a une séparation claire entre ce que le contrôleur a besoin de savoir au sujet d’un client et la façon dont cette information est sauvegardée.
//              Toutes les informations de sauvegarde sont dans la classe 'ClientRepository'.
//                  --> Ainsi, nous pouvons contrôler (ou filtrer) les clients à afficher sur cette page.
//      --> Ligne 4 : Une autre connexion entre le contrôleur et la vue.
//              Celle-ci dit à Spring Boot quelle page utiliser pour afficher les données obtenues à la ligne précédente.
// Si nous suivons cette approche consistant à avoir des communications claires entre les diverses couches, nous pouvons très rapidement ajouter différentes pages, avec des filtres différents.
// Voyons à quelle vitesse vous pouvez le faire !
// -----------
//  - À vous de jouer !
// Ajoutez cette fonctionnalité pour un nouveau cas d’usage :
//      --> "Trouver tous les clients qui doivent beaucoup d’argent (défini comme un montant supérieur à 150), pour que je puisse les appeler personnellement."
// Si vous avez besoin de plus d’instructions, voici les étapes :
//      - Etape 1 : Ajoutez une méthode à la classe ClientController.
//                  @RequestMapping("/clients/owe-lots")
//                  public String clientOweLots( Model model) {
//                      model.addAttribute("clients", clientRepository.findByOustandingBalanceGreaterThan(150.0));
//                      return "clients";
//                  }
//      - Etape 2 : Maintenant, ajoutez un bouton à la page 'clients.html' :
//                  <a href="/clients/owe-lots" class="btn btn-primary">Owe Lots</i></a>
// D’accord, ça me semble logique. Mais comment cette fonctionnalité se retrouve-t-elle en désordre ?
// Elle devient désordonnée lorsque l’on oublie l’objectif de chaque couche.
// C'est facile d’essayer de faire faire plus de choses qu’elle ne le devrait à la couche de contrôleur.
// Par exemple, nous pourrions avoir fait faire son propre filtrage de clients à la méthode 'clientOweLots' :
//                  @RequestMapping("/clients/owe-lots")
//                  public String clientOweLots( Model model) {
//                      List<Client> clients = new ArrayList<>();
//                      Iterable<Client> allClients = clientRepository.findAll();
//                      for (Client client: allClients) {
//                          if (client.getOutstandingBalance() > 150.0) {
//                              clients.add(client);
//                          }
//                      }
//                      model.addAttribute("clients", clients);
//                      return "clients";
//                  }
// C’est facile à court terme, mais ce sera un vrai cauchemar sur le long terme.
// Parfois, le fait de savoir comment une couche est implémentée peut conduire à un mauvais système de messages (communication).
// N’oubliez pas que la couche de données est responsable de la gestion des données. C’est là que la logique doit être conservée.
// -----------
//  - Concevez la communication dans une Data API !
// Actuellement, notre application livre toutes les données enveloppées dans un composant visuel.
// Mais que se passerait-il si nous devions livrer uniquement la partie données ? Nous devrions ajouter une API vers le monde extérieur.
//      - Considérations de design pour les APIs :
//          Il existe plusieurs questions importantes que nous devons poser lorsque nous concevons une API :
//              - 1) Quelle est l’intention de mon API ?
//                      Tout d’abord, nous devons construire une API qui soit utile à nos utilisateurs (ceux qui appellent cette API).
//                      La solution de facilité, ça serait d’exposer toutes nos données en un ensemble d’opérations CRUD.
//                      Bien que la fonctionnalité CRUD soit utile, nous voulons une API qui expose l’intention de notre application.
//                      Comme nous l’avons vu plus tôt dans ce cours, nous devons aller plus loin que cela et fournir une fonctionnalité plus ciblée, alignée sur les besoins de notre client.
//                      Nous devons donc comprendre l’intention de notre API en revisitant nos cas d’usages.
//              - 2) Quels messages devrais-je choisir ?
//                      Une API est définie par les messages qu’elle envoie et reçoit.
//                      Le choix des messages est donc extrêmement important.
//                      Nous explorerons un peu plus ce sujet dans la section ci-dessous.
//              - 3) De quel format de données ai-je besoin ?
//                      Le format des messages doit être pris en compte. Il nous faut de la flexibilité.
//                      Heureusement, les messages basés sur le texte, comme le JSON ou le XML, permettent exactement cela.
//                      Ces deux options traitent les données comme paires de clé/valeur (c’est en fait un peu plus compliqué que ça, mais c’est un détail pour un autre cours).
//          Nous pouvons choisir l’un ou l’autre, mais le JSON est devenu un standard, c’est donc celui que nous choisirons pour notre API.
//          Nous nous appuierons sur le framework Spring Boot, ce qui simplifiera le mécanisme de mise en place d’une API.
//          La définition des messages sera ensuite gérée par le JSON qui sera transféré d’un côté à l’autre.
//      - Considérations de design pour les messages dans les APIs :
//          Prenez en compte deux domaines de réflexion lorsque vous concevez les messages d’une API.
//          Déterminez les données entrantes et sortantes : qu’est-ce qui entre, et qu’est-ce qui revient ?
//          Évaluez les modifications à venir : qu’est-ce qui changera probablement au fil du temps ?
//              - Déterminez les données entrantes et sortantes :
//                  Pour appeler une API, nous devons d’abord savoir quelles données envoyer. Voici trois questions utiles par lesquelles commencer :
//                          --> À quoi ressemblent les données ?
//                          --> Quelles données sont nécessaires ? Qu’est-ce qui est facultatif ?
//                          --> Est-ce qu’il y a des ensembles de valeurs acceptables ?
//                      - 1) À quoi ressemblent les données ?
//                              C’est facile de créer de la confusion autour de la manière dont on représente les données.
//                              Voici une situation simple qui peut créer des problèmes : la représentation des dates.
//                              Par exemple, si la date est 2020-05-09, est-ce qu’on parle du 5 septembre, ou du 9 mai ?
//                              Nous devrons trancher d’un côté ou de l’autre (AAAA-MM-JJ ou AAAA-JJ-MM) et documenter notre décision.
//                              Ceci, afin que chaque utilisateur de notre API sache ce que nous avons choisi. Le JSON n’a pas de type de date intégré, donc cette erreur est possible.
//                              Si possible, utilisez des normes faisant l’unanimité (par exemple, l’échelle de temps UTC), plutôt que de choisir quelque chose au hasard.
//                      - 2) Quelles données sont nécessaires ? Qu’est-ce qui est facultatif ?
//                              Pour illustrer ceci, nous pouvons regarder les 'MaintenanceIssues'.
//                              Lorsque nous avons paramétré les données, au départ, la date d’entrée était obligatoire, mais la date de réparation était optionnelle.
//                              Lorsque notre API prendra connaissance de ces données, nous ferons appliquer ces règles également. Le JSON fonctionne bien pour ceci.
//                              En analysant les données, nous pouvons vérifier si les valeurs nécessaires sont incluses, et rejeter les données si elles sont absentes.
//                              Si des valeurs optionnelles sont fournies, elles seront utilisées.
//                      - 3) Est-ce qu’il y a des ensembles de valeurs acceptables ?
//                              Ici, nous pouvons regarder à nouveau les 'MaintenanceIssues'.
//                              Chaque problème possède un sous-système et une gravité spécifiques.
//                              Notre API ignorera les messages qui n’envoient pas le bon type de données pour ces éléments.
//                              Une fois de plus, le JSON permet ce type de comportement, étant donné que les données peuvent être stockées en tant que chaîne.
//                              La chaîne de données peut ensuite être comparée à un ensemble de valeurs valides.
//                  Tous ces éléments doivent être incorporés aux spécifications de l’API.
//              - Évaluez les modifications à venir :
//                  Le changement constitue une dernière considération dans la conception de notre API.
//                  Il est probable qu’avec le temps, des données différentes soient requises ou deviennent inutiles.
//                  C’est une autre raison pour laquelle le JSON fonctionne bien pour gérer les données de messages.
//                  Sa flexibilité permet d’ajouter de nouveaux éléments, et d’en supprimer des anciens.
//                  Si nous séparons cette couche qui gère les interactions utilisateur et mettons à jour nos endpoints; assurer une rétro-compatibilité est beaucoup plus facile.
// -----------
//  - Implémentez une API de données :
// Et maintenant, ajoutons une API à la partie maintenance de notre application.
// Un excellent aspect de l’utilisation de notre framework existant, c’est que nous avons très peu de choses à faire.
// Nous devons uniquement ajouter un contrôleur d’endpoint. Nous n’avons même pas besoin de générer une page HTML pour montrer les résultats !
// Pour ajouter le nouveau contrôleur :
//      1. Ajoutez une nouvelle classe 'MaintenanceJSONController.java' dans le paquet 'com.airbusiness.airbusinessmvc.controllers'.
//      2. Dites au framework qu’il s’agit d’un contrôleur REST, et donnez-lui l’emplacement de l’endpoint.
//                  @RestController
//                  @RequestMapping(path = "v1/maintenance")
//                  public class MaintenanceJSONController {
//      3. Connectez le contrôleur au repository de maintenance.
//                  private final MaintenanceRepository maintenanceRepository;
//                      @Autowired
//                      public MaintenanceJSONController(MaintenanceRepository maintenanceRepository) {
//                          this.maintenanceRepository = maintenanceRepository;
//                      }
//      4. Ajoutez le gestionnaire d’endpoint.
//                  @GetMapping(path="/", produces = "application/json")
//                  public Iterable<MaintenanceIssue> MaintenanceForm( Model model) {
//                      return maintenanceRepository.findAll();
//                  }
// Une fois achevé, le nouvel ensemble de fonctionnalités ressemble à ceci :
//                  package com.airbusiness.airbusinessmvc.controllers;
//                  import org.springframework.beans.factory.annotation.Autowired;
//                  import org.springframework.ui.Model;
//                  import org.springframework.web.bind.annotation.GetMapping;
//                  import org.springframework.web.bind.annotation.RequestMapping;
//                  import org.springframework.web.bind.annotation.RestController;
//                  import com.airbusiness.airbusinessmvc.entities.MaintenanceIssue;
//                  import com.airbusiness.airbusinessmvc.repositories.MaintenanceRepository;
//                  @RestController
//                  @RequestMapping(path = "v1/maintenance")
//                  public class MaintenanceJSONController {
//                      private final MaintenanceRepository maintenanceRepository;
//                      @Autowired
//                      public MaintenanceJSONController(MaintenanceRepository maintenanceRepository) {
//                          this.maintenanceRepository = maintenanceRepository;
//                      }
//                      // localhost:8080/v1/maintenance/unfixed/
//                      @GetMapping(path="/unfixed", produces = "application/json")
//                      public Iterable<MaintenanceIssue> MaintenanceForm( Model model) {
//                          return maintenanceRepository.findByFixed("");
//                      }
//                  }
// L'avantage quand on fournit des fonctionnalités via une API : on ne risque pas de s'emmêler les pinceaux.
// Bon d’accord, c’est toujours possible de faire des erreurs : un numéro de téléphone peut comporter une coquille par exemple.
// Mais sinon, voici comment une API peut aider à prévenir des erreurs.
// Si une API n'inclut pas une certaine méthode, alors la fonctionnalité n’existe pas.
// Par exemple, s’il n’y a pas d’endpoint 'removeAllClients', alors on ne peut pas accidentellement supprimer tous les clients.
// Comme je l’ai dit, c’est toujours possible, vous pourriez tous les supprimer un par un.
// Au regard de ces éléments, ce qu'il faut garder en tête pour une API découplée, ce sont les descriptions JSON ou XML des données qui entrent et des données qui reviennent.
// -----------
//  - En résumé :
//      --> Respectez la séparation des responsabilités lorsque vous implémentez vos différentes couches.
//      --> Les interactions entre les couches doivent toujours passer par une API bien définie.
//      --> Pour vous assurer que vos données sont bien définies dans votre API :
//              --> Déterminez l’intention et le format des données.
//              --> Pour vos messages entre les couches, définissez :
//                  - À quoi ressembleront vos données.
//                  - Les données obligatoires et les données facultatives.
//                  - Les ensembles de valeurs acceptables.
//                  - Les éventuelles modifications à venir.
// Maintenant que nous avons regardé les messages entre les couches avec une API bien définie, regardons comment choisir le bon style de communication pour notre application !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Choisissez le bon style de communication pour votre application ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans notre application Air Business, la communication entre les couches est simple et directe : nous utilisons des appels de fonction Java internes.
// Cela dit, si nous étendons cette application pour qu’elle soit exécutée sur plusieurs serveurs, quelles options de communication s’offriraient à nous ?
// L’envoi de messages d’une couche à l’autre peut prendre plusieurs formes. Voici quelques options de communication populaires :
//      --> Synchrone.
//      --> Asynchrone.
//      --> Polling.
//      --> Callback.
//      --> Publish-subscribe / Message queuing.
// Voyons quels sont les avantages et les inconvénients de chacune de ces options, et comment les utiliser.
// Mais avant de nous lancer, voici deux termes que vous aurez besoin de connaître :
//      --> Consumer/Consommateur : C’est ce qui formule la requête.
//              Si vous allez au restaurant et que vous passez votre commande, vous êtes le consommateur.
//      --> Producer ou supplier/producteur ou fournisseur : C’est ce qui répond à la requête du consommateur.
//              Dans notre exemple du restaurant, c’est la personne chargée du service.
// Un fournisseur dans une situation donnée peut être un consommateur dans une autre situation.
// Par exemple, une fois que la personne chargée du service a pris notre commande, cette dernière est envoyée en cuisine pour être préparée.
// L’envoi de ce message à la cuisine transforme notre serveur ou serveuse en consommateur pour cette partie du processus du repas.
// -----------
//  - Comprenez le principe de l'approche synchrone :
// Commençons avec un exemple simple et direct : l’appel et la réponse.
// Le consommateur formule une requête : "Puis-je avoir un verre d’eau ?".
// Le fournisseur accomplit ce qui est demandé : "Voici votre verre d’eau".
// Le consommateur ne peut rien faire jusqu’à ce que le fournisseur réponde à sa requête : il ne peut pas boire d’eau jusqu’à ce que l’eau soit amenée à table.
// C’est ainsi qu’Air Business est implémenté actuellement.
//      --> Tous les appels de fonctions internes fonctionnent de cette façon. Et tous nos endpoints externes également.
// Cette approche a l'avantage d'être très simple :
//      --> La requête est formulée.
//      --> Le consommateur attend la réponse.
// Mais que se passe-t-il si la requête est mal formulée ? qu'elle comporte des erreurs ?
// Le consommateur pourrait attendre longtemps si nous n’envoyons pas de réponse d’erreur.
// Cette latence représente le plus gros inconvénient de cette approche.
//      --> Le consommateur ne peut rien faire d’autre tant que la requête est en cours de traitement.
// Les appels synchrones vers un fournisseur peuvent être implémentés avec REST.
// -----------
//  - Découvrez les options asynchrones :
// L'approche asynchrone permet de ne pas subir cette latence justement !
// Le consommateur peut :
//      --> Formuler une requête.
//      --> Puis continuer à faire autre chose en attendant.
// Pour se faire, en Java, nous pouvons lancer des requêtes dans des threads différents.
// Pour notre petite application, cela ne représente peut-être pas d'intérêt aujourd'hui car notre thread client "n’a rien d’autre à faire" en attendant la réponse à une requête.
// Mais que se passera-t-il quand nous déploierons l'application sur un serveur web et que nous recevrons des multitudes de requêtes simultanées ?
// À ce moment-là, l’exploration d’une approche multi-threads pour gérer toutes les requêtes entrantes sera justifiée.
// Spring Boot effectue cela en coulisses. Chaque requête se voit attribuer son propre thread. C'est donc en fait du synchrone, mais par requête.
//      - Optez pour la technique du "polling" :
//          Néanmoins, si le consommateur fait d’autres choses au lieu d’attendre, nous avons un problème.
//          Comment le fournisseur indique-t-il que le résultat est maintenant prêt pour le consommateur ?
//          Nous devons introduire davantage de coordination entre le consommateur et le fournisseur.
//          Dans cette situation, le consommateur continue à demander au fournisseur si la réponse est prête. Un appel séparé est passé à l’API pour voir comment ça se passe.
//          Si vous avez déjà été en voiture avec un enfant, vous connaissez la chanson : "Quand est-ce qu'on arrive ?". Une question répétée inlassablement.
//          C’est une option facile à implémenter. La plus grande partie de la coordination est du côté du consommateur.
//          Il continue simplement à demander si le fournisseur a terminé. Là où ça se complique, c’est si plusieurs consommateurs formulent des requêtes similaires.
//          Le fournisseur doit donner un identifiant ou un token au consommateur. Le consommateur renvoie ensuite ce token au fournisseur, afin qu’il voie si la requête est achevée.
//          Ce fonctionnement ressemble un peu à celui d’un vestiaire dans un théâtre : vous donnez votre manteau et recevez en échange une carte portant un numéro.
//          À la fin du spectacle, lorsque vous rendez la carte, elle permet à la personne du vestiaire de savoir quel manteau vous voulez.
//              --> L'inconvénient de cette approche, ce sont les ressources.
//                      On peut avoir beaucoup de demandes pour savoir si la réponse est prête, avant que la réponse ne le soit vraiment.
//                      Chaque question (et réponse) nécessite de la bande passante (réseau, processeur, etc.) des deux côtés de l’interaction.
//                      Alors, comment limiter le nombre d’interactions ? Avec la méthode du "callback".
//      - Optez pour la technique du "callback" :
//          Le plus efficace dans ce cas-là c'est de stopper les questions du consommateur.
//          Avec le callback, une seule requête est formulée.
//          Lorsque le fournisseur a terminé, le consommateur est rappelé. Seuls deux messages sont envoyés (la requête, la réponse), ce qui réduit considérablement la bande passante.
//          Néanmoins, un chemin de communication supplémentaire doit être ouvert.
//              --> Le fournisseur a besoin d’un moyen de rappeler le consommateur. Par conséquent, le consommateur doit passer un mécanisme en paramètre dans le message d’origine.
//          Dans notre approche d’endpoint, l’endpoint du consommateur peut être envoyé dans le message JSON.
//          Le fournisseur doit sauvegarder ce endpoint, afin de savoir où appeler lorsque la réponse est prête.
//          De plus, le consommateur n’a aucune idée de quand le fournisseur enverra le résultat.
//          Le consommateur devra dédier une ressource (un thread, par exemple) pour attendre et guetter la réponse.
//          De même que pour le polling, une certaine coordination est nécessaire.
//          De nombreuses requêtes peuvent avoir été envoyées au fournisseur par le consommateur.
//          Lorsque le résultat arrive, le consommateur doit savoir à quelle requête le résultat correspond. Dans ce cas aussi, on utilise une approche avec un identifiant ou un token.
//          Si vous intégrez un jour une solution de paiement en ligne, vous utiliserez très probablement le callback :
//              - Via un back-office de la solution, vous indiquerez une URL de rappel.
//              - Lorsque vous requêterez la solution, vous transmettrez un identifiant de paiement.
//              - Quand le paiement sera traité par la banque, la solution rappellera votre application à l’URL fournie, en vous renvoyant aussi l'identifiant de paiement.
//          Un seul appel en requête, un seul appel en réponse !
//      - Optez pour la technique du "publish/subscribe" ou "message queuing" :
//          Et si de nombreux consommateurs s’intéressent au résultat de la réponse d’un fournisseur à un autre consommateur ? Ou vice versa ?
//          Un consommateur soumet une requête, mais ne s’intéresse pas à l’identité du fournisseur qui y répond, pourvu qu’elle soit gérée facilement.
//          Peu m’importe quel est le cuisinier qui prépare mon repas, par exemple. C’est celui qui est libre qui devrait s’en occuper.
//          Avec cette approche, il y a une file d’attente ou un porteur central de toutes les requêtes.
//          Et de la même façon : il y a une file d’attente ou un porteur de toutes les réponses.
//          Un contrôleur s’assure que tous les messages (requêtes et réponses) vont là où ils doivent aller.
//          Il existe de nombreux packages qui effectuent ce travail pour vous. Kafka en est un exemple populaire.
//          Le grand avantage de cette approche, c’est l’efficacité. Les messages ne sont envoyés qu’en cas de besoin. Et ils sont seulement stockés le temps nécessaire.
//          Dans l’entreprise de données médicales pour laquelle je travaillais, nous avions plusieurs files de publications/souscriptions.
//          Certaines étaient configurées pour traiter les choses en quelques minutes, et supprimer les messages envoyés immédiatement.
//          D’autres étaient configurées pour sauvegarder les messages pendant un mois.
//          Pour l’application Air Business, ces mécanismes vont au-delà de notre besoin.
//          En revanche, si les demandes de réservations "s’envolaient" réellement, nous pourrions utiliser cette approche pour aider à répartir la charge sur plusieurs serveurs.
//          Bref, selon dls ressources disponibles et de la vitesse des réponses, vous disposez de plusieurs options pour gérer les messages entre les couches.
//          Ainsi qu'entre votre système et les clients externes.
// -----------
//  - En résumé :
//      --> Il existe de nombreuses options pour communiquer entre les couches, dont la plupart utilisent des consommateurs et des fournisseurs.
//      --> Les appels en synchrone à un fournisseur peuvent être implémentés avec REST.
//      --> Les mécanismes asynchrones doivent être utilisés si le temps de traitement par le fournisseur est long.
//      --> Le polling est facile à implémenter, mais peut être lent.
//      --> Les callbacks sont efficaces.
//      --> Les files d’attente de messages, ou publications/souscriptions, sont très efficaces, mais nécessitent généralement une implémentation tierce pour gérer tous les détails.
// Maintenant que vous maîtrisez la communication, concluons ce cours  !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Adoptez les API REST pour vos projets web /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous êtes-vous déjà demandé comment toutes les dernières publications Facebook et Twitter se retrouvent comme par magie sur votre téléphone ou dans votre navigateur ?
// Comment les sites de comparateurs de vols ou d'hôtels arrivent à avoir tous les prix de toutes les compagnies aériennes ou de tous les hôtels dans leur application ?
// Et qu’en est-il de la façon dont vous pouvez voir et modifier des données à travers vos applications web ?
//      --> Eh bien, tout ça c’est grâce à une API !
// Dans ce cours, vous apprendrez ce qu’est une API et comment l’utiliser dans votre projet de code.
// Vous découvrirez également comment créer et développer l’un des types d’API les plus populaires.
//      --> Celle-ci constitue un élément indispensable de la boîte à outils de tout développeur de nos jours : une API REST !
// Êtes-vous prêt à commencer à travailler avec les API REST et à apporter une toute nouvelle dimension à vos projets web ?
// Objectifs pédagogiques :
//      - Utiliser des API REST pour vos projets de code.
//      - Formuler des requêtes et envoyer des réponses avec une API REST.
//      - Concevoir des API REST.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez des API REST pour vos projets de code ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Initiez-vous au fonctionnement des API ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découvrez ce qu’est une API :
// C’est dimanche. Vous vous réveillez tard, et même si vous savez que vous devriez vous lever, vous voulez juste rester enroulé bien au chaud dans votre couette.
// Vous vous dites qu’en ce mois de février, partir profiter de la douceur du Portugal ne serait pas une mauvaise idée.
// Alors, vous ouvrez une application de comparateur de vols et voilà ! Vous trouvez plusieurs offres de différentes compagnies aériennes pour Lisbonne !
// Bon, l’avion, ce n’est pas très écolo et entre nous les horaires ne sont pas top, alors vous tentez le train.
// Vous ouvrez une application pour réserver un billet de train et pareil ! Vous trouvez plusieurs offres de trains pour Lisbonne en passant par l’Espagne.
// Et tout ça sans avoir à aller chercher l’information sur le site de chaque compagnie ferroviaire ou aérienne. Pas mal, non ?
// Vous avez l’habitude de voir toutes ces données défiler sans arrêt sous vos yeux comme par magie, que ce soit sur les réseaux sociaux ou les applications de comparatifs en tout genre.
// De votre point de vue, c’est assez simple : les informations arrivent au fur et à mesure sans effort, sauf qu’en coulisse, c’est autre chose !
// En effet, un gros travail est effectué pour rendre cela possible et pour que cela fonctionne, il nous faut l’un des outils les plus importants : une API.
// API par ci, API par là, OK OK, mais que signifie API, au juste ?
//      --> API est une abbréviation et signifie Application Programming Interface (ou interface de programmation d’application, en français).
//              Pour faire simple : c’est un moyen de communication entre deux logiciels, que ce soit entre différents composants d’une application ou entre deux applications différentes.
// Ok, mais du coup, quel est le lien  entre une API et le fait de scroller par exemple Instagram non stop jusque 2 h du matin, ou comparer des vols pour Lisbonne ?
// -----------
//  - Découvrez le fonctionnement des API :
// Eh bien, pour répondre à cette question, vous devez connaître un peu plus le fonctionnement d’une API.
// Mais avant, revoyons ensemble les bases d’une communication serveur et client.
// Prenons l’exemple d'Air France, une compagne aérienne française.
// Quelque part dans le monde, les serveurs d'Air France ont accès à toutes les données que vous voulez voir pour un trajet Paris-Lisbonne : les différents avions, les tarifs, les statuts des vols, etc.
// Pour que vous puissiez y avoir accès, votre navigateur (que l’on appelle le client) doit recevoir ces informations de quelqu’un.
// Ce quelqu’un, c’est le serveur. L’application doit avoir une conversation avec le serveur.
// Une conversation typique entre client et serveur : à gauche l'ordinateur client envoie une requête au serveur à droite. Puis le serveur à droite retourne une réponse au client.
// Cela ressemble à ça :
// Client : "Salut serveur, est-ce que  je pourrais avoir un avion pour Lisbonne le 10 décembre ?"
// Serveur : "Voilà, tous les transports disponibles vers Lisbonne le 10 décembre!"
// Ou alors, si le serveur ne parvient pas à trouver les données, il pourrait répondre comme ceci :
// Serveur : "Désolé, en fait il n’y a pas de vols disponibles le 10 décembre."
// C’est ce qu’on appelle la communication entre client et serveur :
//      --> le client formule une requête (ou une demande) pour obtenir une information et le serveur envoie une réponse contenant les données demandées si cela est possible.
// Et du coup, l’API, elle se place où, dans ce schéma ? Et le rapport avec Air France ?
// En web, un service web et une API sont tous les deux des moyens de communication.
// Un service web standard facilite seulement la communication entre deux machines via un réseau.
// Une API facilite l’interaction entre deux applications différentes afin qu’elles puissent communiquer entre elles : elle sert d’intermédiaire.
// Le client va demander à l’API une information, celle-ci va aller chercher cette information dans la base de données puis la renvoyer au client dans un second temps.
// Une conversation entre le client, l'API et la base de données : l'API au milieu récupère des données de la BDD à droite, puis la BDD retourne des données à l'API.
// Les API permettent la communication entre de nombreux composants différents de votre application, mais aussi entre des composants de votre application et d’autres développeurs.
// Elles agissent ainsi comme un intermédiaire qui transmet des messages à travers un système de requêtes et de réponses.
// Reprenons notre exemple avec Air France.
// On crée une application de comparateur de vols que l’on va l’appeler VolScanner.
// Celle-ci ne peut pas accéder directement aux informations d'Air France ou de toute autre compagnie aérienne.
// En effet, l’application n’a pas accès à leurs base de données...
// Mais si Air France a une API à qui on peut demander des informations, alors VolScanner peut demander des informations à l’API d'Air France.
// L’API lui renvoie alors des données que VolScanner peut partager !
// Ainsi, VolScanner peut comparer les prix entre les différentes compagnies qui ont mis en place un vol le 10 décembre pour Lisbonne. À vous les délicieuses pasteis de nata !
// Les API peuvent communiquer :
//      --> D’un logiciel à un logiciel.
//      --> D’un client à un serveur.
//      --> D’un logiciel à des développeurs.
// Je suis certaine que vous avez déjà vu un exemple d’utilisation d’une API pour communiquer entre logiciels et développeurs :
// Sur certains sites, vous pouvez utiliser votre compte Google ou Facebook pour vous identifier sans avoir à créer un identifiant et un mot de passe.
// C’est parce que Google et Facebook ont construit des API que d’autres développeurs peuvent utiliser dans leurs propres sites Internet.
// Et ce, pour s’occuper de l’inscription et de la connexion des utilisateurs à leur place.
// Les API rendent possibles les identifications par un service externe !
// Et du coup, comment c’est possible techniquement ?
// Les API créent des méthodes standardisées et réutilisables qui permettent aux développeurs d’accéder à des données spécifiques lors de la construction d’applications.
// Prenons un exemple. Quand vous sortez manger, le menu du restaurant offre une grande quantité d’options déjà prédéterminées.
// Cela vous simplifie la tâche car vous savez ce que vous pouvez commander, et donc obtenir plus rapidement votre plat.
// Cela donne également une meilleure compréhension de ce que vous voulez pour le chef.
// Au final, vous n’avez qu’à demander à la serveuse (API) un plat du menu qu’elle transmettra en cuisine, la cuisine prépare votre plat, le remet à la serveuse qui vous le ramène.
// -----------
//  - Observez comment utiliser les API en tant que développeur :
// En tant que développeur, vous serez certainement amenés à utiliser diverses API dans votre vie professionnelle ou pour vos projets personnels.
// Il existe deux types principaux : les API privées et les API publiques. Voyons ensemble de quoi il s'agit !
//      - Les API privées :
//          Les API privées garantissent que les personnes en dehors de votre entreprise ou de votre application n’ont pas accès aux données disponibles de votre base de données.
//          Par exemple, imaginons que les développeurs d'OpenClassrooms voulaient construire une application interne pour que les RH puissent gérer et analyser des informations de recrutement.
//          Il y aurait de nombreuses données que les salariés voudraient voir, créer, et modifier.
//          Pour que les utilisateurs puissent interagir avec les données, les développeurs d’OpenClassrooms pourraient créer une API pour que les RH puissent accéder aux données de recrutement.
//          Et ce, à travers leur application, sans pour autant donner ces accès aux utilisateurs de la plateforme comme vous et moi.
//          Une API peut être utilisée comme un tampon ou une couche intermédiaire entre la base de données et la personne qui veut accéder ou manipuler les données.
//          Une requête directe et non contrôlée sur une base de données pourrait engendrer le chaos !
//          Et si quelqu’un supprimait accidentellement un cours ou modifiait quelque chose qu’il n’aurait pas dû toucher ?
//          La base de données est la fondation de toutes les données au sein d’une application, donc il ne faut surtout pas qu’elle soit facilement accessible ou manipulable par n‘importe qui.
//          Question de sécurité !
//          Une API permet un niveau de sécurité supplémentaire pour mieux gérer l’accès et les modifications des données, en attribuant ce qu’on appelle des droits aux personnes qui en ont besoin.
//          Ainsi, on s’assure de contrôler les utilisateurs qui auront ou non accès à la base de données.
//          Ainsi, moi seule peux modifier mes informations personnelles sur mon profil OpenClassrooms.
//              --> Une API privée permet uniquement aux utilisateurs autorisés au sein de votre entreprise ou de votre application d'utiliser l’API qui peut accéder à la base de données.
//      - Les API publiques :
//          Contrairement aux API privées, les API que l’on appelle publiques sont utilisables par d’autres personnes, qu’elles soient sur votre application ou non.
//          Elles permettent aux développeurs de récolter les données d’une autre application pour améliorer ou enrichir leurs propres projets sans autorisation stricte.
//          Il existe de nombreuses manières d’utiliser des données provenant d’API tierces (ou externes), mais en voici quelques-unes :
//              --> Imaginons que vous vouliez construire un site web qui répertorie les conditions météo des stations de ski.
//                      Plutôt que de collecter vos propres données météorologiques, vous pouvez utiliser une API de météo et y trouver vos données !
//              --> Imaginez que vous êtes auteur-compositeur-interprète et que vous voulez créer un site web pour que vos fans puissent écouter votre musique.
//                      Au lieu de construire votre propre lecteur de musique en streaming, vous pouvez utiliser l’API de Spotify et écouter votre musique directement sur votre site web !
//              --> Vous voulez créer une page de fans pour votre série télé favorite (Kaamelot, bien sûr), en réunissant tous les comptes Instagram des différents acteurs sur un seul site web.
//                      Devinez quoi, il existe une API Instagram pour vous aider à le faire !
//          Il existe également certaines API à mi-chemin entre une API publique et privée.
//          Cela peut se produire quand différentes requêtes de l’API sont possibles uniquement en fonction du niveau d’accès dont vous disposez.
//          Nous y reviendrons plus tard lorsque nous traiterons de l’authentification.
//          Il existe des milliers d’API publiques que les développeurs peuvent utiliser de différentes façons pour améliorer leurs projets.
//          Vous trouverez ici une liste de ces API disponibles publiquement que vous pouvez utiliser !
// -----------
//  - En résumé :
//      --> Les API permettent de communiquer des données.
//      --> Elles permettent la communication entre différents composants de votre application et entre votre application et d’autres développeurs, par l’utilisation de requêtes et de réponses.
//      --> Elles donnent un moyen d’accès aux données de façon réutilisable et standardisée.
//      --> Les développeurs peuvent utiliser des API publiques et privées.
//      --> Les API publiques sont utilisables par tous sans restriction.
//      --> Les API privées sont utilisables seulement par ceux qui ont un accès et y sont autorisés.
// Pourquoi utiliser une API REST en particulier et pas une simple API ? REST possède de nombreux avantages. Regardons ensemble dans le chapitre suivant !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Identifiez les avantages d’une API REST ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Bien ! Maintenant que vous savez ce qu’est une API, parlons de ce qui compose une API REST.
// Nous utiliserons REST dans ce cours, car c’est le plus populaire. C’est l’un des standards de création d’API les plus logiques, efficaces, et utilisés.
// Et, d’après le rapport 2017 de l’état d’intégration des API de Cloud Elements (en anglais), 83 % des API sont des API REST.
// -----------
//  - Comprenez tous les avantages de REST :
// REST signifie Representational State Transfer, et constitue un ensemble de normes, ou de lignes directrices architecturales.
// Celles-ci structurent la façon de communiquer les données entre votre application et le reste du monde, ou entre différents composants de votre application.
// Nous utilisons l’adjectif "RESTful" pour décrire les API REST. Toutes les API REST sont un type d’API – mais toutes les API ne sont pas RESTful  !
// Les API RESTful se basent sur le protocole HTTP pour transférer les informations – le même protocole sur lequel la communication web est fondée !
// Donc, lorsque vous voyez http au début d’une URL, comme http://twitter.com – votre navigateur utilise HTTP pour faire une requête de ce site web au serveur.
//      --> REST fonctionne de la même façon !
// Il y a six lignes directrices architecturales clés pour les API REST. Voyons ensemble de quoi il s’agit :
//      - #1 : Client-serveur separation :
//          L’une des normes de REST est la séparation du client et du serveur.
//          Nous avons un peu abordé la question des clients et des serveurs dans le chapitre précédent, il est temps d’approfondir un peu le sujet !
//              --> Un client est celui qui va utiliser l’API. Cela peut être une application, un navigateur ou un logiciel.
//                      Par exemple : en tant que développeur, vous utiliserez peut-être l’API de Twitter.
//                      Comme je l’ai dit précédemment, un client peut aussi être un logiciel ou un navigateur, qu’il s’agisse de Chrome, Safari ou Firefox.
//                      Quand un navigateur se rend sur twitter.com, il formule une requête à l’API de Twitter et utilise les données de l’API afin que vous puissiez accéder aux derniers tweets.
//              --> Un serveur est un ordinateur distant capable de récupérer des données depuis la base de données, de les manipuler si besoin et de les renvoyer à l’API.
//          De façon générale, il existe une séparation entre le client et le serveur.
//          Cette séparation permet au client de s’occuper uniquement de la récupération et de l’affichage de l’information.
//          Elle permet aussi au serveur de se concentrer sur le stockage et la manipulation des données. Chacun son rôle !
//          Les API REST offrent un moyen de communication standardisé entre le client et les données.
//          En gros, peu importe comment le serveur est construit ou comment le client est codé.
//          Et ce, du moment qu’ils structurent tous les deux leur communication selon les lignes directrices architecturales REST, en utilisant le protocole HTTP, ils pourront communiquer entre eux !
//          C’est particulièrement utile lorsque de grandes équipes de développeurs travaillent sur une même application.
//          Vous pouvez avoir une équipe qui travaille indépendamment sur le backend tandis que l’autre travaille sur le frontend.
//          Comme l’API REST communique entre les deux, cela permet aux développeurs de scaler plus facilement les applications et aux équipes de travailler de manière plus efficace.
//      - #2 : Stateless :
//          L’un des autres aspects uniques des API REST est qu’elles sont stateless – sans état, en français – ce qui signifie que le serveur ne sauvegarde aucune des requêtes ou réponses précédentes.
//          Mais le rôle du serveur est de stocker et manipuler les données. Comment est-ce que cela pourrait fonctionner si on ne garde pas une trace des requêtes, alors ?
//          Pour revenir à notre métaphore de l’API en tant que serveuse, imaginons que vous demandiez des frites à votre serveuse.
//          Elle se rend à la cuisine, récupère vos frites, et revient avec votre commande. Parfait !
//          Houla... mais attendez ! Vous venez de vous souvenir que vous voulez également du ketchup avec vos frites.
//          Vous demandez donc à votre serveuse : "Excusez-moi, je pourrais avoir du ketchup avec ?" "Avec quoi ?".
//          Une serveuse stateless n’aurait aucune idée de ce dont vous parlez, car elle ne se souviendrait pas que vous venez de commander des frites !
//          Elle se charge seulement de transférer les commandes de la cuisine au client.
//          OK, mais alors concrètement, qu’est-ce que cela signifie pour les API REST ?
//          Étant donné que chaque message est isolé et indépendant du reste, il vous faudra vous assurer d’envoyer avec la requête que vous formulez toutes les données nécessaires.
//          Ceci, pour être sûr d’avoir la réponse la plus précise possible.
//          Cela nous donnerait quelque chose comme : "Est-ce que je pourrais avoir du ketchup sur les frites que j’ai commandées à ma table ?"
//          Avec toutes ces informations, votre serveuse pourra identifier à quelles frites il faut ajouter du ketchup !
//          Le fait d’être stateless rend chaque requête et chaque réponse très déterminée et compréhensible.
//          Donc, si vous êtes développeur et que vous voyez la requête API de quelqu’un d’autre dans un code déjà existant, vous serez capable de comprendre l’objet de la requête sans contexte !
//      - #3 : Cacheable (sauvegardable) :
//          La réponse doit contenir l’information sur la capacité ou non du client de mettre les données en cache, ou de les sauvegarder.
//          Si les données peuvent être mises en cache, la réponse doit être accompagnée d’un numéro de version.
//          Ainsi, imaginons que votre utilisateur formule deux fois la même requête (c’est-à-dire s’il veut revoir une page) et que les informations n’ont pas changé.
//          Alors, votre serveur n’a pas besoin de rechercher les informations une deuxième fois.
//          À la place, le client peut simplement mettre en cache les données la première fois, puis charger à nouveau les mêmes données la seconde fois.
//          Une mise en cache efficace peut réduire le nombre de fois où un client et un serveur doivent interagir, ce qui peut aider à accélérer le temps de chargement pour l’utilisateur !
//          Vous avez peut-être entendu le terme cache en référence à, par exemple, "Rafraîchissez le cache de votre navigateur".
//          Un cache est un moyen de sauvegarder des données pour pouvoir répondre plus facilement aux prochaines requêtes qui seront identiques.
//          Quand vous allez sur de nombreux sites web depuis votre navigateur, celui-ci peut sauvegarder ces requêtes.
//          Cela, pour pouvoir compléter lui-même le site que vous voulez atteindre ou charger la page plus rapidement la prochaine fois que vous vous y rendez. Pratique !
//      - #4 : Uniforme Interface :
//          Lors de la création d’une API REST, les développeurs acceptent d’utiliser les mêmes normes. Ainsi, chaque API a une interface uniforme.
//          L’interface constitue un contrat entre le client et le service, que partagent toutes les API REST.
//          C’est utile, car lorsque les développeurs utilisent des API, cela leur permet d'être sûrs qu’ils se comprennent entre eux.
//          Une API REST d’une application peut communiquer de la même façon avec une autre application entièrement différente.
//      - #5 : Layered system :
//          Chaque composant qui utilise REST n’a pas accès aux composants au-delà du composant précis avec lequel il interagit.
//          Cela signifie qu’un client qui se connecte à un composant intermédiaire n’a aucune idée de ce avec quoi ce composant interagit ensuite.
//          Par exemple, si vous faites une requête à l’API Facebook pour récupérer les derniers posts : vous n’avez aucune idée des composants avec lesquels l’API Facebook communique.
//          Cela encourage les développeurs à créer des composants indépendants, facilitant le remplacement ou la mise à jour de chacun d’entre eux.
//      - #6 : Code on demand :
//          Le code à la demande signifie que le serveur peut étendre sa fonctionnalité en envoyant le code au client pour téléchargement.
//          C’est facultatif, car tous les clients ne seront pas capables de télécharger et d’exécuter le même code – donc ce n’est pas utilisé habituellement, mais au moins, vous savez que ca existe !
// -----------
//  - Découvrez les alternatives aux API REST :
// REST n’est qu’un type d’API. Il existe des alternatives qui vous seront également utiles à connaître, notamment les API SOAP.
// SOAP est l’acronyme de "Simple Object Access Protocol". Contrairement à REST, il est considéré comme un protocole, et non comme un style d’architecture.
// Les API SOAP étaient les API les plus courantes avant l’arrivée de REST.
// REST utilise le protocole HTTP pour communiquer, SOAP d’un autre côté peut utiliser de multiples moyens de communication.
// Le souci, c’est la complexité qui en ressort, car les développeurs doivent se coordonner pour s’assurer qu’ils communiquent de la même manière afin d’éviter les problèmes.
// De plus, le SOAP peut demander plus de bande passante, ce qui entraîne des temps de chargement beaucoup plus longs.
//      --> REST a été créé pour résoudre certains de ces problèmes grâce à sa nature plus légère et plus flexible.
// De nos jours, le SOAP est plus fréquemment utilisé dans les applications de grandes entreprises.
// En effet, nous pouvons y ajouter des couches de sécurité, de confidentialité des données, et d’intégrité supplémentaires.
// REST peut être tout aussi sécurisé, mais a besoin d’être implémenté, c’est-à-dire d'être développé au lieu d’être juste intégré comme avec le SOAP.
// -----------
//  - En résumé :
//      --> Toutes les API ne sont pas RESTful et les API REST ont des lignes directrices architecturales spécifiques.
//      --> Les avantages clés des API REST sont les suivants :
//              - La séparation du client et du serveur, qui aide à scaler plus facilement les applications.
//              - Le fait d’être stateless, ce qui rend les requêtes API très spécifiques et orientées vers le détail.
//              - La possibilité de mise en cache, qui permet aux clients de sauvegarder les données, et donc de ne pas devoir constamment faire des requêtes aux serveurs.
//      --> SOAP est un autre type d’API, mais est plus utilisé dans les grandes entreprises.
// Vous venez de voir la structure d’une API REST et ses avantages, il est temps de voir ce qui constitue une API REST : les ressources.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez les ressources et collections REST ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Maintenant que vous savez que les API REST servent d’intermédiaires et aident les développeurs à manipuler des données, regardons de plus près à quoi ressemblent réellement ces données.
// -----------
//  - Appréhendez les données REST via l’utilisation des ressources :
// Les données REST sont représentées dans ce qu’on appelle des ressources.
// Une ressource peut être tout type d’objet nominal que vous pouvez utiliser pour représenter les données dans votre application.
// Vous savez, une personne, un lieu, ou autre chose !
// Pour faire simple, voyez les ressources comme des boîtes dans lesquelles vous rangerez des objets par catégorie et sur lesquelles vous collez une étiquette pour savoir quoi mettre dedans.
// Vous trouvez que c’est abstrait ? C’est le but, afin que vous puissiez représenter n’importe quel élément de donnée sous la forme que vous souhaitez.
// Chaque ressource comporte des informations supplémentaires sur les données contenues.
// Si on prend l’exemple d’une application qui liste les héros Marvel, une des ressources pourrait être Superhero et on pourrait avoir par exemple un nom, une description, etc.
// Cela, comme information supplémentaire.
// Les ressources sont regroupées dans un groupe que l’on appelle une collection. On s’y réfère avec la forme au pluriel du nom de la ressource.
//      --> Par exemple une ressource superhero donnerait superheroes.
// Par convention, tous les champs d’une ressource et le nom d’une collection sont en anglais.
// Ils sont traduits ici en français pour une meilleure compréhension du cours, mais privilégiez toujours l’anglais !
// Imaginons que vous créez une API pour qu’une boutique de skateboards ait un service de livraison en ligne.
// Ce que vous voulez, c’est que d’un côté vos clients puissent acheter des skateboards sur le site web, et de l’autre que vos salariés puissent ajouter des produits et mettre l’inventaire à jour.
// Procédons étape par étape et déterminons ensemble les ressources, leurs informations supplémentaires et les collections.
// Pour une boutique de skateboards, vos ressources pourraient être :
//      - Client.
//      - Staff.
//      - Basket.
//      - Skateboard.
//      - Inventory.
// Une ressource Skateboard pourrait comporter comme informations supplémentaires : nom,  marque, id,  prix.
// Vos collections seraient donc :
//      Ressource           Collection
//      skateboard          skateboards
//      client              clients
// Cette liste est un exemple et ne contient pas tous les exemples cités précédemment.
// Bien ! Nous avons nos collections ainsi que les ressources correspondantes et leurs informations supplémentaires.
// Continuons avec notre exemple de boutique de skateboards et suivons ensemble le parcours de la requête d’un client via notre API.
// Quand un client achète un skateboard en utilisant votre application web, cela donne :
//      --> Votre API envoie la requête du navigateur (le client) aux serveurs de l’application pour l’achat d’un skateboard.
//      --> La requête met à jour l’inventaire pour qu’il y ait un skateboard de moins.
//      --> La requête met à jour l’historique de commandes du client pour ajouter le skateboard à son historique d'achats.
// Super ! Vous savez maintenant comment et sous quelle forme stocker les données que vous voulez utiliser dans votre API via des ressources et des collections.
//      --> Mais du coup, comment pouvez-vous y accéder ? Comment savoir où les récupérer, ces données ?
// -----------
//  - URI et Endpoints :
// Le path (ou chemin) que vous donnez à votre API lui permet de savoir exactement où se trouvent les données que vous voulez récupérer.
// Vous pouvez imaginer cela comme le fait de parcourir vos propres fichiers sur votre ordinateur.
// Vous devez aller de dossier en dossier pour trouver vos données, et chaque photo ou document que vous sauvegardez a son propre path, ou chemin de fichier, en français.
// Par exemple, votre photo de série préférée pourrait se trouver au bout de ce path : 'MyComputer/Images/Series/gameofthrones.jpg'.
// Les API REST stockent également les données de façon similaire, et un URI constitue le chemin pour y arriver.
// Si une ressource est l’objet qui stocke vos données, pour les récupérer vous allez avoir besoin d’un identifiant de ressource uniforme, ou URI pour 'Uniform Resource Identifier'.
// L’URI est le moyen d’identifier votre ressource, comme une étiquette.
// Imaginons que vous créez une API pour un site web qui présenterait toutes les informations de Game of Thrones, que ce soit sur le livre ou la série.
//      --> L’URI qui listerait tous les personnages pourrait être la suivante : '/characters'.
//      --> Si vous voulez voir les informations sur un seul personnage, qui porte l’ID 123, votre URI serait le suivant : '/characters/123'.
// Tout comme les paths pour les fichiers, les URI peuvent avoir des ressources imbriquées.
//      --> Si vous voulez obtenir uniquement le nom du personnage qui vous intéresse, votre URI pourrait ressembler à ceci : '/characters/123/description'.
// Voilà du progrès ! Le souci, c’est que sans l’adresse réelle du site web, l’API ne saura pas du tout où chercher l’URI pour commencer !
//      --> C’est là que les endpoints (ou points de terminaison, en français) interviennent !
// Un endpoint est une URL/URI qui fait partie d’une API. Si un URI est comme un chemin de fichier, alors un endpoint est comme l’adresse complète du fichier.
// Il vous suffit d’ajouter votre nom de domaine au début de votre URI, et vous avez un endpoint  !
// Par exemple, si le nom de domaine de notre app est 'gameofthrones-informations.com', nous aurons : 'https://gameofthrones-informations.com/characters'.
// Houla, attends deux secondes, c’est quoi la différence entre URI et URL ?
//      --> Toutes les URL sont des URI, mais toutes les URI ne sont pas des URL.
//      --> L’URI permet d’identifier une ressource tandis que l’URL permet de la localiser.
// On confond souvent les deux. On va tout simplifier avec un exemple !
// Reprenons notre site de Game of Thrones. Si le personnage de Jon Snow a pour ID 890, alors l’URI serait '/characters/890'. L’URL serait 'https://gameofthrones-informations.com/characters/890'.
//      --> L’URL de la requête est l’endpoint complet que vous utilisez pour votre requête.
// Il associe le nom de domaine + le path de votre ressource. À présent, vous savez comment accéder aux données que vous souhaitez !
// -----------
//  - Distinguez XML et JSON :
// Une fois que vous avez le bon endpoint sur lequel faire votre requête, il est temps pour vous d’obtenir vos données !
// C’est là que vous obtenez les informations sur les ressources que vous avez créées.
// Le terme données est un terme général qui décrit toute information envoyée ou reçue, tandis que que le terme ressource décrit plus précisément les éléments qui sont contenus dans cette information.
//      --> Les données des API REST peuvent utiliser deux langages : XML et JSON.
// Si une API renvoie un set de données en XML ou en JSON, le contenu restera le même, mais la forme change. Le format de données est différent.
//      - Le XML :
//          En XML, chaque élément de donnée a une balise ouvrante et une balise fermante qui peut également avoir des balises imbriquées :
//                  <series>
//                      <serie>
//                          <titre>Game Of Thrones</titre>
//                          <realisateur>Random</realisateur>
//                      </serie>
//                      <serie>
//                          <titre>Peaky Blinders</titre>
//                          <realisateur>Random</realisateur>
//                      </serie>
//                  </series>
//                  <series>
//                      <serie>
//                          <titre>Game Of Thrones</titre>
//                          <realisateur>Random</realisateur>
//                      </serie>
//                      <serie>
//                          <titre>Peaky Blinders</titre>
//                          <realisateur>Random</realisateur>
//                      </serie>
//                  </series>
//          Vous pouvez voir une balise ouvrante pour la collection en haut – series – entre crochets < >.
//          La balise fermante à la fin est identique, sauf qu’on y ajoute une barre oblique / au début : </series>, qui indique que c’est une balise fermante.
//          Chaque ressource listée a la balise ouvrante <serie> et la balise fermante </serie>.
//          Au sein de chaque ressource se trouvent davantage d’informations, comme "titre" et "réalisateur".
//      - Le JSON :
//          Le JSON stocke les données sous un format de clé-valeur avec comme clé le type de données, suivi de deux points ':', suivi de la valeur de la donnée.
//          Les données JSON sont entourées d'accolades { }, et chaque paire clé-valeur est envoyée comme chaîne de caractères avec des guillemets autour "".
//          Ce qui nous donne ceci :
//                  { "titre" :"Game of Thrones"}
//          Les tableaux, ou listes, en JSON sont entourées de crochets [].
//          L’exemple ci-dessous montre comment une liste complète peut être considérée comme la valeur de la clé "series".
//          Les mêmes données en XML ci-dessus seraient représentées ainsi en JSON :
//                  { "series": [
//                      {   "titre": "Game Of Thrones",
//                          "realisateur": "Alan Taylor"
//                      },
//                      {   "titre": "Peaky Blinders",
//                          "realisateur": "Otto Bathurst"
//                      }  ]
//                  }
//          Le JSON est généralement considéré comme :
//              - Plus facile à analyser avec du code.
//              - Plus court.
//              - Plus rapide à lire et à écrire pour les machines.
//              - Très "léger" et efficace grâce à sa structure en arborescence et sa syntaxe simple.
//          Voici quelques exemples d’API réelles qui renvoient du JSON et du XML :
//              --> Penguin Random House : XML.
//              --> Potter API : JSON.
//              --> Ghibli API: JSON.
//          Comme vous pouvez le constater, le JSON est le langage de données le plus utilisé, c’est pour cette raison que nous l’utiliserons dans le reste de ce cours !
// -----------
//  - En résumé :
//      --> Une ressource est un objet de type nominal utilisé pour sauvegarder des données dans une API.
//      --> Une ressource peut contenir des informations supplémentaires.
//      --> Les ressources sont regroupées en collection et sont nommées au pluriel.
//      --> Vous pouvez accéder aux ressources dans les API avec des URI.
//      --> Les données REST peuvent être en langage JSON ou XML, mais le JSON est le plus courant.
// Dans la seconde partie, dans laquelle nous allons sauter dans le grand bain et utiliser une API !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Formulez des requêtes et envoyez des réponses avec une API REST ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez Postman pour formuler vos requêtes ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Structure d'une requête HTTP :
//      - Verbe HTTP : GET, PUT, POST & DELETE sont les plus courants.
//      - Header.
//      - Path.
//      - Body.
// Structure d'une réponse HTTP :
//      - Code de réponse HTTP.
//      - Header.
//      - Body.
// -----------
//  - Identifiez les avantages de Postman :
// Vous savez déjà qu’une API REST implique l’envoi de requêtes du client à l’API, qui passe la requête au serveur, l’API récupère la réponse et la renvoie enfin au client.
//      --> Dans ce chapitre, nous allons voir comment formuler ces requêtes grâce à Postman.
// Cette interface graphique est utilisée par de nombreux développeurs.
// Elle facilite la construction de nos requêtes. C’est donc l’outil idéal pour tester des API sans devoir utiliser de code.
// Mais pourquoi utiliser Postman en particulier ?
// Parce que cette interface offre beaucoup d’avantages :
//      --> Vous pouvez l’utiliser quel que soit le langage avec lequel vous programmez.
//      --> Son interface utilisateur est simple : vous effectuez vos requêtes facilement.
//      --> Vous n’avez pas besoin de savoir coder, ou d’utiliser une application.
// -----------
//  - Téléchargez Postman :
// L’heure est venue de vous lancer : téléchargez Postman.
// Choisissez votre système d’exploitation. Postman est disponible pour Linux, Windows et OS X. Les instructions sont en anglais.
// La page d'accueil de Postman : à gauche de l'interface les icônes proposent de télécharger votre système d'exploitation.
// Une fois que vous l’aurez fait, vous allez être redirigé sur une page pour télécharger le logiciel. Cliquez sur le bouton Download the App.
// Parfait ! Et maintenant, passons à la formulation des requêtes.
// -----------
//  - Formulez une requête sur Postman :
//      - La structure d’une requête :
//          Chaque requête a une structure spécifique qui a cette forme :
//              --> Verbe HTTP + URI + Version HTTP + Headers + Body (facultatif).
//          Une structure de requête typique en 3 couches superposées :
//              - En bas le body.
//              - Au milieu les Headers.
//              - Au-dessus le verbe HTTP.
//              - L'URI et la version HTTP.
//          L’aspect peut varier en fonction du logiciel ou du langage utilisé.
//      - Visualisez une requête sur Postman :
//          Maintenant que vous avez lancé le logiciel, regardons ensemble à quoi ressemble une requête sur Postman.
//          Le champ utilisé pour réaliser une requête dans Postman est entouré en vert dans l'onglet Workspaces de l'interface.
//          Détaillons ensemble chaque zone une à une en suivant la structure d’une requête :
//              - Le verbe : Commençons avec le verbe. Les verbes HTTP correspondent à différents types d’actions que vous pouvez accomplir avec votre requête.
//                  Ceux que vous rencontrerez le plus couramment sont GET (obtenir), PUT (mettre), POST (publier), et DELETE (supprimer).
//                  Ne vous y attardez pas trop pour le moment, nous les étudierons tous plus en détail plus tard !
//              - L’URI : Passons à l’URI. Un URI est le moyen d’identifier les ressources.
//                  Par exemple, si vous voulez voir tous les utilisateurs sur votre site web, le path serait le suivant : '/users'.
//                  Imaginons que vous vouliez obtenir les informations d’un utilisateur spécifique.
//                  Dans ce cas-là, il vous faudrait préciser son ID. On obtiendrait quelque chose comme ceci : 'users/:user_id'.
//                  Pourquoi on utilisait un nombre avant, et tout d’un coup tu nous mets  '':user_id' ?
//                  On utilise ':user_id' pour matérialiser l’ID de l’utilisateur, c’est ce qu’on appelle un placeholder.
//                  En pratique, avec un ID réel, le path ressemblerait plutôt à ça : 'users/145'.
//              - Le header : Un header (ou en-tête) vous permet de faire passer des informations supplémentaires sur le message. Par exemple :
//                      --> De quel langage s’agit-il ?
//                      --> À quelle date l’envoyez-vous ?
//                      --> Quel logiciel la personne utilise-t-elle ?
//                      --> Quelle est votre clé d’authentification ?
//                  Les headers sont représentés par une paire clé et valeur, et il existe de nombreux types d’options différents pour eux. Par exemple :
//                              Date : Mardi 19 Janvier 2019 18:15:41 GMT
//                              Utilisateur-Agent : Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)
//                  Vous pouvez consulter la liste complète des différentes options pour les headers : 'https://developer.mozilla.org/fr/docs/Web/HTTP/Headers'.
//              - Le body : Pour finir, parlons du body ! Pour formuler une requête, il n’est utilisé qu’avec PUT (mise à jour) ou POST (création).
//                  Il contient les données réelles de la ressource que vous essayez de créer ou de mettre à jour. Les données sont envoyées sous format JSON.
//                  Petit rappel : le JSON est largement utilisé, toutefois il se peut que certaines API n’acceptent que le XML.
//                  Vous trouverez cette information dans la documentation de l’API que vous utiliserez.
//                  Prenons un exemple ! Vous voulez ajouter ou mettre à jour les informations d’un utilisateur.
//                      --> Vous ajouterez donc les détails de l’utilisateur (prénom, nom , adresse…) dans le body, en JSON.
//                  Notez que le body est facultatif dans ces deux cas. Cela signifie qu’il est tout à fait possible d’envoyer un body vide en fonction des actions de l’API visée.
//                  Vous en apprendrez plus à ce sujet dans les prochains chapitres.
// -----------
//  - Obtenez une réponse avec Postman :
// Le format du message de réponse est très similaire à celui de la requête :
//                  Version HTTP + Code de réponse HTTP + Headers + Body
// Une structure de réponse typique en 3 couches superposées :
//      - En bas le Body.
//      - Au milieu le Header.
//      - Au-dessus la version et le code HTTP.
// Un message de réponse typique de Postman est affiché sur l'interface dans l'onglet Body.
// Le body ? Mais il n'est pas censé être utilisé seulement pour faire une requête avec POST et PUT ?
// Pour formuler une requête, oui ! Mais pour les réponses, le body contient l’information que vous avez demandée, et que l’API vous renvoie.
// Celle-ci est matérialisée au sein du body sous la forme d’un JSON ou en XML.
// Et si elle échoue ? Que se passe-t-il ? On obtient une information différente ?
// Exactement ! Si la requête échoue, le body peut contenir un message d’erreur.
// Mais le message ne suffit pas, et entre nous il peut arriver que des API n’envoient pas de messages du tout, que la requête soit un succès ou non.
// Cela peut arriver, même si c’est rare ! Dans ce cas, votre meilleur allié sera le code de réponse HTTP !
// -----------
//  - Analysez le code de réponse HTTP :
// Le code de réponse HTTP aide le développeur et/ou le client à comprendre le statut de la réponse.
// Jetons un oeil sur les exemples obtenus avec Postman :
//      --> Un code de statut HTTP 200 OK pour une requête réussie.
//      --> Un code de statut HTTP pour une requête réussie.
//      --> Un code de statut HTTP 404 Not found pour un échec.
//      --> Un code de statut HTTP pour un échec.
// Un client vous envoie une requête comme "Salut, pourriez-vous m’envoyer tous les tweets de cet utilisateur ?".
// Vous pouvez vous représenter le code de réponse comme un feu de signalisation qui vous dit par exemple :
//      --> VERT : "Cette requête a été traitée avec succès."
//      --> ROUGE : "Nous n’avons rien trouvé pour cette requête !"
// Il existe de nombreux codes de réponse différents – vous connaissez probablement le 404 not found (ou introuvable, en français).
// Vous l’avez peut-être vu sur quelques sites web.
// Un autre code de réponse important à connaître est le 200 OK, qui signifie que votre requête a réussi, et que votre réponse est prête !
// En général, les règles de base pour les codes de réponse HTTP sont les suivantes :
//      --> 100+ : Information.
//      --> 200+ : Succès.
//      --> 300+ : Redirection.
//      --> 400+ : Erreur client.
//      --> 500+ : Erreur serveur.
// Les codes HTTP sont très codifiés, et chaque nombre correspond à une réponse particulière.
// De ce fait, toutes les API renverront une 404 si la ressource est introuvable, et cela permet aux développeurs de comprendre de quel type de réponse il s’agit.
// C’est une sorte de nomenclature générale respectée par tous.
// Si vous avez un doute sur un code HTTP, n’hésitez pas à consulter cette documentation : 'https://developer.mozilla.org/fr/docs/Web/HTTP/Status'.
// -----------
//  - En résumé :
//      --> Postman est un logiciel gratuit qui vous permet d’effectuer des requêtes API sans coder.
//      --> Les requêtes prennent la forme suivante : Verbe HTTP + URI + Version HTTP + Headers + Body facultatif.
//      --> Les verbes HTTP sont des types d’actions que l’on peut faire lors de la formulation d’une requête.
//      --> Les réponses prennent la forme suivante : Code de réponse HTTP + Version HTTP + Headers + Body.
//      --> Les codes de réponse HTTP sont des sortes de feux de signalisation avec des codes spécifiques, pour informer les clients si la requête est un succès ou un échec.
//      --> Les codes HTTP sont codifiés en fonction du type de réponse ; vous trouverez la liste ici.
// Dans le chapitre suivant, nous allons remonter nos manches et commencer à travailler avec de vraies API !
// Pour que votre apprentissage soit le plus efficace, il est important de connaître les formats généraux de requêtes et de réponses, ainsi que de savoir à quoi ressemble une réponse réussie ou non !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Réalisez vos premières requêtes sur une API ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans le chapitre précédent, nous avons parlé des verbes HTTP et de la façon dont ils permettent de réaliser des actions spécifiques lors de la formulation d’une requête API.
// Rappelez-vous, j’avais mentionné GET, POST, PUT et DELETE. Eh bien, il est temps d’en apprendre un peu plus, et surtout de les utiliser !
// -----------
//  - Découvrez le CRUD :
// Le CRUD est la liste des actions de base que vous pouvez effectuer sur une ressource.
// C’est un acronyme qui signifie Create (créer), Read (lire), Update (mettre à jour), et Delete (supprimer).
// Bien que le CRUD ne constitue pas vraiment un mécanisme technique en soi, chaque action CRUD est associée à un verbe HTTP. Voici la cartographie :
//      Action CRUD                 Verbe HTTP associé
//      Create (Créer)              POST (Publier)
//      Read (Lire)                 GET (Obtenir)
//      Update (Mettre à jour)      PUT (Mettre)
//      Delete (Supprimer)          DELETE (Supprimer)
// -----------
//  - Obtenez des résultats avec votre première requête GET :
// Maintenant que nous avons vu tout le contexte qui se cache derrière une API, il est temps de pratiquer !
// Utilisons une API pour obtenir des données. Nous utiliserons le verbe HTTP GET et l’API GitHub (de GitHub) pour obtenir des données sur un utilisateur GitHub spécifique.
// GitHub est une plateforme qu’utilisent les développeurs pour stocker leur code et travailler seul ou en équipe.
// Cela permet de faciliter la collaboration entre développeurs d'un même projet. En tant que développeur, vous l’utiliserez beaucoup !
// Pour faire une requête sur l’API, utilisons le logiciel Postman que vous avez téléchargé précédemment.
// Commencez par ouvrir le programme.
// Nous l’avions survolé lors du dernier chapitre, mais il est toujours bon de revoir ce que nous avons appris. Détaillons un peu ce que nous voyons, de haut en bas !
// Interface utilisateur Postman avec 3 encadrés :
//      - En haut à gauche, un menu déroulant encadré en noir : vous permet de sélectionner votre type de requête dans le menu déroulant (dans notre cas, ce sera GET).
//          À côté, vous pouvez remplir la case avec l’URL complète de votre requête.
//      - En-dessous : le bouton Params encadré en rouge : Si vous cliquez dessus, vous aurez un emplacement pour définir les valeurs clés de vos paramètres.
//      - A droite du bouton : l'onglet Headers encadré en bleu : Cela vous permettra de définir vos headers de requête.
//      - Et pour finir, en dessous, en jaune , vous pouvez voir l’emplacement du body de votre réponse.
// Nous voulons obtenir des informations sur un utilisateur. Mais comment faire ? Quelle URL utiliser ?
// Avant de  faire une requête sur l’API GitHub et d'obtenir un utilisateur en particulier, vous devez avant tout faire une chose très importante : consulter la documentation GitHub !
// Et plus précisément la section Users, car c’est celle-ci qui nous intéresse.
// La documentation, c’est le mode d’emploi d’une API. C’est ainsi que vous trouverez les ressources, URI et endpoints que vous pouvez utiliser pour récupérer des données.
// Allez sur la section Users de l’API GitHub via cette URL : https://developer.github.com/v3/users/
// La partie qui nous intéresse ici est celle qui nous permet d’obtenir un seul utilisateur (Get a user en anglais). Cliquez dessus !
// La documentation GitHub est affichée. A droite, Get a user est encadré en vert.
// Voici ce que dit la documentation en français :
//      Obtenir un utilisateur unique :
//      Fournit les informations disponibles publiquement sur quelqu’un ayant un compte GitHub.
//      Les applications GitHub avec la permission utilisateur Plan peuvent utiliser cet endpoint pour récupérer des informations sur le plan GitHub d’un utilisateur.
//      L’application GitHub doit être authentifiée en tant qu’utilisateur. Voir "Identifier et autoriser les utilisateurs pour les applications GitHub" pour plus de détails sur l’authentification.
//      Pour un exemple de réponse, voir « Réponse avec l’information du plan GitHub ».
//      La clé e-mail dans la réponse ci-dessous correspond à votre adresse e-mail visible publiquement depuis votre page de profil GitHub.
//      Lors de la création de votre profil, vous pouvez sélectionner une adresse e-mail principale comme "publique", ce qui fournit une entrée e-mail pour cet endpoint.*
//      Si vous ne choisissez pas d’adresse e-mail publique pour e-mail, alors sa valeur sera nulle.
//      Vous ne voyez que les adresses e-mail visibles publiquement lorsque vous êtes authentifié dans GitHub. Pour plus d’informations, voir Authentification.
//      L’API Emails vous permet de lister toutes vos adresses e-mail, et d’ajouter un toggle à une adresse e-mail principale pour qu’elle soit visible publiquement.
//      Pour plus d’informations, voir "API Emails".
// La documentation nous apprend plusieurs choses :
//      - Cette section fournit les informations disponibles publiquement sur quelqu’un ayant un compte GitHub.
//      - On peut accéder aux informations d’un utilisateur via GET /users/:username.
//      - Un exemple de réponse est affiché et encadré au milieu de l'interface.
// Si on résume, cela signifie que, imaginons que nous voulons obtenir la donnée user de l’utilisateur "tenderlove".
// Allez dans Postman et entrez https://api.github.com/users/tenderlove dans l’URL, puis appuyez sur Send (Envoyer).
// La requête GET est entourée en vert et contient une adresse HTTP.
// Vous pouvez remplacer tenderlove par votre login GitHub et observer la réponse.
// N’hésitez pas à comparer les données récupérées par l’API et celles de GitHub : vous verrez, ce sont les mêmes !
// GET est le verbe HTTP le plus utilisé. Il permet de faire une requête afin de récupérer un groupe de données mais aussi des données précises.
// Comme vous l’avez vu avec l’API GitHub, avec une requête GET vous allez obtenir des données précises grâce à un ID, dans notre exemple, votre nom d’utilisateur GitHub.
// Notez la façon dont votre navigateur (ou client) utilise une API pour afficher les données sur un site web. Ici, la réponse est sous un format JSON.
// Rappelez-vous, en JSON, la réponse est affichée sous un format clé-valeur.
// Vous pouvez même effectuer des requêtes GET directement depuis votre navigateur, car les endpoints REST utilisent le même protocole HTTP que le web.
// Essayez d’aller sur 'https://api.github.com/users/tenderlove' maintenant, et vous verrez !
// -----------
//  - Utilisez la documentation pour connaître le mode d’emploi de l’API :
// Comme vous pouvez le constater, la documentation d’une API ressemble à un manuel d’utilisation très très détaillé.
// Étant donné que chaque API est différente, vous ne sauriez pas les utiliser sans une documentation claire et précise.
//      --> Quelles informations nous donne cette documentation ?
// La documentation liste tous les appels API possibles, les requêtes et réponses typiques, mais surtout les verbes à utiliser pour chaque requête. Cette API Ghibli constitue un bon exemple.
// Documentation de l’API Ghibli. A gauche, les réponses renvoyées par l'API sont affichées, à droite la réponse s'affiche sous forme d'array.
// Dans cet exemple, pour récupérer tous les films Ghibli, vous voyez qu’il vous suffit de faire une requête GET sur 'https://ghibliapi.herokuapp.com/films'.
// Vous avez aussi une indication sur les messages d’erreur que renvoie l’API en cas de mauvais format de la requête (400) ou d’absence de ressources trouvées (404).
// Vous voyez aussi qu’en cas de succès, vous obtiendrez une réponse sous forme d’un array (ou tableau) qui contiendra la liste des films Ghibli.
// Un exemple de cette donnée se trouve sur la droite dans l’encadré.
// Chaque fois que vous voulez utiliser une API, commencez par consulter la documentation.
// -----------
//  - En résumé :
//      --> CRUD signifie create (créer), read (lire), update (mettre à jour) et delete (supprimer).
//      --> GET est le verbe HTTP pour obtenir des données, et il est généralement utilisé avec un ID pour obtenir une donnée spécifique.
//      --> Les applications utilisent GET pour présenter des informations sur des pages web.
//      --> Utilisez Postman pour tester les API.
//      --> La documentation est le manuel d’utilisation d’une API.
//      --> La documentation vous permet de trouver la liste des endpoints accompagnée du verbe HTTP correspondant.
// Que ce soit à des fins personnelles ou professionnelles, utiliser une API c’est utiliser des données.
// Ces données sont parfois sensibles et il est important de les sécuriser.
// Abordons à présent un élément que je considère comme ultra important : la sécurité des données et l’authentification.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Authentifiez une API pour plus de sécurité ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Comprenez l’importance de l’authentification pour une API :
// Avant d’aborder d’autres verbes HTTP, il est important que nous parlions davantage de l’authentification.
// L’authentification constitue simplement un moyen pour les API de garantir que le client a les autorisations nécessaires pour accéder aux données et les manipuler.
// Si je crée une API, je ne veux pas que n’importe qui puisse changer le mot de passe de n’importe quel utilisateur, n’est-ce pas ?
// Lorsque nous avions fait notre requête GET avec l’API GitHub, nous n’avions pas besoin d’authentification pour obtenir des données utilisateurs.
// Pourquoi ? Rappelez-vous : il existe des API privées et des API publiques !
//      --> Ah, GitHub est une API publique !
// Oui et non. GitHub est une API qui possède une partie publique qui vous permet de faire des requêtes sans autorisation, comme nous l’avons fait dans le chapitre précédent.
// Cependant, toute l’application n’est pas publique. Une partie des endpoints nécessite une authentification, afin d’avoir les autorisations nécessaires pour mettre à jour des données.
// Si vous voulez modifier, ajouter ou supprimer des données, GitHub doit vous donner l’autorisation de le faire.
// Vous ne voulez pas que n’importe qui puisse remplacer votre photo de profil par celle de Homer Simpson, duh !
// Donc, pour que ce soit possible, GitHub doit disposer d’un processus d’authentification.
// Une des méthodes d’authentification les plus utilisées consiste à exiger qu’un développeur s’inscrive par le site web de l’API pour obtenir un token ou clé.
// Une fois le token obtenu, le développeur l’utilise dans sa requête pour s’identifier, et voilà.
// Eh bien, en quelque sorte ! Un token est généralement une chaîne longue et unique de lettres et de chiffres aléatoires que l’on assigne à un utilisateur.
// Le token est un peu comme un numéro de passeport : il est unique et permet de vous identifier.
// L’API peut donc l’utiliser pour savoir qui effectue la requête, et surtout de quel niveau d’autorisation cette personne dispose.
// Les autorisations peuvent décrire des accès spécifiques à certaines fonctionnalités, comme le nombre de requêtes que l’on peut envoyer.
// Mais aussi quelles actions on peut effectuer (si on est un administrateur ou non, par exemple)...
// La documentation de l’API se doit de fournir toutes les informations sur les fonctionnalités accessibles à travers un token d’authentification.
//      --> Comment ajouter le token à la requête ?
//              --> On l’envoie soit dans les paramètres du header, soit dans l’endpoint lui-même.
// Pour illustrer ce qu’on vient de voir, nous allons regarder ensemble comment obtenir un token GitHub pas à pas !
//      - Pour commencer, allez sur ce lien : https://github.com/settings/tokens.
//          Vous êtes à présent sur la partie qui vous permet de demander à GitHub de vous donner un token afin de pouvoir effectuer des opérations via l’API GitHub.
//      - Cliquez sur Generate new token.
//          Page GitHub pour générer un token : Les éléments Note, repo et delete_repo sont encadrés en vert.
//          Dans notre cas, nous voulons que GitHub nous donne l’autorisation pour deux choses :
//              - Effectuer des actions sur les repositories GitHub.
//                  Un repo (repository, ou répertoire) est un espace de stockage pour le code dans GitHub.
//                  Si vous voulez en savoir plus à ce sujet, consultez ce chapitre du cours Gérez du code avec Git et GitHub.
//          Suivez l’exemple ci-dessus et n’oubliez pas d’inscrire dans la section Note une information qui vous permettra plus tard de vous souvenir à quoi servait ce token.
//          Cela peut être le nom d’une application, de votre API, etc. Dans mon cas, j’ai indiqué OpenClassrooms.
//      - Cliquez ensuite sur Generate token (générer un token), et tada !
//          Le ruban de génération de token est affiché au milieu.
//          Votre token sera visible à l’emplacement du marqueur noir. J’ai choisi de masquer le mien.
//          Un token est personnel et privé autant que votre code de carte bleue, alors gardez-le pour vous !
//          L’encadré bleu explique qu'il faut copier votre token personnel car vous ne serez plus en mesure de le voir.
//          Gardez-le précieusement et copiez-le, ou faites une capture d’écran afin de ne pas le perdre. Nous allons l’utiliser dans les chapitres suivants !
//      - Après avoir copié soigneusement votre token, rechargez la page.
//          Vous devriez voir apparaître comme ci-dessus votre nouveau token par le nom que vous lui avez attribué, dans mon cas : Open Classrooms.
//          Vous verrez aussi les actions qu’il vous permet de faire sur l’API GitHub ; dans notre cas, les deux que nous avons séléctionnés : 'delete_repo' et 'repo'.
// Nous avons vu ensemble comment utiliser des API. Sauf que les API peuvent être créées par des entreprises, des services, ou des développeurs indépendants.
// Comment être certain qu’elles sont fiables ?
// -----------
//  - Privilégiez la sécurité : choisissez vos API avec discernement :
// Comme vous l’avez appris précédemment, il existe des milliers d’API différentes que vous pouvez utiliser dans vos projets.
// Comme toujours, il est important de garder en tête la sécurité de vos données et de votre application.
// En tant que développeur, vous êtes responsable de la sécurité des données de vos utilisateurs !
//      --> Vous devez vous assurer que vos API proviennent d’une source fiable.
// Mais comment faire ? Comment puis-je savoir si une API est fiable ou non ?
// Il existe quelques méthodes simples et rapides pour vérifier si une API est fiable ou non.
// Les API de qualité auront plusieurs mesures de sécurité comme l’authentification, l’autorisation et le cryptage.
// Elles auront aussi été mises à jour récemment; vous saurez donc qu’elles sont mises à jour en fonction des derniers standards de sécurité.
// Prenons un exemple ! Sur GitHub, vous trouverez l’API Pokémon nommée PokeApi qui a été mise à jour récemment.
// Un exemple d’une API mise à jour récemment #PokeApi est affiché et encadré en vert.
// Vous pouvez constater sur leur GitHub que la date de leur dernier commit est assez récente, vous savez donc que cette API est maintenue et mise à jour.
// Avant chaque utilisation d’une API externe, vérifiez la date de la dernière mise à jour sur GitHub ou bien sur son site Internet.
// Lisez la documentation et si vous avez des doutes (ou non), regardez en ligne des avis ou posez simplement la question à un autre développeur.
// -----------
//  - En résumé :
//      --> Pour obtenir un token d’authentification GitHub, vous pouvez :
//              --> Aller sur https://github.com/settings/developers et cliquer sur Personal Access Tokens (tokens d’accès personnel).
//              --> Cliquer sur Generate new token (générer nouveau token) et saisir « Open Classrooms » dans les notes.
//              --> Vous verrez alors toutes les différentes options d’autorisation dont vous voulez doter votre API.
//              --> Choisissez toutes celles que vous voulez tester. Nous avons utilisé Repo et Delete (supprimer).
//              --> Cliquez sur Generate token (générer token) et obtenez votre token API personnel.
//              --> ssurez-vous de copier et sauvegarder ce token, car nous l’utiliserons par la suite.
//      --> L’authentification est nécessaire pour garantir que seules les personnes avec les autorisations adéquates peuvent accéder à votre API.
//      --> Les clés ou tokens API sont couramment utilisés dans une requête pour authentifier un utilisateur.
//      --> Assurez-vous de bien vérifier la fiabilité d’une API avant de l’utiliser.
//      --> Vous pouvez trouver les indications de mise à jour d’une API sur GitHub ou sur son site Internet.
// GET n’a plus de secret pour vous, vous avez créé votre compte GitHub et obtenu votre premier token. Il est temps de passer à la vitesse supérieure et de jouer avec l’API GitHub !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Entraînez-vous avec l’API GitHub //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Manipulez des données avec l’API GitHub :
// On avance, on avance ! Maintenant que vous avez un token d’authentification, vous pouvez utiliser l’API pour mettre à jour votre profil GitHub !
// Dans ce chapitre, nous allons pratiquer et utiliser le reste des opérations CRUD – Create (créer), Update (mettre à jour) et Delete (supprimer).
// Avec leurs verbes HTTP équivalents – POST (publier), PUT (mettre) et DELETE (supprimer).
// Je vous invite vivement à suivre pas à pas les étapes suivantes et à pratiquer afin de maximiser votre apprentissage.
// -----------
//  - Créez un repo GitHub avec la méthode POST :
// Pour créer quelque chose de nouveau, ou une nouvelle ressource, on utilise le verbe HTTP POST (publier).
// Qu’il s’agisse d’un nouveau tweet, d’une nouvelle photo ou d’une nouvelle publication.
// Par exemple, dès que vous remplissez un formulaire en ligne ou que vous en utilisez un pour vous inscrire et vous créer un nouveau compte, le verbe associé par défaut est POST.
//      --> Comment l’API sait-elle ce qu’on essaie de créer quelque chose ?
// C’est là qu’intervient le body ! Vous vous souvenez ? On l’a vu dans les chapitres précédents.
//      --> Le body accompagne les requêtes POST et PUT pour contenir des informations supplémentaires.
// Vous pouvez intégrer les données que vous voulez créer dans le body de votre requête en utilisant du JSON.
// On veut créer un nouveau repo sur GitHub pour notre API. Super, mais comment faire ? 1re étape : la documentation !
//      --> Regardons ce que nous dit la documentation GitHub au sujet des repositories : 'https://developer.github.com/v3/repos'.
// Houlà, on a beaucoup de choix ! Nous, ce qu’on veut, c’est créer un nouveau repo.
// Cliquez en bas à droite sur Create a repository for the authenticated user.
// Dans le premier encadré en vert, on peut lire "Crée un nouveau repository pour un utilisateur authentifié".
// Pour créer un nouveau repository, il faut faire une requête POST vers /user/repos.
// Parfait, on avance ! Maintenant, scrollez un peu et vous tomberez sur les paramètres.
// L’encadré vert vous montre que le paramètre name est obligatoire.
// Mais ce n’est pas tout ! La documentation nous donne un exemple de requête et de réponse réussies.
// Une réponse réussie est affichée et entourée en vert.
// Nous avons notre endpoint, notre verbe http, nos paramètres et même un exemple ! Allons faire cette requête. Lancez Postman !
// Sélectionnez POST dans le menu déroulant puis tapez l’endpoint pour créer un nouveau repo via l’API GitHub : 'https://api.github.com/user/repos' et appuyez sur Send.
// Un message d'erreur est affiché et encadrée en vert. Arf, mais on a une erreur. Qu’est-ce que c’est ?
// Le message nous indique qu’une authentification est nécessaire.
//      --> Le code de réponse HTTP est 401 : Unauthorized (401 Non autorisé). Eh oui, notre token !
// Reprenez votre token d’authentification API GitHub, celui que vous avez précieusement gardé
//  Ajoutez-le, comme sur l’image suivante, dans l’onglet Headers sous forme de clé-valeur où la clé sera Authorization et la valeur sera Token, votre token.
// Si mon token est abcde, alors la valeur sera : token abcde.
// Ensuite, appuyez sur Send et regardez la réponse.
// Encore une erreur ?! Mmmh... on a le bon endpoint, le token. Cette fois-ci, le code de réponse HTTP est : 400 Bad Request.
// Mais oui ! Il nous manque les paramètres. Eh oui, on demande à GitHub de nous créer un repo, mais on ne lui donne pas les informations.
//      --> Cliquez sur la section Body, puis sur Raw, binary et sélectionnez JSON.
// Interface affichée depuis l'onglet Body. JSON est affiché et encadré dans une liste déroulante.
// Maintenant, on peut ajouter nos paramètres sous forme de clé-valeur. Il nous faut un nom de repo qui est obligatoire, et ajoutons une description.
// {
//    "name": "OpenClassrooms API",
//    "description": "Nouveau repo !"
// }
// Appuyez sur Send et observez la réponse.
// Notre repository a été créé. Le code de réponse HTTP est bien 201 Created.
// L’API nous renvoie les informations du nouveau repo crée. On peut aussi vérifier sur GitHub si le repo apparaît bien dans notre liste, et c’est le cas !
// Pour créer un repo GitHub en utilisant l’API GitHub, nous avons :
//      --> Consulté la documentation GitHub pour trouver l'endpoint adapté : POST user/repos.
//      --> Ajouté notre token d’authentification à nos paramètres dans le header avec Postman.
//      --> Ajouté les détails de notre repo à notre body en JSON avec Postman.
//      --> Vu qu’une fois que nous avons effectué une requête réussie avec notre API, le repo est apparu sur l’UI de notre profil GitHub !
// Et voilà ! Vous avez un nouveau repo ! Et si maintenant on essayait de le modifier avec l’API GitHub ?
// -----------
//  - Mettez à jour un repo GitHub avec les méthodes PUT/PATCH :
// Vous avez créé votre repo GitHub, mais la description ne vous plaît plus trop, vous changez d’avis et vous voulez la modifier !
// Vous pouvez utiliser PUT pour mettre à jour une ressource déjà existante dans votre API.
// Sur Internet, on croise souvent PUT avec PATCH ? Les deux signifient la même chose ou est-ce qu’ils sont différents ?
//      --> PUT : met à jour la ressource complète (c’est-à-dire, remplace tout).
//      --> PATCH : met à jour uniquement la partie de la ressource qui a été envoyée.
// On ne va pas s’attarder ici sur la différence entre les deux. Mais si vous ne savez pas lequel utiliser et pour quelle situation : consultez la documentation de l’API !
// Et c’est ce que nous allons faire ! Reprenons la documentation des repos GitHub mais cette fois-ci cliquons sur Update a repository.
//      --> Pour mettre à jour un repo, il nous faut utiliser la méthode PATCH sur l’endpoint /repos/:Owner/:repo.
// Les deux points ':' devant owner et repo signifient qu’il nous faut l’identifiant unique du repository que vous voulez modifier, et celui du owner du repo : vous, en l'occurrence.
// Changez le verbe par PATCH. Puis entrez l’endpoint correspondant. Mon username est Kadaaran et mon repo se nomme OpenClassrooms-API.
// Changez Kadaaran par votre username et OpenClassrooms-API par votre nom de repo s’il est différent.
// Dans la section Body, tapez une nouvelle description. Dans mon cas, j’ai mis : Paragraphe ci-dessus à revoir.
// {
//    "description": "Ceci est une nouvelle description plus cool que la précédente."
// }
// Appuyez sur Send et regardez la réponse.
// Notre repo a été mis à jour ! Nous obtenons la réponse avec le body : le code de réponse HTTP est bien 200 OK.
// Vous pouvez vérifier sur GitHub et vous devriez voir votre nouvelle description apparaître.
// Pour mettre à jour un repo GitHub, nous avons :
//      --> Vérifié la documentation GitHub pour l’URI approprié : PATCH /repos/wner/:repo.
//      --> Utilisé Postman, changé notre verbe HTTP en PATCH, et saisi le propriétaire et le nom de repository que nous voulons modifier, ainsi que changé la description dans le body.
//      --> Vu la nouvelle description de notre repository dans notre UI GitHub.
// Bravo ! Vous avez créé un repo, puis vous l’avez modifié. Essayons à présent de le supprimer !
// -----------
//  - Supprimez votre repo GitHub avec la méthode DELETE :
// Vous décidez à présent que vous n’avez pas réellement besoin de votre repo GitHub – alors allez-y et supprimez-le avec DELETE !
// Allez hop ! On reprend la même gymnastique que pour les requêtes précédentes.
//      --> Tout d’abord : la documentation ! Comment supprime-t-on un repository GitHub ?
// Dans la liste des méthodes disponibles, nous trouvons : Delete a repository. Cliquez dessus !
// Selon la documentation, pour supprimer un repository GitHub, il nous faut utiliser le verbe DELETE sur l’endpoint /repos/Owner/:repo.
// Si la requête est un succès, alors nous devrions avoir 204 No Content (204 Aucun contenu) comme réponse. Essayons avec Postman.
// Tapez les informations nécessaires : votre username et le nom du repo que vous souhaitez supprimer.
// Pas besoin de body pour DELETE, cliquez sur none. Puis cliquez sur Send et regardez la réponse obtenue.
// Le repo est supprimé : status : 204 no content est encadré en vert.
// Et voilà ! Votre repository est supprimé à tout jamais ! Nous obtenons un body vide et un statut 204 No Content comme l’a indiqué la documentation.
// Vous avez vu comment fonctionnent POST, PUT et DELETE et vous les avez vous-même utilisés avec l’API GitHub et Postman. Félicitations !
// Vous les avez utilisés dans le contexte d’un repo GitHub, mais vous pouvez utiliser ces verbes HTTP pour tout type de fonctionnalité, en fonction de l’API.
// Vous avez vu dans la documentation GitHub que l’URI correct est le même que pour Update, mais avec un nouveau verbe HTTP : DELETE /repos/:Owner/:repo.
// Vous avez vu que notre repo est supprimé et ne se trouve plus dans notre UI GitHub !
// -----------
//  - En résumé :
//      --> Vous pouvez utiliser POST pour créer des ressources.
//      --> PUT ou PATCH vous permet de mettre à jour des ressources.
//      --> DELETE vous permet de supprimer des ressources !
// Dans la prochaine partie, nous allons étudier les meilleures pratiques lorsque vous concevez vous-même une API  ! Mais avant, il est temps de réviser ce que vous venez d’apprendre avec le quiz de fin de partie !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Concevez des API REST /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définissez la structure de votre API REST /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Définir les fonctionnalités :
//      - Quels types d'endpoints.
//      - Quelles ressources.
// -----------
//  - Préparez-vous à concevoir votre propre API REST :
// Maintenant que vous avez vu comment utiliser une API externe, parlons davantage de quand et comment construire concrètement une API REST vous-même.
// Pourquoi aurais-je besoin de construire ma propre API REST ?
// Je ne peux pas utiliser l’une de ces milliers d’API qui existent et dont tu nous as parlé dans la dernière partie ?
// Il existe deux raisons principales pour lesquelles vous pourriez vouloir développer votre propre API :
//      --> Si vous construisez votre propre application web ou mobile, par exemple pour des recettes de cuisine, où vous savez que vous devrez sauvegarder et manipuler beaucoup de données.
//              Vous auriez absolument besoin d’une base de données, mais il n’est pas souhaitable que les développeurs front-end aient besoin de connaître SQL pour afficher les informations sur votre UI.
//              Vous voulez aussi respecter les normes pour les applications web pour qu’il y ait une couche API entre votre base de données et l’accès à vos données.
//              Vous ne voulez pas que n’importe quel développeur soit en capacité d’accéder directement à votre base de données, pour des questions de sécurité et de confidentialité.
//              Et vous voulez une manière rapide et efficace de rechercher et requêter les données existantes. Pour ce faire, vous aurez besoin d’une API interne.
//      --> Si vous construisez une application web ou mobile où vous voulez que d’autres développeurs soient en capacité d’interagir avec vos données.
//              Par exemple, imaginez une application où vous collectez des données sur les personnages de votre série télé favorite.
//              Vous voulez que d’autres développeurs puissent ajouter et utiliser des données.
// UI signifie User Interface ou interface utilisateur en français.
// Le terme UI fait référence à l’interface utilisateur par le biais de laquelle l’utilisateur interagit, que ce soit un site internet, un logiciel ou une application mobile.
// -----------
//  - Lancez-vous dans la conception de votre API :
// Comme pour toute chose un peu compliquée, un design réfléchi et structuré est essentiel pour obtenir un succès sur le long terme.
// Vous devez réfléchir aux concepts de design-clés qui rendront votre API plus agréable d’utilisation et plus facile à scaler.
// Scaler vient de l’anglais to scale et signifie en quelques mots la capacité de votre 'application/logiciel/site' internet à s’adapter et à fonctionner.
// Et ce, même en cas de forte augmentation soudaine du trafic, de demandes ou juste d’un grand nombre de fonctionnalités implémentées.
// Ok allons-y. Par quoi commence-t-on ?
// Allons-y étape par étape. Commencez d'abord par vous poser des questions sur les fonctionnalités importantes dont vous avez besoin pour votre API :
//      - De quel type d’endpoints avez-vous besoin ?
//      - Quelles ressources devez-vous créer ?
//      - De quelles ressources avez-vous besoin pour y effectuer les opérations CRUD ?
//      - Avez-vous besoin des quatre opérations CRUD pour chaque ressource ? Ou seulement d’une ou deux ?
// Une fois que vous aurez répondu à ces questions, vous serez prêt à commencer à préparer … votre documentation.
// -----------
//  - Documentez toute la journée : découvrez pourquoi une documentation adaptée est essentielle :
// Attends, on n'est pas censé créer une API ? Pourquoi est-ce que la documentation arrive tout de suite, on peut la faire à la fin non ?
// Non, non, non ! Lors des chapitres précédents nous avons dû consulter la documentation GitHub afin de pouvoir utiliser l’API comme il se doit.
// Sans toutes les informations de la documentation, nous aurions eu du mal à avoir le bon endpoint ou savoir quels paramètres préciser.
// La documentation est une des partie les plus importantes des API ! Quand vous créez une API, vous devez également tenir compte des autres développeurs qui utilisent votre API.
// Cela implique d’avoir une bonne documentation pour qu’ils puissent facilement comprendre ce que votre API peut accomplir et comment l’utiliser.
// Comme vous l’avez vu avec la documentation GitHub, de nombreuses informations doivent être expliquées à votre utilisateur API. Elles incluent :
//      --> Les descriptions des ressources API.
//      --> Les URI et verbes HTTP disponibles ainsi que leur fonction.
//      --> Les paramètres (s’il y en a) qui doivent être donnés à l’endpoint.
//      --> Un exemple de requête.
//      --> Une réponse typique pour la requête donnée.
// Chaque API organise la documentation de manière légèrement différente, mais voici quelques bons exemples pour vous aider.
//      - Documentation de l’API Stripe :
//          Dans l’API de Stripe vous pouvez clairement voir que la documentation décrit l’URL de la ressource et les informations pertinentes que les développeurs doivent pouvoir comprendre.
//          La documentation montre également un exemple de réponse aux requêtes API.
//      - Documentation de l’API Pinterest :
//          L’API Pinterest contient un bon exemple d’affichage d’un verbe HTTP, d’un URI, de paramètres, et d’une description de la fonction de l’endpoint.
//          Documentation de l’API Pinterest : tableau en 3 colonnes Definition, Parameters et Description.
//          La documentation donne de nombreuses informations sur les endpoints et les requêtes, mais elle se doit aussi de documenter la gestion des erreurs.
// -----------
//  - Gérez les erreurs :
// Comme nous l’avons vu dans les chapitres précédents, une requête peut être un succès mais aussi un échec, et ce pour diverses raisons : ressource introuvable, serveur indisponible...
// Votre API doit avoir une bonne gestion des erreurs.
// Si un développeur essaye accidentellement d’utiliser votre API pour un usage non souhaité, votre API doit être capable de dire à l’utilisateur quelle a été son erreur pour qu’il puisse la corriger.
// Et oui, personne n’est à l’abri d’une faute de frappe ! Le code HTTP donne une information sur le type d’erreur mais est généralement accompagné d’un message d’erreur dans le body de réponse.
// Vous avez vu à quoi ressemblaient certaines erreurs dans l’API GitHub lorsque nous avons voulu créer un repository dans la dernière partie.
// Souvenez-vous, quand nous avons essayé d’effectuer une requête sans notre token d’authentification, nous avons reçu la réponse suivante :
//                  {
//                      "message": "Requires authentication",
//                      "documentation_url": "https://developer.github.com/v3/repos/#edit"
//                  }
// C’est ainsi que grâce au message d’erreur nous avons su que nous avions oublié notre code d’authentification !
// Il existe de nombreux types d’erreurs différents pouvant se produire dans votre API qui, si elles sont gérées correctement, peuvent faciliter la vie des développeurs lorsqu’ils utilisent votre API.
// L’API de Meetup contient un bon exemple de toutes les erreurs différentes qui peuvent se produire quand vous utilisez leur API et ce qu’elles signifient :
// Toutes les erreurs possibles de l’API Meetup :
//      announce_error                          Erreur dans l’annonce d’un événement
//      description_error                       Désolé, votre description Meetup est trop longue
//      duration_error                          La durée de cet événement n’est pas valide.
//      event_error                             L’ID fourni ne correspond pas à un évènement pouvant être modifié
//      event_hosts_error                       Un ou plusieurs des membres donnés ne sont pas des membres actifs de ce groupe
//      featured_photo_id_error                 Il y a un problème avec la photo fournie.
//      fee.amount_error                        Si le groupe se trouve aux États-Unis, le montant à acquitter ne peut pas excéder 4999. Sinon, il ne peut pas excéder 1 000 000.
//      fee.refund_policy_error                 La politique de remboursement de fonds ne peut pas excéder 250.
//      guest_limit_error                       Le nombre d’invités maximum n’est pas valide.
//      how_to_find_us_error                    Votre description « Comment nous retrouver » est trop longue.
// Une partie nécessaire et importante lors de la conception de votre API est la réflexion sur les possibilités de mauvaise utilisation par les utilisateurs !
// Ainsi en fonction de l’erreur, vous pouvez renvoyer le message approprié dans la réponse.
// -----------
// En résumé :
//      --> Vous pouvez construire une API soit pour l’utiliser dans votre propre application, soit pour que d’autres développeurs puissent interagir avec vos données.
//      --> Il est important en concevant une API de penser à toutes les fonctionnalités nécessaires avant de commencer à la développer.
//      --> La documentation et une bonne gestion des erreurs sont importantes pour que d’autres développeurs puissent comprendre votre API.
// Maintenant que vous avez les bases, concevez les endpoints de votre API. OK, mais comment faire ? Voyons cela ensemble dans le chapitre suivant.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Concevez les endpoints de votre API ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Lors de la création d’une API, il est important de ne pas se lancer tête baissée et de réfléchir à l’architecture de votre API, quitte à tout poser sur papier avant.
// Quel sera le rôle de votre API ? Quelles seront les ressources ? Quels seront les différents accès autorisés pour les utilisateurs ?
// Bien structurer votre API dès le début de sa conception vous permettra d’anticiper les erreurs mais aussi d’avoir une API plus solide et mieux conçue.
// Dans ce chapitre, vous ne coderez pas une API mais allez la concevoir. C’est un exercice de réflexion, afin de vous préparer au mieux à la création d’une API.
// -----------
//  - Concevez une API de partage de photos :
// Dans cette partie, nous allons réfléchir à la manière de concevoir une API pour une application de partage de photos nommée InstaPhoto.
// Nous voulons que les utilisateurs puissent publier et partager des photos avec leurs amis, commenter les photos des autres, créer des hashtags, rechercher des photos par localisation...
// Prenez une minute pour écrire ce à quoi vous avez besoin de réfléchir lors de la conception d’une API pour InstaPhoto.
// De quelles ressources avez-vous besoin ? Quels URI seraient compréhensibles par d’autres développeurs ?
// C’est aussi une belle occasion de revoir ce que vous avez appris dans les parties précédentes !
// Voici quelques exemples de ressources dont vous aurez absolument besoin :
//      - Photo.
//      - User.
//      - Location.
//      - Post.
// À partir de là, vous pouvez commencer à réfléchir à des questions importantes, comme celles-ci :
//      --> Quels endpoints auront besoin d’autorisations ?
//      --> Quelles ressources voulez-vous pouvoir mettre à jour ?
//      --> Aurez-vous besoin de pouvoir modifier des publications après leur création ?
//      --> Les commentaires doivent-ils pouvoir être supprimés ?
//      --> Avez-vous besoin de toutes les opérations CRUD pour chaque ressource ? Ou seulement d’une ou deux ? Lesquelles ?
// Il n’y a pas de bonne ou de mauvaise réponse ici, cela dépend simplement de l’application InstaPhoto que vous voulez développer !
// -----------
//  - Créez vos endpoints :
// Lors de la conception d’endpoints, le naming est un élément clé. Vous voulez que les développeurs qui l’utilisent comprennent naturellement ce que chaque endpoint est censé faire.
// Les conventions de naming actuelles demandent d’inclure uniquement la ressource que vous voulez mettre à jour, et non le verbe que vous voulez mettre en œuvre.
// Pour faire simple, utilisez uniquement le nom de la ressource dans l’URI, car l’action se trouve déjà dans le verbe HTTP. Cela donnerait :
//      - POST /photo.
//      - PUT /photo.
//      - GET /photo.
// Puisque que le verbe de l’action est déjà inclus dans la requête HTTP, il n’est pas nécessaire de le préciser lors de la conception des endpoints.
// Pour que vous puissiez mieux comprendre, des endpoints mal nommés ressembleraient à ceci :
//      - POST /createPhoto.
//      - PUT /updatePhoto.
//      - GET /getPhoto.
// -----------
//  - Simulez des endpoints supplémentaires :
// Considérons les endpoints possibles pour notre InstaPhoto.
// Ici aussi, il n’y a pas de bonne ou de mauvaise réponse, cela dépend simplement des besoins de votre application et de la façon dont vous voulez la concevoir.
// Imaginons que vous vouliez que les utilisateurs soient en capacité de créer, voir et supprimer des photos, mais pas de les modifier une fois publiées.
// Tous ces éléments nécessitent également une authentification, car vous ne voudriez pas que les utilisateurs puissent publier, modifier ou supprimer des photos qui ne leur appartiennent pas !
// Maintenant, prenez une feuille de papier et écrivez quelques endpoints pour créer, voir et supprimer des photos.
// Rappelez-vous que vous voudrez peut-être spécifier une photo en particulier à visionner et à mettre à jour, non ?
// Une fois que vous aurez fini, regardez juste en-dessous si ce que vous avez écrit correspond à mes réponses.
// Alors, curieux de connaître mes réponses :
//      --> POST /photos.
//      --> GET /photos/{photo_id}.
//      --> DELETE /photos/{photoId}.
// Vu que l’on veut généralement voir ou supprimer des photos en particulier, le fait d’ajouter un ID pour les deux derniers endpoints est logique.
// Il permet à l’API de savoir de quelle photo il s’agit.
// Et maintenant, vos utilisateurs ! De quels verbes HTTP aurez-vous besoin pour un compte utilisateur ?
// Et puis, même si vous ne voulez pas que les utilisateurs puissent modifier leurs photos une fois qu’elles sont déjà créées, il doivent au moins pouvoir modifier leur profil utilisateur !
// Par ailleurs, vous voulez qu’ils puissent voir les informations disponibles publiquement sur un utilisateur sans authentification (exactement comme l’API GitHub).
// Donc pour cet endpoint, vous n’aurez pas besoin d’authentification. Quelles sortes d’endpoint pourriez-vous concevoir pour cela ?
//      --> POST /users.
//      --> GET /users/{userId}.
//      --> PUT /users/{userId}.
//      --> DELETE /users/{userId}.
// Et maintenant, les commentaires  ! Comment les ajouter ?
// Si vous voulez que les utilisateurs puissent commenter les photos d’un autre utilisateur, il vous faudra imbriquer une ressource dans une autre.
// Et ce, parce qu’un commentaire doit être associé à une photo spécifique.
// Par exemple, imaginons que vous vouliez créer un nouveau commentaire pour une photo avec ID.
// Vous pourriez créer l’endpoint POST /photos/{photoId}/comments. Utilisez POST parce que vous créez quelque chose.
// Ensuite, travaillez en arrière : créez un commentaire (/comments) pour une photo spécifique (/{photoId}) parmi toutes les autres photos (/photos).
// Et maintenant, voici une description de trois endpoints supplémentaires que vous devrez créer :
//      - Obtenir tous les commentaires pour une photo spécifique avec l’ID {photoId}.
//      - Obtenir le commentaire avec l’ID {commentId} pour la photo avec l’ID {photoId}.
//      - Supprimer le commentaire avec l’ID {commentId} pour la photo avec l’ID {photoId}.
// Vous ne voulez pas que les commentaires soient modifiables, n’incluez donc pas d’endpoint pour cela. Essayez d’écrire les endpoints pour ces trois éléments.
//      --> POST /photos/{photoId}/comments Créer un nouveau commentaire pour la photo avec l’ID {photoId}.
//      --> GET /photos/{photoId}/comments Obtenir tous les commentaires pour une photo spécifique avec l’ID {photoId}.
//      --> GET /photos/{photoId}/comments/{commentId} Obtenir le commentaire avec l’ID {commentId} de la photo avec l’ID {photoId}.
//      --> DELETE /photos/{photoId}/comments/{commentId} Supprimer le commentaire avec l’ID {commentId} de la photo avec l’ID {photoID}.
// Tous ces endpoints nécessitent une authentification, car ils doivent seulement être modifiables par l’utilisateur qui les a créés, et non les autres.
// Et vous pourriez adopter le même mode de raisonnement pour toutes les autres ressources dont vous aurez besoin.
//      --> Rappel : ici, nous avons seulement conçu les endpoints.
//              Les informations supplémentaires comme par exemple le contenu du commentaire, ou le nom de l’utilisateur que vous souhaitez modifier, seront contenus dans le body.
// -----------
//  - En résumé :
//      --> Lors de la planification, pensez à quelles opérations CRUD seront nécessaires aux ressources.
//      --> Utilisez des noms de ressources et non des verbes en nommant les endpoints.
//      --> Pensez aux ressources que vous devrez imbriquer dans d’autres ressources.
//      --> Pensez aux ressources qui nécessiteront une authentification.
// Vous avez la liste des opérations CRUD nécessaires, vos ressources et leur nom, les ressources complémentaires, celles qui nécessiteront une authentification, la liste de vos endpoints.
// Votre base est solide, mais vous pouvez approfondir le tout avec la recherche, par exemple.
// Dans le chapitre suivant, nous allons étoffer nos endpoints grâce à quelques fonctionnalités avancées !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez les fonctionnalités avancées des endpoints ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Jusqu’à présent, nous avons uniquement vu des endpoints basiques pour obtenir une liste de ressources ou une ressource unique par ID.
// Mais il existe tellement plus de possibilités avec les API  !
// Selon la manière dont vous concevez vos URI, vous pouvez créer des requêtes plus complexes comme la recherche, le classement, et plus encore.
// Nous reprendrons l’application InstaPhoto pour décider de quels types d’URI complexes vous aurez besoin.
// -----------
//  - Filtrez :
// Et si vous vouliez que vos utilisateurs puissent rechercher des photos pour des lieux particuliers ? Faites entrer les filtres !
//      --> Vous pourriez concevoir un endpoint comme celui-ci : 'GET /photos?location={locationId}'.
// Ce  '?' est nouveau ! Le point d’interrogation est un moyen pour l’API de savoir que vous passez un paramètre.
// Un paramètre est une donnée qui sera manipulée, utilisée d’une certaine manière par le client, le serveur ou le programme informatique visé : ici, l’API.
// Il vous permet de créer une requête qui peut changer selon le terme recherché.
// Dans ce cas, vous voulez que les utilisateurs puissent rechercher une location (ou un lieu) égale à 'locationId'.
// Ainsi, vous pouvez écrire tout ID de lieu dans le paramètre de requête, et vous pourrez voir des photos de ce lieu.
// Mais, ces valeurs n'étaient pas uniquement appelées endpoints quand elles contenaient le nom de domaine et l’URI !
// C’est une bonne remarque. Oui, les URI sont le chemin de la ressource, et un endpoint correspond au nom de domaine plus le chemin de la ressource.
// -----------
//  - Recherchez :
// La recherche vous permet de faire une requête sur une liste de ressources correspondant à votre requête de recherche.
// OK, alors admettons que vous vouliez avoir un endpoint où les utilisateurs peuvent rechercher toutes les photos qui ont un quelconque rapport avec le snowboard.
//      --> Votre endpoint pourrait être celui-ci : 'GET /photos?search=snowboard'.
// Si vous avez déjà utilisé la fonctionnalité de recherche sur Twitter, vous avez pu constater que leur API de recherche fonctionne de façon très similaire !
// Quelle est la différence entre le filtrage et la recherche, alors ?
// C’est une question courante, qui dépend de la façon dont on trouve un élément.
//      --> Pour filtrer, vous partez d’un élément plus petit et plus spécifique et vous collectez tous les items qui correspondent à cette valeur.
//              Par exemple : vous allez chercher toutes les séries comiques qui commencent par la lettre C. Dans ce cas, vous filtrez.
//      --> La recherche constitue une approche plus large et élargit votre périmètre à toute chose associée à une certaine valeur.
// -----------
//  - Triez :
// Disons que vous voulez que vos utilisateurs voient tous leurs followers par ordre alphabétique ascendant et par nom de famille.
// Ce qui est assez complexe. Vous pouvez créer un endpoint pour cela !
//      --> 'GET /users/{userId}/followers?sort=lastName&order=asc'.
// Le '&' est nouveau ici ! Il vous permet d’enchaîner différentes requêtes ensemble !
// Par exemple, vous pouvez trier les utilisateurs par 'lastName' (nom de famille) en ordre ascendant.
// Vous avez déjà vu un résultat trié quand vous naviguez sur le web.
// D’habitude, vous voulez voir les publications les plus récentes sur Twitter ou Instagram, ce qui constitue en fait un tri par date !
// Vous pouvez enchaîner tous types de requêtes différentes entre elles.
// Par exemple, si vous voulez voir tous les utilisateurs vérifiés avec le prénom (firstName) Jamie, vous pouvez faire la requête suivante :
//      --> 'GET /users?verified=true&firstName=Jamie'.
// Si vous voulez voir toutes les photos prises à New York qui ont été postées le soir du 31 décembre et qui ont plus de 5 000 likes, vous pouvez faire la requête suivante :
//      --> 'GET /photos?location=NYC&created_at=2018-12-31&likes_greater_than=5000'
// Pour que ces options fonctionnent, il vous faudra installer cette fonctionnalité en utilisant le langage de code que vous avez choisi pour l’application.
// En effet, aucun d’entre eux n’est intégré à une API lorsque vous la créez.
// Ici, nous avons juste simplement illustré quelques-uns des moyens possibles dont vous pouvez utiliser les requêtes avancées dans votre API.
// -----------
//  - Paginez vos résultats :
// InstaPhoto a décollé et rencontre un immense succès !
// Mais vous avez maintenant des milliers de photos dans votre base de données, ce qui a rendu vos endpoints /photos très lents, au grand dam de vos utilisateurs. Que faire ?
// Le moyen pour corriger cela se trouve dans ce qu’on appelle la pagination.
// Cela signifie que vos endpoints ne retournent qu’un nombre limité d’entrées par numéro de page dans votre réponse.
// Vous pouvez décider de combien d’items vous voulez sur chaque page, mais habituellement ce chiffre se situe entre 10 et 100.
// Pour faire plus simple, '/photos' renvoie toutes les photos de votre application. Au lieu d’avoir '/photos', vous devez donc préciser la page que vous voulez obtenir dans la requête :
//      --> 'GET /photos?page=23'.
// Ainsi, vous obtiendrez uniquement la 23e page de photos qui en contient, disons 100 par exemple, et non la totalité d’entre elles.
// Le temps de chargement sera réduit et votre utilisateur sera ravi !
// Pour voir les photos suivantes, on peut imaginer que votre utilisateur clique sur un bouton pour charger la suite. Et vous aurez donc :
//      --> 'GET /photos?page=24'.
// De la même façon, lorsque vous effectuez une recherche Google, il n’est pas rare d’obtenir des millions de résultats.
// Du coup, Google ne renvoie qu’une page des résultats les plus haut classés, et vous pouvez parcourir le reste pour en voir plus.
// Google a besoin de paginer ses résultats pour ne pas surcharger votre UI.
// La pagination permet aux utilisateurs de votre API de n’appeler qu’une page de résultats à la fois, pour que votre client ou votre UI ne soit pas débordé par les résultats !
// -----------
//  - Versionnez :
// Le dernier outil de design important pour les API est le versioning (ou versionnage).
// En donnant une version à vos API, vous pourrez facilement suivre les changements et vous assurer que votre application puisse être compatible pour les versions antérieures.
// Cela signifie que vous pouvez continuer à mettre à jour votre API, tout en garantissant que les utilisateurs dépendants d’une version plus ancienne puissent continuer à l’utiliser.
// Par exemple, si certains de vos clients utilisent déjà la version 1 de votre API, vous pouvez publier une version 2 de votre API.
// Alors, les utilisateurs de la version 1 de l’API peuvent continuer à l’utiliser jusqu’à ce qu’ils soient prêts à passer à la version 2.
// Les développeurs peuvent versionner leurs API de deux manières :
//      --> Ajoutez un champ version dans vos paramètres d’en-tête de requête : "accept-version": "1.3".
//      --> Ajoutez une version à votre URI : '/v1/'.
// L’approche la plus courante est d’ajouter un '/v1' au début de votre URI :
//      --> 'GET /v1/photos'.
// Les éléments ci-dessus sont des fonctionnalités basées sur le design et que vous devez prendre en compte pour le contenu de votre API, puisque vous devrez choisir votre langage ou framework.
// Nous aborderons ce sujet dans le dernier chapitre.
// -----------
//  - En résumé :
//      --> Le filtrage, la recherche et le tri sont des moyens d’ajouter de la complexité à vos requêtes API.
//      --> La pagination aide vos clients et utilisateurs API à éviter d’être submergés par trop de données.
//      --> Le versionnage vous permet de continuer à mettre à jour votre API sans casser le code des personnes qui en dépendent déjà.
// Vous venez de faire un sacré bout de chemin : vous avez construit votre première API et découvert les fonctionnalités avancées des endpoints.
// Mais qu’en est-il si vous souhaitez coder votre propre API ? Quels frameworks existent ? Quels langages utiliser ?
// Abordons cela rapidement dans le prochain et dernier chapitre de ce cours.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Choisissez des frameworks pour construire votre API ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tout au long de cette partie, nous avons seulement traité la théorie.
// Vous avez acquis des connaissances sur la conception d’endpoints, le filtrage, la recherche, le tri, la pagination et le versionnage.
//      --> Mais comment construire l’une de ces API vous-même ?
// Le processus de développement d’une API dépend du langage ou de l’outil de programmation utilisé.
// Nous avons vu les meilleures pratiques de développement pour que vous soyez préparé au mieux une fois que vous plongerez dans un langage.
// Voici quelques outils et frameworks populaires utilisés par les développeurs.
// -----------
//  - Express.js (JavaScript) :
// Express utilise Node.js et le JavaScript. C’est un framework minimal et rapide.
// Il est très flexible et gère des applications complètes aussi bien que des API REST.
// Le plus gros inconvénient est qu’il n’y a pas de manière définie de faire les choses, ce qui peut être difficile pour les débutants.
// -----------
//  - Ruby on Rails (Ruby) :
// Ruby on Rails est basé sur Ruby. C’est un framework populaire pour de nombreux développeurs.
// On le considère comme un framework magique, car derrière sa simplicité d’utilisation se cache une grande complexité.
// Cela aide les débutants à commencer dans le développement web plus facilement.
// De nombreuses librairies externes (appelées "Ruby gems") sont disponibles, et la communauté de développeurs Rails est très vaste et met en ligne de très nombreux tutoriels.
// La courbe d’apprentissage de Rails devient très ardue une fois que vous plongez plus profondément dans le framework (pour comprendre la magie qui opère derrière).
// -----------
//  - Django (Python) :
// Django est basé sur Python. Il est utilisé par de grands noms comme Google, YouTube et Instagram.
// Le framework REST de Django est facile à utiliser lorsque vous construisez vos API REST avec Django.
// Il demande un effort d’apprentissage aux débutants, mais possède d’excellentes fonctionnalités intégrées, comme l’authentification et la messagerie.
// -----------
//  - Flask (Python) :
// Flask utilise Python pour le web et le développement des API REST.
// C’est un framework minimaliste, facile d’apprentissage et d’utilisation.
// Flask comprend moins de fonctionnalités intégrées que Django, mais permet aux développeurs d’avoir davantage de choix dans les outils additionnels qu’ils utilisent.
// -----------
//  - Spring (Java) :
// Spring est un framework web qui utilise Java, un langage très populaire.
// Il est utilisé par des sites web tels que Wix, TicketMaster et BillGuard.
// Il possède de nombreux outils liés qui boostent sa performance et vous permettent de mettre facilement votre business à l’échelle, mais il peut être difficile à prendre en main au début.
// -----------
//  - AWS API Gateway :
// AWS API Gateway et AWS Lambda sont des moyens de créer et d’utiliser des API REST en utilisant principalement une interface utilisateur.
// Ils vous permettent d’intégrer facilement votre site web avec tous les services AWS, et vous pouvez aisément scaler et gérer plus de requêtes avec leur infrastructure.
// Vous devez payer par requête effectuée par utilisateur à vos serveurs, mais le premier million est gratuit.
// -----------
//  - En résumé :
//      --> Il existe de nombreux outils et frameworks que vous pouvez utiliser pour mettre en pratique ces concepts.
//      --> Assurez-vous de bien faire vos recherches avant de choisir quel outil API vous convient le mieux.
// Le choix de l’outil doit avant tout dépendre des besoins de votre application.
// Assurez-vous de faire les recherches nécessaires sur les frameworks et les librairies disponibles, pour choisir ce qui correspond à vos besoins.
// Une fois votre API construite et déployée sur le web, vous pouvez utiliser Postman comme nous l’avons fait dans l’ensemble de ce cours, pour la tester !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Construisez des microservices /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// L'architecture Microservices rencontre un essor fulgurant depuis quelques années.
// Des géants comme Amazon, Uber, Ebay, Groupon ou encore Netflix, ont remanié leurs applications et leurs systèmes d'information pour reposer sur cette architecture.
// Les applications qui en résultent sont d'une robustesse et d'une scalabilité sans précédent.
// La complexité de l'application s'en trouve divisée en petits problèmes, facilement abordables. La résilience de l'application s'en trouve ainsi décuplée.
// Dans ce premier cours sur l'architecture Microservices, vous allez commencer par vous familiariser avec les principes de base, et par acquérir une vue d'ensemble de cette architecture.
// Ensuite, vous allez apprendre à créer et à tester un Microservice en Java de A à Z.
// Pour cela, vous utiliserez des outils modernes comme Spring Boot et Spring Data JPA.
// Vous découvrirez comment exposer une API REST, traiter les différentes requêtes HTTP possibles, et générer les bons codes de réponse.
// Enfin, vous apprendrez à gérer les erreurs, tester votre Microservice et générer automatiquement une documentation en vue de sa publication.
// À la fin de ce cours, vous serez capable de :
//      --> Créer un Microservice.
//      --> Tester et améliorer un Microservice.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez un Microservice de A à Z ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Appréhendez l'architecture Microservices //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Définissez les problématiques et les besoins :
// L'utilisation d'applications gourmandes en ressources (streaming vidéo, banques, musique, e-commerce, etc.) est en plein essort.
// Les entreprises sont confrontées à des challenges liés à la performance de ces services, au coût de l'infrastructure technique et au coût du développement et de la maintenance.
//      - Problème n° 1 :
//          Comment faire en sorte que les applications proposées en ligne soient toujours disponibles et ne souffrent jamais de coupure ou de ralentissement.
//          Et ce, quelle que soit l'affluence des utilisateurs sur celles-ci ?
//          Prenons un exemple : si une entreprise a pour activité l'e-commerce de vêtements, comment peut-elle faire face à l'explosion du nombre d'utilisateurs se connectant sur son site ?
//          Et cela, à 8h du matin le premier jour des soldes ? Ajouter 200 serveurs pour supporter l'affluence pendant 2 heures ? Ce n'est pas réalisable, ou du moins c’est très coûteux.
//              --> Une solution est d'utiliser le cloud. Celui-ci permet d'augmenter et de diminuer le nombre de ressources nécessaires au fonctionnement d'une application à la demande.
//                      Cette solution paraît idéale, car il suffit à notre entreprise d'e-commerce d'augmenter les ressources à 8 heures du matin et de les diminuer à 10 h.
//                      Cela, sans avoir à acheter de nouveaux serveurs, à les installer et à les maintenir, pour finalement ne plus en avoir l'utilité lorsque l'affluence diminue.
//          Cependant, vous vous en doutez, il y a un problème : il faut que l'application soit conçue de façon à ce qu'elle puisse être scalable.
//          C'est-à-dire capable de s'étendre sur plus de ressources (plus de serveurs, de disques durs, de bases de données), tout en gardant une parfaite consistance dans ses données.
//          Ainsi qu'une cohérence dans son comportement. Or, l'application de cette entreprise, conçue sur une architecture plus classique (3-tiers, par exemple) est très difficilement scalable.
//          Il faut donc envisager, dès le départ, une autre approche dans la conception de l'application, afin que celle-ci soit "Cloud-native".
//          C'est-à-dire conçue pour fonctionner et profiter pleinement des avantages qu'offre le cloud.
//      - Problème n° 2 :
//          Les entreprises se livrent à une "guerre de la mise à jour".
//          Il faut que l'entreprise soit capable de faire évoluer son application de façon très fréquente, et de répondre rapidement aux nouvelles fonctionnalités que propose la concurrence.
//          Or, avec une application traditionnelle, le processus de mise à jour est long et compliqué car il faut mettre à jour toute l'application.
//          Il est ensuite nécessaire de retester et de déployer l'application complète.
//          Cela est dû à la forte interdépendance au sein d'une application.
//          Par exemple, celle-ci peut reposer sur une seule base de données qui regroupe les tables de tous ses composants.
//          Ces composants peuvent eux-mêmes être liés par des clés étrangères et des triggers, qu'on ne peut pas modifier à la légère.
//          Les entreprises sont donc obligées de passer à des architectures permettant de faire des mises à jour qui visent des composants ciblés, très rapidement et de façon fiable.
//          Et cela, sans se soucier des éventuelles conséquences sur le reste de l'application.
//      - Problème n° 3 :
//          Les technologies utilisées pour développer ces applications évoluent très vite, et les nouveautés offrent parfois des avantages énormes.
//          Comment les entreprises peuvent-elles s'adapter rapidement pour tirer profit de ces évolutions ?
//          Imaginez une entreprise qui permet de placer des transactions sur les marchés boursiers.
//          Nous parlons ici de millions d'opérations par seconde. Il faut donc être capable de vendre et acheter très vite, à la microseconde près, lorsque la fluctuation d'une action est favorable.
//          L'application de cette entreprise repose sur un algorithme puissant écrit en Java.
//          Un beau matin, si elle ne s'adapte pas, elle perdra des clients car elle sera dépassée par la concurrence.
//          Qui par exemple, mettra en oeuvre un algorithme très rapide en Node.js dans les semaines suivantes.
//          Pour éviter ce genre de situation, l'entreprise doit adopter une architecture qui lui permettra de passer d'une technologie à l'autre sur des portions individuelles de son application.
// À ces problèmes, il faut ajouter ceux liés à la sécurité, qui devient très compliquée à gérer dans les applications complexes.
// Ainsi que les difficultés liées à la coordination entre développeurs, et bien d'autres !
//      --> Il faut donc que les entreprises conçoivent leurs applications dès le départ à partir d'architectures répondant à ces besoins, et qui soient parfaitement adaptées au cloud.
//              C'est ainsi que l'architecture Microservices est apparue, apportant une réponse concrète à toutes ces préoccupations et la promesse d'obtenir des applications dites "Cloud-native".
// -----------
//  - Comprenez le principe de l'architecture Microservices :
// L'architecture Microservices propose une solution en principe simple :
//      --> Découper une application en petits services, appelés Microservices, parfaitement autonomes, qui exposent une API REST que les autres microservices pourront consommer.
// C'est un schéma simplifié d'une application basée sur l'architecture Microservices.
// Un schéma simplifié serait celui d'une application basée sur l'architecture Microservices :
// User Interface   --> REST --> Microservice A.
//                  --> REST --> Microservice B.
//                  --> REST --> Microsercice C.
// Cette application affiche par exemple un produit à vendre.
// Cette fiche produit est donc constituée par exemple d'une photo, d'un descriptif et d'un prix.
// Dans le schéma, l'interface utilisateur fait appel à un microservice pour chaque composant à renseigner.
// Ainsi, celle-ci peut faire une requête REST au microservice A, qui s'occupe de la gestion des photos des produits, afin d'obtenir celles correspondant au produit à afficher.
// De même, les microservices B et C s'occupent respectivement des descriptifs et des prix.
// Vous voyez alors, à travers cet exemple, quelle est l'idée générale de l'architecture Microservices.
// Dans une architecture traditionnelle, vous avez une application au format WAR qui comporte tous les composants.
// Lorsqu'un utilisateur demande une fiche de produit, l'application applique sa logique interne et va puiser dans une base de données, puis produit un HTML final.
// Dans l'exemple que je vous ai donné, l'interface utilisateur est elle-même un microservice qui a pour responsabilité d'appeler les autres microservices.
// Puis de rassembler donc cette "fiche produit" partie par partie avant de la servir à l'utilisateur final.
// Chaque microservice est parfaitement autonome : il a sa propre base de données, son propre serveur d'application (Tomcat, Jetty, etc.).
// Ainsi que ses propres librairies et ainsi de suite.
// La plupart du temps, ces microservices sont chacun dans un container Docker, ils sont donc totalement indépendants y compris vis-à-vis de la machine sur laquelle ils tournent.
// C'est le même schéma que le précédent mais avec le détail de ce que gère chaque microservice.
// Chaque mocroservice est autonomes : il a sa propre base de données, son serveur d'application et ses librairies notamment.
// Bien entendu, d'autres éléments viennent s'ajouter dans le cas d'une architecture Microservices réelle.
// Néanmoins, nous allons partir de ce cas simplifié, et nous allons l'enrichir au fur et à mesure de l'avancement du cours.
// -----------
//  - Répondez à ces problèmes avec l'architecture Microservices :
// Chacun des microservices dans notre schéma, comme je l'ai dit plus tôt, est parfaitement autonome.
// Ceci fait que notre application peut parfaitement profiter de tout ce que le Cloud peut offrir.
// Ainsi, on peut, par exemple, dupliquer le microservice A sur plusieurs serveurs.
// Le microservice qui s'occupe de l'interface utilisateur (UI) va appeler une des instances de ce service et recevoir la même réponse, quelle que soit l'instance choisie.
// Nous verrons plus tard qu'il existe d'autres microservices spécialisés dans le dispatching des requêtes vers les différentes instances.
// Finalement, notre application est parfaitement élastique : vous pouvez lui envoyer 5 utilisateurs ou 5 millions, il suffit d'augmenter ou de diminuer le nombre d'instances en service.
// Notons au passage que l'entreprise réalise des économies substantielles.
// En effet, là où une application classique tourne sur 10 serveurs en permanence, notre application en microservices peut tourner en bas régime sur très peu de ressources.
// Quand on voudra mettre à jour l'application, il suffira de cibler directement le microservice responsable de la fonctionnalité en question.
// Imaginons que nous disposons d'une nouvelle technologie de pricing qui permet de proposer des prix compétitifs en fonction de la concurrence en temps réel.
// Tout ce qu'il y a à faire est de modifier le microservice C et de le redéployer.
// À aucun moment vous n'aurez à vous soucier de l'ensemble de l'application ou de quelles répercussions vos changements pourraient avoir sur celle-ci.
// De cette manière, le processus de mise à jour est d'autant plus rapide que les microservices sont par nature petits et relativement simples.
// Le risque de bug ou d'indisponibilité de l'application devient très bas, car vous n'avez pas à builder votre application dans un grand WAR, puis à croiser les doigts.
// Encore une fois, du fait du cloisonnement complet de nos microservices, on peut utiliser dans chacun la technologie qu'on veut.
// Le microservice A peut être en Java alors que le B est en C++ ou Node.js, l'essentiel étant qu'il expose une API REST.
// Ceci offre un avantage énorme à l'entreprise, qui va pouvoir tirer profit des dernières avancées technologiques sans limite de langage, de framework ou d'environnement.
// Cerise sur le gâteau, les équipes de développement dans une entreprise deviennent beaucoup plus autonomes.
// En effet, il n'y a plus lieu de consulter toutes les équipes pour concrétiser une idée et vérifier sa compatibilité technique avec ce que font les autres.
// Les équipes vont pouvoir travailler de façon autonome et aller au bout de leurs projets, avec la technologie et les outils de leur choix. On a donc ici un gain de temps et d'innovation.
// -----------
//  - Faites la différence entre SOA et MSA :
// Si vous avez étudié le cours sur la SOA, vous avez certainement l'impression que l'architecture Microservices ressemble beaucoup, au premier abord, à la SOA.
//      --> Cependant, le diable est dans les détails.
// En effet, l'architecture Microservices (MSA) est une évolution de la SOA, dans laquelle les concepts de la SOA ont été repris et poussés à l'extrême.
// D'ailleurs, dans un service de l'architecture SOA, vous pouvez trouver des éléments typiques d'un microservice.
// Pour autant, cela n'en fait pas un microservice en bonne et due forme.
//      --> Quelles sont les différences entre SOA et MSA ?
// Les services dans l'architecture Microservices sont très spécialisés.
// Ils s'occupent d'une et d'une seule fonctionnalité, alors que dans la SOA, la pratique est de créer des services qui gèrent un domaine, par exemple un service de gestion des utilisateurs.
// Dans la MSA vous aurez plutôt un microservice de gestion des rôles des utilisateurs, un autre pour l'ajout / suppression / suspension des utilisateurs, etc.
// La taille des services dans une MSA est souvent beaucoup plus petite que dans une SOA.
// Dans la MSA, le couplage faible est primordial, à savoir que chaque microservice doit être très indépendant à tous les niveaux.
// Chaque microservice possède sa propre base de données, alors que dans une SOA, il est courant de trouver une base de données commune à plusieurs services.
// Théoriquement, ce n'est pas censé être le cas, mais la pratique est différente. Cela s'explique par le fait que la SOA a été utilisée comme une approche pour moderniser les anciens systèmes.
// Or, manipuler ou redesigner les bases de données est tellement délicat que, souvent, on se contente de les optimiser.
// Néanmoins, ne soyez pas surpris si vous rencontrez une MSA où il y a une base de données partagée.
// Une des pratiques consiste à avoir une base de données partagée mais avec, par exemple, des "schémas" différents qui garantissent une indépendance totale.
// Les résultats sont les mêmes, il y a une relation d'exclusivité entre le microservice et ses données, car le seul moyen d'accéder à celles-ci et de passer par ce microservice.
// La SOA vient souvent avec un grand ESB central qui s'occupe des messages et de leur transformation.
// Vous devinez bien que si l'ESB, qui relie tous ces services, est en panne, c'est tout le SI qui l'est aussi.
// Dans une MSA, on utilise un simple système très léger de messaging, qui n'est d'ailleurs pas toujours nécessaire.
// De plus, il est tout à fait possible d'appeler un microservice directement si ce système de messages ne fonctionne pas.
// En effet, il n'a pas de rôle de modification ou d'adaptation des messages, mais un simple rôle de gestion de leur queue et de dispatching.
// Les microservices se basent majoritairement sur l’architecture REST, mais peuvent fonctionner avec tout type d’architecture, comme SOAP (Simple Object Access Protocol).
// La SOA accepte que ses composants (services et autres) communiquent avec des protocoles différents, l'ESB s'occupant ensuite d'adapter et de transformer.
// La MSA tend à obliger à utiliser un seul protocole et à s'y tenir. On a bien sûr moins de liberté, mais l'architecture s'en trouve simplifiée tout en se débarrassant de l'ESB.
// Ces divergences engendrent des tendances différentes dans l'utilisation de certaines technologies, renforçant, de fait, le fossé entre les 2 architectures.
// Par exemple, l'utilisation de Docker est très courante dans la MSA, alors qu'elle est anecdotique dans la SOA.
// Il en est de même pour l'utilisation des PaaS (Platform as a Service) qui offrent d'énormes avantages, et qui sont là aussi très peu utilisés dans la SOA.
// -----------
//  - En résumé :
//      --> Les microservices permettent de rendre une application scalable pour s’adapter au nombre d’utilisateurs.
//      --> Les microservices se basent sur un couplage faible entre les composants.
//      --> Les microservices communiquent entre eux via des requêtes HTTP/HTTPS en suivant le protocole REST.
//      --> La taille des services dans une MSA est souvent beaucoup plus petite que dans une SOA.
//              Dans la MSA, le couplage faible est primordial, à savoir que chaque microservice doit être très indépendant à tous les niveaux.
//              Chaque microservice possède sa propre base de données, alors que dans une SOA, il est courant de trouver une base de données commune à plusieurs services.
// Avant de s’attaquer à l’écriture de nos microservices, nous allons présenter SpringBoot, qui est le framework Java de référence. C'est parti pour le prochain chapitre !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découvrez le framework Spring Boot/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Si vous êtes amené à travailler sur une application développée autour de l'architecture Microservices en Java, vous aurez tôt ou tard affaire à Spring Boot.
// Dans ce chapitre, nous allons donc prendre le temps de comprendre ce que fait ce framework, et surtout lever l'ambiguïté sur la différence avec les autres frameworks Spring.
// Spring Boot est un framework qui facilite le développement d'applications fondées sur Spring en offrant des outils permettant d'obtenir une application packagée en JAR, totalement autonome.
// Ce qui nous intéresse particulièrement, puisque nous essayons de développer des  microservices !
// -----------
//  - Découvrez ce que propose Spring Boot :
// Si vous avez du mal à comprendre l'ensemble des notions à venir, ne vous inquiétez pas !
// Nous reprendrons tous ces concepts dans le prochain chapitre, avec un exemple concret.
// Spring et Spring MVC sont de formidables outils quand on essaie de développer une application web.
// Néanmoins, un de leurs plus gros problèmes est la configuration.
// Si vous avez déjà développé une application avec ces outils, vous avez dû remarquer que votre application est bardée de fichiers XML.
// Ces derniers indiquant les configurations des servlets, des vues, des contenus statiques, etc.
// Ces fichiers de configuration deviennent un vrai challenge lorsque vous avez une application complexe.
// Comment Spring Boot permet-il de créer une application sans écrire une seule ligne de configuration, ou presque ?
// Pour simplifier cette configuration, Spring Boot propose 2 fonctionnalités principales que nous allons voir dans la suite de ce chapitre :
//      --> L'autoconfiguration.
//      --> Les starters.
// -----------
//  - Utilisez la fonctionnalité d'autoconfiguration :
// Cette fonctionnalité est la plus importante de Spring Boot.
// Elle permet de configurer automatiquement votre application à partir des JAR trouvés dans votre classpath.
// En d'autres termes, si vous avez importé des dépendances, Spring Boot ira consulter cette liste, puis produira la configuration nécessaire pour que tout fonctionne correctement.
// Prenons l'exemple d'une application web dans laquelle vous avez les dépendances : Hibernate et Spring MVC.
// Normalement, vous devez créer les fichiers de configuration suivants :
//      - appconfig-mvc.xml.
//      - web.xml.
//      - persistence.xml.
// Comme vous ne connaissez pas nécessairement la syntaxe de ces fichiers par cœur, il vous faut consulter la documentation, ou vous inspirer d'un ancien projet.
// Vous devez ensuite écrire le code Java qui permet de lier ces fichiers XML à ApplicationContext de Spring.
// Si vous n'êtes pas familier avec 'ApplicationContext' de Spring, je vous recommande de lire ces explications :
//      --> 'https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/context/ApplicationContext.html'.
// Ensuite, vous adaptez et testez, puis réadaptez et retestez encore pendant un bon moment avant que tout fonctionne...
// Bien sûr, dès que vous faites un changement dans votre application, il ne faut pas oublier de mettre à jour tous les fichiers de configuration, puis débugger de nouveau.
//      --> Cela devient très vite très fastidieux !
// Voici l'équivalent de l'ensemble de ces étapes avec Spring MVC :
//                  @EnableAutoConfiguration
// C'est tout ! Avec cette annotation, Spring Boot ira scanner la liste de vos dépendances, trouvant par exemple Hibernate.
// Ayant constaté que vous n'avez défini aucune autre datasource, il créera la configuration nécessaire et l'ajoutera à 'ApplicationContext'.
// Bien entendu, vous pouvez très facilement personnaliser ces configurations, en créant vos Beans ou vos propres fichiers de configuration.
//      --> Spring Boot utilisera alors en priorité vos paramètres.
// -----------
//  - Utilisez les starters :
// Les starters viennent compléter l'autoconfiguration et font gagner énormément de temps, notamment lorsqu'on commence le développement d'un microservice.
// Un starter va apporter à votre projet un ensemble de dépendances, communément utilisées pour un type de projet donné.
// Ceci va vous permettre de créer un "squelette" prêt à l'emploi très rapidement.
// L'autre énorme avantage est la gestion des versions.
// Plus besoin de chercher quelles versions sont compatibles, puis de les ajouter une à une dans le pom.xml !
//      --> Il vous suffit d'ajouter une simple dépendance au starter de votre choix.
//              Cette dépendance va alors ajouter, à son tour, les éléments dont elle dépend, avec les bonnes versions.
// Prenons l'exemple où vous souhaitez créer un microservice. En temps normal, vous aurez besoin des dépendances suivantes :
//      - Spring.
//      - Spring MVC.
//      - Jackson (pour JSON).
//      - Tomcat...
// Avec Spring Boot, vous allez tout simplement avoir une seule dépendance dans votre pom.xml :
//                  <dependency>
//                      <groupId>org.springframework.boot</groupId>
//                      <artifactId>spring-boot-starter-web</artifactId>
//                  </dependency>
//      --> Tous les starters de Spring Boot sont au format 'spring-boot-starter-NOM_DU_STARTER'.
// Ce starter va charger les dépendances présentes dans le pom suivant :
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                      xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
//                      <modelVersion>4.0.0</modelVersion>
//                      <parent>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-parent</artifactId>
//                          <version>2.6.0</version>
//                          <relativePath/> <!-- lookup parent from repository -->
//                      </parent>
//                      <groupId>com.example</groupId>
//                      <artifactId>demo</artifactId>
//                      <version>0.0.1-SNAPSHOT</version>
//                      <name>demo</name>
//                      <description>Demo project for Spring Boot</description>
//                      <properties>
//                          <java.version>11</java.version>
//                      </properties>
//                      <dependencies>
//                          <dependency>
//                              <groupId>org.springframework.boot</groupId>
//                              <artifactId>spring-boot-starter</artifactId>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.springframework.boot</groupId>
//                              <artifactId>spring-boot-starter-test</artifactId>
//                              <scope>test</scope>
//                          </dependency>
//                      </dependencies>
//                      <build>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.springframework.boot</groupId>
//                                  <artifactId>spring-boot-maven-plugin</artifactId>
//                              </plugin>
//                          </plugins>
//                      </build>
//                  </project>
// D'accord, mais cela ne m'explique pas comment il devine les versions !
// Voici la réponse :
//                  <parent>
//                      <groupId>org.springframework.boot</groupId>
//                      <artifactId>spring-boot-starter-parent</artifactId>
//                      <version>2.6.0</version> <!-- permet de sélectionner la version -->
//                      <relativePath/>
//                  </parent>
// Ce tag, ajouté en haut du pom.xml, permet à votre pom d'hériter des propriétés d'un autre pom (qui lui-même hérite d'un autre pom : spring-boot-dependencies) :
//      --> https://github.com/mahendra-shinde/maven-repo-springboot/blob/master/repository/org/springframework/boot/spring-boot-starter-parent/2.1.6.RELEASE/spring-boot-starter-parent-2.1.6.RELEASE.pom.
// Il permet de définir principalement :
//      --> Une liste complète des versions des dépendances prises en charge, ce qui permet d'ajouter des dépendances sans indiquer leur version.
//              Comme dans le pom.xml du starter 'spring-boot-starter-web' vu plus haut. Vous allez donc pouvoir ajouter les dépendances de votre choix, sans vous soucier des versions.
// Bien entendu, spring-boot-starter-web n'est pas le seul starter disponible.
// Selon ce que vous comptez développer, vous trouverez pratiquement toujours un starter adéquat. Voici quelques exemples :
//      --> spring-boot-starter-mail : pour les applications et services d'envoi de mails.
//      --> spring-boot-starter-thymeleaf : si vous souhaitez créer une application qui offre une interface utilisateur en utilisant le moteur de template Thymeleaf.
//      --> spring-boot-starter-web-services : pour les services plus classiques utilisant SOAP.
// Vous trouverez dans la documentation de spring une liste de tous les starters existants : 'https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#using-boot-starter'.
// -----------
//  - En résumé :
//      --> Spring Boot est un framework qui permet de démarrer rapidement le développement d'applications ou services, en fournissant les dépendances nécessaires et en autoconfigurant celles-ci.
//      --> Pour activer l'autoconfiguration, on utilise l'annotation '@EnableAutoConfiguration'. Si vous écrivez vos propres configurations, celles-ci priment sur celles de Spring Boot.
//      --> Les starters permettent d'importer un ensemble de dépendances selon la nature de l'application à développer, afin de démarrer rapidement.
// Nous allons maintenant utiliser Spring Initializer pour initialiser notre projet : 'https://start.spring.io'.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez un microservice grâce à Spring Boot /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Découvrez Spring Initializr :
// Avez-vous déjà commandé une salade à composer au restaurant ?
// Eh bien, Spring Initializr fait plus ou moins la même chose : il vous permet de composer votre application selon vos besoins.
//      --> Pour débuter, rendez-vous sur 'https://start.spring.io'.
// Vous pourrez sélectionner :
//      - Le gestionnaire de projet (Maven ou Gradle).
//      - Le langage Java (Kotlin ou Groovy).
//      - Et la version de SpringBoot.
// Et vous pourrez initialiser :
//      - Les métadonnées de notre projet.
//      - Le packaging et la version de Java.
//      - Et surtout, les dépendances grâce au bouton “Add dependencies” en haut à droite.
// Nous allons, dans les prochains chapitres, développer un mini-système d'e-commerce fondé sur l'architecture Microservices avec Spring Boot.
// Nous allons commencer par un premier microservice qui gère les produits que nous allons proposer à la vente.
// Il doit pouvoir ajouter, supprimer, mettre à jour et afficher les produits.
// Dans une première étape, nous allons créer une version très simplifiée de ce microservice.
// Nous enrichirons ce microservice au fur et à mesure de notre découverte des différents concepts à assimiler.
//      - Créez et importez à partir de Spring Initializr :
//          Retournez sur Spring Initializr et renseignez les Metadata du projet comme suit :
//              --> Group : 'com.ecommerce'.
//              --> Artifact : 'microcommerce'.
//              --> Name : 'microcommerce'.
//              --> Packaging : 'jar'.
//              --> Java Version : '11'.
//          Ensuite, suivez les étapes suivantes :
//              - Sélectionnez en bas le starter Web 'Spring Web' qui s'ajoute une fois sélectionné dans les dépendances.
//              - Cliquez sur "Generate Project" et téléchargez l'application générée.
//              - Procédez à l'extraction de l'application téléchargée. Si vous avez utilisé les mêmes noms que moi, elle devrait s'appeler microcommerce.zip.
//              - Une fois sur la page d'accueil d'IntelliJ, cliquez sur Fichier puis Importer un projet depuis des sources existantes.
//              - Sélectionnez le dossier de l'application microcommerce, puis sélectionnez le pom.xml :
//      - Analysez le code obtenu :
//          Étudions maintenant en détail les différents éléments de l'arborescence générée par Spring Boot :
//              - pom.xml :
//                  Comme nous l'avons vu dans le chapitre précédent, ce 'pom.xml' hérite du parent 'spring-boot-starter-parent'.
//                  Celui-ci nous permet de ne plus nous soucier des versions des dépendances ni de leur compatibilité :
//                      <parent>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-parent</artifactId>
//                          <version>2.6.0</version>
//                          <relativePath/> <!-- lookup parent from repository -->
//                      </parent>
//                  Rappelez-vous : vous avez la possibilité de choisir la version de Java à utiliser.
//                  Comme nous avons sélectionné Java 11 dans l'interface de Spring Initializr, une balise XML <java.version> a été ajoutée dans la partie Properties du fichier pom.xml.
//                  Et ce, comme nous pouvons le voir dans le code qui suit :
//                      <properties>
//                          <java.version>11</java.version>
//                      </properties>
//                  Le pom.xml définit ensuite une dépendance vers le starter qui va ajouter à notre microservice toutes les dépendances de base nécessaires pour démarrer rapidement :
//                      <dependencies>
//                          <dependency>
//                              <groupId>org.springframework.boot</groupId>
//                              <artifactId>spring-boot-starter-web</artifactId>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.springframework.boot</groupId>
//                              <artifactId>spring-boot-starter-test</artifactId>
//                              <scope>test</scope>
//                          </dependency>
//                      </dependencies>
//                  Pour voir la liste des dépendances importées, rendez-vous à gauche dans "External Libraries" :
//                      --> Vous avez dans cette liste principalement :
//                              - Jackson : permet de parser JSON et faire le lien entre les classes Java et le contenu JSON.
//                              - Tomcat : intégré, va nous permettre de lancer notre application en exécutant tout simplement le JAR sans avoir à le déployer dans un serveur d'application.
//                              - Hibernate : facilite la gestion des données.
//                              - Logging : remonte ce qui se passe dans l'application grâce à logback et autres.
//              - MicrocommerceApplication.java
//                  Cette classe, générée automatiquement par Spring Boot, est le point de démarrage de l'application :
//                      package com.ecommerce.micrommerce;
//                      import org.springframework.boot.SpringApplication;
//                      import org.springframework.boot.autoconfigure.SpringBootApplication;
//                      @SpringBootApplication
//                      public class MicrommerceApplication {
//                          public static void main(String[] args) {
//                              SpringApplication.run(MicrommerceApplication.class, args);
//                          }
//                      }
//                  Elle lance, entre autres, la classe SpringApplication, responsable du démarrage de l'application Spring.
//                  Cette classe va créer le fameux ApplicationContext dans lequel iront toutes les configurations générées automatiquement ou ajoutées par vos soins.
//                  Mais le plus important ici, c'est bien sûr l'annotation '@SpringBootApplication', qui est une simple encapsulation de trois annotations :
//                      - @Configuration : donne à la classe actuelle la possibilité de définir des configurations qui iront remplacer les traditionnels fichiers XML.
//                          Ces configurations se font via des Beans.
//                      - @EnableAutoConfiguration : l'annotation vue précédemment qui permet, au démarrage de Spring, de générer automatiquement les configurations nécessaires.
//                          Et ce, en fonction des dépendances situées dans notre classpath.
//                      - @ComponentScan : indique qu'il faut scanner les classes de ce package afin de trouver des Beans de configuration.
//                  Nous reviendrons sur la configuration dans une prochaine section.
//                  Si vous souhaitez personnaliser finement le comportement de Spring Boot, il vous suffit de remplacer '@SpringBootApplication' par ces 3 annotations :
//                      ...
//                      ...
//                      @Configuration
//                      @EnableAutoConfiguration
//                      @ComponentScan
//                      public class MicrocommerceApplication {
//                          ...
//                      }
//                  Cette modification permet notamment de paramétrer l'annotation '@ComponentScan', par exemple pour cibler des fichiers à scanner.
//              - application.properties :
//                  Ce fichier va vous permettre de modifier très simplement un nombre impressionnant de configurations liées à Spring Boot et à ses dépendances. Par exemple :
//                      --> Changer le port d'écoute de Tomcat.
//                      --> Changer l'emplacement des fichiers de log.
//                      --> Changer les paramètres d'envoi d'e-mails.
//                      --> Etc.
//                  Je vous invite à jeter un œil sur la liste complète ici : 'https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html'.
//                  Nous reviendrons sur ce fichier dans une prochaine section.
//              - MicrocommerceApplicationTests.java :
//                  Ce fichier vous permet d'écrire vos tests.
//      - Exécutez l'application :
//          Nous n'avons rien ajouté dans notre application pour l'instant, mais nous pouvons déjà l'exécuter.
//          Si vous n'avez pas le panneau Maven à droite, rendez-vous en bas à gauche d'IntelliJ pour l'activer.
//          Double-cliquez ensuite sur "Install" sous "LifeCycle" de Maven dans le panneau de droite.
//          L'application sera compilée, et vous retrouverez le JAR sous le nouveau dossier "Target" créé pour l'occasion par Maven.
//          Exécutez enfin l'application depuis un terminal comme n'importe quel JAR, grâce à la commande :
//                      java -jar Chemin/vers/microcommerce/target/microcommerce-0.0.1-SNAPSHOT.jar
//          Dans les dernières lignes du retour, vous remarquerez cette phrase : "Tomcat started on port(s): 8080 (http)".
//          Ce qui vous indique que votre application tourne, et qu'elle est en écoute grâce à Tomcat sur le port 8080.
//              --> Eh bien, rendez-vous dans votre navigateur à l'adresse http://localhost:8080.
//          Vous obtenez alors cette magnifique erreur, car nous n'avons pas encore fourni d'éléments à afficher : "Whitelabel Error Page", "type = Not Found", "status = 404".
//          Pour faciliter l'exécution de notre service, vous pouvez profiter d'un raccourci d'IntelliJ.
//          Pour cela, faites un clic droit sur le nom de la classe contenant la méthode main (MicroserviceApplication.java), puis cliquez sur "Run" dans le menu contextuel qui s'affiche.
//          L'application se lance, et vous pouvez avoir le retour dans la console intégrée en bas.
//                  --> Cette opération est à faire uniquement la première fois.
//          Pour les fois suivantes, il suffira d'appuyer sur le bouton Play en haut à droite pour la démarrer, et l'arrêter avec le bouton rouge.
//                  --> N'oubliez pas, dans votre console, d'arrêter l'application afin de libérer le port pour une utilisation ultérieure.
//          Vous pouvez en profiter pour essayer la personnalisation de l'autoconfiguration de Spring Boot via 'application.properties'.
//          Vous pouvez ainsi changer un nombre impressionnant de paramètres grâce à une simple ligne dans le fichier 'application.properties'.
//          Changeons par exemple le port du serveur. Ajoutez tout simplement cette ligne : 'server.port=9090'
//          Exécutez maintenant l'application. Spring vous indique alors que l'application tourne désormais sur le port 9090 :
//          Vous pouvez le vérifier en vous rendant également à l'URL http://localhost:9090/Produits.
// -----------
//  - Créez l'API REST :
// Nous arrivons maintenant au coeur du microservice que nous voulons développer.
//      --> Ce microservice va devoir être RESTful, et donc pouvoir communiquer de cette manière.
// Il est indispensable, si vous n'êtes pas déjà à l'aise avec REST, de consulter ce cours afin de pouvoir comprendre ce qui suit.
//      - Définissez les besoins :
//          Nous avons besoin d'un microservice capable de gérer les produits.
//          Pour cela, il doit pouvoir exposer une API REST qui propose toutes les opérations CRUD (Create, Read, Update, Delete).
//              --> Nous allons donc avoir :
//                      - Une classe Produit qui représente les caractéristiques d'un produit (nom, prix, etc.).
//                      - Un contrôleur qui s'occupera de répondre aux requêtes CRUD et de faire les opérations nécessaires.
//              --> Nous voulons donc pouvoir appeler notre microservice sur les URL suivantes :
//                      - Requête GET à /Produits : affiche la liste de tous les produits.
//                      - Requête GET à /Produits/{id} : affiche un produit par son Id.
//                      - Requête PUT à /Produits/{id} : met à jour un produit par son Id.
//                      - Requête POST à /Produits : ajoute un produit.
//                      - Requête DELETE à /Produits/{id} : supprime un produit par son Id.
//              --> Passons au code !
//      - Créez le contrôleur REST :
//          Nous allons créer un contrôleur et le placer dans un package "controller", lui-même situé dans un package "web".
//          Pour ce faire, faites un clic droit sur le package principal, puis New -> Java Class : 'web.controller.ProductController'.
//          Lorsque vous cliquez sur OK, IntelliJ crée un package web, puis crée à l'intérieur de celui-ci un package controller.
//              --> Enfin, la classe ProductController est créée à l'intérieur de ce dernier package.
//          IntelliJ affiche les packages vides de façon compacte, comme vous pouvez le voir dans le cas du package web qui est fusionné avec controller : 'web.controller'.
//          Si cette façon d'afficher les packages ne vous plaît pas, vous pouvez opter pour un affichage classique.
//              --> Pour ce faire, clic droit sur la barre du projet, puis "Hide Empty Middle Packages" comme suit :
//          Nous allons commencer par indiquer à Spring que ce contrôleur est un contrôleur REST. Saisissez le code suivant dans la classe ProductController :
//                      package com.ecommerce.microcommerce.web.controller;
//                      import org.springframework.web.bind.annotation.RestController;
//                      @RestController
//                      public class ProductController {
//                      }
//          Vous connaissez sans doute l'annotation '@Controller' de Spring qui permet de désigner une classe comme contrôleur.
//              --> Ceci lui conférant la capacité de traiter les requêtes de type GET, POST, etc.
//                      Vous ajoutez ensuite '@ResponseBody' aux méthodes qui devront répondre directement sans passer par une vue.
//          '@RestController' est simplement la combinaison des deux annotations précédentes.
//          Une fois ajouté, il indique que cette classe va pouvoir traiter les requêtes que nous allons définir.
//          Il indique aussi que chaque méthode va renvoyer directement la réponse JSON à l'utilisateur, donc pas de vue dans le circuit.
//              - Méthode pour GET /Produits :
//                  Commençons par créer une méthode 'listeProduits', très simple, qui retourne une string.
//                  Comme nous n'avons pas encore de produits, on retourne une simple phrase pour tester.
//                      package com.ecommerce.micrommerce.web.controller;
//                      import org.springframework.web.bind.annotation.GetMapping;
//                      import org.springframework.web.bind.annotation.RestController;
//                      @RestController
//                      public class ProductController {
//                          @GetMapping("/Produits")
//                          public String listeProduits() {
//                              return "Un exemple de produit";
//                          }
//                      }
//                  Dans les versions plus anciennes de Spring, nous aurions utilisé '@RequestMapping(value = "/Produits", method = RequestMethod.GET)'.
//                  '@RequestMapping' prend deux paramètres :
//                      --> 'value' qui sert à définir l’URL sur laquelle on peut atteindre la méthode.
//                      --> Et 'method' qui définit le verbe HTTP pour interroger l’URL.
//                  De nouvelles annotations sont dorénavant disponibles, telles que :
//                      --> '@GetMapping'.
//                      --> '@PostMapping'.
//                      --> '@PutMapping'.
//                      --> '@DeleteMapping'.
//                  Elles permettent de ne spécifier que l’URL, tout en utilisant le verbe HTTP lié, présent juste avant le mapping.
//                  Dans ce code, c'est l'annotation '@GetMapping' qui permet de faire le lien entre l'URI "/Produits", invoquée via GET, et la méthode 'listeProduits'.
//                  Cette annotation accepte plusieurs paramètres, dont voici les principaux :
//                      - 'value' : C'est ici que vous indiquez l'URI à laquelle cette méthode doit répondre.
//                          Vous pouvez également indiquer des paramètres, nous y reviendrons.
//                      - 'produces' : Dans certains cas d'utilisations avancées, vous aurez besoin de préciser, par exemple, que votre méthode est capable de répondre en XML et en JSON.
//                          Cela entre aussi dans le choix de la méthode qui correspond le mieux à la requête.
//                          Si la requête contient du XML et que vous avez 2 méthodes identiques, dont une capable de produire du XML, c'est celle-ci qui sera appelée.
//                          Il en va de même pour 'consumes' qui précise les formats acceptés.
//                              --> Dans la plupart des cas, vous n'avez pas besoin de renseigner ces paramètres.
//                  Très bien! Il ne reste plus qu'à lancer l'application et à se rendre à 'http://localhost:9090/Produits'.
//              - Méthode pour GET /Produits/{id} :
//                  Créons maintenant une autre méthode capable d'accepter un Id de produit en paramètre :
//                      @GetMapping("/Produits/{id}")
//                      public String afficherUnProduit(@PathVariable int id) {
//                          return "Vous avez demandé un produit avec l'id  " + id;
//                      }
//                  La première différence dans cette méthode est l'ajout de '{id}' à l'URI.
//                  Cette notation permet d'indiquer que cette méthode doit répondre uniquement aux requêtes avec une URI de type '/Produits/25', par exemple.
//                  Comme nous avons indiqué que 'Id' doit être un 'int' (dans '@PathVariable int id').
//                  Vous pouvez vous amuser à passer une chaîne de caractères à la place, vous verrez que Spring vous renverra une erreur.
//                  Tout cela est très bien, mais nous aimerions bien renvoyer une liste de vrais produits au format JSON, et non plus seulement des phrases inutiles.
//                      --> C'est ce que nous allons voir dans la prochaine section.
//      - Renvoyez une réponse JSON :
//          Nous allons commencer par créer une classe qui représente un produit.
//          Cette classe est souvent appelée Model (ou plus anciennement Bean, ou POJO, pour Plain Old Java Object).
//              --> Un Model est une classe classique qui doit être "sérialisable" et avoir au minimum :
//                      - Un constructeur public sans argument.
//                      - Des getters et setters pour toutes les propriétés de la classe.
//          Commencez par créer une nouvelle classe Product que vous allez placer dans un package "model" sous le package microcommerce.
//          Créez ensuite les propriétés de base de la classe :
//                      package com.ecommerce.micrommerce.model;
//                      public class Product {
//                          private int id;
//                          private String nom;
//                          private int prix;
//                      }
//          Vous allez maintenant générer le constructeur et les getters et setters.
//              --> Faites Alt + insert  ou clic droit puis Générer, afin d'afficher la fenêtre de génération de code.
//          Générez le constructeur sans argument puis les getters et setters pour toutes les propriétés, ainsi que la méthode toString.
//          Pour nos tests, nous allons ajouter un constructeur afin d'obtenir des instances de produits préremplies avec des informations de tests. Vous obtenez ceci :
//                      package com.ecommerce.micrommerce.model;
//                      public class Product {
//                          private int id;
//                          private String nom;
//                          private int prix;
//                          public Product() {
//                          }
//                          public Product(int id, String nom, int prix) {
//                              this.id = id;
//                              this.nom = nom;
//                              this.prix = prix;
//                          }
//                          public int getId() {
//                              return id;
//                          }
//                          public void setId(int id) {
//                              this.id = id;
//                          }
//                          public String getNom() {
//                              return nom;
//                          }
//                          public void setNom(String nom) {
//                              this.nom = nom;
//                          }
//                          public int getPrix() {
//                              return prix;
//                          }
//                          public void setPrix(int prix) {
//                              this.prix = prix;
//                          }
//                          @Override
//                          public String toString() {
//                              return "Product{" +
//                                      "id=" + id +
//                                      ", nom='" + nom + '\'' +
//                                      ", prix=" + prix +
//                                      '}';
//                          }
//                      }
//          Très bien ! Maintenant, à chaque fois que quelqu'un appelle notre URI "/Produits/{id}", nous voudrions renvoyer un produit au format JSON qui correspond à notre classe Product.
//          Retournez sur le code précédent et remplacez la méthode afficherUnProduit par celle-ci :
//                      //Récupérer un produit par son Id
//                      @GetMapping(value = "/Produits/{id}")
//                      public Product afficherUnProduit(@PathVariable int id) {
//                          Product product = new Product(id, new String("Aspirateur"), 100);
//                          return product;
//                      }
//          Intellij vous surlignera product en jaune, car selon le linter (un outil intégré dans Intellij qui analyse le code), la variable est redondante.
//          Pour votre information, la syntaxe “parfaite” serait :
//                      return product = new Product(id, new String("Aspirateur"), 100);
//              --> Explications :
//                      Tout d'abord, nous avons indiqué que notre méthode va retourner un 'Product' au lieu de 'String'.
//                      Normalement, nous sommes censés aller chercher le produit par l'Id que nous avons reçu dans la base de données, et le retourner à l'utilisateur.
//                      Comme nous n'avons pas encore de base de données, nous avons tout simplement instancié un objet Product grâce au constructeur que nous avons défini plus tôt.
//                      Nous simulons donc la récupération d'un produit dans la base de données.
//                      Une fois notre instance de Product prête, nous la retournons.
//          Voici le contrôleur complet :
//                      package com.ecommerce.micrommerce.web.controller;
//                      import com.ecommerce.micrommerce.model.Product;
//                      import org.springframework.web.bind.annotation.GetMapping;
//                      import org.springframework.web.bind.annotation.PathVariable;
//                      import org.springframework.web.bind.annotation.RestController;
//                      @RestController
//                      public class ProductController {
//                          @GetMapping("/Produits")
//                          public String listeProduits() {
//                              return "Un exemple de produit";
//                          }
//                          //Récupérer un produit par son Id
//                          @GetMapping(value = "/Produits/{id}")
//                          public Product afficherUnProduit(@PathVariable int id) {
//                              Product product = new Product(id, new String("Aspirateur"), 100);
//                              return product;
//                          }
//                      }
//          Lancez de nouveau le projet puis rendez-vous par exemple sur 'http://localhost:9090/Produits/27' pour regarder ce qui se passe.
//          Vous obtenez une belle réponse formatée en JSON comme par magie.
//              --> Comment est-ce possible ?
//                      Vous avez indiqué au début que cette classe est un contrôleur REST grâce à l'annotation @RestController.
//                      Spring sait alors que les réponses aux requêtes qu'il vous passe devront être très probablement en format JSON.
//                          --> L'autoconfigurateur va alors chercher si vous avez dans votre classpath une dépendance capable de transformer un objet Java en JSON, et inversement.
//                                  Bingo ! Il y a justement Jackson qui a été importé avec le starter que nous avons utilisé.
//                                  Le Bean Product que nous renvoyons est donc transformé en JSON, puis servi en réponse.
//          Vous venez donc de créer un premier microservice REST sans avoir à manipuler JSON, ni à parser les requêtes HTTP.
//      - Créez le DAO :
//          Nous allons nous rapprocher un peu plus d'un cas d'utilisation réelle, en créant la DAO nécessaire pour communiquer avec une base de données.
//          Nous allons simuler celle-ci grâce à des données statiques.
//          Créez un package et nommez-le dao, puis créez dedans une interface nommée ProductDao, dans laquelle vous allez déclarer les opérations que nous allons implémenter.
//                      package com.ecommerce.micrommerce.web.dao;
//                      import com.ecommerce.micrommerce.web.model.Product;
//                      import org.springframework.stereotype.Repository;
//                      import java.util.List;
//                      public interface ProductDao {
//                          List<Product> findAll();
//                          Product findById(int id);
//                          Product save(Product product);
//                      }
//          Nous indiquons dans cette interface que les opérations suivantes sont possibles :
//              - findAll : renvoie la liste complète de tous les produits.
//              - findById : renvoie un produit par son Id.
//              - save : ajoute un produit.
//          En effet, il faut suivre les conventions de nommage des méthodes afin de bénéficier plus tard de certaines fonctionnalités qui vous feront gagner beaucoup de temps.
//          Maintenant que notre interface est prête, nous allons pouvoir créer son implémentation.
//          Créez une classe ProductDaoImpl qui implémente l'interface que nous venons de créer. Vous obtenez alors ceci :
//                      package com.ecommerce.micrommerce.web.dao;
//                      import com.ecommerce.micrommerce.web.model.Product;
//                      import java.util.List;
//                      public class ProductDaoImpl implements ProductDao{
//                          @Override
//                          public List<Product> findAll() {
//                              return null;
//                          }
//                          @Override
//                          public Product findById(int id) {
//                              return null;
//                          }
//                          @Override
//                          public Product save(Product product) {
//                              return null;
//                          }
//                      }
//          Normalement , cette classe est censée communiquer avec la base de données pour récupérer les produits ou en ajouter.
//          Nous allons simuler ce comportement en créant des produits en dur dans le code, nous obtenons donc ceci :
//                      package com.ecommerce.micrommerce.web.dao;
//                      import com.ecommerce.micrommerce.web.model.Product;
//                      import org.springframework.stereotype.Repository;
//                      import java.util.ArrayList;
//                      import java.util.List;
//                      @Repository
//                      public class ProductDaoImpl implements ProductDao{
//                         public static List<Product> products = new ArrayList<>();
//                         static {
//                             products.add(new Product(1, "Ordinateur portable", 350));
//                             products.add(new Product(2, "Aspirateur Robot", 500));
//                             products.add(new Product(3, "Table de Ping Pong", 750));
//                         }
//                         @Override
//                         public List<Product> findAll() {
//                             return products;
//                         }
//                         @Override
//                         public Product findById(int id) {
//                             for (Product product : products){
//                                 if (product.getId() == id){
//                                     return product;
//                                 }
//                             }
//                             return null;
//                         }
//                         @Override
//                         public Product save(Product product) {
//                             products.add(product);
//                             return product;
//                         }
//                      }
//          '@Repository' : cette annotation est appliquée à la classe afin d'indiquer à Spring qu'il s'agit d'une classe qui gère les données.
//          Ceci nous permettra de profiter de certaines fonctionnalités, comme les translations des erreurs. Nous y reviendrons.
//          Pour tester avec des données statiques, vu que nous n'en sommes pas encore à la base de données, nous définissons ici un tableau de 'Products'.
//          Dans celui-ci, nous ajoutons 3 produits statiques. Les méthodes suivantes sont ensuite redéfinies afin de renvoyer les données adéquates :
//              - findAll  : renvoie tous les produits que nous avons créés.
//              - findById : vérifie s'il y a un produit avec l'Id donné dans notre liste de produits, et le renvoie en cas de correspondance.
//              - save : ajoute le produit reçu à notre liste.
//          Très bien, votre couche DAO est prête ! Vous allez pouvoir l'utiliser pour simuler la récupération et l'ajout de produits depuis une base de données.
//      - Interagissez avec les données :
//          Nous allons maintenant modifier notre contrôleur afin qu'il utilise notre couche DAO pour manipuler les produits :
//                      package com.ecommerce.micrommerce.web.controller;
//                      import com.ecommerce.micrommerce.web.dao.ProductDao;
//                      import com.ecommerce.micrommerce.web.model.Product;
//                      import org.springframework.web.bind.annotation.GetMapping;
//                      import org.springframework.web.bind.annotation.PathVariable;
//                      import org.springframework.web.bind.annotation.RestController;
//                      import java.util.List;
//                      @RestController
//                      public class ProductController {
//                          private final ProductDao productDao;
//                          public ProductController(ProductDao productDao){
//                              this.productDao = productDao;
//                          }
//                          @GetMapping("/Produits")
//                          public List<Product> listeProduits() {
//                              return productDao.findAll();
//                          }
//                          @GetMapping(value = "/Produits/{id}")
//                          public Product afficherUnProduit(@PathVariable int id) {
//                              return productDao.findById(id);
//                          }
//                      }
//          Tout d'abord, nous avons créé une variable de type 'ProductDao', que nous avons définie en 'private final'.
//          De cette manière, Spring se charge d'en fabriquer une instance que nous injectons dans le constructeur.
//          'ProductDao' a désormais accès à toutes les méthodes que nous avons définies.
//          Pour information, s’il n’y a qu’un seul constructeur, Spring s’occupe d’ajouter l’annotation automatiquement à la compilation.
//          Mais pour des raisons de lisibilité, nous avons choisi de le rendre explicite.
//          Nous avons changé 'listeProduits' afin qu'elle nous retourne une liste de produits List.
//          Ensuite, il a suffi d'invoquer la méthode 'findAll' créée précédemment pour qu'elle nous retourne tous les produits.
//          De même pour 'afficherUnProduit' qui fait appel à 'findById'.
//      - Testez !
//              --> Lancez le microservice et rendez-vous à 'http://localhost:9090/Produits/'.
//                      Bingo ! Vous avez la liste des produits que vous avez définis au format JSON, prête à être consommée par n'importe quel microservice REST.
//              --> Rendez-vous ensuite à 'http://localhost:9090/Produits/1' pour afficher produit par produit.
//                      Le processus pour obtenir le résultat est le suivant :
//                          - L'utilisateur envoie une requête GET vers /Produits/2.
//                          - Le dispatcheur cherche dans votre contrôleur la méthode qui répond au pattern "/Produits/{id}" et l'exécute.
//                          - La méthode 'listeProduits' fait appel au DAO pour qu'il communique avec la base de données.
//                              Il récupère les informations sur le produit puis il crée une instance de Product qu'il renvoie ensuite à votre méthode.
//                              Votre méthode retourne l'instance reçue, qui est transformée à la volée en JSON grâce à Jackson.
// -----------
//  - En résumé :
//      --> Spring est utilisé pour instancier nos objets.
//      --> Nous avons un microservice fonctionnel.
//      --> Vous pouvez retrouver le code de ce chapitre sur github.
// Maintenant que les bases de notre microservice sont prêtes, nous allons pouvoir tester celui-ci avec Postman.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Testez votre API grâce à Postman //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Comme vous avez dû le remarquer, j'ai jusqu'ici soigneusement évité d'implémenter la requête POST.
// En effet, lorsque nous créons une méthode utilisant ce verbe HTTP, il n'est pas possible de la tester simplement via le navigateur, comme pour une simple requête GET.
// Nous allons utiliser un logiciel appelé Postman qui permet d'envoyer toutes sortes de requêtes et de les personnaliser très finement.
// Il permet également de gérer l'authentification, les scripts de tests, etc.
// -----------
//  - Implémentez POST :
// Commençons par créer la méthode qui permet d'ajouter un produit :
//                  @PostMapping(value = "/Produits")
//                  public void ajouterProduit(@RequestBody Product product) {
//                      productDao.save(product);
//                  }
//      - '@PostMapping' : Vous pouvez voir qu'ici l'URI indiquée '/Produits' est exactement la même que dans la méthode 'listeProduits' définie au chapitre précédent.
//          Alors, comment Spring sait-il laquelle appeler ? Eh bien, grâce justement aux annotations '@PostMapping' et '@GetMapping' !
//          Celles-ci indiquent à quel type de requête HTTP  la méthode est associée, POST ou GET respectivement.
//          Si on envoie une requête POST "/Produits", c'est la méthode annotée avec '@PostMapping' qui sera donc appelée.
//      -'@RequestBody' : Nous avons vu plus tôt comment Spring Boot a configuré Jackson pour convertir les objets Java renvoyés en réponse (Product, dans notre cas) en JSON.
//          Ici, nous avons besoin du contraire. Nous allons recevoir une requête POST avec les informations d'un nouveau produit au format JSON.
//          Il nous faut donc constituer un objet Product à partir de ce JSON.
//          C'est là que '@RequestBody' vient à la rescousse. Cette annotation demande à Spring que le JSON contenu dans la partie body de la requête HTTP soit converti en objet Java.
//          Comment ? Spring, qui a déjà tout autoconfiguré au début, ira simplement chercher la librairie capable de faire cela, et l'utiliser.
//          Dans notre cas c'est 'Jackson', mais cela pourrait tout à fait être 'Gson'.
//          La requête JSON est ainsi convertie, dans notre cas, en objet Product, puis passée en paramètre à 'ajouterProduit'.
//          Il ne nous reste plus qu'à appeler la méthode 'save' que nous avons déjà créée, et le nouveau produit est ajouté.
// Testons tout cela, voulez-vous ?
// -----------
//  - Comprenez le principe de Postman :
// Postman est un logiciel qui se focalise sur les tests des API.
// Il est devenu très populaire pour tester les microservices, notamment grâce à sa simplicité et ses fonctionnalités très spécialisées.
// Postman existe à ce jour en extension pour Chrome, mais l'éditeur a annoncé la fin prochaine de celle-ci.
// L'application est régulièrement mise à jour, et l'interface peut donc être légèrement différente de celle présentée dans la suite de ce chapitre.
// Voici les principales fonctionnalités à connaître pour nos tests :
//      --> ( 1 ) : Ici vous pouvez choisir le type de requête à envoyer : GET, POST, PUT, etc.
//      --> ( 2 ) : L'URL de l'API.
//      --> ( 3 ) : Les paramètres à passer avec l'URL. Dans le cas où vous avez des paramètres nommés, comme '?prenom=alexandre'.
//                      Vous allez pouvoir ajouter dans le formulaire comme paramètre prenom, et comme valeur, fabien.
//                      Ceci se révèle particulièrement utile quand vous avez beaucoup de paramètres qu'il faut organiser.
//      --> ( 4 ) : Ici vous retrouverez les connexions que vous avez créées. Nous y reviendrons.
//      --> ( 5 ) : Ici vous trouverez tout ce qui constitue une requête HTTP (header, body, etc.). Vous pouvez à partir de là créer votre requête de façon totalement personnalisée.
// Faisons tout de suite un premier test. Lancez le microservice, puis revenez sur Postman et saisissez l'URL http://localhost:9090/Produits.
// Cliquez ensuite sur l'onglet Header. La figure qui suit présente l'en-tête de la réponse HTTP fournie par votre microservice.
// Vous pouvez remarquer que Spring a réglé la valeur 'Content-Type' sur 'application/json;charset=UTF-8'.
// Le plus important est le code de réponse en haut à droite, dans ce cas, 200. Ce code est particulièrement important pour débugger.
// -----------
//  - Testez POST :
// Nous allons pouvoir tester à présent notre méthode ajouterProduit.
//      - Sélectionnez POST puis ajoutez l'URL 'http://localhost:9090/Produits'.
//      - Cliquez sur l'onglet Body qui n'est plus grisé, puis sélectionnez raw pour définir manuellement le contenu de la requête HTTP.
//      - Collez ensuite un JSON avec les informations d'un produit, par exemple :
//                  {
//                      "id": 4,
//                      "nom": "Poney en bois cracheur de feu",
//                      "prix": 145
//                  }
//      - Sélectionnez à droite JSON à la place de Text afin d'indiquer dans notre requête le type de données que nous envoyons.
//      - Cliquez sur "Send". Rien ne se passe ? C'est normal puisque notre méthode ne retourne rien. Néanmoins, vous pouvez voir que notre microservice a répondu avec le code 200 OK.
//          --> Vérifions si notre produit a bien été ajouté. Créez un nouvel onglet et faites appel, via GET, à http://localhost:9090/Produits.
// Bingo ! Votre nouveau produit est ajouté. On peut dire que vous avez désormais un microservice fonctionnel.
// -----------
//  - Utilisez les collections dans Postman :
// Dans le panneau de gauche, vous avez 2 onglets : History et Collections.
// Dans History, vous avez l'historique de toutes les requêtes que vous avez exécutées.
// Vous pouvez y retourner et réexécuter une requête parmi celles déjà essayées.
// Les collections sont une façon plus permanente d'organiser et garder des requêtes pour faire des tests.
// Elles vont vous permettre de regrouper un ensemble de requêtes et de les lancer selon les paramètres et l'ordre de votre choix pour réaliser, par exemple, un test de scénario.
//      - Commencez par créer une nouvelle collection en cliquant sur le bouton "Ajouter collection".
//      - Renseignez ensuite le nom de votre collection : 'Microcommerce'.
//      - Parmi les onglets proposés, vous avez "Authorization" qui va vous permettre d'ajouter la méthode d'authentification à votre microservice.
//          Nous y reviendrons dans la prochaine partie du cours. Cliquez sur "Create".
//      - Ajoutez les deux requêtes que nous avons créées en cliquant sur "Save" situé à côté du bouton "Send".
//          Vous pouvez donner un nom à la requête, mais il est plus lisible de laisser le nom par défaut, qui est tout simplement l'URL appelée.
//      - Choisissez ensuite la collection que vous venez de créer, et validez :
//          Vous obtenez alors une collection avec 2 requêtes à gauche. Vous pouvez distinguer les opérations grâce au type : GET, POST, etc.
//      - Redémarrez le microservice afin de réinitialiser la liste des produits, puis rendez-vous sur votre collection et cliquez sur la flèche pour développer les opérations possibles.
//          Glissez-déposez les requêtes afin que POST soit avant GET, puis cliquez sur "Run" :
//          Cette fenêtre vous permet de choisir un certain nombre d'options, comme par exemple le nombre de fois où vous souhaitez exécuter les requêtes (champ "Iterations").
//      - Cliquez sur "Run Microcommerce". Les requêtes sont alors exécutées, et celles qui ont réussi sont marquées par un carré vert, ainsi que les codes de réponse en face.
//          Si vous souhaitez voir ce qui se passe "sous le capot", dans le cas où une des requêtes n'aurait pas fonctionné, vous pouvez avoir tous les retours via la console Postman.
//          Allez dans "View" puis "Show Postman Console". Une fois la console lancée, réexécutez la collection.
//          Vous pouvez alors naviguer dans le résultat de chaque requête et voir tous les détails sur celle-ci et sur sa réponse :
//              --> À noter que vous pouvez choisir l'onglet "raw" pour visualiser les données brutes sans mise en forme.
// -----------
//  - En résumé :
//      --> Postman permet de facilement interagir avec une API, notamment pour les méthodes POST et PUT.
//      --> Les suites de tests nous permettent de nous assurer du fonctionnement de nos microservices.
// Nous allons maintenant affiner notre microservice en personnalisant les codes de retour.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Renvoyez les bons codes et filtrez les réponses ! /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Renvoyez les bons codes HTTP :
// Quand vous avez testé votre méthode 'ajouterProduit', vous avez dû remarquer que celle-ci renvoie un code 200 OK une fois exécutée.
// Or, selon les standards du protocole HTTP, en cas de requête POST pour créer une ressource sur le serveur distant, il faut définir, dans l'en-tête de la réponse :
//      --> Le code '201 Created'.
// Si possible, l'URI vers la ressource créée dans le champ Location.
// Ce microservice est censé être consommé par d'autres services qui ne doivent surtout rien connaître, ni de son fonctionnement interne, ni de ses spécificités.
//      --> Il faut que votre microservice respecte les conventions et les standards.
// En effet, s'il est nécessaire d'adapter les autres composants au comportement particulier d'un microservice, il perd tout intérêt.
// Changeons donc 'ajouterProduit' pour qu'elle renvoie le code de statut 201.
// Voici le code complet, afin que vous preniez connaissance de l'ensemble des librairies à importer pour les objets que nous allons utiliser :
//                  package com.ecommerce.micrommerce.web.controller;
//                  import com.ecommerce.micrommerce.web.dao.ProductDao;
//                  import com.ecommerce.micrommerce.web.model.Product;
//                  import org.apache.coyote.Response;
//                  import org.springframework.http.ResponseEntity;
//                  import org.springframework.web.bind.annotation.*;
//                  import org.springframework.web.servlet.support.ServletUriComponentsBuilder;
//                  import java.net.URI;
//                  import java.util.List;
//                  import java.util.Objects;
//                  @RestController
//                  public class ProductController {
//                      private final ProductDao productDao;
//                      public ProductController(ProductDao productDao) {
//                          this.productDao = productDao;
//                      }
//                      @GetMapping("/Produits")
//                      public List<Product> listeProduits() {
//                          return productDao.findAll();
//                      }
//                      @GetMapping(value = "/Produits/{id}")
//                      public Product afficherUnProduit(@PathVariable int id) {
//                          return productDao.findById(id);
//                      }
//                      @PostMapping(value = "/Produits")
//                      public ResponseEntity<Product> ajouterProduit(@RequestBody Product product) {
//                          Product productAdded = productDao.save(product);
//                          if (Objects.isNull(productAdded)) {
//                              return ResponseEntity.noContent().build();
//                          }
//                          URI location = ServletUriComponentsBuilder
//                                  .fromCurrentRequest()
//                                  .path("/{id}")
//                                  .buildAndExpand(productAdded.getId())
//                                  .toUri();
//                          return ResponseEntity.created(location).build();
//                      }
//                  }
// Le code de la méthode 'ajouterProduit' est ici défini avec un code un peu plus élaboré que précédemment.
// Tout d'abord, nous remplaçons la valeur de retour 'void' de la méthode 'ajouterProduit' par 'ResponseEntity<Product>'.
//      --> 'ResponseEntity' est une classe qui hérite de 'HttpEntity', qui permet de définir le code HTTP à retourner.
//              L'intérêt de 'ResponseEntity' est de nous donner la main pour personnaliser le code facilement.
// Vous pouvez consulter ici toutes les méthodes disponibles pour renvoyer divers codes :
//      --> 'https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/http/ResponseEntity.HeadersBuilder.html'.
// Dans un premier temps, nous faisons appel à la DAO pour ajouter le produit.
// Dans le cas où le produit ajouté est vide ou n'existe pas, nous retournons le code 204 No Content.
// Pour cela, la méthode 'noContent()'' est utilisée. Cette méthode est chaînée avec la méthode 'build()' qui construit le header, et y ajoute le code choisi.
// Dans le cas où tout s'est bien passé et que 'productAdded' n'est donc pas null, nous avons besoin, en plus du code 201, d'ajouter l'URI vers cette nouvelle ressource créée.
// Et cela, afin d'être conformes avec le protocole HTTP.
// Nous déclarons donc une instance de la classe URI afin de la passer ensuite comme argument de 'ResponseEntity'.
//      --> Nous instancions cette URI à partir de l'URL de la requête reçue.
// Le fait de ne pas coder l'URL en dur vous offre la liberté de modifier l'emplacement de votre microservice à volonté.
// Nous ajoutons ensuite l'Id du produit à l'URI à l'aide de la méthode 'buildAndExpand'.
//      --> Nous retrouvons l'Id dans l'instance de Product que nous avons reçu : 'productAdded.getId()'.
// Enfin, nous invoquons la méthode 'created' de 'ResponseEntity', qui accepte comme argument l'URI de la ressource nouvellement créée, et renvoie le code de statut 201.
// Voilà ! Redémarrez le microservice et rendez-vous dans Postman pour relancer la requête POST, comme illustré ci-dessous :
//                  {
//                      "id" : "17",
//                      "nom" : "Poney en bois"
//                      "prix" : "145"
//                  }
// Nous constatons :
//      --> Le code de statut est bien 201 Created.
//      --> Il existe bien un champ Location dont la valeur est l'URL de la ressource créée.
// Vous pouvez le vérifier en saisissant cette URL dans votre navigateur : vous obtiendrez alors un JSON contenant le produit que vous avez ajouté.
// -----------
//  - Filtrez les réponses de votre microservice :
// Jusqu'à maintenant, notre microservice va récupérer une ou des instances de 'Product', et les renvoyer au format JSON.
// Cependant, cela pose un problème : que se passe-t-il si mon produit comporte des informations sensibles que je ne veux pas exposer ?
// Par exemple, le prix d'achat du produit ou le nombre d'unités restantes en stock.
// Pour résoudre ce problème, modifions la classe 'Product' située dans le package 'model' pour ajouter le prix d'achat du produit que nous ne souhaitons pas modifier. Voici la classe :
//                  package com.ecommerce.microcommerce.model;
//                  public class Product {
//                      private int id;
//                      private String nom;
//                      private int prix;
//                      //information que nous ne souhaitons pas exposer
//                      private int prixAchat;
//                      //constructeur par défaut
//                      public Product() {
//                      }
//                      //constructeur pour nos tests
//                      public Product(int id, String nom, int prix, int prixAchat) {
//                          this.id = id;
//                          this.nom = nom;
//                          this.prix = prix;
//                          this.prixAchat = prixAchat;
//                      }
//                      public int getId() {
//                          return id;
//                      }
//                      public void setId(int id) {
//                          this.id = id;
//                      }
//                      public String getNom() {
//                          return nom;
//                      }
//                      public void setNom(String nom) {
//                          this.nom = nom;
//                      }
//                      public int getPrix() {
//                          return prix;
//                      }
//                      public void setPrix(int prix) {
//                          this.prix = prix;
//                      }
//                      public int getPrixAchat() {
//                          return prixAchat;
//                      }
//                      public void setPrixAchat(int prixAchat) {
//                          this.prixAchat = prixAchat;
//                      }
//                      @Override
//                      public String toString() {
//                          return "Product{" +
//                                  "id=" + id +
//                                  ", nom='" + nom + '\'' +
//                                  ", prix=" + prix +
//                                  '}';
//                      }
//                  }
// N'oubliez pas d'ajouter les getters et setters, et de modifier le constructeur.
// Rendez-vous ensuite dans 'ProductDaoImpl' et ajoutez le dernier paramètre 'prixAchat' manquant :
//                  package com.ecommerce.micrommerce.web.dao;
//                  import com.ecommerce.micrommerce.web.model.Product;
//                  import org.springframework.stereotype.Repository;
//                  import java.util.ArrayList;
//                  import java.util.List;
//                  @Repository
//                  public class ProductDaoImpl implements ProductDao{
//                      public static List<Product> products = new ArrayList<>();
//                      static {
//                          products.add(new Product(1, "Ordinateur portable", 350, 120));
//                          products.add(new Product(2, "Aspirateur Robot", 500, 200));
//                          products.add(new Product(3, "Table de Ping Pong", 750, 400));
//                      }
//                      @Override
//                      public List<Product> findAll() {
//                          return products;
//                      }
//                      @Override
//                      public Product findById(int id) {
//                          for (Product product : products){
//                              if (product.getId() == id){
//                                  return product;
//                              }
//                          }
//                          return null;
//                      }
//                      @Override
//                      public Product save(Product product) {
//                          products.add(product);
//                          return product;
//                      }
//                  }
// Redémarrez votre application et appelez avec Postman l'URL http://localhost:9090/Produits. Vous obtenez cette réponse :
//                  [
//                    {
//                        "id": 1,
//                        "nom": "Ordinateur portable",
//                        "prix": 350,
//                        "prixAchat": 120
//                    },
//                    {
//                        "id": 2,
//                        "nom": "Aspirateur Robot",
//                        "prix": 500,
//                        "prixAchat": 200
//                    },
//                    {
//                        "id": 3,
//                        "nom": "Table de Ping Pong",
//                        "prix": 750,
//                        "prixAchat": 400
//                    }
//                  ]
// Aïe ! Votre prix d'achat est exposé à tous. Vos clients ne vont pas être contents d'apprendre que vous faites une marge si importante sur les ventes.
//      - Utilisez le filtrage statique :
//          Jackson, qui s'occupe de convertir les objets Java en JSON, vous offre une méthode toute simple.
//              --> Ajoutez l'annotation @JsonIgnore au-dessus des propriétés que vous souhaitez cacher :
//                      //information que nous ne souhaitons pas exposer
//                      @JsonIgnore
//                      private int prixAchat;
//          Redémarrez votre microservice et bingo ! prixAchat a disparu !
//              --> Une autre notation qui peut être pratique quand vous avez beaucoup de choses à cacher :
//                      @JsonIgnoreProperties(value = {"prixAchat", "id"})
//                      public class Product {
//                          ...
//                      }
//                  Il vous suffit d'entrer la liste des propriétés à ignorer. Dans ce cas, il n'y aura plus que le nom et le prix de chaque produit :
//                      [
//                          {
//                              "nom": "Ordinateur portable",
//                              "prix": 350
//                          },
//                          {
//                              "nom": "Aspirateur Robot",
//                              "prix": 500
//                          },
//                          {
//                              "nom": "Table de Ping Pong",
//                              "prix": 750
//                          }
//                      ]
//      - Utilisez le filtrage dynamique :
//          La première méthode est simple et marchera dans pas mal de cas, mais elle est assez définitive.
//          Que faire si vous souhaitez afficher le prix d'achat ou non, en fonction de qui le demande ?
//          Par exemple, vous n'affichez jamais le prix d'achat à un service qui s'occupe de vendre le produit aux clients finaux.
//          Par contre vous exposez ce prix aux services qui s'occupent des calculs des bénéfices journaliers.
//          Dans ce cas, il vous faut filtrer dynamiquement au cas par cas.
//          Commencez par enlever les annotations que nous avons appliquées précédemment à la classe Product, et remplacez-les par celles-ci :
//                      @JsonFilter("monFiltreDynamique")
//                      public class Product {
//                          ...
//                      }
//          Cette annotation indique que ce Bean (Product) accepte un filtre qui porte le nom très créatif de monFiltreDynamique.
//          Il ne reste plus qu'à créer ce filtre. Rendez-vous sur votre contrôleur 'ProductController', et modifiez la méthode 'listeProduits' comme suit :
//                      //Récupérer la liste des produits
//                      @GetMapping("/Produits")
//                      public MappingJacksonValue listeProduits() {
//                          List<Product> produits = productDao.findAll();
//                          SimpleBeanPropertyFilter monFiltre = SimpleBeanPropertyFilter.serializeAllExcept("prixAchat");
//                          FilterProvider listDeNosFiltres = new SimpleFilterProvider().addFilter("monFiltreDynamique", monFiltre);
//                          MappingJacksonValue produitsFiltres = new MappingJacksonValue(produits);
//                          produitsFiltres.setFilters(listDeNosFiltres);
//                          return produitsFiltres;
//                      }
//          Ce code stocke la liste des produits retournés par findAll dans une liste.
//          'SimpleBeanPropertyFilter' est une implémentation de 'PropertyFilter' qui permet d'établir les règles de filtrage sur un Bean donné.
//          Ici, nous avons choisi la règle 'serializeAllExcept' qui exclut uniquement les propriétés que nous souhaitons ignorer.
//          Inversement, vous pouvez procéder avec la méthode 'filterOutAllExcept' qui marque toutes les propriétés comme étant à ignorer, sauf celles passées en argument.
//          Maintenant que nous avons établi notre règle de filtrage, la ligne suivante nous permet d'indiquer à Jackson à quel Bean l'appliquer.
//          Nous utilisons 'SimpleFilterProvider' pour déclarer que les règles de filtrage que nous avons créées peuvent s'appliquer à tous les Beans qui sont annotés avec 'monFiltreDynamique'.
//          Nous avons établi la règle et indiqué que cette règle ne s'applique qu'aux Beans qui sont annotés avec 'monFiltreDynamique'.
//          Mais nous ne l'avons pas encore appliquée. Pour cela, nous les mettons au format 'MappingJacksonValue'.
//          Cela permet de donner accès aux méthodes qui nous intéressent, comme 'setFilters' qui applique les filtres que nous avons établis à la liste de 'Product'.
//          Nous retournons ensuite la liste filtrée. Ne vous inquiétez pas si vous devez renvoyer 'MappingJacksonValue'.
//          En effet, ce n'est qu'un simple "conteneur" qui ne change absolument rien au contenu.
//          'MappingJacksonValue' est donc exactement comme produits, avec des méthodes de filtrage en plus.
//              --> Il ne vous reste plus qu'à tester !
// -----------
//  - En résumé :
//      --> Nous avons remplacé les types de retour pour rendre notre application cohérente avec la norme, grâce à ResponseEntity.
//      --> Nous savons appliquer des filtres sur notre API grâce à Jackson.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Améliorez votre microservice //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Utilisez JPA pour communiquer avec une base de données ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Transformez la classe Product en entité :
// Afin de pouvoir générer nos tables, nous avons besoin de transformer notre classe 'Product' en entité gérée par JPA.
// Nous allons commencer par importer toutes les dépendances nécessaires à l'utilisation du JPA.
// Spring Boot nous offre pour cela un starter prêt à l'emploi : 'spring-boot-starter-data-jpa'.
// Commençons par l'ajouter dans la balise '<dependencies>' de notre 'pom.xml', comme illustré ci-dessous :
//                  <dependencies>
//                      <dependency>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-web</artifactId>
//                      </dependency>
//                      <dependency>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-data-jpa</artifactId>
//                      </dependency>
//                      <dependency>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-test</artifactId>
//                          <scope>test</scope>
//                      </dependency>
//                  </dependencies>
// Nous pouvons désormais ajouter les annotations '@Entity' et '@Id' à la classe 'Product'. Modifiez donc la classe pour obtenir le code ci-après :
//                  package com.ecommerce.micrommerce.web.model;
//                  import com.fasterxml.jackson.annotation.JsonFilter;
//                  import javax.persistence.Entity;
//                  import javax.persistence.GeneratedValue;
//                  import javax.persistence.Id;
//                  //@JsonFilter("monFiltreDynamique")
//                  @Entity
//                  public class Product {
//                      @Id
//                      private int id;
//                      private String nom;
//                      private int prix;
//                      //information que nous ne souhaitons pas exposer
//                      private int prixAchat;
//                      ...
//                  }
//      --> Explications :
//              --> Vous annotez la classe avec '@Entity' afin qu'elle soit scannée et prise en compte.
//                      Il n'y a ainsi pas besoin de passer par le traditionnel (et complexe) fichier 'persistence.xml'.
//              --> Vous annotez l'attribut id avec '@Id' et '@GeneratedValue' afin qu'il soit identifié en tant que clé unique autogénérée.
//              --> Pensez à commenter '@JsonFilter("monFiltreDynamique")' pour pouvoir utiliser les autres méthodes qui n'ont pas de filtres.
// -----------
//  - Ajoutez une base de données :
// Dans un cas réel, notre microservice doit communiquer avec une base de données qui lui est dédiée, disponible sur un serveur distant.
// Pour nos tests, nous allons utiliser une base de données H2 qui est intégrable directement dans notre microservice.
//      --> H2 est une base de données très légère (1 Mo). Elle va créer les tables et les données uniquement en mémoire vive.
//              Une fois l'application fermée, ces données sont perdues.
//              Cette approche est très utile quand vous développez un microservice, car elle permet de refaire les tests autant de fois que nécessaire, en partant d'une base de données propre.
//              L'autre avantage est qu'elle est très simple à mettre en place, et complètement autoconfigurée par Spring Boot.
// Modifiez le fichier pom.xml afin d'ajouter H2, comme illustré ci-après :
//                  <dependencies>
//                      <dependency>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-web</artifactId>
//                      </dependency>
//                      <dependency>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-data-jpa</artifactId>
//                      </dependency>
//                      <dependency>
//                          <groupId>com.h2database</groupId>
//                          <artifactId>h2</artifactId>
//                          <scope>runtime</scope>
//                      </dependency>
//                      <dependency>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-test</artifactId>
//                          <scope>test</scope>
//                      </dependency>
//                  </dependencies>
// Actualisez Maven afin d'importer la dépendance. Nous allons maintenant modifier 'application.properties' afin de remplacer les configurations par défaut.
// Et par conséquent demander à Spring d'afficher les requêtes SQL et d'activer l'interface graphique H2, ce qui permettra de visualiser nos tables.
// Complétez le fichier 'application.properties' afin d''obtenir le fichier suivant :
//                  server.port 9090
//                  spring.jpa.show-sql=true
//                  spring.h2.console.enabled=true
//                  spring.datasource.url=jdbc:h2:mem:testdb
//                  spring.datasource.driverClassName=org.h2.Driver
//                  spring.datasource.username=sa
//                  spring.datasource.password=
//                  spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
//                  spring.jpa.hibernate.ddl-auto=none
//      --> L'entité et la base de données sont désormais prêtes à l'emploi !
// Il nous reste une dernière étape : configurer la table 'Product' qui va être créée pour qu'elle contienne des données par défaut.
// Créez tout simplement un fichier 'data.sql' dans le dossier 'resources' et écrivez les requêtes SQL nécessaires à l'insertion de vos données.
// Dans notre cas, nous allons utiliser les mêmes données que nous avions écrites en dur dans le DAO :
//                  INSERT INTO product VALUES(1, 'Ordinateur portable' , 350, 120);
//                  INSERT INTO product VALUES(2, 'Aspirateur Robot' , 500, 200);
//                  INSERT INTO product VALUES(3, 'Table de Ping Pong' , 750, 400);
// Nous avons aussi besoin de créer un fichier 'schema.sql' pour définir les tables de notre base de données.
//                  CREATE TABLE product (
//                      id INT PRIMARY KEY,
//                      nom VARCHAR(255) NOT NULL,
//                      prix INT NOT NULL,
//                      prix_achat INT NOT NULL
//                  );
// C'est tout ! Ce fichier sera récupéré automatiquement, puis exécuté dans la base de données une fois que la table sera créée.
// Redémarrez votre application et rendez-vous sur la console de H2 à l'adresse http://localhost:9090/h2-console/.
// Dans le champ JDBC URL, saisissez 'jdbc:h2:mem:testdb' afin de configurer la connexion vers la base de données 'testdb' située en mémoire vive.
// Cliquez ensuite sur 'Connect'. La console vous propose alors une interface permettant de visualiser la table 'PRODUCT'.
// Celle-ci a été créée grâce à l'annotation '@Entity' définie pour la classe 'Product'.
//      --> Cette table contient comme prévu les données de notre fichier 'data.sql'.
// -----------
//  - Utilisez Spring Data JPA :
//      - Créez un Repository et utilisez les opérations CRUD autogénérées :
//          Spring Data JPA est un autre framework de Spring, qui facilite grandement l'utilisation de JPA.
//          Il va nous permettre de générer toutes sortes d'opérations vers la base de données, sans que nous ayons à écrire la moindre requête, ni même la moindre implémentation DAO.
//          Il nous suffit d'hériter de l'interface 'JpaRepository'.
//              --> Rendez-vous dans le fichier 'ProductDao' et modifiez-le comme suit :
//                      package com.ecommerce.micrommerce.web.dao;
//                      import com.ecommerce.micrommerce.web.model.Product;
//                      import org.springframework.data.jpa.repository.JpaRepository;
//                      import org.springframework.stereotype.Repository;
//                      import java.util.List;
//                      @Repository
//                      public interface ProductDao extends JpaRepository<Product, Integer> {
//                          Product findById(int id);
//                      }
//          Quand vous héritez de 'JpaRepository', il faut indiquer comme premier paramètre l'entité concernée, puis le type d'Id. Dans ce cas, 'Product' et 'Integer'.
//      - Supprimez la classe 'ProductDaoImpl' qui n'est plus nécessaire :
//          Dans le contrôleur 'ProductController', commentez toutes les méthodes sauf 'listeProduits', afin que l'on puisse les modifier et les tester une à une :
//                      package com.ecommerce.microcommerce.web.controller;
//                      import com.ecommerce.microcommerce.dao.ProductDao;
//                      import com.ecommerce.microcommerce.model.Product;
//                      import com.fasterxml.jackson.databind.ser.FilterProvider;
//                      import com.fasterxml.jackson.databind.ser.impl.SimpleBeanPropertyFilter;
//                      import com.fasterxml.jackson.databind.ser.impl.SimpleFilterProvider;
//                      import org.springframework.beans.factory.annotation.Autowired;
//                      import org.springframework.http.ResponseEntity;
//                      import org.springframework.http.converter.json.MappingJacksonValue;
//                      import org.springframework.web.bind.annotation.*;
//                      import org.springframework.web.servlet.support.ServletUriComponentsBuilder;
//                      import java.net.URI;
//                      import java.util.List;
//                      @RestController
//                      public class ProductController {
//                          @Autowired
//                          private ProductDao productDao;
//                          //Récupérer la liste des produits
//                          @RequestMapping(value = "/Produits", method = RequestMethod.GET)
//                          public MappingJacksonValue listeProduits() {
//                              Iterable<Product> produits = productDao.findAll();
//                              SimpleBeanPropertyFilter monFiltre = SimpleBeanPropertyFilter.serializeAllExcept("prixAchat");
//                              FilterProvider listDeNosFiltres = new SimpleFilterProvider().addFilter("monFiltreDynamique", monFiltre);
//                              MappingJacksonValue produitsFiltres = new MappingJacksonValue(produits);
//                              produitsFiltres.setFilters(listDeNosFiltres);
//                              return produitsFiltres;
//                          }
//                          //Récupérer un produit par son Id
//                          /*  @GetMapping(value = "/Produits/{id}")
//                              public Product afficherUnProduit(@PathVariable int id) {
//                              return productDao.findById(id);
//                              }
//                              //ajouter un produit
//                              @PostMapping(value = "/Produits")
//                              public ResponseEntity<Void> ajouterProduit(@RequestBody Product product) {
//                                  Product productAdded =  productDao.save(product);
//                                  if (productAdded == null)
//                                      return ResponseEntity.noContent().build();
//                                  URI location = ServletUriComponentsBuilder
//                                      .fromCurrentRequest()
//                                      .path("/{id}")
//                                      .buildAndExpand(productAdded.getId())
//                                      .toUri();
//                                  return ResponseEntity.created(location).build();
//                              }
//                          */
//                          }
//          Parmi les opérations qu'offre 'JpaRepository', nous trouvons 'findAll()'' qui permet de récupérer toutes les données de l'entité concernée.
//              --> 'findAll()' retourne un 'Iterable', qu'il nous faut spécifier comme type de retour de la méthode.
//          Dans notre cas, le type de retour est bien un 'Iterable', puisque nous retournons une réponse filtrée de type 'MappingJacksonValue'.
//          Pour vérifier le bon fonctionnement, lancez votre application puis rendez-vous sur 'http://localhost:9090/Produits'.
//          Vous pouvez admirer le résultat, sorti tout droit de la base de données. Vous pouvez le vérifier en changeant une valeur dans celle-ci, comme illustré ci-dessous :
//                      [
//                          {
//                              "id": 1,
//                              "nom": "Ordinateur portable changé !!",
//                              "prix": 350
//                          },
//                          {
//                              "id": 2,
//                              "nom": "Aspirateur Robot",
//                              "prix": 500
//                          },
//                          {
//                              "id": 3,
//                              "nom": "Table de Ping Pong",
//                              "prix": 750
//                          }
//                      ]
//          Les autres principales opérations autogénérées que nous pouvons utiliser sont :
//              - 'delete(int id)' : supprime le produit correspondant à l'Id passé en argument.
//              - 'count()' : calcule le nombre de produits.
//              - 'save(Product produit)' : ajoute le produit passé en argument. Cette méthode peut également recevoir un 'Iterable<>' de produits pour ajouter plusieurs produits.
//          Vous pouvez consulter la liste complète ici : 'https://docs.spring.io/spring-data/jpa/docs/current/api/org/springframework/data/jpa/repository/JpaRepository.html'.
//      - Utilisez les requêtes générées par le nom de la méthode :
//          La magie de Spring Data va au-delà des requêtes CRUD.
//              --> Le framework est capable de générer la requête SQL automatiquement en partant du nom de votre méthode !
//          Prenons un exemple : tout d'abord, ajoutons cette méthode à notre Repository :
//                      @Repository
//                      public interface ProductDao extends JpaRepository<Product, Integer> {
//                          Product findById(int id);
//                      }
//          Puis retournons dans 'ProductController' et décommentons 'afficherUnProduit' :
//                      //Récupérer un produit par son Id
//                      @GetMapping(value = "/Produits/{id}")
//                      public Product afficherUnProduit(@PathVariable int id) {
//                          return productDao.findById(id);
//                      }
//          Une fois l'application démarrée, nous obtenons le bon résultat sans avoir écrit la moindre requête.
//              --> Mais comment est-ce possible ?
//          Les conventions ! Spring Data JPA propose un ensemble de conventions qui lui permettront de déduire la bonne requête à partir du nom de la méthode.
//              --> Vous avez ici l'ensemble des mots clés acceptés : 'https://docs.spring.io/spring-data/data-jpa/docs/1.1.x/reference/html/#jpa.query-methods.query-creation'.
//          Prenons comme exemple la récupération des produits dont le prix est supérieur à 400.
//          Commençons par ajouter une méthode 'findByPrixGreaterThan' au 'Repository', à l'intérieur de la définition de l'interface 'ProductDAO' :
//                      @Repository
//                      public interface ProductDao extends JpaRepository<Product, Integer> {
//                          Product findById(int id);
//                          List<Product> findByPrixGreaterThan(int prixLimit);
//                      }
//              --> Toute la logique est fournie par le nom de la méthode :
//                      - 'findBy' : indique que l'opération à exécuter est un 'SELECT'.
//                      - 'Prix' : fournit le nom de la propriété sur laquelle le 'SELECT' s'applique.
//                      - 'GreaterThan' : définit une condition "plus grand que".
//                      - La valeur à appliquer à la condition est, quant à elle, définie par le paramètre 'prixLimit'.
//          Cette méthode génère une requête équivalant au pseudo-code SQL suivant :
//                      select * from product where prix > [un chiffre ici]
//          Afin de mettre cette méthode en action, nous allons créer une méthode 'testDeRequetes' dans notre contrôleur :
//                      @GetMapping(value = "test/produits/{prixLimit}")
//                      public List<Product> testeDeRequetes(@PathVariable int prixLimit) {
//                          return productDao.findByPrixGreaterThan(400);
//                      }
//          Rendez-vous à l'adresse 'http://localhost:9090/test/produits/300'.
//          Vous pouvez constater que seuls les produits dont le prix est supérieur à 300 sont retournés.
//          Si vous souhaitez vérifier la requête générée, par curiosité ou afin de débugger, rendez-vous dans la console.
//          Le fait d'avoir ajouté précédemment 'spring.jpa.show-sql=true' à notre fichier 'application.properties' permet d'afficher l'ensemble des requêtes, comme illustré ci-après :
//              --> Hibernate : select product0_.id as id1_0_, product0_.nom as nom2_0_, product0_.prix as prix3_0_, product0_.prix_achat as prix_ach4_0_ from product product0_ where product0_.prix>?
//      - Implémentez POST, DELETE et PUT :
//              - POST :
//                  Pour gérer l'ajout de produit, il nous suffit de décommenter la méthode 'ajouterProduit'.
//                  Comme 'save()' fait partie des requêtes CRUD autogénérées par Spring Data, vous n'avez absolument rien à faire de plus.
//                  Démarrez votre application et rendez-vous dans Postman.
//                  Récupérez dans l'historique la requête POST que nous avons utilisée dans la partie précédente du cours, et exécutez-la.
//                  En bas à droite, vous voyez le code 201 vous indiquant que le produit a été créé.
//                  Rendez-vous dans la base de données pour vérifier qu'il a bien été ajouté.
//              - DELETE :
//                  Passons à DELETE. À nouveau, il n'y a rien à faire, à part créer la méthode dans notre contrôleur :
//                      @DeleteMapping (value = "/Produits/{id}")
//                      public void supprimerProduit(@PathVariable int id) {
//                          productDao.deleteById(id);
//                      }
//                  Cette fois, dans Postman, veillez à bien choisir DELETE comme type de requête, comme illustré ci-dessous.
//                  Vous pouvez ensuite vérifier que le produit 1 a bien été supprimé.
//              - PUT :
//                  Pour mettre à jour, la méthode est exactement comme pour POST, excepté que le produit passé en paramètre a le même Id qu'un produit existant :
//                      @PutMapping (value = "/Produits")
//                          public void updateProduit(@RequestBody Product product) {
//                              productDao.save(product);
//                          }
//                  Voilà, votre produit avec l'Id "1" a été mis à jour dans la base de données.
//      - Écrivez des requêtes à la main :
//          Soyons francs, il est parfois nécessaire d'exécuter des requêtes plus complexes qui ne peuvent pas être générées par ce système de conventions.
//          Pragmatique, Spring nous permet d'écrire une bonne requête artisanale à l'ancienne !
//              --> Pour cela, nous allons utiliser la notation JPA (JPQL).
//          En effet, il est hors de question d'utiliser un langage spécifique à une base de données, puisque notre microservice ne doit être couplé à aucun type de base de données.
//              --> L'annotation qui permet de le faire est '@Query'. Regardons un exemple :
//                      @Query("SELECT id, nom, prix FROM Product p WHERE p.prix > :prixLimit")
//                      List<Product> chercherUnProduitCher(@Param("prixLimit") int prix);
//          En paramètre de l'annotation, vous placez tout simplement votre requête JPQL.
//          L'annotation '@Param' permet de spécifier le nom du paramètre que vous allez recevoir.
//          Cette annotation est optionnelle. Si elle n'est pas utilisée, l'ordre dans lequel les arguments sont fournis est utilisé.
//          Vous aurez alors une requête de type :
//                      SELECT id, nom, prix FROM Product p WHERE p.prix > ?1
// -----------
//  - En résumé :
//      --> Nous avons découvert JPA pour interagir avec notre Database.
//      --> Nous avons créé une base de données embarquée avec H2.
// Nous allons nous attaquer à la validation des données.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Gérez les erreurs et validez les données //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Gérez les erreurs :
// Pour introduire la problématique, lançons dans Postman une requête GET vers 'http://localhost:9090/Produits/42' en indiquant l'Id d'un produit qui n'existe pas.
//      --> Étant donné que ce produit n'existe pas, cette requête ne fournit logiquement pas de réponse.
// Avez-vous prêté attention au code de statut retourné ?
//      --> Malgré l'absence de réponse, la requête a fourni un code de statut 200 OK.
// Celui-ci indique que la requête a réussi, c'est-à-dire que le serveur a pu être appelé et n'a retourné aucune erreur particulière.
// Or, ce comportement peut induire en erreur ou déboussoler tout service extérieur qui viendrait utiliser notre API.
// Pour remédier à ceci, nous allons générer une exception lorsqu'on ne trouve pas de produit :
//                  @GetMapping(value = "/Produits/{id}")
//                  public Product afficherUnProduit(@PathVariable int id) {
//                      Product produit = productDao.findById(id);
//                      if(produit==null) throw new ProduitIntrouvableException("Le produit avec l'id " + id + " est INTROUVABLE. Écran Bleu si je pouvais.");
//                      return produit;
//                  }
// Si la variable produits est null, nous lançons une exception 'ProduitIntrouvableException'.*
//      --> En effet, nous allons créer notre propre exception afin d'être le plus spécifique possible.
// Dans IntelliJ, 'ProduitIntrouvableException' devrait être rouge car il n'y a pas de classe de ce nom.
// Cliquez sur 'ProduitIntrouvableException' et une lampe rouge s'affiche à gauche, vous proposant de créer cette exception automatiquement : 'com.ecommerce.microcommerce.web.exceptions'.
// Un nouveau package est créé avec la nouvelle classe.
// Modifiez cette classe afin qu'elle hérite de 'RuntimeException'.
// Passez ensuite le message reçu en argument via notre exception et vers la classe parent, pour qu'elle l'intègre dans l'affichage de l'erreur. Voici notre exception finale :
//                  package com.ecommerce.microcommerce.web.exceptions;
//                  public class ProduitIntrouvableException extends RuntimeException {
//                      public ProduitIntrouvableException(String s) {
//                          super(s);
//                      }
//                  }
// Relancez maintenant votre requête GET sur Postman, vous obtenez donc une erreur en bonne et due forme avec notre petit message personnel.
// Tout ça est bien joli, mais il y a encore quelque chose qui cloche. Est-ce que vous le voyez ?
//      --> Il s'agit de l'erreur renvoyée : 500 Internal Server Error.
// Or, nous n'avons aucun problème de serveur, le problème est que la ressource recherchée est introuvable.
//      --> Il nous faut donc retourner le code de statut adapté : 404 Not Found.
// Nous allons donc modifier notre exception afin qu'elle renvoie le bon code.
// À cet effet, Spring fournit l'annotation '@ResponseStatus' qui définit le code de statut associé à l'exception. Modifiez donc votre code comme suit :
//                  package com.ecommerce.microcommerce.web.exceptions;
//                  import org.springframework.http.HttpStatus;
//                  import org.springframework.web.bind.annotation.ResponseStatus;
//                  @ResponseStatus(HttpStatus.NOT_FOUND)
//                  public class ProduitIntrouvableException extends RuntimeException {
//                      public ProduitIntrouvableException(String s) {
//                          super(s);
//                      }
//                  }
// L'annotation désigne le code d'erreur à renvoyer parmi la liste de tous les codes possibles.
// Vous pouvez d'ailleurs afficher ces codes dans IntelliJ grâce à l'assistant de code.
// Redémarrez et retestez avec Postman.
// Vous renvoyez ainsi un message d'erreur explicite avec le bon code HTTP.
// -----------
//  - Effectuez les validations :
// Jusqu'ici, lorsque nous créons un nouveau 'Produit' grâce à la méthode 'ajouterProduit', nous  ne vérifions à aucun moment que les données sur le produit sont correctes.
//      --> Par exemple, la longueur du nom du produit doit être supérieure à 3 caractères, et le prix ne doit jamais être défini à 0 (rien n'est gratuit).
// Spring propose de valider les données grâce à une dépendance 'spring-boot-starter-validation' que je vous laisse ajouter à votre POM :
//                  <dependency>
//                      <groupId>org.springframework.boot</groupId>
//                      <artifactId>spring-boot-starter-validation</artifactId>
//                      <version>2.6.0</version>
//                  </dependency>
// Cette librairie va vous permettre de valider les données grâce à de simples annotations.
// Modifions la classe 'Product' en ajoutant les annotations '@Length' et '@Min', comme suit :
//                  package com.ecommerce.micrommerce.web.model;
//                  import javax.persistence.Entity;
//                  import javax.persistence.Id;
//                  import javax.validation.constraints.Min;
//                  import javax.validation.constraints.Size;
//                  //@JsonFilter("monFiltreDynamique")
//                  @Entity
//                  public class Product {
//                      @Id
//                      private int id;
//                      @Size(min = 3, max = 25)
//                      private String nom;
//                      @Min(value = 1)
//                      private int prix;
//                      ...
//                  }
// Explications :
//      - '@Size' : accepte en argument un minimum et un maximum, et vérifie donc si la longueur de la chaîne est conforme.
//      - '@Min' : définit la valeur minimale.
// Vous trouverez ici une liste non exhaustive des validations possibles : 'https://docs.jboss.org/hibernate/annotations/3.4/reference/fr/html/validator.html'.
// Et vous trouverez ici la documentation avec l'ensemble des possibilités :'https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#preface'.
// Il nous faut également indiquer dans notre contrôleur que le produit reçu de l'utilisateur est à valider. Pour ce faire, il faut ajouter l'annotation '@Valid', comme illustré ci-après :
//                  public ResponseEntity<Void> ajouterProduit(@Valid @RequestBody Product product) {
//                      ...
//                  }
// Lancez un POST depuis Postman pour tester.
//      --> Vous voyez le bon code d'erreur : 400 Bad Request.
// -----------
//  - En résumé :
//      --> Nous savons générer nos entités avec '@Valid'.
// Nous allons maintenant documenter notre API avec Swagger.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Documentez votre microservice avec Swagger 2 //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Contrairement à la SOA, des contrats de type WSDL (Web Services Description Language) sont rarement utilisés dans une architecture Microservices.
// C'est pour cela qu'il est primordial d'avoir une documentation standardisée et de très bonne qualité.
//      --> À partir de votre code, Swagger est capable de générer une documentation détaillée au format JSON, répondant aux spécifications OpenAPI.
//      --> Il vous offre également la possibilité de visualiser cette documentation dans un format HTML élégant.
// Afin de bénéficier de Swagger, nous allons importer cette dépendance dans notre pom.xml :
//                  <dependency>
//                      <groupId>io.springfox</groupId>
//                      <artifactId>springfox-boot-starter</artifactId>
//                      <version>3.0.0</version>
//                  </dependency>
// Pour générer la documentation, il faut placer l'annotation '@EnableSwagger2' dans la classe contenant avec la méthode 'Main'. Dans notre cas, il s'agit de 'MicrocommerceApplication'.
//                  package com.ecommerce.micrommerce;
//                  import org.springframework.boot.SpringApplication;
//                  import org.springframework.boot.autoconfigure.SpringBootApplication;
//                  import org.springframework.data.jpa.repository.config.EnableJpaRepositories;
//                  import springfox.documentation.swagger2.annotations.EnableSwagger2;
//                  @SpringBootApplication
//                  @EnableSwagger2
//                  public class MicrommerceApplication {
//                      public static void main(String[] args) {
//                          SpringApplication.run(MicrommerceApplication.class, args);
//                      }
//                  }
// Il faut aussi ajouter cette ligne dans application properties :
//                  spring.mvc.pathmatch.matching-strategy=ant_path_matcher
// Celle-ci permettra de donner toutes les informations nécessaires à Swagger.
// Redémarrez votre application et rendez-vous sur 'http://localhost:9090/v2/api-docs'.
//      --> Vous obtenez alors la documentation complète de votre microservice, générée au format JSON.
// Vous pouvez également accéder à une version au format HTML à l'adresse suivante : 'http://localhost:9090/swagger-ui/'.
// Dans cette version HTML de la documentation générée par Swagger, nous retrouvons toutes les méthodes que nous avons définies.
// En cliquant sur une méthode, nous retrouvons les détails sur :
//      - le type de données qu'elle accepte en entrée et qu'elle produit en retour.
//      - Un exemple d'une réponse typique.
//      - Tous les codes d'erreur qu'elle peut générer.
// -----------
// ATTENTION : Swagger ne fonctionne pas avec SpringBoot 3 !
// -----------
//  - Configurez Swagger :
// Ce niveau de documentation peut sembler suffisant, mais dans une application professionnelle, il peut être utile de la personnaliser de multiples manières.
// Nous allons donc voir comment créer une classe de configuration pour Swagger.
// Créez une classe 'SwaggerConfig' dans un nouveau package appelé 'configuration',  et écrivez le code suivant :
//                  package com.ecommerce.micrommerce.configuration;
//                  import org.springframework.context.annotation.Bean;
//                  import org.springframework.context.annotation.Configuration;
//                  import springfox.documentation.builders.PathSelectors;
//                  import springfox.documentation.builders.RequestHandlerSelectors;
//                  import springfox.documentation.spi.DocumentationType;
//                  import springfox.documentation.spring.web.plugins.Docket;
//                  import springfox.documentation.swagger2.annotations.EnableSwagger2;
//                  @Configuration
//                  @EnableSwagger2
//                  public class SwaggerConfig {
//                      @Bean
//                      public Docket api() {
//                          return new Docket(DocumentationType.SWAGGER_2)
//                                 .select()
//                                 .apis(RequestHandlerSelectors.any())
//                                 .paths(PathSelectors.any())
//                                 .build();
//                      }
//                  }
// Explications :
// L'annotation '@Configuration' appliquée à la classe permet de remplacer un fichier de configuration classique en XML.
// Elle nous donne accès à plusieurs méthodes très intéressantes pour la personnalisation de Swagger, grâce à la classe 'Docket' qui gère toutes les configurations.
// On commence alors par initialiser un objet Docket en précisant que nous souhaitons utiliser Swagger 2.
//      --> 'select' permet d'initialiser une classe du nom de ApiSelectorBuilder qui donne accès aux méthodes de personnalisation suivantes.
//              Ne vous attardez pas sur cette méthode, elle n'est d'aucune utilité pour la suite.
//      --> 'apis' est la première méthode importante. Elle permet de filtrer la documentation à exposer selon les contrôleurs.
//              Ainsi, vous pouvez cacher la documentation d'une partie privée ou interne de votre API. Dans ce cas, nous avons utilisé 'RequestHandlerSelectors.any()'.
//      --> 'RequestHandlerSelectors' est un prédicat (introduit depuis Java 8) qui permet de retourner TRUE ou FALSE selon la condition utilisée.
//              Dans ce cas, nous avons utilisé any qui retournera toujours TRUE.
//              En d'autres termes, nous indiquons vouloir documenter toutes les classes dans tous les packages.
//              RequestHandlerSelectors offre plusieurs autres méthodes, comme 'annotationPresent' qui vous permet de définir une annotation en paramètre.
//              Swagger ne documente alors que les classes qu'il utilise. La plus utilisée est 'basePackage' qui permet de trier selon le Package. Nous allons voir un exemple juste après.
//      --> 'paths' : cette méthode donne accès à une autre façon de filtrer : selon l'URI des requêtes.
//              Ainsi, vous pouvez, par exemple, demander à Swagger de ne documenter que les méthodes qui répondent à des requêtes commençant par "/public".
// Appliquons tout cela à notre API pour mieux comprendre.
// Vous avez certainement remarqué que la documentation contient le contrôleur d'erreur de Spring.
// Ce contrôleur n'a rien à faire dans notre documentation, nous allons donc utiliser les filtres pour l'éliminer :
//                  package com.ecommerce.micrommerce.configuration;
//                  import org.springframework.context.annotation.Bean;
//                  import org.springframework.context.annotation.Configuration;
//                  import springfox.documentation.builders.PathSelectors;
//                  import springfox.documentation.builders.RequestHandlerSelectors;
//                  import springfox.documentation.spi.DocumentationType;
//                  import springfox.documentation.spring.web.plugins.Docket;
//                  import springfox.documentation.swagger2.annotations.EnableSwagger2;
//                  @Configuration
//                  @EnableSwagger2
//                  public class SwaggerConfig {
//                      @Bean
//                      public Docket api() {
//                          return new Docket(DocumentationType.SWAGGER_2)
//                                      .select()
//                                      .apis(RequestHandlerSelectors.basePackage("com.ecommerce.micrommerce.web"))
//                                      .paths(PathSelectors.any())
//                                      .build();
//                       }
//                   }
// Nous utilisons la méthode 'basePackage' du prédicat 'RequestHandlerSelectors' afin de demander à Swagger de ne rien documenter en dehors du package "web" qui contient notre code.
// Si vous redémarrez votre application, vous verrez que 'basic-error-controller' a disparu.
// Nous avons créé, dans le chapitre sur Spring Data JPA, une méthode de test qui répond à l'URL '/test/produits/{prix}'.
// Éliminons-la de la documentation grâce à la méthode paths :
//                  @Configuration
//                  @EnableSwagger2
//                  public class SwaggerConfig {
//                      @Bean
//                      public Docket api() {
//                          return new Docket(DocumentationType.SWAGGER_2)
//                              .select()
//                              .apis(RequestHandlerSelectors.basePackage("com.ecommerce.microcommerce.web"))
//                              .paths(PathSelectors.regex("/Produits.*"))
//                              .build();
//                      }
//                  }
//      --> 'PathSelectors.regex("/Produits.*")' permet de passer une expression régulière qui n'accepte que les URI commençant par '/Produits'.
// Actualisez : la méthode de test a disparu.
// -----------
//  - Personnalisez la documentation grâce aux annotations :
// La dépendance Swagger que nous avons utilisée nous donne accès à un certain nombre d'annotations pour personnaliser la documentation directement dans nos classes.
// Nous pouvons ainsi ajouter une description pour chaque API grâce à l'annotation '@Api', comme illustré ci-après :
//                  @Api("API pour les opérations CRUD sur les produits.")
//                  @RestController
//                  public class ProductController {
//                      ...
//                  }
// Nous pouvons également définir une description pour chaque opération/méthode à l'aide de l'annotation '@ApiOperation' :
//                  //Récupérer un produit par son Id
//                  @ApiOperation(value = "Récupère un produit grâce à son ID à condition que celui-ci soit en stock!")
//                  @GetMapping(value = "/Produits/{id}")
//                  public Product afficherUnProduit(@PathVariable int id) {
//                      ...
//                  }
// Vous trouverez ici dans la documentation toutes les annotations possibles : 'https://springfox.github.io/springfox/docs/current/#docket-spring-java-configuration'.
// -----------
//  - En résumé :
//      --> Nous pouvons maintenant documenter notre API grâce à Swagger.
// Ça y est, vous avez tous les éléments pour créer vos microservices ! Dans le prochain chapitre, vous allez compléter notre application !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Entraînez-vous en améliorant et en testant un microservice ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - À vous de jouer !
// Pour vous entraîner, réalisez cet exercice étape par étape. Une fois terminé, vous pouvez comparer votre travail avec les pistes que je vous propose.
//      - Améliorez et testez le projet vu en cours !
//          Pour cette activité, vous allez reprendre et améliorer le projet du cours.
//          Dans un premier temps, forkez et clonez le projet depuis GitHub : 'https://github.com/OpenClassrooms-Student-Center/4668056-Construisez-des-Microservices/tree/P2C3'.
//          Vous devez bien avoir forké le projet avant de le cloner.
//          Cette opération copie le projet dans votre compte GitHub, et vous permet de pousser les commits résultant de votre travail.
//          Puis implémentez les 2 méthodes suivantes dans 'ProductController.java' :
//              --> 'calculerMargeProduit', qui calcule la marge de chaque produit (différence entre prix d‘achat et prix de vente).
//              --> 'trierProduitsParOrdreAlphabetique' qui retournera la liste de tous les produits triés par nom croissant.
//          Ensuite, ajoutez à la méthode 'ajouterProduit' une condition afin de vérifier que le prix de vente n’est pas égal à 0.
//          Enfin, testez les 2 méthodes créées avec Postman.
//      - Suivez ces consignes pour la réalisation :
//          À la fin de chaque partie, créez un commit et poussez-le vers votre projet GitHub.
//              - Partie 1 – Affichage de la marge :
//                  La méthode 'calculerMargeProduit' doit répondre à une requête GET sur l’URI '/AdminProduits'.
//                  Les données doivent être récupérées depuis la base de données mise en place dans le projet.
//                  Voici un exemple de réponse attendue :
//                      {
//                          "Product{id=1, nom='Ordinateur portable', prix=350}": 230,
//                          "Product{id=2, nom='Aspirateur Robot', prix=500}": 300,
//                          "Product{id=3, nom='Table de Ping Pong', prix=750}": 350
//                      }
//              - Partie 2 – Tri par ordre alphabétique :
//                  La méthode 'trierProduitsParOrdreAlphabetique' doit impérativement faire appel à une méthode que vous allez ajouter dans 'ProductDao'.
//                  Cette dernière utilisant le nommage conventionné de Spring Data JPA pour générer automatiquement les requêtes.
//                  Voici le résultat à obtenir avec le contenu de la base de données du cours :
//                      {
//                          {
//                              "id": 2,
//                              "nom": "Aspirateur Robot",
//                              "prix": 500,
//                              "prixAchat": 200
//                          },
//                          {
//                              "id": 1,
//                              "nom": "Ordinateur portable",
//                              "prix": 350,
//                              "prixAchat": 120
//                          },
//                          {
//                              "id": 3,
//                              "nom": "Table de Ping Pong",
//                              "prix": 750,
//                              "prixAchat": 400
//                          }
//                      }
//          - Partie 3 – Validation du prix de vente :
//              Si le prix de vente est de 0, lancez une exception du nom de 'ProduitGratuitException' (à créer).
//              Celle-ci retournera le bon code HTTP pour ce cas, avec un message explicatif à définir.
//          - Partie 4 – Test des méthodes créées :
//              Suivez les étapes suivantes pour écrire la collection, l'exécuter et fournir le résultat pour votre testeur :
//                  - Créez un dossier 'TestsPostman' à la racine de votre projet.
//                  - Dans Postman, créez une collection pour définir vos tests.
//                  - Faites une capture d'écran du résultat de l'exécution de la collection.
//                  - Exportez la collection au format JSON dans le dossier 'TestsPostman'.
//                  - Commitez et poussez vers le dépôt GitHub.
//      - Rendez ces livrables :
//          Vérifiez bien que vous avez les éléments suivants :
//              --> Les captures d'écran résultant de l'exécution des collections Postman.
//              --> Un fichier README.txt contenant l'URL du dépôt Git contenant votre code à jour.
// -----------
//  - Vérifiez votre travail :
// Alors, vous êtes allé au bout ? Suivez le guide pour vérifier votre travail !
//      - Créez une opération REST de type GET dans un microservice :
//          Ouvrez le fichier README.txt contenant l'URL du projet.
//          Clonez le projet sur votre machine et ouvrez le fichier 'ProductController.java'.
//          Lancez le programme et accédez à l’URI 'http://localhost:9090/AdminProduits'.
//          Vérifiez que les critères suivants sont correctement appliqués :
//              --> La classe 'ProductController' contient une méthode 'calculerMargeProduit'.
//              --> La méthode est correctement annotée, par exemple avec '@GetMapping' ou '@RequestMapping'.
//              --> Les données sont récupérées depuis la base de données via la couche DAO, par exemple en utilisant 'productDao.findAll()'.
//              --> Un Iterable est retourné, fournissant pour chaque clé le Produit et comme valeur associée la marge calculée.
//                      L'Iterable peut par exemple être un HashMap, ou une classe personnalisée.
//              --> L'appel de l'URI 'http://localhost:9090/AdminProduits' retourne bien le JSON attendu (si le port utilisé est différent, adaptez l'URI).
//      - Implémentez une Exception personnalisée pour le code de statut dans un microservice :
//          Vous allez évaluer la capacité à implémenter une exception personnalisée permettant de renvoyer le code HTTP adapté à la situation.
//          Vérifiez que les critères suivants sont correctement appliqués :
//              --> Une classe est créée dans le package 'com.ecommerce.microcommerce.web.exceptions;' pour implémenter l'exception.
//              --> La classe définissant l'exception est annotée avec '@ResponseStatus(HttpStatus.BAD_REQUEST)'.
//              --> Le constructeur de la classe passe le message à la classe parent avec 'super(...)'.
//              --> Dans la classe 'ProductController', un code est ajouté à la méthode 'ajouterProduit'. Ce code lance l'exception si 'productAdded.getPrix() == 0'.
//              --> L'ajout d'un produit avec un prix fixé à 0 génère bien le code de statut attendu.
//      - Mettez en œuvre une requête générée automatiquement par Spring Data JPA :
//          Vous allez maintenant valider la capacité à créer une méthode en utilisant des mots clés, afin que Spring Data JPA génère automatiquement la requête.
//          Pour cela, dans 'ProductDAO.java', vérifiez qu'une méthode a été ajoutée à 'ProductDAO.java'.
//          Vérifiez que les critères suivants sont correctement appliqués :
//              --> La classe 'ProductDAO' contient une méthode respectant le nommage conventionné, comme par exemple 'List<Product> findAllByOrderByNom();'.
//                      Cette méthode ne définit pas de requête explicite en JPQL.
//              --> La classe 'ProductController' contient une méthode 'trierProduitsParOrdreAlphabetique()' correctement annotée, par exemple avec '@GetMapping' ou '@RequestMapping'.
//              --> L'appel de l'URI 'http://localhost:9090/TriProduits' retourne bien les produits issus de la base de données, au format JSON.
//                      Ces derniers, triés par ordre alphabétique du nom (si le port utilisé est différent, adaptez l'URI).
//      - Testez un microservice avec Postman :
//          Récupérez la collection Postman qui doit se trouver dans le dossier 'TestsPostman' du dépôt que vous avez cloné.
//          Vérifiez que les critères suivants sont correctement appliqués :
//              --> L'import dans Postman fonctionne.
//              --> Les tests se lancent et affichent le résultat attendu.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Optimisez votre architecture Microservices ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Vous avez développé vos microservices, et votre application est fonctionnelle. Plusieurs questions peuvent à présent se poser, par exemple :
//      --> Comment sécuriser votre application ?
//      --> Comment équilibrer la charge entre les microservices sans pour autant se reposer sur un équilibreur central ?
//      --> Comment débugger ?
//      --> Comment faire communiquer les microservices entre eux plus facilement ?
// Toutes ces questions sont adressées par un type spécial de microservice appelé Edge Microservice.
// Dans ce cours, vous allez découvrir comment construire une application scalable et facilement maintenable.
// Et ce, grâce à un ensemble d'outils open source qui s'intégreront très simplement dans votre application.
// À la fin de ce cours, vous serez capable de :
//      - Construire les microservices d’une application.
//      - Mettre en oeuvre les Edge Microservices.
//      - Débugger et maintenir des microservices.
// Pour pouvoir suivre ce cours, vous devez savoir :
//      --> Créer un Microservice grâce à Spring Boot.
//      --> Communiquer avec une base de données grâce à Spring Data JPA.
//      --> Gérer et générer les exceptions dans les Microservices.
// -----------
// https://github.com/OpenClassrooms-Student-Center/4668216-Optimisez-votre-architecture-Microservices.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Construisez les microservices d'une petite application ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez les microservices e-commerce et leur client /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Mettez en place l'application "Mcommerce" :
// Afin de vous aider à mieux comprendre les Edge Microservices, nous allons commencer par créer une petite application e-commerce ultraminimaliste que nous allons appeler "Mcommerce".
// Cette application est composée de 3 microservices :
//      - Microservice-produits : ce microservice gère le produit. Il propose 2 opérations simples : lister tous les produits, et récupérer un produit par son ID.
//      - Microservice-commandes : microservice de gestion des commandes. Il permet de passer une commande et de récupérer une commande par son ID.
//      - Microservice-paiements : ce microservice permet de simuler le paiement d'une commande.
//          Une fois le paiement enregistré, il fait appel au Microservice-commandes pour mettre à jour le statut de la commande.
// Nous allons commencer par mettre en place notre application dans IntelliJ IDEA.
// Retrouvez notre application dans ce dépôt GIT : 'https://github.com/OpenClassrooms-Student-Center/4668216-Optimisez-votre-architecture-Microservices'.
// Commencez par cloner le projet vers un dossier de votre choix : 'git clone'.
// Une fois le projet cloné, cliquez sur "Import Project", puis sélectionnez le dossier "mcommerce".
// Sélectionnez "Create project from existing sources" et sélectionnez un pom.
// Puis sélectionnez Module from Existing Sources.
// Cette forme de projet , assez spéciale dans IntelliJ, fait que le projet est constitué de plusieurs modules. Ces modules sont des microservices, dans notre cas.
// L'avantage est que chaque module est un projet en soi.
// Il a ses propres dépendances, ses propres fichiers de configuration et surtout, vous allez pouvoir les exécuter tous simultanément, comme si vous aviez ouvert trois projets IntelliJ différents.
// Vous pourrez ainsi avoir votre projet localisé à un seul endroit, tout en gardant vos microservices parfaitement isolés.
// Vous pourrez également les lancer dans la même fenêtre et les faire communiquer, sans jongler entre plusieurs projets IntelliJ différents.
// Changez de branche dans le projet vers "TestBranch", spécialement créé pour que vous puissiez vous familiariser avec le passage de branche en branche (non, je ne parle pas de singes) dans IntelliJ.
// Tout en bas à droite, sélectionnez 'origin/TestBranch' -> Checkout as new local branch.
// Nommez ensuite du même nom votre copie de cette branche "TestBranch" dans la boîte de dialogue qui s'ouvre.
// Vous êtes désormais sur la branche "TestBranch". Vérifiez que c'est bien le cas, en bas à droite.
// -----------
//  - Explorez l'application :
// Nous allons analyser les différents microservices afin que vous soyez à l'aise pour les manipuler durant le cours.
// Je vous conseille vivement de créer un autre projet à part dans lequel vous clonerez le dépôt, et sur lequel vous allez écrire le code que je vous donnerai durant le cours.
// Le premier projet que vous avez créé plus haut doit servir surtout à voir et à analyser la version du cours, pour pouvoir reproduire les concepts.
// Tous ces microservices ont en commun :
//      --> L'utilisation de Spring Data JPA pour la communication avec la base de données.
//      --> Une base de données en mémoire de type H2.
//      --> Les mêmes paramètres dans le fichier 'application.properties' :
//                  server.port 9001 #Configurations H2 spring.jpa.show-sql=true
//                  spring.h2.console.enabled=true #défini l'encodage pour data.sql
//                  spring.datasource.sql-script-encoding=UTF-8
// Seul 'server.port' change. Chaque microservice a son propre port.
// -----------
//  - Analysez le Microservice Produits :
// Ce microservice permet une gestion très basique des produits.
//                  package com.mproduits.web.controller;
//                  import com.mproduits.dao.ProductDao;
//                  import com.mproduits.model.Product;
//                  import com.mproduits.web.exceptions.ProductNotFoundException;
//                  import org.springframework.web.bind.annotation.GetMapping;
//                  import org.springframework.web.bind.annotation.PathVariable;
//                  import org.springframework.web.bind.annotation.RestController;
//                  import java.util.List;
//                  import java.util.Optional;
//                  @RestController
//                  public class ProductController {
//                    private final ProductDao productDao;
//                    public ProductController(ProductDao productDao){
//                        this.productDao = productDao;
//                    }
//                    // Affiche la liste de tous les produits disponibles
//                    @GetMapping(value = "/Produits")
//                    public List<Product> listeDesProduits(){
//                        List<Product> products = productDao.findAll();
//                        if(products.isEmpty()) throw new ProductNotFoundException("Aucun produit n'est disponible à la vente");
//                        return products;
//                    }
//                    //Récuperer un produit par son id
//                    @GetMapping( value = "/Produits/{id}")
//                    public Optional<Product> recupererUnProduit(@PathVariable int id) {
//                        Optional<Product> product = productDao.findById(id);
//                        if(!product.isPresent())  throw new ProductNotFoundException("Le produit correspondant à l'id " + id + " n'existe pas");
//                        return product;
//                    }
//                  }
// Microservice-produits écoute le port 9001. Il est constitué des éléments suivants :
//      - La méthode 'listeDesProduits', qui permet la récupération de la liste de tous les produits.
//      - La méthode 'recupererUnProduit', qui permet de récupérer un produit par son ID.
//      - Une exception 'ProductNotFoundException', qui renvoie le code 404 si le ou les produits ne sont pas trouvés.
//      - Le fichier 'data.sql', qui permet de préremplir automatiquement la base de données avec plusieurs produits, afin de pouvoir faire des tests.
// -----------
//  - Analysez le Microservice Commandes :
// Ce microservice permet de passer des commandes et d'en récupérer :
//                  package com.mcommandes.web.controller;
//                  import com.mcommandes.dao.CommandesDao;
//                  import com.mcommandes.model.Commande;
//                  import com.mcommandes.web.exceptions.CommandeNotFoundException;
//                  import com.mcommandes.web.exceptions.ImpossibleAjouterCommandeException;
//                  import org.springframework.beans.factory.annotation.Autowired;
//                  import org.springframework.http.HttpStatus;
//                  import org.springframework.http.ResponseEntity;
//                  import org.springframework.web.bind.annotation.*;
//                  import java.util.Optional;
//                  @RestController
//                  public class CommandeController {
//                    private final CommandesDao commandesDao;
//                    public CommandeController(CommandesDao commandesDao){
//                        this.commandesDao = commandesDao;
//                    }
//                    @PostMapping (value = "/commandes")
//                    public ResponseEntity<Commande> ajouterCommande(@RequestBody Commande commande){
//                        Commande nouvelleCommande = commandesDao.save(commande);
//                        if(nouvelleCommande == null) throw new ImpossibleAjouterCommandeException("Impossible d'ajouter cette commande");
//                        return new ResponseEntity<Commande>(commande, HttpStatus.CREATED);
//                    }
//                    @GetMapping(value = "/commandes/{id}")
//                    public Optional<Commande> recupererUneCommande(@PathVariable int id){
//                        Optional<Commande> commande = commandesDao.findById(id);
//                        if(!commande.isPresent()) throw new CommandeNotFoundException("Cette commande n'existe pas");
//                        return commande;
//                    }
//                  }
// Microservice-commandes écoute le port 9002. Il est constitué des éléments suivants :
//      - La méthode 'ajouterCommande', qui  permet l'ajout d'une commande via un POST.
//      - La méthode 'recupererUneCommande', qui  récupère une commande via son ID.
//          'Optional' permet de ne plus vérifier si l'objet est null à chaque fois, et évite les 'NullPointerExceptions'.
//          Vous pouvez en savoir plus ici. 'isPresent' vérifie que l'objet commande existe et n'est pas vide.
//      - L'exception 'ImpossibleAjouterCommandeException', qui est déclenchée en dernier recours quand on n'arrive pas à enregistrer la commande pour cause d'erreur interne.
//          Le code renvoyé est alors 500.
//      - L'exception 'CommandeNotFoundException', qui renvoie le code 404 lorsqu'une commande n'est pas trouvée.
// -----------
//  - Analysez le Microservice Paiement :
// Ce microservice reçoit l'ID d'une commande, le montant et le numéro de la carte bancaire, puis enregistre le paiement dans la base de données :
//                  package com.mpaiement.web.controller;
//                  import com.mpaiement.dao.PaiementDao;
//                  import com.mpaiement.model.Paiement;
//                  import com.mpaiement.web.exceptions.PaiementExistantException;
//                  import com.mpaiement.web.exceptions.PaiementImpossibleException;
//                  import org.springframework.http.HttpStatus;
//                  import org.springframework.http.ResponseEntity;
//                  import org.springframework.web.bind.annotation.*;
//                  @RestController
//                  public class PaiementController {
//                    private final PaiementDao paiementDao;
//                    public PaiementController(PaiementDao paiementDao){
//                        this.paiementDao = paiementDao;
//                    }
//                    @PostMapping(value = "/paiement")
//                    public ResponseEntity<Paiement>  payerUneCommande(@RequestBody Paiement paiement){
//                        //Vérifions s'il y a déjà un paiement enregistré pour cette commande
//                        Paiement paiementExistant = paiementDao.findByidCommande(paiement.getIdCommande());
//                        if(paiementExistant != null) throw new PaiementExistantException("Cette commande est déjà payée");
//                        //Enregistrer le paiement
//                        Paiement nouveauPaiement = paiementDao.save(paiement);
//                        if(nouveauPaiement == null) throw new PaiementImpossibleException("Erreur, impossible d'établir le paiement, réessayez plus tard");
//                        //Nous allons appeler le Microservice Commandes ici pour lui signifier que le paiement est accepté
//                        return new ResponseEntity<Paiement>(nouveauPaiement, HttpStatus.CREATED);
//                    }
//                  }
// Il dispose d'une seule opération : 'payerUneCommande'. Une commande ne peut être payée qu'une seule fois, on vérifie alors si le paiement à effectuer n'a pas déjà eu lieu.
//      --> Pour cela, nous devons chercher s'il y a un paiement correspondant à l'ID de commande 'idCommande'. On crée donc une méthode dans 'PaiementDao' :
//                  Paiement findByidCommande(int idCommande);
// Si un paiement précédent est trouvé, on déclenche l'exception 'PaiementExistantException'.
// Cette exception renvoie un code particulier, '409 CONFLICT', qui indique que les données reçues entrent en conflit avec des données existantes.
//      --> En cas d'impossibilité d'enregistrer le paiement, le code 500 est renvoyé.
//      --> En cas de succès, le code 201 Created est renvoyé, avec le contenu du paiement enregistré.
// -----------
//  - Découvrez ce que nous allons faire avec ces microservices :
// Voici les 7 étapes décrites dans un diagramme de l'application finale que nous souhaitons développer :
//      - 1 : Proposition des produits.
//      - 2 : Sélection d'un produit.
//      - 3 : Commande du produit.
//      - 4 : Récupération de la commande.
//      - 5 : Demande de paiement.
//      - 6 : Statut du paiement.
//      - 7 : Confirmation.
// L'application que nous allons mettre en place ici est très basique, largement optimisable, mais elle a l'avantage de nous faire décortiquer, étape par étape, son fonctionnement.
// Nous allons faire l'impasse sur la gestion des erreurs, les validations et plein d'autres concepts que vous pouvez voir ou revoir dans le cours précédent sur le microservice.
// -----------
//  - Créez un client :
// Nous allons maintenant créer notre squelette du client qui ira consommer nos microservices.
// Pour créer une interface graphique, nous allons utiliser Thymeleaf comme moteur de template.
// Pour cela, nous allons créer une nouvelle branche nommée Thymeleaf.
// Nous allons commencer par créer un client très minimaliste afin que vous vous familiarisiez avec l'utilisation de Thymeleaf (pour ceux qui ne connaissent pas), puis nous allons l'enrichir.
// Commencez par créer un projet sur Spring Initializr, nommez-le client-ui, puis cochez "Web" et "Thymeleaf".
// Rendez-vous dans IntelliJ, et importez le projet comme nouveau module.
// Créez un nouveau contrôleur "ClientController" sous un package "controller".
// Voici donc notre contrôleur :
//                  package com.clientui.controller;
//                  import org.springframework.stereotype.Controller;
//                  import org.springframework.ui.Model;
//                  import org.springframework.web.bind.annotation.RequestMapping;
//                  @Controller
//                  public class ClientController {
//                    @RequestMapping("/")
//                    public String accueil(Model model) {
//                        return "Accueil";
//                    }
//                  }
// Explications :
//      - L'annotation '@Controller' est une annotation de Spring MVC qui dit au 'DispatcherServlet', qui reçoit toutes les requêtes pour le dispatcher, de chercher dans cette classe.
//          Et cela, pour voir s'il y a une opération qui correspond à l'URI appelé.
//      - Nous créons ensuite une méthode qui répond aux URI de type "/", c'est-à-dire la page d'accueil de notre interface.
//      - 'model' est une instance de la classe Model, que l'on passera en argument à notre méthode, et qui nous permettra de renseigner des données à passer à la vue. Nous y reviendrons plus tard.
//      - 'return "Accueil"' : Spring ira chercher dans le dossier "template", dans "resources", la page HTML du nom de 'Accueil.html'.
// Justement, rendez-vous dans 'resources/templates' et créez un fichier 'Accueil.html', puis écrivez quelque chose à l'intérieur du fichier. Lancez ensuite votre client.
//      --> Rendez-vous à http://localhost:8080/, et vous verrez le contenu de votre HTML s'afficher.
// Nous allons utiliser Bootstrap pour créer notre interface. Pour faciliter son intégration, nous allons ajouter une dépendance à notre pom.xml :
//                  <dependency>
//                      <groupId>org.webjars</groupId>
//                      <artifactId>bootstrap</artifactId>
//                      <version>4.0.0-2</version>
//              </dependency>
//      --> Cette dépendance rendra les fichiers de Bootstrap disponibles pour notre HTML, sans aucune configuration ou chemin à trouver.
// À noter qu'il est possible d'utiliser la version hébergée par Google par exemple, mais comme nous souhaitons que notre microservice soit autonome, nous allons garder les fichiers en local.
// Ajoutez ensuite ce contenu HTML à Accueil.html :
//                  <!DOCTYPE HTML>
//                  <html xmlns:th="http://www.thymeleaf.org">
//                      <head>
//                          <title>Mcommerce</title>
//                          <link rel="stylesheet" type="text/css" href="webjars/bootstrap/4.0.0-2/css/bootstrap.min.css"/>
//                      </head>
//                      <body>
//                          <div class="container">
//                              <h1>Application Mcommerce</h1>
//                          </div>
//                          <script type="text/javascript" src="webjars/bootstrap/4.0.0-2/js/bootstrap.min.js"></script>
//                      </body>
//                  </html>
// Relancez le client et vérifiez que tout fonctionne correctement.
// Nous allons maintenant mettre en place Feign pour simplifier nos appels HTTP entre nos services.
// -----------
//  - En résumé :
//      --> Nous avons mis en place nos microservices et mise en place la base de notre front.
//      --> Spring Initializr permet de générer le squelette des projets.
// Dans le prochain chapitre, vous allez apprendre à utiliser Feign pour faire communiquer vos Microservices. On y va !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Faites communiquer vos microservices grâce à Feign ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Feign est un client HTTP qui facilite grandement l'appel des API exposées par les différents microservices.
// Il est donc capable de créer et d'exécuter des requêtes HTTP basées sur les annotations et informations que l'on fournit. C'est un peu l'équivalent en code de Postman.
// Il se présente sous forme de dépendance à ajouter au microservice.
// Commençons par ajouter Feign à notre pom.xml.
// Afin d'activer Feign dans ce microservice, rendez-vous à ClientUiApplication et ajoutez l'annotation @EnableFeignClients :
//                  @SpringBootApplication
//                  @EnableFeignClients("com.clientui")
//                  public class ClientUiApplication {
//                      public static void main(String[] args) {
//                          SpringApplication.run(ClientUiApplication.class, args);
//                      }
//                  }
// L'annotation '@EnableFeignClients' demande à Feign de scanner le package "com.clientui" pour rechercher des classes qui se déclarent clients Feign.
// -----------
//  - Étape 1 : Récupérez la liste des produits :
// Quand Feign fera appel à 'Microservice-produits' afin de récupérer la liste des produits, il lui faudra stocker chaque produit dans un objet de type 'Product'.
// Et ce, afin que nous puissions les manipuler facilement plus tard (vous conviendrez que si Feign nous retourne le JSON brut, il ne nous sert pas à grand-chose).
// Nous allons donc créer un bean qui reprend les mêmes champs que 'Product.java'.
// Créez une classe 'ProductBean' sous un package "beans" :
//                  package com.clientui.beans;
//                  public class ProductBean {
//                      private int id;
//                      private String titre;
//                      private String description;
//                      private String image;
//                      private Double prix;
//                      public ProductBean() {
//                      }
//                      public int getId() {
//                          return id;
//                      }
//                      public void setId(int id) {
//                          this.id = id;
//                      }
//                      public String getTitre() {
//                          return titre;
//                      }
//                      public void setTitre(String titre) {
//                          this.titre = titre;
//                      }
//                      public String getDescription() {
//                          return description;
//                      }
//                      public void setDescription(String description) {
//                          this.description = description;
//                      }
//                      public String getImage() {
//                          return image;
//                      }
//                      public void setImage(String image) {
//                          this.image = image;
//                      }
//                      public Double getPrix() {
//                          return prix;
//                      }
//                      public void setPrix(Double prix) {
//                          this.prix = prix;
//                      }
//                      @Override
//                      public String toString() {
//                          return "ProductBean{" +
//                              "id=" + id +
//                              ", titre='" + titre + '\'' +
//                              ", description='" + description + '\'' +
//                              ", image='" + image + '\'' +
//                              ", prix=" + prix +
//                              '}';
//                          }
//                      }
//                  }
//      --> Nous avons repris les mêmes champs que dans 'Product.java', puis nous avons généré les Getters et Setters.
// Nous allons maintenant créer une interface qui va regrouper les requêtes que nous souhaitons passer au 'Microservice-produits'.
// Cette interface est ce que nous appelons un proxy, car elle se positionne comme une classe intermédiaire qui fait le lien avec les microservices extérieurs à appeler.
// Créez une classe 'MicroserviceProduitsProxy' sous un package "proxies" :
//                  package com.clientui.proxies;
//                  import com.clientui.beans.ProductBean;
//                  import org.springframework.cloud.openfeign.FeignClient;
//                  import org.springframework.web.bind.annotation.GetMapping;
//                  import org.springframework.web.bind.annotation.PathVariable;
//                  import java.util.List;
//                  @FeignClient(name = "microservice-produits", url = "localhost:9001")
//                  public interface MicroserviceProduitsProxy {
//                      @GetMapping(value = "/Produits")
//                      List<ProductBean> listeDesProduits();
//                      @GetMapping(value = "/Produits/{id}")
//                      ProductBean recupererUnProduit(@PathVariable("id") int id);
//                  }
// Explications :
//      --> '@FeignClient' déclare cette interface comme client Feign.
//              Feign utilisera les informations fournies ici pour construire les requêtes HTTP appropriées afin d'appeler le Microservice-Produits.
//      --> On donne à cette annotation 2 paramètres : le premier est "name", il s'agit du nom du microservice à appeler.
//              Il ne s'agit pas ici de n'importe quel nom, mais du nom "officiel" qui sera utilisé plus tard par des Edge Microservices comme Eureka et Ribbon.
//              Celui-ci est à renseigner dans 'application.properties' du microservice à appeler grâce à 'spring.application.name'.
//              Voici donc à quoi ressemble ce fichier dans Microservice-produits :
//                  spring.application.name=microservice-produits
//                  server.port=9001
//                  #Configurations H2
//                  spring.jpa.show-sql=true
//                  spring.h2.console.enabled=true
//      --> Le deuxième paramètre est l'URL du microservice (localhost:9001). Vous comprenez maintenant pourquoi nos microservices écoutent des ports différents.
//              Même s'ils partagent le même domaine, Feign (et d'autres composants) pourra les différencier grâce aux ports.
// Dans cette interface créée, il faut déclarer les signatures des opérations à appeler dans le microservice "produits".
// Dans notre cas, comme nous avons accès au code source de Microservice-produits, il suffit de copier ses signatures.
// Néanmoins, même sans avoir accès aux sources, il suffit de préciser les types de retour, par exemple List, un nom quelconque pour votre méthode et un URI.
// Toutes ces informations sont normalement disponibles dans la documentation qui accompagne chaque microservice.
// Si vous copiez les signatures, il faut veiller à remplacer Product par son équivalent dans ce client ProductBean que nous avons créé.
// Remarquez que j'ai changé la signature avec Optional par ProductBean dans la deuxième méthode, afin de simplifier son utilisation.
// TFeign a désormais tout ce qu'il faut pour déduire qu'il faut une requête HTTP de type GET (grâce à GetMapping), à quelle URL l'envoyer, et une fois la réponse reçue, dans quel objet la stocker.
// Il ne reste plus alors qu'à utiliser ce proxy. Revenez dans le contrôleur :
//                  package com.clientui.controller;
//                  import com.clientui.beans.ProductBean;
//                  import com.clientui.proxies.MicroserviceProduitsProxy;
//                  import org.springframework.stereotype.Controller;
//                  import org.springframework.ui.Model;
//                  import org.springframework.web.bind.annotation.RequestMapping;
//                  import java.util.List;
//                  @Controller
//                  public class ClientController {
//                      private final MicroserviceProduitsProxy produitsProxy;
//                      public ClientController(MicroserviceProduitsProxy produitsProxy){
//                          this.produitsProxy = produitsProxy;
//                      }
//                      @RequestMapping("/")
//                      public String accueil(Model model){
//                          List<ProductBean> produits =  produitsProxy.listeDesProduits();
//                          model.addAttribute("produits", produits);
//                          return "Accueil";
//                      }
//                  }
// Explications :
// Nous créons une variable de type MicroserviceProduitsProxy qui sera instanciée automatiquement par Spring.
// Nous avons donc maintenant accès à toutes les méthodes que nous avons définies dans MicroserviceProduitsProxy.
// Il suffit de faire appel à listeDesProduits. Feign ira exécuter la requête HTTP, et nous renverra une liste de ProductBean.
// Nous utilisons la méthodeaddAttribute de model afin de passer en revue la liste des produits.
// Rendez-vous maintenant dans Accueil.html :
//                  <!DOCTYPE HTML>
//                  <html xmlns:th="http://www.thymeleaf.org">
//                      <head>
//                          <title>Mcommerce</title>
//                          <link rel="stylesheet" type="text/css" href="webjars/bootstrap/4.0.0-2/css/bootstrap.min.css" />
//                      </head>
//                      <body>
//                          <div class="container">
//                              <h1>Application Mcommerce</h1>
//                              <div class="row">
//                                  <div th:each="produit : ${produits}" class="col-md-4 my-1">
//                                      <a th:href="@{|/details-produit/${produit.id}|}" >
//                                          <img th:src="${produit.image}"  class="card-img-top" />
//                                          <p th:text= "${produit.titre}"></p>
//                                      </a>
//                                  </div>
//                              </div>
//                          </div>
//                          <script type="text/javascript" src="webjars/bootstrap/4.0.0-2/js/bootstrap.min.js"></script>
//                      </body>
//                  </html>
// Explications :
//      --> Dans le HTML, nous recevons grâce à 'model' la variable 'produits' avec la liste de tous les produits.
//              Il suffit d'utiliser la syntaxe Thymeleaf pour parcourir cette liste, et afficher les images des produits et leurs titres.
//      --> 'th:each="produit : ${produits}"'  parcourt la liste produits et stocke à chaque fois un objet de type ProductBean dans la variable 'produit'.
//      --> On a accès ensuite aux attributs de chaque objet pour créer le lien vers chaque produit sous le format "/details-produit/id_produit_ici".
//              Nous créerons ensuite la méthode nécessaire pour cet URI dans notre contrôleur.
//      --> On ajoute également les images et les titres.
// Si vous voulez aller plus loin, vous pouvez vous familiariser avec Thymeleaf grâce à sa documentation : 'https://www.thymeleaf.org/doc/tutorials/2.1/usingthymeleaf.html'.
// Vous avez un client fonctionnel capable de faire appel à un autre microservice, de récupérer et de formater les données reçues, et de les présenter dans une page web.
// Nous venons donc de réaliser l'étape (1) de notre diagramme d'application.
// -----------
// Étape 2 : Ajoutez la page de produit et de commande :
// Vous avez maintenant tous les outils nécessaires pour ajouter une page qui affiche les détails d'un produit avec un bouton "Commander", et une autre pour le retour après la commande.
// Nous avons défini l'URL vers chaque produit dans le HTML grâce à :
//                  <a th:href="@{|/details-produit/${produit.id}|}" >
// Il faut donc créer une méthode dans le contrôleur qui répond aux URI de type '/details-produit/{id}'.
//      --> ClientController.java :
//                  @RequestMapping("/details-produit/{id}")
//                  public String ficheProduit(@PathVariable int id,  Model model){
//                      ProductBean produit = produitsProxy.recupererUnProduit(id);
//                      model.addAttribute("produit", produit);
//                      return "FicheProduit";
//                  }
// Explications :
//      --> Nous récupérons donc l'ID passé dans l'URL du produit pour faire appel au Microservice-produits grâce à 'ProduitsProxy'.
//              Celui-ci nous retourne les détails du produit en question 'recupererUnProduit(id)'.
//      --> Nous passons ensuite classiquement l'objet 'produit' à 'model'.
//      --> Puis nous demandons à ce que l'on affiche la page 'FicheProduit.html'.
// Voici la page HTML :
//                  <!DOCTYPE HTML>
//                  <html xmlns:th="http://www.thymeleaf.org">
//                      <head>
//                          <title>Mcommerce</title>
//                          <link rel="stylesheet" type="text/css"
//                              href="http://localhost:8080/webjars/bootstrap/4.0.0-2/css/bootstrap.min.css"/>
//                      </head>
//                      <body>
//                          <div class="container">
//                              <h1 class="text-center">Application Mcommerce</h1>
//                              <div class="row">
//                                  <div class="col-md-4 mx-auto mt-5 text-center">
//                                      <img th:src="${produit.image}" class="card-img-top"/>
//                                      <p th:text="${produit.titre}" class="font-weight-bold"></p>
//                                      <p th:text="${produit.description}"></p>
//                                      <p>
//                                          <a th:href="@{|/details-produit/commander-produit/${produit.id}|}" class="font-weight-bold">COMMANDER</a>
//                                      </p>
//                                  </div>
//                              </div>
//                          </div>
//                          <script type="text/javascript" src="http://localhost:8080/webjars/bootstrap/4.0.0-2/js/bootstrap.min.js"></script>
//                      </body>
//                  </html>
// Explications :
//      --> On affiche les détails du produit en accédant aux propriétés de celui-ci via la notation '${produit.PROPRIÉTÉ}'.
//      --> On insère ensuite le lien de commande qui fera appel à une méthode dans notre contrôleur.
//              Celui-ci s'occupera d'envoyer la requête GET vers le microservice de commande, grâce à '@{|/details-produit/commander-produit/${produit.id}|}'.
// Vous devriez obtenir ce résultat :
// -----------
//  - Suivez les étapes 3 à 7 du diagramme : Gestion et propagation des erreurs :
// Pour les prochaines étapes, nous allons réutiliser les mêmes principes pour faire communiquer tous les microservices.
// Je vous invite à récupérer le code commenté qui explique étape par étape tout le processus dans la branche 'ClientEtMSCommuniquant' de l'application.
//      --> Que se passe-t-il si on demande la récupération d'un produit qui n'existe pas ?
// Faisons en sorte que 'Microservice-produits' renvoie un code '400 Bad Request' si le produit n'existe pas (nous allons éviter le 404, car son cas est particulier).
//      --> Pour ce faire, rendez-vous dans 'ProductNotFoundException.java', et changez le code à renvoyer :
//                  @ResponseStatus(HttpStatus.BAD_REQUEST)
//                  public class ProductNotFoundException extends RuntimeException {
//                      public ProductNotFoundException(String message) {
//                          super(message);
//                      }
//                  }
// Essayons maintenant en appelant cette URL, par exemple sur Postman : 'http://localhost:8080/details-produit/20'.
// Vous recevez le code 500 en réponse, avec un corps de réponse comme celui-ci :
//                  {
//                      "timestamp": "2018-04-15T23:29:07.112+0000",
//                      "status": 500,
//                      "error": "Internal Server Error",
//                      "message": "status 400 reading MicroserviceProduitsProxy#recupererUnProduit(int);
//                                      content:\n{\"timestamp\":\"2018-04-15T23:29:06.999+0000\",
//                                      \"status\":400,\"error\":\"Bad Request\",\"message\":
//                                      \"Le produit correspondant à l'id 20 n'existe pas\",\"path\":\"/Produits/20\"}",
//                      "path": "/details-produit/20"
//                  }
// Vous pouvez donc constater 2 choses :
//      --> Le Microservice-produit a bien répondu comme prévu en renvoyant un code 400, mais Feign a tout simplement constaté que le code n'était pas au format 2XX.
//              Feign a renvoyé un code 500 générique pour indiquer qu'un problème était survenu au niveau du serveur.
//      --> Vous pouvez voir que le message d'erreur renvoyé par notre microservice est stocké dans "message", et qu'il comporte le bon code.
// Si vous vous rendez dans la console de ClientUI, vous trouvez cette erreur :
//                  FeignException: status 400 reading MicroserviceProduitsProxy#recupererUnProduit(int);
// L'exception que Feign a renvoyée est donc 'FeignException'. Cette exception est celle que renvoie Feign à chaque fois que le code de retour est différent de 2XX.
// Vous pouvez me dire que l'on peut se contenter dans ce cas du code 500, mais il faut penser aux cas où des microservices appellent d'autres microservices à la chaîne.
// Prenons l'exemple de ClientUI qui appelle 'Microservice-paiement' pour enregistrer un paiement et qui, à son tour, appelle 'Microservice-commande' pour passer le statut de la commande à "payée".
// Si 'Microservice-commande' renvoie par exemple un code disant que la commande est déjà payée, Feign générera le fameux code 500 et n'aura aucune chance d'informer 'ClientUI' de la nature du problème.
// 'ClientUI' se retrouvera réduit à annoncer à l'utilisateur qu'un problème inconnu est survenu.
// Or, si nous arrivons, dans 'Microservice-produits', à décrypter l'exception générée par Feign pour retomber sur les bons codes HTTP renvoyés, nous pourrons transmettre ce code en réponse à 'ClientUI'.
// Ce dernier affichera au client que le paiement n'a pas abouti, car la commande est déjà payée !
//      --> C'est ce que l'on appelle la propagation des erreurs à travers les microservices.
// Nous allons donc maintenant nous atteler à décoder l'exception générique de Feign, afin de retomber sur les bons codes renvoyés.
// Heureusement, Feign propose une interface nommée 'ErrorDecoder' spécialement dédiée au décodage de la réponse HTTP, afin de lancer l'exception de notre choix en fonction de la nature de l'erreur.
//      --> Créez donc votre propre décodeur qui viendra hériter de 'ErrorDecoder'.
// Pour cela, rendez-vous dans le projet 'clientui', et créez un package exceptions :
//                  package com.clientui.exceptions;
//                  import feign.Response;
//                  import feign.codec.ErrorDecoder;
//                  public class CustomErrorDecoder implements ErrorDecoder {
//                      private final ErrorDecoder defaultErrorDecoder = new Default();
//                      @Override
//                      public Exception decode(String invoqueur, Response reponse) {
//                          if(reponse.status() == 400 ) {
//                              return new ProductBadRequestException(
//                                  "Requête incorrecte "
//                              );
//                          }
//                          return defaultErrorDecoder.decode(invoqueur, reponse);
//                      }
//                  }
// Explications :
//      --> On hérite de 'ErrorDecoder'.
//      --> On récupère une instance de 'ErrorDecoder'. Si nous ne sommes pas en capacité d'identifier le code d'erreur ou que nous n'avons aucune exception prévue pour un code en particulier.
//              Dans ce cas là nous demandons à ce que l'erreur soit traitée par le décodeur par défaut : 'ErrorDecoder'.
//      --> On implémente la méthode 'decode' qui nous permet de récupérer le code d'erreur envoyé, afin de lancer des exceptions en fonction de celui-ci.
//              Cette méthode nous donne accès à un premier paramètre que j'ai appelé 'invoqueur', et qui contient la classe et la méthode qui a généré la requête.
//              Dans notre cas, par exemple, le contenu de 'invoqueur' est 'MicroserviceProduitsProxy#recupererUnProduit(int)'.
//                  --> En effet, c'est la méthode 'recupererUnProduit' qui a été utilisée pour appeler 'microservice-produits'.
//      --> 'reponse' contient donc la réponse de celui-ci. C'est la partie la plus importante, car elle va nous permettre de récupérer le code d'erreur.
//      --> 'reponse.status()' nous donne donc accès au code d'erreur renvoyé par le microservice distant.
//              Dans ce cas, nous vérifions s'il est égal à 400. Si c'est le cas, on lance une exception que nous allons créer et appeler 'ProductBadRequestException'.
//      --> Si l'erreur ne rentre pas dans nos critères, on la passe tout simplement au décodeur par défaut qui s'occupera de lancer l'exception par défaut vue plus haut : 'FeignException'.
// Créez enfin l'exception à renvoyer 'ProductBadRequestException' :
//                  package com.clientui.exceptions;
//                  import org.springframework.http.HttpStatus;
//                  import org.springframework.web.bind.annotation.ResponseStatus;
//                  @ResponseStatus(HttpStatus.BAD_REQUEST)
//                  public class ProductBadRequestException extends RuntimeException{
//                      public ProductBadRequestException(String message) {
//                          super(message);
//                      }
//                  }
// Il s'agit là d'une exception classique, équivalente à celle créée dans 'Microservice-produits', par exemple.
//      --> Elle renvoie tout simplement l'erreur 400 Bad Request avec le message qui lui a été passé précédemment en argument.
// Si vous testez maintenant, vous remarquerez que vous avez toujours la fameuse erreur 500.
// C'est normal, car il faut informer Spring de l'existence de notre propre décodeur 'CustomErrorDecoder'.
//      --> Nous allons donc déclarer notre décodeur afin que celui-ci soit utilisé à la place de celui par défaut.
// Pour cela, nous allons tout simplement le mettre dans un bean.
// Créez une classe de configuration et appelez-la 'FeignExceptionConfig' dans un package 'configuration' :
//                  package com.clientui.configuration;
//                  import com.clientui.exceptions.CustomErrorDecoder;
//                  import org.springframework.context.annotation.Bean;
//                  import org.springframework.context.annotation.Configuration;
//                  @Configuration
//                  public class FeignExceptionConfig {
//                      @Bean
//                      public CustomErrorDecoder mCustomErrorDecoder(){
//                          return new CustomErrorDecoder();
//                      }
//                  }
// Nous créons tout simplement une méthode 'mCustomErrorDecoder' qui renvoie notre décodeur, et le tour est joué.
//      --> Attention, il est tout à fait possible de déclarer notre décodeur de manière plus simple en ajoutant par exemple '@Component' à celui-ci.
//              Néanmoins, nous allons préférer garder les déclarations des beans séparément, dans un package 'configuration', pour une meilleure lisibilité du code.
// Lancez ClientUI et Microservice-produits.
//      --> Vous avez bien votre code d'erreur 400 renvoyé par votre propre exception, au lieu du code 500 générique.
//              Vous avez également le message d'erreur que vous avez indiqué.
// Maintenant que le mécanisme de propagation d'erreur est en place, vous pouvez générer des exceptions facilement pour tous les cas et codes d'erreurs, par exemple :
//                  else if(reponse.status() > 400 && reponse.status() <=499 ) {
//                      return new Product4XXException(
//                          "Erreur de au format 4XX "
//                      );
//                  }
// N’ajoutez pas le morceau de code précédent, c’est juste un exemple pour vous montrer comment gérer les exceptions de façon plus fine.
// Ce code va vous permettre de lancer une exception pour tous les cas où le code HTTP est entre 401 et 499.
// Enfin, vous pouvez même récupérer le message renvoyé dans le corps de la réponse par 'Microservice-produit', en y accédant via 'reponse.body()'.
// Le cas 404 Not Found :
// Au début, nous avons changé 'ProductNotFoundException' afin qu'elle nous renvoie 400 au lieu de 404. L'objectif était de lever une ambiguïté sur cette erreur.
// En effet, Feign propose un argument 'decode404' qui s'utilise comme ceci :
// Dans la classe 'MicroServiceProduitProxy', modifier l’annotation pour :
//                  @FeignClient(name = "microservice-produits", url = "localhost:9001", decode404 = true)
//                  decode404 = true  est souvent utilisé à tort afin de gérer automatiquement les cas de ressources non trouvées.
// Si vous lancez ClientUI avec 'decode404' à true, et que vous appelez de nouveau 'http://localhost:8080/details-produit/20', vous obtenez un code 200 OK et du HTML sans contenu.
// En effet, cet argument 'decode404' permet simplement de passer l'erreur, et donc d'éviter de lancer la fameuse 'FeignException'.
// Le but dépasse le cadre de ce cours, mais si vous êtes curieux, c'est simplement pour éviter le déclenchement des circuits breakers comme Hystrix.
// Vous devez donc toujours traiter l'erreur 404 exactement comme nous l'avons fait avec l'erreur 400, grâce à une condition dans votre décodeur.
// Voici donc le code pour gérer l'erreur 404 :
//                  {
//                      if(reponse.status() == 400 ) {
//                          return new ProductBadRequestException(
//                              "Requête incorrecte "
//                          );
//                      }
//                      return defaultErrorDecoder.decode(invoqueur, reponse);
//                  }
// Remettez 'HttpStatus.NOT_FOUND' dans 'ProductNotFoundException' de 'Microservice-produit', modifiez votre classe 'MicroServiceProduitsProxy' pour qu’elle ressemble à :
//                  @FeignClient(name = "microservice-produits", url = "localhost:8080")
//                  public interface MicroserviceProduitsProxy {
//                      @GetMapping(value = "/Produits")
//                      List<ProductBean> listeDesProduits();
//                      @GetMapping( value = "/Produits/{id}")
//                      ProductBean recupererUnProduit(@PathVariable("id") int id);
//                  }
// La branche pour récupérer le code de ce chapitre est : 'ClientEtMSCommuniquant'.
// -----------
//  - En résumé :
//      --> Feign est un outil qui permet la simplification de la communication entre microservices.
//              Cela, en générant automatiquement les requêtes HTTP à partir des données fournies dans des classes appelées proxies.
//      --> Une fois la réponse du microservice distant reçue, Feign l'associe à un bean local que l'on aura créé.
//              On obtient alors en retour directement des objets Java prêts à l'emploi.
//      --> Quand Feign rencontre un autre code de réponse que 2XX, il génère une exception 'FeignException'.
//              Afin de pouvoir décoder la réponse et extraire les bons codes d'erreur, il faut créer une classe qui hérite de 'ErrorDecoder' et qui implémente decode.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Mettez en oeuvre les Edge Microservices grâce à Spring Cloud ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Découvrez les Edge Microservices //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Les Edge Microservices sont des microservices spécialisés dans l'orchestration des microservices centraux responsables de la logique de l'application.
// Les Edge Microservices les plus populaires sont ceux publiés et utilisés par Netflix pour sa plateforme.
// Ils sont en grande partie regroupés sous Spring Cloud, et disposent de fonctionnalités pour fonctionner nativement ensemble.
// Présentons une application auquel l'utilisateur a accès et peut utiliser.
//      --> Cette application est constituée de différents microservices responsables de fonctionnalités en particuliers. Ils utilisent des outils comme Eureka ou Zipkin.
// Ces Edge Microservices répondent chacun à un problème particulier. En voici quelques-uns auxquels nous allons nous attaquer dans les prochains chapitres.
// -----------
//  - La configuration :
// Dans une application grandeur nature, les microservices et leurs différentes instances reposent énormément sur des fichiers de configuration tels que 'application.properties'.
// Imaginez que vous souhaitiez changer un paramètre concernant une application en production.
// Il faut alors arrêter toutes les instances du microservice, puis modifier et redéployer, en bloquant, de fait, l'application.
//      --> Comment éviter de bloquer l'application à chaque mise à jour de la configuration ?
//              --> La solution est Spring Cloud Config.
// Il va permettre de centraliser tous les fichiers de configuration dans un dépôt GIT, et se positionner comme serveur de fichiers de configuration.
// Ainsi, quand vous mettez à jour un fichier de configuration dans votre dépôt GIT, Spring Cloud Config se met à servir cette nouvelle version.
// Ceci, obligeant le microservice à le prendre en compte à la volée.
// -----------
//  - La découvrabilité :
// En cas de grande charge sur notre application, nous souhaitons ajouter plusieurs instances d'un microservice.
//      --> Comment garder la trace des URL des différentes instances disponibles, ainsi que leurs états ?
// Pour répondre à ce problème, 'Eureka' se propose en naming server. Grâce à une simple annotation, toute nouvelle instance de votre microservice va être enregistrée auprès d'Eureka.
// Votre client n'a plus qu'à consulter ce registre pour trouver les instances disponibles d'un microservice donné.
// Eureka s'occupe également de vérifier régulièrement si chaque instance enregistrée est toujours disponible, afin de mettre à jour son registre en éliminant celles qui n'existent plus.
// -----------
//  - L'équilibrage de la charge (Load Balancing) :
// Nous souhaitons que nos microservices soient les plus découplés et autonomes possible. Quand nous avons plusieurs instances d'un microservice, il faut équilibrer la charge entre celles-ci.
// On ne peut pas utiliser un équilibreur de charge central classique, car celui-ci limiterait la résilience de notre application en créant un point de centralisation.
// Comment permettre à chaque microservice de faire appel à un autre directement, sans être dépendant d'un Load Balancer central ?
//      --> La réponse est Ribbon : ce load Balancer côté client est capable d'indiquer directement, depuis le microservice, quelle instance du microservice distant appeler.
// -----------
//  - API Gateway :
// Imaginez que nous développions notre application e-commerce dans le cadre d'une véritable application professionnelle.
// L'affichage d'une fiche produit reposera alors sur des dizaines de microservices.
// Il y aura par exemple des microservices pour : les images, le pricing, les recommandations, les textes et caractéristiques des produits, un comparateur, la livraison, etc.
// Quand notre client voudra afficher cette fiche produit, il devra faire appel à tous ces microservices.
// Cela implique de les identifier, de repérer leurs instances, de s'authentifier auprès de chacun d'entre eux pour accéder aux ressources.
// Ainsi que de transformer le résultat reçu pour qu'il soit adapté au type d'appareil, etc.
// Avec tout cela, vous imaginez que le client deviendra méchamment complexe, d'autant plus qu'il ne s'occupe pas uniquement des fiches produits !
//      --> Comment résoudre cette complexité ?
// La solution est d'installer un point d'entrée unique vers les microservices. C'est ce qu'on appelle une API Gateway.
//      --> L'API Gateway que nous allons utiliser s'appelle ZUUL.
// Elle va nous donner énormément d'avantages, notamment en ce qui concerne la sécurité.
//      --> Plus besoin de sécuriser chaque microservice, il suffit d'imposer les règles d'authentification et de sécurité à ZUUL.
// -----------
//  - Le traçage des requêtes :
// Reprenons l'exemple de la fiche produit : quand vous demandez celle-ci, votre requête doit traverser plusieurs microservices avant d'aboutir.
// Pensez, par exemple, à notre application Mcommerce.
// Dans celle-ci, la requête de demande de paiement envoyée par le client déclenche dans le Microservice-produits une autre requête vers le Microservice-commandes.
// Et ce, afin de mettre à jour le statut de la commande.
//      --> Si une erreur vous est retournée, il est difficile de savoir si elle s'est produite au niveau du Microservice-produits ou au niveau du Microservice-commandes.
// Imaginez maintenant le problème quand votre requête traverse 25 microservices avant d'aboutir !
//      --> Comment identifier le microservice posant problème ?
// Zipkin va vous permettre de suivre vos requêtes de microservice en microservice, et de consulter les différentes réponses et interactions afin de cibler directement le problème.
// -----------
//  - En résumé :
//      --> Zipkin permet de tracer les requêtes.
//      --> Zuul est un proxy inverse qui sert de point d’entrée à nos applications.
// Dans le prochain chapitre, nous allons voir comment faire pour externaliser la configuration de vos microservices. Vous êtes prêt ? Allons-y !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Externalisez la configuration de vos microservices ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Ajoutez vos propres configurations :
// Quand vous développez un microservice, vous avez souvent besoin de définir certaines propriétés ou valeurs fixes qui conditionnent le fonctionnement de votre application.
// Par exemple : le port d'écoute d'un microservice, une clé secrète d'accès à des ressources protégées, ou encore des valeurs liées aux langues et dictionnaires utilisés.
//      --> Pourquoi ne pas mettre tout simplement des constantes dans le code ?
// Cette solution est à éviter, car quand vous avez un microcommerce avec énormément de valeurs fixes à renseigner, il devient complexe de les retrouver dans les dizaines de classes de votre microservice.
// Pire encore, quand vous souhaitez changer une constante, il faut arrêter le microservice et le mettre à jour avant de le redéployer.
// La solution est de regrouper toutes vos constantes de configuration dans un fichier que nous avons depuis le début : 'application.properties'.
// Pour prendre un exemple, nous allons essayer de créer une valeur limite du nombre de produits à retourner quand on fait appel à l'URI '/Produits' (méthode 'listeDesProduits').
// Rendez-vous dans 'application.properties' de 'Microservice-produits', et ajoutez ceci :
//                  spring.application.name=microservice-produits
//                  server.port=9001
//                  #Configurations H2
//                  spring.jpa.show-sql=true
//                  spring.h2.console.enabled=true
//                  spring.datasource.url=jdbc:h2:mem:testdb
//                  spring.datasource.driverClassName=org.h2.Driver
//                  spring.datasource.username=sa
//                  spring.datasource.password=
//                  spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
//                  spring.jpa.hibernate.ddl-auto=none
//                  #Nos configurations
//                  mes-configs.limitDeProduits=4
// Nous avons donc ajouté 'mes-configs.limitDeProduits= 4'.
// Il faut veiller à ce que tous les noms de vos propriétés soient précédés d'un préfixe afin qu'elles soient identifiables plus tard.
//      --> Dans notre cas, le préfixe est 'mes-configs'.
// Afin de récupérer les valeurs que nous avons indiquées dans 'application.configuration', nous allons utiliser l'annotation '@ConfigurationProperties'.
//      --> Pour ce faire, nous allons créer une classe de configuration.
// Créez une classe appelée 'ApplicationPropertiesConfiguration' dans un package nommé configurations.
//                  package com.mproduits.configurations;
//                  import org.springframework.boot.context.properties.ConfigurationProperties;
//                  import org.springframework.stereotype.Component;
//                  @Component
//                  @ConfigurationProperties("mes-configs")
//                  public class ApplicationPropertiesConfiguration {
//                      private int limitDeProduits;
//                      public int getLimitDeProduits() {
//                          return limitDeProduits;
//                      }
//                      public void setLimitDeProduits(int limitDeProduits) {
//                          this.limitDeProduits = limitDeProduits;
//                      }
//                  }
// Explications :
//      - '@Component' : demande à Spring de scanner cette classe à la recherche de configurations.
//      - '@ConfigurationProperties("mes-configs")' : précise que cette classe de configuration va récupérer des propriétés dans 'application.properties' dont le préfixe est 'mes-configs'.
// Il suffit ensuite de déclarer des propriétés avec les mêmes noms que celles du fichier de configuration.
//      --> Dans notre cas, il s'agit de 'limitDeProduits'.
//      --> Il ne faut pas oublier de générer les Getters et Setters.
// Il nous suffit à présent de retourner dans notre contrôleur pour accéder aux valeurs très simplement.
// Extrait de ProductController.java :
//                  private final ProductDao productDao;
//                  private final ApplicationPropertiesConfiguration appProperties;
//                  public ProductController(ProductDao productDao, ApplicationPropertiesConfiguration appProperties){
//                      this.productDao = productDao;
//                      this.appProperties = appProperties;
//                  }
//                  // Affiche la liste de tous les produits disponibles
//                  @GetMapping(value = "/Produits")
//                  public List<Product> listeDesProduits(){
//                      List<Product> products = productDao.findAll();
//                      if(products.isEmpty()) throw new ProductNotFoundException("Aucun produit n'est disponible à la vente");
//                      List<Product> listeLimitee = products.subList(0, appProperties.getLimitDeProduits());
//                      return listeLimitee;
//                  }
// Explications :
//      - 'appProperties.getLimitDeProduits()' va retourner le chiffre 4 que nous avons défini dans le fichier de configuration.
//          On le passe donc à 'subList' qui coupe une liste donnée à la limite donnée en 2e argument.
// Voilà, le tour est joué ! Vous pouvez définir autant de valeurs que vous le souhaitez dans le fichier de configuration, et y accéder très simplement dans votre code.
// Il ne vous reste qu’à relancer vos services puis vous rendre sur 'http://localhost:8080/Accueil', pour voir les 4 premiers produits.
// -----------
//  - Découvrez comment fonctionne l'externalisation :
// Spring Cloud Config se positionne comme serveur de distribution des fichiers de configuration. On place les fichiers de configuration dans un dépôt GIT.
// Afin d'externaliser les fichiers de configuration, nous allons utiliser un Edge Microservice appelé Spring Cloud Config.
//      --> Il se positionne comme serveur de distribution des fichiers de configuration.
// Il suffit de placer tous les fichiers de configuration dans un dépôt GIT.
//      --> Grâce à des conventions de nommage de fichiers, Spring Cloud Config sera capable de savoir quel fichier va servir à quel microservice, en se basant sur le nom du microservice.
// Pour modifier plus tard la configuration d'un microservice, il suffira de pousser les changements dans le GIT.
// Spring Cloud Config se mettra alors à servir la nouvelle version ! Pas besoin d'arrêter le moindre microservice !
// -----------
//  - Créez le dépôt GIT :
// Commençons par le bas du diagramme, et créons un dépôt GIT dans lequel iront nos fichiers de configuration.
//      - Créez un compte sur GitHub (si vous n'en avez pas déjà un), puis créez un dépôt et appelez-le par exemple 'mcommerce-config-repo'.
//      - Revenez dans le dossier du projet Mcommerce sur votre ordinateur, et créez un nouveau dossier appelé 'config-server-repo'.
//              --> Nous allons mettre dans ce dossier les fichiers de configuration des microservices, puis nous le connecterons au dépôt distant que vous avez créé.
//      - Importez ce dossier en tant que nouveau module, comme vous l'avez fait pour les autres microservices.
//              --> La différence est que, cette fois, vous choisirez "Create module from existing source".
//      - Continuez l'importation par défaut. Il n'y a pas besoin de choisir de dossier "source" ou "resources".
//      - Le dossier apparaîtra alors à gauche dans votre projet à côté des autres microservices.
//              --> L'utilité d'importer le dossier comme nouveau module dans notre projet IntelliJ est d'avoir le dossier sous les yeux, et de pouvoir le manipuler depuis le projet.
//                      Vous pouvez tout à fait le laisser à l'extérieur du projet. Ce qui importe est le contenu du dépôt distant.
//      - Créez maintenant un nouveau fichier dans ce dossier : 'microservice-produit.properties'.
//              --> Le nom doit correspondre exactement au nom que vous avez donné à votre 'Microservice-produits' dans 'application.properties'.
//                      spring.application.name=microservice-produits
//              --> C'est grâce à cette correspondance de noms que notre serveur de configuration fera le lien entre ce fichier et le microservice correspondant.
//      - Coupez le contenu d''application.properties' du 'Microservice-produits', excepté le nom de celui-ci, et collez le tout dans le nouveau fichier créé :
//                  microservice-produits.properties
//                  server.port=9001
//                  #Configurations H2
//                  spring.jpa.show-sql=true
//                  spring.h2.console.enabled=true
//                  spring.datasource.url=jdbc:h2:mem:testdb
//                  spring.datasource.driverClassName=org.h2.Driver
//                  spring.datasource.username=sa
//                  spring.datasource.password=
//                  spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
//                  spring.jpa.hibernate.ddl-auto=none
//                  #Nos configurations
//                  mes-configs.limitDeProduits= 4
//      - Dans 'application.properties' du Microservice-produits, il vous restera donc :
//                  spring.application.name=microservice-produits
//      - Rendez-vous au terminal d'IntelliJ, puis pointez vers le dossier créé :
//                  cd config-server-repo/
//      - Initialisez un nouveau dépôt GIT local que nous allons pousser plus tard vers le distant :
//                  git init
//      - Ajoutez les fichiers du dossier au GIT :
//                  git add .
//      - Ajoutez l'URL du dépôt distant à celui-ci :
//                  git remote add origin https://NOM-UTILISATEUR:MOT-DE-PASSE@github.com/AmarMicroDev/mcommerce-config-repo.git
//          --> Veillez à faire les remplacements de nom d'utilisateur et de mot de passe, ainsi qu'à mettre votre propre URL à la place de la mienne.
//      - Faites un commit du contenu :
//                  git commit -m "Premier commit"
//      - Puis rendez-vous dans la branche 'Main' :
//                  git branch -M main
//      - Poussez enfin le tout vers le dépôt distant :
//                  git push -u origin master
// Vous avez maintenant toutes les configurations du 'Microservice-produits' disponibles dans le dépôt distant.
//      --> Maintenant, mettons en place le serveur de configuration.
// -----------
//  - Utilisez Spring Cloud Config :
// Nous allons utiliser un starter afin de créer notre serveur de configuration.
// Rendez-vous dans Spring Initializr, choisissez Spring Cloud Config, puis renseignez les champs comme suit :
//      --> Project : Maven Project.
//      --> Language : Java.
//      --> SpringBoot : 2.7.17.
//      --> Project Metadata :
//              --> Group : com.mcommerce.
//              --> Artifact : config-server.
//              --> Name : config-server.
//              --> Packaging : jar.
//              --> Java : 11.
//      --> Dependencies : Config Server.
// Téléchargez et extrayez le dossier dans celui de notre projet.
// Importez-le ensuite comme nouveau module, exactement comme vous l'avez fait pour les autres microservices dans la première partie de ce cours.
// Pour que notre serveur fonctionne, nous avons besoin de lui indiquer où aller chercher les fichiers de configuration pour les servir ensuite à nos microservices.
// Modifiez le pom pour qu’il ressemble à :
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                      xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
//                      <modelVersion>4.0.0</modelVersion>
//                      <groupId>com.mcommerce</groupId>
//                      <artifactId>config-server</artifactId>
//                      <version>0.0.1-SNAPSHOT</version>
//                      <packaging>jar</packaging>
//                      <name>config-server</name>
//                      <description>Demo project for Spring Boot</description>
//                      <parent>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-parent</artifactId>
//                          <relativePath/> <!-- lookup parent from repository -->
//                      </parent>
//                      <properties>
//                          <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
//                          <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
//                          <java.version>11</java.version>
//                          <spring-cloud.version>2020.0.4</spring-cloud.version>
//                      </properties>
//                      <dependencies>
//                          <dependency>
//                              <groupId>org.springframework.cloud</groupId>
//                              <artifactId>spring-cloud-config-server</artifactId>
//                              <version>3.1.0</version>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.springframework.boot</groupId>
//                              <artifactId>spring-boot-starter-test</artifactId>
//                              <scope>test</scope>
//                          </dependency>
//                      </dependencies>
//                      <dependencyManagement>
//                          <dependencies>
//                              <dependency>
//                                  <groupId>org.springframework.cloud</groupId>
//                                  <artifactId>spring-cloud-dependencies</artifactId>
//                                  <version>${spring-cloud.version}</version>
//                                  <type>pom</type>
//                                  <scope>import</scope>
//                              </dependency>
//                          </dependencies>
//                      </dependencyManagement>
//                      <build>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.springframework.boot</groupId>
//                                  <artifactId>spring-boot-maven-plugin</artifactId>
//                              </plugin>
//                          </plugins>
//                      </build>
//                      <repositories>
//                          <repository>
//                              <id>spring-milestones</id>
//                              <name>Spring Milestones</name>
//                              <url>https://repo.spring.io/milestone</url>
//                              <snapshots>
//                                  <enabled>false</enabled>
//                              </snapshots>
//                          </repository>
//                      </repositories>
//                  </project>
// Rendez-vous donc à 'application.properties' et renseignez l'URL de dépôt distant :
//                      spring.cloud.compatibility-verifier.enabled=false
//                      spring.application.name=config-server
//                      server.port:9101
//                      spring.cloud.config.server.git.uri=https://github.com/EmileVitu/mcommerce-config-repo.git
//                      spring.cloud.config.server.git.username=EmileVitu
//                      spring.cloud.config.server.git.password=A@rs3GitHub
//                      spring.cloud.config.server.git.ignore-local-ssh-settings=true
// N’oubliez pas de remplacer l’URL de Git par votre URL.
// Tous nos Edge Microservices seront sur des ports commençant par 91.
//      --> Celui de config-server est donc 9101. N'oubliez pas de renseigner également son nom (config-server).
// Il suffit maintenant de déclarer ce microservice comme étant un serveur de configuration, grâce à '@EnableConfigServer'.
//                  package com.mcommerce.configserver;
//                  import org.springframework.boot.SpringApplication;
//                  import org.springframework.boot.autoconfigure.SpringBootApplication;
//                  import org.springframework.cloud.config.server.EnableConfigServer;
//                  @SpringBootApplication
//                  @EnableConfigServer
//                  public class ConfigServerApplication {
//                      public static void main(String[] args) {
//                          SpringApplication.run(ConfigServerApplication.class, args);
//                      }
//                  }
// Démarrez votre serveur Spring Cloud Config et rendez-vous à l'URL 'http://localhost:9101/microservice-produits/default'.
// Vous obtenez alors :
//                  {
//                      "name": "microservice-produits",
//                      "profiles":
//                          [
//                          "default"
//                          ],
//                          "label": null,
//                          "version": "6c360ea596e6d23a71eaa53788643c40ac22acdd",
//                      "state": null,
//                      "propertySources":
//                          [
//                              {
//                                  "name": "https://github.com/aiwanesk/config-server-repo.git/microservice-produits.properties",
//                                  "source":
//                                      {
//                                          "server.port": "9001",
//                                          "spring.jpa.show-sql": "true",
//                                          "spring.h2.console.enabled": "true",
//                                          "spring.datasource.sql-script-encoding": "UTF-8",
//                                          "mes-configs.limitDeProduits": "4"
//                                      }
//                              }
//                          ]
//                  }
// Le serveur est donc allé chercher le fichier de configuration dans le GIT, et expose une API qui répond à l'URL "/nom-du-microservice/default".
// Il fournit ensuite sous format JSON toutes les configurations présentes dans le fichier.
// -----------
//  - Liez un microservice à Spring Cloud Config :
// Nous avons un dépôt distant relié à notre serveur Spring Cloud Config.
// Il reste à demander au Microservice-produits de récupérer le contenu de ces fichiers de configuration depuis le serveur de configuration.
// Pour ce faire, il suffit de modifier pom.xml de Microservice-produits afin d'ajouter le starter spring-cloud-starter-config :
//                  <?xml version="1.0" encoding="UTF-8"?>
//                  <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
//                      xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
//                      <modelVersion>4.0.0</modelVersion>
//                      <groupId>com.mproduits</groupId>
//                      <artifactId>mproduits</artifactId>
//                      <version>0.0.1-SNAPSHOT</version>
//                      <packaging>jar</packaging>
//                      <name>mproduits</name>
//                      <description>Microservice de gestion des produits</description>
//                      <parent>
//                          <groupId>org.springframework.boot</groupId>
//                          <artifactId>spring-boot-starter-parent</artifactId>
//                          <version>2.5.5</version>
//                          <relativePath/> <!-- lookup parent from repository -->
//                      </parent>
//                      <properties>
//                          <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
//                          <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
//                          <java.version>11</java.version>
//                          <spring-cloud.version>2020.0.4</spring-cloud.version>
//                      </properties>
//                      <dependencies>
//                          <dependency>
//                              <groupId>org.springframework.boot</groupId>
//                              <artifactId>spring-boot-starter-web</artifactId>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.springframework.boot</groupId>
//                              <artifactId>spring-boot-starter-data-jpa</artifactId>
//                          </dependency>
//                          <dependency>
//                              <groupId>com.h2database</groupId>
//                              <artifactId>h2</artifactId>
//                              <scope>runtime</scope>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.springframework.boot</groupId>
//                              <artifactId>spring-boot-starter-test</artifactId>
//                              <scope>test</scope>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.springframework.cloud</groupId>
//                              <artifactId>spring-cloud-starter-config</artifactId>
//                          </dependency>
//                          <dependency>
//                              <groupId>org.springframework.cloud</groupId>
//                              <artifactId>spring-cloud-starter-bootstrap</artifactId>
//                              <version>3.0.0</version>
//                          </dependency>
//                      </dependencies>
//                      <dependencyManagement>
//                          <dependencies>
//                              <dependency>
//                                  <groupId>org.springframework.cloud</groupId>
//                                  <artifactId>spring-cloud-dependencies</artifactId>
//                                  <version>${spring-cloud.version}</version>
//                                  <type>pom</type>
//                                  <scope>import</scope>
//                              </dependency>
//                          </dependencies>
//                      </dependencyManagement>
//                      <build>
//                          <plugins>
//                              <plugin>
//                                  <groupId>org.springframework.boot</groupId>
//                                  <artifactId>spring-boot-maven-plugin</artifactId>
//                              </plugin>
//                          </plugins>
//                      </build>
//                      <repositories>
//                          <repository>
//                              <id>spring-milestones</id>
//                              <name>Spring Milestones</name>
//                              <url>https://repo.spring.io/milestone</url>
//                              <snapshots>
//                                  <enabled>false</enabled>
//                              </snapshots>
//                          </repository>
//                      </repositories>
//                  </project>
// Renommez ensuite 'application.properties' en 'bootstrap.properties', puis ajoutez :
//                  spring.cloud.config.uri=http://localhost:9101
// Lancez 'config-server' et 'Microservice-produits'. Vous verrez dans la console en première ligne :
//                  Fetching config from server at: http://localhost:9101
// Cette ligne indique que la première chose que fait votre microservice est de récupérer la configuration via 'server-config'.
// Testez votre microservice "produits" en récupérant la liste des produits.
// Vous devriez n'en recevoir que 4, comme configuré dans le dépôt GitHub.
// -----------
//  - Actualisez la configuration de votre microservice :
// Nous avons un dernier problème à résoudre. Si vous changez la valeur de 'mes-configs.limitDeProduits' et que vous réinvoquez '/Produits', vous remarquerez que rien ne change.
// En effet, la configuration est chargée une seule fois au démarrage du microservice, pour des raisons évidentes de performance.
//      --> Vous avez néanmoins la possibilité de demander à votre microservice de s'actualiser et de recharger le fichier de configuration.
//              --> Pour ce faire, il faut lui envoyer un signal de "Refresh".
// Pour cela, nous devons ajouter Spring Actuator à notre microservice, qui nous exposera un URI /refresh permettant de forcer la réactualisation des valeurs de configuration.
//      - Ajoutez donc Spring Actuator dans le pom.xml de Microservice-produits :
//                  <dependency>
//                      <groupId>org.springframework.boot</groupId>
//                      <artifactId>spring-boot-starter-actuator</artifactId>
//                  </dependency>
//      - Actualisez Maven.
//      - Rendez-vous dans bootstrap.properties (ou dans le fichier correspondant dans le GIT), et ajoutez ceci :
//                  'management.endpoints.web.exposure.include=refresh'
// Cela aura pour effet d'exposer l’endpoint refresh d'Actuator. Nous y reviendrons dans un prochain chapitre.
// Nous allons maintenant indiquer à un de nos beans qui accède aux propriétés, de se rafraîchir à chaque fois qu'un événement 'Refresh' est lancé.
// Nous allons donc ajouter l'annotation '@RefreshScope' à 'ApplicationPropertiesConfiguration.java' :
//                  @Component
//                  @ConfigurationProperties("mes-configs")
//                  @RefreshScope
//                  public class ApplicationPropertiesConfiguration {
//                      private int limitDeProduits;
//                      public int getLimitDeProduits() {
//                          return limitDeProduits;
//                      }
//                      public void setLimitDeProduits(int limitDeProduits) {
//                          this.limitDeProduits = limitDeProduits;
//                      }
//                  }
//      --> Lancez tous les microservices, puis appelez Microservice-produits : localhost:9001/Produits.
// Changez la valeur de 'mes-configs.limitDeProduits' dans le GIT, puis appelez de nouveau 'localhost:9001/Produits'.
// Comme vous pouvez le constater, vous avez le même nombre de produits retournés. Cela indique que votre microservice n'a pas pris en compte ce changement.
// Déclenchez alors un événement Refresh en envoyant une requête POST à 'http://localhost:9001/actuator/refresh' via Postman. Vous obtenez alors ce résultat :
//                  [
//                      "config.client.version",
//                      "mes-configs.limitDeProduits"
//                  ]
// Ce retour vous indique clairement que 'mes-configs.limitDeProduits' a changé.
//      --> Cela déclenche la réactualisation dans tous les beans annotés par '@RefreshScope'.
// Maintenant, si vous retentez 'localhost:9001/Produits', vous avez le bon nombre de produits en retour.
// Le bean 'ApplicationPropertiesConfiguration' s'est actualisé et a récupéré les nouvelles valeurs mises à jour dans le GIT.
// Comme on accède à ces propriétés dans notre microservice exclusivement via ce bean, cette valeur est mise à jour partout.
//      --> Challenge : Essayez d'externaliser tous les fichiers de configuration des autres microservices !
// La branche pour retrouver tout le code de ce chapitre est 'ExternalisationConfig' :
//      --> 'https://github.com/OpenClassrooms-Student-Center/4668216-Optimisez-votre-architecture-Microservices/tree/ExternalisationConfig'.
// -----------
// - En résumé :
//      --> 'application.properties' peut être utilisé pour stocker des constantes auxquelles on peut accéder grâce à un bean annoté avec '@ConfigurationProperties'.
//      --> 'Config-Server' permet de récupérer les fichiers de configuration dans un dépôt, et de les servir aux microservices en se basant sur leurs noms.
//      --> Pour récupérer automatiquement ces configurations, il suffit d’ajouter le 'starter spring-cloud-starter-config', et de renommer 'application.properties' en bootstrap.properties.
//      --> Nous pouvons actualiser à la volée la configuration d’un microservice en l’obligeant à récupérer une version fraîche du fichier '.properties'.
//              Pour ce faire, il suffit d’envoyer un POST vers l'endpoint '/refresh' exposé par 'Spring Actuator'.
// Dans le prochain chapitre, vous allez apprendre à utiliser Eureka pour rendre vos mocroservices "découvrables".
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Rendez vos microservices découvrables grâce à Eureka //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Quand votre application répond à une montée en charge et que vous avez plusieurs instances de chaque microservice, il est vital de pouvoir garder un registre de toutes les instances disponibles.
// Et ce, afin de distribuer la charge entre celles-ci.
// Une fois en place, les instances des microservices viennent s'enregistrer dans le registre d'Eureka.
// Pour appeler un microservice, il suffit de piocher dans cette liste d'instances qu'Eureka expose via une API REST.
// Eureka de Netflix remplit précisément cette fonction. Une fois en place, les instances des microservices viennent s'enregistrer dans le registre d'Eureka.
// Pour appeler un microservice, il suffira de piocher dans cette liste d'instances qu'Eureka expose via une API REST.
// Eureka offre un client capable de réaliser des opérations de récupération des listes d'instances.
// -----------
//  - Mettez en place Eureka :
// Commencez par générer un microservice Eureka sur Spring Initializr, en y ajoutant "Eureka Server" et "Config Client" qui va nous permettre d'externaliser la configuration :
//      --> Project : Maven Project.
//      --> Language : Java.
//      --> SpringBoot : 2.7.17.
//      --> Project Metadata :
//              --> Group : com.mcommerce.
//              --> Artifact : zuul-server.
//              --> Name : zuul-server.
//              --> Packaging : jar.
//              --> Java : 11.
//      --> Dependencies :
//              --> Config Server.
//              --> Eureka Discovery Client.
// Importez le microservice dans IntelliJ, de la même façon que vous l'avez fait pour les précédents.
// Externalisez le fichier de configuration en créant un fichier 'eureka-server.properties' dans 'config-server-repo'.
//                  eureka-server.properties
//                  server.port= 9102
//                  spring.application.name=microservice-produits
//                  eureka.client.registerWithEureka=false
//                  eureka.client.fetchRegistry=false
//                  spring.cloud.config.import-check.enabled=false
// Explications :
//      - On définit le port dans lequel Eureka sera accessible : 9102.
//      - 'eureka.client.serviceUrl.defaultZone' : pour utilisez le client Eureka pour accéder au registre d'Eureka, vous devez renseigner cette ligne de configuration.
//          Et ce, pour pointer vers l'URL d'Eureka. Alors pourquoi allons-nous renseigner l'URL d'Eureka si ce microservice est déjà enregistré dans Eureka ?
//          Eh bien parce qu'Eureka offre la possibilité de se répliquer en plusieurs instances.
//          Vous pouvez alors pointer vers d'autres instances d'Eureka. Ce mode s'appelle "cluster mode".
//          Comme nous n'allons utiliser qu'un seul serveur Eureka, nous allons pointer vers sa propre URL.
//      - 'eureka.client.registerWithEureka' et 'eureka.client.fetchRegistry' sont tous les 2 à false, étant donné que nous n'allons pas utiliser Eureka en mode cluster.
//              --> N'oubliez pas de renommer 'application.properties' en 'bootstrap.properties'.
// Ajoutez l'annotation '@EnableEurekaServer' à 'EurekaServerApplication.java' :
//                  package com.mcommerce.eurekaserver;
//                  import org.springframework.boot.SpringApplication;
//                  import org.springframework.boot.autoconfigure.SpringBootApplication;
//                  import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;
//                  @SpringBootApplication
//                  @EnableEurekaServer
//                  public class EurekaServerApplication {
//                      public static void main(String[] args) {
//                          SpringApplication.run(EurekaServerApplication.class, args);
//                      }
//                  }
// C'est tout ! Assurez-vous que 'config-server' est lancé, puis lancez Eureka.
// Rendez-vous ensuite à http://localhost:9102/.
//      --> Vous arriverez alors sur une page qui présente un certain nombre d'informations sur votre serveur Eureka.
// La plus importante est que c'est ici que vous verrez apparaître la liste des instances des microservices qui viendront s'enregistrer.
// -----------
//  - Ajoutez le Client Eureka :
// Afin que les différents microservices commencent à s'enregistrer dans notre serveur Eureka, nous devons ajouter le client Eureka à chacun d'entre eux.
// Prenons comme exemple Microservices-produits. Rendez-vous dans le pom.xml et ajoutez cette dépendance :
//                  <dependency>
//                      <groupId>org.springframework.cloud</groupId>
//                      <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
//                  </dependency>
// Ajoutez ensuite cette ligne à microservice-produits.properties dans le dépôt :
//                  #Eureka
//                  eureka.client.serviceUrl.defaultZone: http://localhost:9102/eureka/
// Cette ligne indique l'URL d'Eureka à laquelle il faut s'enregistrer.
// Rendez-vous enfin à 'MproduitsApplication.java', et ajoutez l'annotation '@EnableDiscoveryClient' :
//                  package com.mproduits;
//                  import com.mproduits.configurations.ApplicationPropertiesConfiguration;
//                  import org.springframework.boot.SpringApplication;
//                  import org.springframework.boot.autoconfigure.SpringBootApplication;
//                  import org.springframework.boot.context.properties.EnableConfigurationProperties;
//                  import org.springframework.cloud.client.discovery.EnableDiscoveryClient;
//                  @SpringBootApplication
//                  @EnableConfigurationProperties
//                  @EnableDiscoveryClient
//                  public class MproduitsApplication {
//                      public static void main(String[] args) {
//                          SpringApplication.run(MproduitsApplication.class, args);
//                      }
//                  }
// Votre microservice bénéficie à présent du client Eureka, qui ira enregistrer votre instance à chaque démarrage.
// Démarrez votre service et rendez-vous à 'http://localhost:9102/' :
// Vous voyez alors que votre microservice est enregistré avec un statut "UP" indiquant qu'il est en fonction.
// Si vous arrêtez le Microservice-produits, vous verrez qu'Eureka le détecte immédiatement, et le supprime du registre !
//      --> La branche GIT pour ce chapitre est Eureka :
// -----------
//  - En résumé :
//      --> Eureka permet de visualiser nos applications et leur état.
//      --> Eureka permet de tenir la montée en charge de nos applications.
// Dans le prochain chapitre, nous allons mettre en place du load balancing avec Ribbon.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Équilibrez la charge de votre application grâce à Ribbon //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Ribbon est un équilibreur de charge côté client. Une fois installé, il va pouvoir aller consulter la liste des instances disponibles pour un microservice.
// Et cela, pour les choisir à tour de rôle afin d'équilibrer la charge.
// Pour tester Ribbon, nous devons tout d'abord lancer plusieurs instances du Microservice-produits, qui feront l'objet de nos tests.
// -----------
//  - Lancez plusieurs instances d'un microservice avec IntelliJ :
// Pour lancer différentes instances d'un microservice, vous pouvez soit utiliser 'Docker', soit les lancer sur différents ports directement depuis IntelliJ.
// Afin de garder notre application regroupée dans notre IDE et de pouvoir jouer avec les instances facilement, nous allons opter pour la deuxième méthode.
// Pour lancer différentes instances du Microservice-produits sur différents ports, nous allons commencer par supprimer 'server.port=9001' de 'microservices-produits.properties' dans notre GIT.
// Éditez votre application.properties dans clientui :
//                  spring.application.name=microservice-clientui
//                  spring.cloud.config.uri=http://localhost:9101
//                  eureka.client.registerWithEureka=true
//                  eureka.client.fetchRegistry=true
//                  eureka.client.serviceUrl.defaultZone=http://localhost:9102/eureka/
// Puis, microservices-produits.properties :
//                  #Configurations H2
//                  spring.jpa.show-sql=true
//                  spring.h2.console.enabled=true
//                  #défini l'encodage pour data.sql
//                  spring.datasource.sql-script-encoding=UTF-8
//                  #Nos configurations
//                  mes-configs.limitDeProduits= 3
//                  #Eureka
//                  eureka.client.serviceUrl.defaultZone: http://localhost:9102/eureka/
//      --> Nous allons ensuite décider du port de chaque instance en fournissant directement celui-ci en argument à la VM.
// Allez dans la liste des microservices en haut à droite, puis cliquez sur "Edit Configuration" :
// Cliquez sur le Microservice-produits puis ajoutez à son nom (9001) afin de le différencier.
// Ajoutez ensuite l'argument -Dserver.port=9001 dans le champ VM options : Ce microservice tournera alors sur le port 9001.
// Dupliquez maintenant la configuration de ce microservice.
// Dans la nouvelle copie de configuration de votre microservice, changez encore le nom en y ajoutant le port (9011), idem pour VM Options.
// Très bien ! Vous avez maintenant 2 configurations de lancement de votre microservice. Fermez la fenêtre et rendez-vous en haut à droite pour lancer vos 2 instances.
//      --> Assurez-vous qu'Eureka et config-server sont bien lancés avant.
// Rendez-vous à l'URL d'Eureka , vous verrez apparaître les 2 instances lancées de Microservice-produits dans la colonne "Status".
// -----------
//  - Ajoutez Ribbon :
// Nous allons maintenant ajouter Ribbon à notre client. La procédure est un peu la même que pour Eureka.
// Ajoutez cette dépendance dans le pom.xml et actualisez Maven :
//                  <dependency>
//                      <groupId>org.springframework.cloud</groupId>
//                      <artifactId>spring-cloud-netflix-ribbon</artifactId>
//                  </dependency>
// Modifiez MicroserviceProduitsProxy comme suit :
//                  package com.clientui.proxies;
//                  import com.clientui.beans.ProductBean;
//                  import org.springframework.cloud.netflix.ribbon.RibbonClient;
//                  import org.springframework.cloud.openfeign.FeignClient;
//                  import org.springframework.web.bind.annotation.GetMapping;
//                  import org.springframework.web.bind.annotation.PathVariable;
//                  import java.util.List;
//                  import java.util.Optional;
//                  @FeignClient(name = "microservice-produits")
//                  @RibbonClient(name = "microservice-produits")
//                  public interface MicroserviceProduitsProxy {
//                      @GetMapping(value = "/Produits")
//                      List<ProductBean> listeDesProduits();
//                      // Notez ici la notation @PathVariable("id") qui est différente de celle qu'on utlise dans le contrôleur
//                      @GetMapping( value = "/Produits/{id}")
//                      ProductBean recupererUnProduit(@PathVariable("id") int id);
//                  }
// Explications :
//      --> Nous commençons par supprimer l'argument URL qui indiquait à Feign l'adresse de Microservice-produits.
//      --> On ajoute '@RibbonClient(name = "microservice-produits")' qui va demander à Ribbon d'aller chercher automatiquement la liste des URL.
//              Et par conséquent les instances de Microservice-produits disponibles.
// Très bien ! Maintenant, nous allons indiquer à Ribbon la liste de toutes ces URL de Microservice-produits.
// Pour ce faire, rendez-vous dans le fichier de configuration du client dans le Git, et ajoutez ceci :
//                  #Ribbon
//                  microservice-produits.ribbon.listOfServers=localhost:9001,localhost:9011
// Votre client Ribbon est prêt, et il a tout ce qu'il faut pour alterner entre les 2 URL fournies quand vous faites appel au Microservice-produits.
// Pour vérifier l'activité des deux instances de nos microservices, rendez-vous à l'onglet "Run" en bas d'IntelliJ :
// Actualisez une première fois la page et revenez dans la console. Vérifiez les 2 instances, vous devriez voir, dans une des deux, une requête qui s'est ajoutée en bas, de type :
//                  Hibernate: select product0_.id as id1_0_, product0_.description as descript2_0_,
//                      product0_.image as image3_0_, product0_.prix as prix4_0_, product0_.titre as
//                      titre5_0_ from product product0_
// Cette requête est celle générée par cette instance de Microservice-produits pour récupérer la liste des produits dans la base de données.
// Si vous réactualisez plusieurs fois, vous verrez à chaque fois cette requête s'afficher alternativement dans l'instance (9001) et (9011).
// Ceci vous confirme que les 2 instances sont appelées à tour de rôle par le client grâce à Ribbon.
// Celui-ci exécute un algorithme afin de distribuer les requêtes alternativement sur toutes les instances disponibles, équilibrant ainsi la charge.
// Cela ne serait-il pas mieux de lui demander d'aller les chercher dans le registre d'Eureka plutôt que de les noter en dur dans le fichier de configuration ?
// Tout à fait, et c'est là que la magie de Spring Cloud opère. Ribbon et Eureka fonctionnent ensemble sans besoin d'ajouter de configuration.
// Il suffit de supprimer la ligne où sont définies les URL, pour que Ribbon contacte Eureka pour avoir la liste des instances.
// Supprimez alors cette ligne :
//                  #Ribbon
//                  microservice-produits.ribbon.listOfServers=localhost:9001,localhost:9011
// Redémarrez vos microservices, et vous verrez que la charge est bien équilibrée entre les instances. Vous pouvez vous amuser à ajouter une 3e instance pour vérifier cela.
// Maintenant que Ribbon est là, nous allons mettre en place une Gateway avec Zuul, qui est un service créé par Netflix !
// -----------
//  - En résumé :
//      --> Ribbon est un outil de load balancing.
//      --> Le load balancing permet de répartir uniformément les instances sur différents serveurs.
// Dans le chapitre suivant, vous allez apprendre à utiliser Zuul pour créer une API gateway pour votre application.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Créez une API Gateway pour votre application Zuul /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Zuul va se positionner comme le point d'entrée unique de notre application.
// Ainsi, quand ClientUi, par exemple, voudra appeler les microservices, il passera par Zuul.
// Ce dernier s'occupe de dispatcher, modifier et appliquer des filtres et des règles à ces requêtes.
// -----------
//  - Ajoutez Zuul à l'application :
// Rendez-vous sur Spring Initializr, et choisissez les composants suivants :
//      --> Project : Maven Project.
//      --> Language : Java.
//      --> SpringBoot : 2.7.17.
//      --> Project Metadata :
//              --> Group : com.mcommerce.
//              --> Artifact : zuul-server.
//              --> Name : zuul-server.
//              --> Packaging : jar.
//              --> Java : 11.
//      --> Dependencies :
//              --> Config Server.
//              --> Eureka Discovery Client.
// Ensuite, ajoutez cette dépendance à votre pom nouvellement généré.
//                  <!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-netflix-zuul -->
//                  <dependency>
//                      <groupId>org.springframework.cloud</groupId>
//                      <artifactId>spring-cloud-starter-netflix-zuul</artifactId>
//                  </dependency>
// Téléchargez et importez le microservice dans le projet, comme vous l'avez fait pour les autres microservices.
// Renommez 'application.properties' en 'bootstrap.properties', puis ajoutez ceci :
//                  spring.application.name=zuul-server
//                  spring.cloud.config.uri=http://localhost:9101
// Créez dans le dépôt distant 'zuul-server.properties' :
//                  server.port 9004
//                  #Eureka
//                  eureka.client.serviceUrl.defaultZone: http://localhost:9102/eureka/
// Activez ZUUL ainsi que le client Eureka :
//                  import org.springframework.boot.SpringApplication;
//                  import org.springframework.boot.autoconfigure.SpringBootApplication;
//                  import org.springframework.cloud.client.discovery.EnableDiscoveryClient;
//                  import org.springframework.cloud.netflix.zuul.EnableZuulProxy;
//                  @SpringBootApplication
//                  @EnableZuulProxy
//                  @EnableDiscoveryClient
//                  public class ZuulServerApplication {
//                      public static void main(String[] args) {
//                          SpringApplication.run(ZuulServerApplication.class, args);
//                      }
//                  }
// Démarrez ZUUL et vérifiez qu'Eureka le reconnaît bien.
// ZUUL fonctionne nativement avec Eureka. Il récupère la liste de tous les microservices disponibles dans Eureka, et les expose via l'URL 'localhost:9004/nom-du-microservice'.
// Ainsi, pour récupérer la liste des produits, il suffit d'appeler 'localhost:9004/microservice-produits/Produits'.
// Vous récupérez alors la liste des produits, comme si vous aviez appelé Microservice-produits directement.
// -----------
//  - Appliquez des filtres :
// Les filtres sont une des fonctionnalités les plus importantes de ZUUL.
//      --> Quand un client appelle ZUUL, celui-ci vous offre la possibilité d'appliquer un filtre à cette requête avant de la passer au microservice concerné.
// Dans votre filtre, vous pouvez manipuler, modifier ou adapter une requête selon les besoins.
// Par exemple, vous pouvez faire un contrôle de sécurité afin de vérifier que le client a bien le droit d'appeler tel ou tel microservice.
// Créons alors un premier filtre ZUUL. Ce filtre va tout simplement utiliser un logger SL4j afin d'afficher un message dans la console.
// Créez une classe, appelez-la LogFilter et mettez-la dans un package "filters" :
//                  package com.mcommerce.zuulserver.filters;
//                  import com.netflix.zuul.ZuulFilter;
//                  import com.netflix.zuul.exception.ZuulException;
//                  import org.springframework.stereotype.Component;
//                  @Component
//                  public class LogFilter extends ZuulFilter {
//                      @Override
//                      public String filterType() {
//                          return null;
//                      }
//                      @Override
//                      public int filterOrder() {
//                          return 0;
//                      }
//                      @Override
//                      public boolean shouldFilter() {
//                          return false;
//                      }
//                      @Override
//                      public Object run() throws ZuulException {
//                          return null;
//                      }
//                  }
// Explications :
//      --> Un filtre ZUUL est simplement une classe qui hérite de 'ZuulFilter'. Vous devez implémenter les 4 méthodes obligatoires.
//      --> filterType : cette méthode sert à déterminer le type de filtre à appliquer, elle propose 4 possibilités :
//              - pre : permet d'exécuter du code avant la redirection de la requête vers sa destination finale.
//              - post : permet d'exécuter du code après que la requête a été redirigée.
//              - route : permet d'agir sur la façon de rediriger les requêtes.
//              - error : permet d'agir en cas d'erreur lors de la redirection de la requête.
//      --> filterOrder  : dans votre API Gateway ZUUL, vous aurez forcément des dizaines de filtres. Cette méthode détermine l'ordre d'exécution de ces filtres.
//      --> shouldFilter  : permet d'écrire les conditions qui doivent être remplies pour que le filtre s'exécute.
//      --> run  : c'est ici que va la logique de votre filtre.
// Modifiez alors le filtre afin de déterminer toutes ces options :
//                  package com.mcommerce.zuulserver.filters;
//                  import com.netflix.zuul.ZuulFilter;
//                  import com.netflix.zuul.exception.ZuulException;
//                  import org.springframework.stereotype.Component;
//                  @Component
//                  public class LogFilter extends ZuulFilter {
//                      @Override
//                      public String filterType() {
//                          return null;
//                      }
//                      @Override
//                      public int filterOrder() {
//                          return 0;
//                      }
//                      @Override
//                      public boolean shouldFilter() {
//                          return false;
//                      }
//                      @Override
//                      public Object run() throws ZuulException {
//                          return null;
//                      }
//                  }
//                  import com.netflix.zuul.ZuulFilter;
//                  import com.netflix.zuul.context.RequestContext;
//                  import com.netflix.zuul.exception.ZuulException;
//                  import org.slf4j.Logger;
//                  import org.slf4j.LoggerFactory;
//                  import org.springframework.stereotype.Component;
//                  import javax.servlet.http.HttpServlet;
//                  import javax.servlet.http.HttpServletRequest;
//                  @Component
//                  public class LogFilter extends ZuulFilter {
//                      Logger log = LoggerFactory.getLogger(this.getClass());
//                      @Override
//                      public String filterType() {
//                          return "pre";
//                      }
//                      @Override
//                      public int filterOrder() {
//                          return 1;
//                      }
//                      @Override
//                      public boolean shouldFilter() {
//                          return true;
//                      }
//                      @Override
//                      public Object run() throws ZuulException {
//                          HttpServletRequest req = RequestContext.getCurrentContext().getRequest();
//                          log.info("**** Requête interceptée ! L'URL est : {} " , req.getRequestURL());
//                          return null;
//                      }
//                  }
// Explications :
//      --> Afin de logger les requêtes reçues, on crée une instance du logger de SL4J.
//      --> On retourne "pre" de 'filterType' afin d'afficher notre message avant que la requête ne soit redirigée.
//      --> On retourne true directement dans 'shouldFilter' afin d'exécuter ce filtre sur toutes les requêtes sans conditions.
//      --> run() : On récupère la requête grâce à 'RequestContext' qui est utilisé par les filtres dans ZUUL, afin de manipuler les requêtes en attendant leur redirection.
//              On affiche ensuite un message avec l'URL de la requête reçue.
// Lancez ZUUL et tous les microservices, puis rendez-vous par exemple à 'localhost:9004/microservice-produits/Produits' afin de tester ZUUL.
// Vous devriez voir votre message de log s'afficher dans la console de ZUUL dans IntelliJ à chaque nouvelle requête :
// Vous pouvez également créer un autre filtre qui s'exécute à la réponse de la requête, par exemple :
//                  package com.mcommerce.zuulserver.filters;
//                  import com.netflix.zuul.ZuulFilter;
//                  import com.netflix.zuul.context.RequestContext;
//                  import com.netflix.zuul.exception.ZuulException;
//                  import org.slf4j.Logger;
//                  import org.slf4j.LoggerFactory;
//                  import org.springframework.stereotype.Component;
//                  import javax.servlet.http.HttpServletRequest;
//                  import javax.servlet.http.HttpServletResponse;
//                  @Component
//                  public class ReponseFilter extends ZuulFilter {
//                      Logger log = LoggerFactory.getLogger(this.getClass());
//                      @Override
//                      public String filterType() {
//                          return "post";
//                      }
//                      @Override
//                      public int filterOrder() {
//                          return 1;
//                      }
//                      @Override
//                      public boolean shouldFilter() {
//                          return true;
//                      }
//                      @Override
//                      public Object run() throws ZuulException {
//                          HttpServletResponse response = RequestContext.getCurrentContext().getResponse();
//                          response.setStatus(400);
//                          log.info(" CODE HTTP {} ", response.getStatus());
//                          return null;
//                      }
//                  }
// Ce filtre récupère toutes les réponses et change le code en 400.
// Redémarrez ZUUL et envoyez via Postman des requêtes vers n'importe quel microservice, vous recevrez invariablement un code HTTP 400 Bad Request.
// N'oubliez pas de désactiver ce filtre (shouldFilter à false), pour qu'il ne vous bloque pas pour le reste du cours.
// -----------
//  - Connectez le client à ZUUL :
// Nous avons mis en place un filtre qui intercepte les requêtes, pour les logger avant de les rediriger vers leur destination finale.
// Nous souhaitons à présent que ClientUI puisse faire appel aux différents microservices via ZUUL.
// Afin que notre client passe par ZUUL, nous devons indiquer aux proxy Feign qu'il faut contacter ZUUL, et non les microservices directement.
// Remplacez alors le nom du microservice de destination par celui de ZUUL :
//                  @FeignClient(name = "zuul-server")
//                  @RibbonClient(name = "microservice-produits")
//                  public interface MicroserviceProduitsProxy {
//                      @GetMapping(value = "/microservice-produits/Produits")
//                      List<ProductBean> listeDesProduits();
//                      // Notez ici la notation @PathVariable("id") qui est différente de celle qu'on utlise dans le contrôleur
//                      @GetMapping( value = "/microservice-produits/Produits/{id}")
//                      ProductBean recupererUnProduit(@PathVariable("id") int id);
//                  }
// On ajoute /microservice-produits/ devant tous les URI. Feign ira alors contacter ZUUL avec l'URI "/microservice-produits/Produits".
// Comme ZUUL extrait alors le nom du microservice concerné de l'URL "microservice-produits", il pourra rediriger la requête vers la destination voulue.
// Redémarrez le client et testez. Vous devriez voir, dans la console de ZUUL, le log de toutes les requêtes et la liste des produits s'afficher.
// Faites de même avec tous les proxies, et votre application devrait fonctionner normalement tout en passant par ZUUL.
// La branche pour ce chapitre est ZUUL.
// -----------
//  - En résumé :
//      --> Zuul permet de rediriger les requêtes à l’intérieur de notre application.
// Il est temps de sécuriser notre application !
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Sécurisez votre application ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Une multitude de possibilités s'offre à nous afin de sécuriser notre API.
// Cela va de l'authentification basique par mot de passe à l'authentification par tokens, en passant par les filtres de ZUUL.
// Nous allons implémenter dans ce chapitre une authentification basique par mot de passe.
// Comme ZUUL est notre point d'entrée unique vers nos microservices, il suffit de sécuriser son accès.
// Nous allons donc utiliser Spring Security, qui offre des mécanismes d'authentification prêts à l'emploi très facilement.
// Ajoutez donc Spring Security à ZUUL :
// pom.xml
//                  <dependency>
//                      <groupId>org.springframework.cloud</groupId>
//                      <artifactId>spring-cloud-starter-security</artifactId>
//                  </dependency>
//                  <dependency>
//                      <groupId>org.springframework.cloud</groupId>
//                      <artifactId>spring-cloud-starter-security</artifactId>
//                  </dependency>
// Nous allons maintenant définir un nom d'utilisateur et un mot de passe. Pour cela, rendez-vous dans 'zuul-server.properties' dans le dépôt GIT, et modifiez-le comme suit :
//                  server.port 9004
//                  #Eureka
//                  eureka.client.serviceUrl.defaultZone: http://localhost:9102/eureka/
//                  #Spring Security
//                  spring.security.user.name=utilisateur
//                  spring.security.user.password=mdp
// ZUUL est maintenant sécurisé, il ne répondra qu'aux requêtes présentant ces informations d'authentification.
// Pour tester, rendez-vous dans Postman et appelez Microservice-produits via ZUUL : 'localhost:9004/microservice-produits/Produits'.
// Vous recevez alors en retour un formulaire HTML d'authentification.
// Afin d'authentifier vos requêtes, rendez-vous dans l'onglet "Authorization" et choisissez "Basic Auth". Entrez ensuite les identifiants :
// Réexécutez la requête, vous recevez alors une réponse JSON, comme prévu.
// -----------
//  - Consommez des microservices sécurisés :
// Si vous essayez à nouveau de lancer le client, vous constaterez que l'application ne marche pas.
// Afin d'ajouter les informations d'authentification à utiliser, nous allons créer un bean de configuration de Feign.
// Créez une classe FeignConfig dans un package "configuration" :
//                  package com.clientui.configuration
//                  import feign.auth.BasicAuthRequestInterceptor;
//                  import org.springframework.context.annotation.Bean;
//                  import org.springframework.context.annotation.Configuration;
//                  @Configuration
//                  public class FeignConfig {
//                      @Bean
//                      public BasicAuthRequestInterceptor mBasicAuthRequestInterceptor(){
//                          return  new BasicAuthRequestInterceptor("utilisateur", "mdp");
//                      }
//                  }
// On retourne un objet de type 'BasicAuthRequestInterceptor' avec les informations d'authentification que Feign utilisera lors de la génération des requêtes.
// Relancez les microservices, vous devriez alors constater que tout fonctionne correctement.
// -----------
//  - Revoyez ce que vous venez d'apprendre :
//      --> Les Edge Microservices sont des microservices qui s'occupent principalement de l'orchestration des microservices métier contenant la logique de l'application.
//      --> Feign est un outil permettant de faire communiquer les microservices très simplement entre eux, en générant automatiquement les requêtes HTTP adéquates à partir de classes appelées proxies.
//      --> Les fichiers de configuration des microservices peuvent être externalisés vers un dépôt GIT.
//              Par exemple grâce à Spring Boot Config. Cet Edge Microservice va alors récupérer la dernière version de chaque fichier de configuration, et la servir au microservice correspondant.
//      --> Pour forcer l'actualisation des données d'un fichier de configuration dans un microservice, il suffit d'envoyer une requête POST vers l'endpoint/refresh exposé par 'Actuator'.
//      --> Eureka est un autre Edge Microservice, qui permet de garder un registre de toutes les instances disponibles des microservices métier.
//              Chaque microservice qui intègre Eureka ira s'enregistrer à chaque démarrage ou lancement d'une nouvelle instance.
//              Eureka vérifie ensuite régulièrement que les microservices sont toujours disponibles, afin de mettre à jour son registre.
//      --> Ribbon est un équilibreur de charge côté client. Une fois intégré dans un microservice, il est capable de communiquer automatiquement avec Eureka.
//              Et ce, afin de choisir l'instance à appeler d'un microservice donné. Un algorithme s'occupe ainsi de répartir les requêtes sur toutes les instances disponibles.
//      --> Lorsque vous avez un nombre important de microservices, ZUUL se positionne comme un microservice servant de point d'entrée unique aux autres microservices.
//              --> C'est ce que l'on appelle une API Gateway.
//      --> ZULL va permettre ainsi de réaliser des opérations communes à tous les microservices, comme la sécurisation de l'accès par exemple.
//              Ou encore la mise en place d'un nombre d'appels limite à l'API, la transformation des requêtes afin de les enrichir avant qu'elles n'atteignent les microservices cibles, etc.
// Notre application est sécurisée, maintenant, passons à l’optimisation. Dans le prochain chapitre, vous allez faire un TP pour vous entraîner à optimiser votre microservice.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Entraînez-vous en optimisant votre microservice ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Pour vous entraîner, réalisez cet exercice étape par étape. Une fois terminé, vous pouvez comparer votre travail avec les pistes que je vous propose.
// Dans cette activité,  vous allez créer un microservice pour gérer les expéditions des commandes.
// Ce microservice permettra de créer l'expédition d’une commande, puis de faire évoluer l’état de celle-ci (en préparation, expédiée, livrée).
// Vous allez réaliser cette activité en 2 parties :
//      - Dans un premier temps, vous allez créer un microservice pour gérer les expéditions.
//      - Puis vous allez créer une page pour le suivi de la commande côté client.
// Forkez puis clonez le projet du cours : 'https://github.com/OCCourses/McommerceActivites' (branche master).
// Vous pousserez ensuite les modifications dans le dépôt issu du fork.
// -----------
//  - Partie 1 : créez un nouveau microservice :
//      1- Créez un nouveau microservice et nommez-le   microservice-expedition  . Ce microservice doit :
//              - Intégrer les starters web, Actuator, JPA et H2.
//              - Avoir un nom déclaré.
//              - Ecouter le port 9006.
//      2- Créez une classe Expedition dans un package appelé model avec comme attributs : id, idCommande et etat.
//      3- Créez une méthode qui répond aux requêtes de type POST, et qui permet d’ajouter une nouvelle expédition à la base de données.
//          Par exemple, si vous exécutez une requête POST avec le JSON suivant :
//                  {
//                      "id": 1,
//                      "idCommande": 3,
//                      "etat": 1
//                  }
//      4- Créez une méthode qui permet de récupérer une expédition par son ID.
//      5- Créez une méthode qui permet de mettre à jour une expédition.
// -----------
//  - Partie 2 : interface de visualisation :
// Dans ClientUI, créez une page qui affiche l’état de la commande.
// Les états possibles sont les suivants :
//      - 0 : En préparation
//      - 1 : Expédiée
//      - 2 : Livrée
// Pour cela :
//      1- Ajoutez Ribbon à microservice-expedition.
//      2- Pour faire appel à microservice-expedition, vous devez utiliser Feign.
//          Le rôle de Feign est :
//              - D'utiliser Ribbon pour aller chercher l’URL.
//              - D'envoyer les requêtes en passant par l’API Gateway ZUUL.
//      3- Ajoutez Eureka à Microservice-expedition.
//      4- Faites les modifications nécessaires afin que les requêtes générées par Feign via le proxy d’expédition passent par ZUUL.
// -----------
//  - Vérifiez votre travail :
// Alors, vous êtes allé au bout ?
// Voici un exemple pour vous permettre de vérifier votre travail : 'https://static.oc-static.com/activities/2625/evaluation_resources/optimisez-votre-microservice_exemple-2018-06-29T102523.zip'.
// Suivez le guide pour vérifier votre travail :
//      - Créez des microservices exposant une API REST pour les opérations CRUD et configurez-les
//          L'implémentation de l'exercice 1 doit répondre aux critères suivants :
//              - Une classe DAO, un model et un contrôleur sont créés.
//              - Les trois méthodes créées répondent à POST, GET et PUT.
//              - Le nom du microservice et le port sont définis dans 'application.properties'.
//              - Les opérations fonctionnent quand on teste avec Postman.
//          Pour cette compétence, l'ensemble du code à valider doit se trouver dans le dossier 'microservice-expedition'.
//                  --> Vous pouvez comparer le code rendu et l'exemple ci-dessus.
//          Pour valider qu'une classe DAO, un model et un contrôleur ont été créés, vérifiez les classes :
//              - dao/ExpeditionDAO.
//              - model/Expedition.
//              - web/controller/ExpeditionController.
//          Conformément aux critères, vérifiez également que :
//              - Les trois méthodes créées répondent à POST, GET et PUT.
//              - Le nom du microservice et le port sont définis dans 'application.properties'.
//              - Les opérations fonctionnent quand on teste avec Postman.
//      - Faites communiquer les microservices grâce à Feign et créez des classes proxy :
//          Étudiez le code de l'exercice 2, vous devez créer une classe proxy dans 'ClientUI'. Celle-ci doit comporter :
//              - Les annotations '@FeignClient' et '@RibbonClient' correctement paramétrées.
//              - Une méthode 'etatExpedition' utilisant la notation '@PathVariable' à l'endroit pertinent.
//              - Une classe 'ExpeditionBean' qui reprend la structure du modèle 'Expedition'.
//              - Une méthode dans 'ClientController' qui fait appel à la classe proxy pour récupérer une expédition.
//          Vérifiez notamment la classe MicroserviceExpeditionProxy.
//              1- Les annotations doivent être paramétrées de la manière suivante :
//                  @FeignClient(name = "zuul-server")
//                  @RibbonClient(name = "microservice-expedition")
//              2- La méthode 'etatExpedition' doit comporter la bonne notation du paramètre, au format '@PathVariable("id")'.
//          Vous pouvez retrouver la syntaxe complète dans l'exemple ci-dessus.
//          De plus, la classe 'ExpeditionBean' doit reprendre la structure du modèle 'Expedition'.
//          Enfin, une méthode de la classe 'ClientController' doit faire appel à la classe proxy pour récupérer une expédition.
//          Cette méthode s'appelle suivi dans le corrigé, mais le nom peut être différent dans le code que vous corrigez.
//          Le rendu de la partie HTML avec la syntaxe Thymeleaf ne fait pas partie des critères d'évaluation.
//          Ne refusez pas une validation pour des raisons liées à cette partie.
//      - Mettez en œuvre Ribbon et Eureka et utiliser-les avec ZUUL :
//          Vérifiez que les critères suivants sont tous respectés :
//              - Le starter 'Ribbon' et 'Eureka' sont ajoutés dans le 'pom.xml' de 'microservice-expedition'.
//              - L'annotation '@EnableDiscoveryClient' est ajoutée à 'MicroserviceExpeditionApplication'.
//              - L’appel de l’URL 'http://localhost:8080/suivi/1' retourne le résultat attendu.
// Dans le chapitre suivant, vous allez pouvoir tester vos connaissances avec un quiz.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Débuggez et maintenez vos microservices ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Tracez des requêtes grâce à Zipkin ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Un des problèmes rencontrés dans une application basée sur l'architecture Microservices est la difficulté de débugger.
// En effet, chaque requête peut transiter par des dizaines de microservices avant d'aboutir.
// Rien que dans notre application très basique, la récupération d'une liste de produits passe par ZUUL, puis par Microservice-produits, avant de refaire le chemin dans le sens inverse.
// À tout moment, cette requête peut rencontrer un problème.
//      --> La question est : où chercher quand il y a un bug ? Comment voir le chemin qu'une requête a parcouru afin de détecter où le problème s'est déclenché ?
// Eh bien, nous avons des outils très puissants qui répondent à ces problématiques.
//      - Étape 1 : Nous avons besoin d'identifier de façon unique chaque requête pour pouvoir la tracer.
//          L'outil que l'on va utiliser pour cela est Spring Sleuth.
//          Il va donner un ID unique à chaque requête à travers nos microservices, de façon à pouvoir les suivre avec précision.
//      - Étape 2 : Nous avons des requêtes marquées par des ID, mais comment les suivre concrètement ?
//          Afficher dans la console chaque requête, puis plisser les yeux pour pouvoir distinguer d'où chacune vient et où elles partent ?
// La solution est d'avoir un microservice à part, qui centralise et organise toutes les traces des requêtes qui passent à tous les niveaux de notre application.
// Nous allons donc utiliser Zipkin pour cette tâche.
// -----------
//  - Ajoutez Spring Sleuth aux microservices :
// Afin d'accomplir la première étape qui consiste à ajouter un ID unique à chaque requête transitant par nos microservices, nous allons les enrichir des dépendances Sleuth.
// Faisons cela sur ZUUL pour commencer. Comme d'habitude, ajoutez le starter de Sleuth :
//                  <dependency>
//                      <groupId>org.springframework.cloud</groupId>
//                      <artifactId>spring-cloud-starter-sleuth</artifactId>
//                  </dependency>
// N'oubliez pas d'actualiser Maven.
// Nous devons maintenant configurer Sleuth afin de lui préciser quelles requêtes tracer. Pour cela, nous allons ajouter une classe de configuration.
// Créez une classe SleuthConfig sous un package : configuration :
//                  package com.mcommerce.zuulserver.configuration;
//                  import brave.sampler.Sampler;
//                  import org.springframework.context.annotation.Bean;
//                  import org.springframework.context.annotation.Configuration;
//                  @Configuration
//                  public class SleuthConfig {
//                      public Sampler defaultSampler(){
//                          return Sampler.ALWAYS_SAMPLE;
//                      }
//                  }
// 'Sampler.ALWAYS_SAMPLE' demande que toutes les requêtes soient marquées par des ID et soient exportables vers d'autres services comme Zipkin.
// Faites la même opération pour ClientUI et Microservice-produits.
// Afin de pouvoir vérifier que Sleuth fonctionne directement dans la console avant d'en arriver à Zipkin, affichez un message de log dans chaque service que traversera la requête.
// Dans notre cas, nous allons appeler la page d'accueil de l'application.
//      --> La requête passera alors par ClientUI -> ZUUL -> Microservice-produits.
// Voici l'exemple d'un message de log dans ProductController.java :
//                  Logger log = LoggerFactory.getLogger(this.getClass());
//                      @Autowired
//                      ApplicationPropertiesConfiguration appProperties;
//                      // Affiche la liste de tous les produits disponibles
//                      @GetMapping(value = "/Produits")
//                      public List<Product> listeDesProduits(){
//                          List<Product> products = productDao.findAll();
//                          if(products.isEmpty()) throw new ProductNotFoundException("Aucun produit n'est disponible à la vente");
//                          List<Product> listeLimitee = products.subList(0, appProperties.getLimitDeProduits());
//                          log.info("Récupération de la liste des produits");
//                          return listeLimitee;
//                      }
// Très bien. Lancez tous les microservices et rendez-vous sur la page d'accueil de l'application.
// La phrase que nous avons loggée est précédée d'une liste entre crochets ajoutée par Sleuth :
//                  INFO [microservice-clientui,80ae7a23f6c62de8,80ae7a23f6c62de8,true] 12648 ---
//                  [nio-8080-exec-2] c.clientui.controller.ClientController : Envoi requête vers microservice-produits
//                  [microservice-clientui,80ae7a23f6c62de8,80ae7a23f6c62de8,true]  se compose de 4 éléments : [Nom de l'application, ID de traçage, ID du Span, Export (true/false)].
// Cette série d'informations donne tous les éléments à connaître pour pouvoir suivre l'application à travers les différents microservices.
//      - Nom de l'application : le nom fourni dans 'application.properties'.
//      - ID de traçage : ID unique pour identifier cette requête.
//      - Span ID : un Span est une étape dans le trajet d'une requête.
//          Chaque requête commence avec un ID et un Span ID identiques, mais à chaque étape, le Span ID change, alors que l'ID de traçage reste fixe.
//          Dans notre cas, nous allons avoir un Span ID différent pour ZUUL et pour Microservice-produits.
//      - Export : c'est la classe de configuration que nous avons ajoutée qui a fixé cette valeur à true. Elle permet de dire si cette requête est exportable vers Zipkin ou équivalent.
// Remarquez que l'ID de traçage reste le même (80ae7a23f6c62de8), alors que le Span ID change à chaque étape.
// -----------
//  - Ajoutez Zipkin :
// Depuis la version 2 de Spring Boot, le serveur Zipkin n'est plus inclus par défaut, et ne peut pas être ajouté facilement via un starter.
// Nous allons donc télécharger Zipkin et le lancer comme un fichier JAR classique.
// Une fois téléchargé, lancez-le via la commande :
//                  java -jar /chemin/vers/zipkin-server-2.6.1-exec.jar
// Assurez-vous d'avoir Java 8 ou au-dessus.
// Une fois lancé, rendez-vous à l'URL 'http://localhost:9411' pour afficher la page d'accueil de Zipkin.
// Ajoutez ensuite cette dépendance à tous les microservices :
//                  <dependency>
//                      <groupId>org.springframework.cloud</groupId>
//                      <artifactId>spring-cloud-sleuth-zipkin</artifactId>
//                  </dependency>
// Actualisez Maven et redémarrez le tout.
// Rendez-vous sur Postman et exécutez plusieurs GET sur 'localhost:8080' afin de générer des requêtes que 'Sleuth' va tracer et envoyer automatiquement à 'Zipkin'.
// Actualisez Zipkin. Vous devriez alors voir la liste des microservices par lesquels les requêtes ont transité dans la liste déroulante.
// Cliquez sur une requête. Vous voyez le cheminement de la requête dans l'ordre, en partant de 'Microservice-clientui', jusqu'à l'aboutissement dans 'Microservice-produits'.
// Cliquez sur la première requête, par exemple. Vous avez un tableau avec toutes les informations sur la requête et le contrôleur qui l'a traitée.
// Maintenant que nous pouvons tracer nos requêtes nous allons utiliser un outil merveilleux qu’est Spring Actuator qui nous permet de visualiser plein de metrics sur nos applications.
// -----------
//  - En résumé :
//      --> Zipkin sert à tracer les requêtes, que ce soit pour voir le temps d'exécution ou les directions.
// Dans le prochain chapitre, vous allez apprendre à débugger votre application grâce à Spring Actuator.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Débuggez votre application grâce à Spring Actuator ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Spring Boot Actuator ajoute à chaque microservice un ensemble de fonctionnalités permettant de débugger et de surveiller ceux-ci.
// Spring Boot Actuator n'est pas un Edge Microservice en soi, mais simplement une dépendance que vous ajoutez à votre microservice.
// -----------
//  - Ajoutez Spring Boot Actuator au Microservice-produits :
//      - Ajoutez cette dépendance au pom.xml :
//                  <dependency>
//                      <groupId>org.springframework.boot</groupId>
//                      <artifactId>spring-boot-starter-actuator</artifactId>
//                  </dependency>
//      - Actualisez Maven.
//      - Rendez-vous dans 'bootstrap.properties' et ajoutez ceci :
//                  management.endpoints.web.exposure.include=*
//          Actuator fonctionne en exposant des endpoints, c'est-à-dire des URL qui vous fournissent des données sur des aspects de votre microservice, une API, en somme.
//          Regardons la liste de ces endpoints.
//      - Lancez Microservice-produit, puis rendez-vous à 'http://localhost:9001/actuator'.
//          Vous avez cette liste d'endpoints ouverts qui s'affiche :
//                  {
//                      "_links":
//                          {
//                              "self":
//                                  {
//                                      "href": "http://localhost:9001/actuator",
//                                      "templated": false
//                                  },
//                              "archaius":
//                                  {
//                                      "href": "http://localhost:9001/actuator/archaius",
//                                      "templated": false
//                                  },
//                              "auditevents":
//                                  {
//                                      "href": "http://localhost:9001/actuator/auditevents",
//                                      "templated": false
//                                  },
//                              "beans":
//                                  {
//                                      "href": "http://localhost:9001/actuator/beans",
//                                      "templated": false
//                                  },
//                              "health":
//                                  {
//                                      "href": "http://localhost:9001/actuator/health",
//                                      "templated": false
//                                  },
//                              "conditions":
//                                  {
//                                      "href": "http://localhost:9001/actuator/conditions",
//                                      "templated": false
//                                  },
//                              "configprops":
//                                  {
//                                      "href": "http://localhost:9001/actuator/configprops",
//                                      "templated": false
//                                  },
//                              "env":
//                                  {
//                                      "href": "http://localhost:9001/actuator/env",
//                                      "templated": false
//                                  },
//                              "env-toMatch":
//                                  {
//                                      "href": "http://localhost:9001/actuator/env/{toMatch}",
//                                      "templated": true
//                                  },
//                              "info":
//                                  {
//                                      "href": "http://localhost:9001/actuator/info",
//                                      "templated": false
//                                  },
//                              "loggers-name":
//                                  {
//                                      "href": "http://localhost:9001/actuator/loggers/{name}",
//                                      "templated": true
//                                  },
//                              "loggers":
//                                  {
//                                      "href": "http://localhost:9001/actuator/loggers",
//                                      "templated": false
//                                  },
//                              "heapdump":
//                                  {
//                                      "href": "http://localhost:9001/actuator/heapdump",
//                                      "templated": false
//                                  },
//                              "threaddump":
//                                  {
//                                      "href": "http://localhost:9001/actuator/threaddump",
//                                      "templated": false
//                                  },
//                              "metrics-requiredMetricName":
//                                  {
//                                      "href": "http://localhost:9001/actuator/metrics/{requiredMetricName}",
//                                      "templated": true
//                                  },
//                              "metrics":
//                                  {
//                                      "href": "http://localhost:9001/actuator/metrics",
//                                      "templated": false
//                                  },
//                              "scheduledtasks":
//                                  {
//                                      "href": "http://localhost:9001/actuator/scheduledtasks",
//                                      "templated": false
//                                  },
//                              "httptrace":
//                                  {
//                                      "href": "http://localhost:9001/actuator/httptrace",
//                                      "templated": false
//                                  },
//                              "mappings":
//                                  {
//                                      "href": "http://localhost:9001/actuator/mappings",
//                                      "templated": false
//                                  },
//                              "refresh":
//                                  {
//                                      "href": "http://localhost:9001/actuator/refresh",
//                                      "templated": false
//                                  },
//                              "features":
//                                  {
//                                      "href": "http://localhost:9001/actuator/features",
//                                      "templated": false
//                                  },
//                              "service-registry":
//                                  {
//                                      "href": "http://localhost:9001/actuator/service-registry",
//                                  "templated": false
//                          }
//                      }
//                  }
//          Deux endpoints sont publics par défaut : '/health' et '/info'.
//              - '/health' :
//                  Cet endpoint affiche un simple message comme celui-ci :
//                      {
//                          "status": "UP"
//                      }
//                  Il permet de tester si le microservice est en fonction ou pas.
//                  Il est très utilisé dans la surveillance des instances en cours d'exécution des microservices.
//                  En faisant un check régulier de cet endpoint, vous suivez en direct l'état de vos microservices.
//                      --> Cet endpoint fonctionne en analysant le retour de toutes les classes qui héritent de 'HealthIndicator'.
//                              Chacune de ces classes doit effectuer ses tests, et dire si le service est UP ou DOWN.
//                  Vous pouvez créer votre propre indicateur afin de tester si votre microservice fonctionne correctement en fonction de vos propres critères.
//                  Imaginez que, dans 'Microservice-produits', vous estimiez que le microservice est DOWN s'il n'y a pas de produits dans la base de données à servir.
//                      --> En effet, dans ce cas, ni le microservice ni l'application n'ont plus d'utilité.
//                  Ce point est donc critique et mériterait de renvoyer un indicateur DOWN.
//                      - Pour ce faire, rendez-vous dans 'ProductController.java', héritez de 'HealthIndicator', puis implémentez la méthode obligatoire :
//                          @RestController
//                          public class ProductController implements HealthIndicator {
//                              @Autowired
//                              ProductDao productDao;
//                              Logger log = LoggerFactory.getLogger(this.getClass());
//                              @Autowired
//                              ApplicationPropertiesConfiguration appProperties;
//                              @Override
//                              public Health health() {
//                                  List<Product> products = productDao.findAll();
//                                  if(products.isEmpty()) {
//                                      return Health.down().build();
//                                  }
//                                  return Health.up().build();
//                              }
//                              // Suite du code ...
//                          }
//                  La 'méthodehealth()' est à surcharger, elle doit faire les tests nécessaires afin de donner son avis sur l'état du microservice.
//                  Dans notre cas, nous récupérons la liste de tous les produits. Si cette liste est vide, on considère que le microservice est DOWN.
//                      - On retourne alors 'Health.down().build()' qui construira le message à retourner au format adéquat.
//                      - Relancez le microservice et rendez-vous à l'URL 'http://localhost:9001/actuator/health' pour vérifier l'état de celui-ci. Vous avez alors :
//                          {
//                              "status": "UP"
//                          }
//                      - Rendez-vous maintenant à la console de la base de données 'http://localhost:9001/h2-console', puis videz-la.
//                              --> De retour dans notre endpoint, vous obtenez :
//                          {
//                              "status": "DOWN"
//                          }
//                              --> Bingo ! Votre test a fonctionné.
//              - '/Info' :
//                  Cet endpoint est accessible via 'http://localhost:9001/actuator/info'.
//                  Il permet d'afficher des informations que vous fournissez, et qui sont propres à votre cas d'utilisation.
//                  Cet endpoint est souvent utilisé pour afficher des informations sur la version, la description ou les liens vers la documentation, et d'autres informations utiles.
//                  Pour l'utiliser, il suffit d'ajouter dans votre fichier ''.properties' des lignes sous ce format :
//                          info.app.NOM_DE_VOTRE_VALEUR= quelque chose ici
//                      - Testez en ajoutant par exemple ceci à bootstrap.properties :
//                          info.app.version=1.0-Beta
//                      - Relancez le microservice et rendez-vous à l'endpoint /info. Vous obtenez alors votre valeur :
//                          {
//                              "app":
//                              {
//                                  "version": "1.0-Beta"
//                              }
//                          }
// -----------
//  - Choisissez les autres endpoints à afficher :
// Les autres endpoints sont protégés et considérés comme sensibles.
// Afin de les afficher, nous avons utilisé :
//                  management.endpoints.web.exposure.include=*
// Ce n'est pas une bonne idée quand votre microservice est en production. Au lieu de cela, il faut choisir les endpoints à afficher.
// Plusieurs méthodes sont possibles, mais la plus simple est d'inclure uniquement ceux qui nous intéressent :
//                  management.endpoints.web.exposure.include=health,info,metrics
// Voici quelques autres endpoints.
//      - '/metrics' :
//          Cet endpoint donne des informations sur les paramètres de l'application : mémoires utilisées, données liées à JVM, données sur Tomcat, URI appelés et leurs statistiques, etc.
//          Si vous vous rendez à http://localhost:9001/actuator/metrics/, vous obtenez la liste de tous les "sous-endpoints" qui vous donnent chacun accès à une série d'informations spécifiques :
//                  {
//                      "names":
//                          [
//                              "jvm.buffer.memory.used",
//                              "jvm.memory.used",
//                              "jvm.gc.memory.allocated",
//                              "jvm.memory.committed",
//                              "tomcat.global.error",
//                              "jdbc.connections.min",
//                              "tomcat.sessions.created",
//                              "tomcat.sessions.expired",
//                              "hikaricp.connections.usage",
//                              "tomcat.global.sent",
//                              "jvm.gc.max.data.size",
//                              "logback.events",
//                              "system.cpu.count",
//                              "jvm.memory.max",
//                              ...
//                              ...
//                              ...
//                          ]
//                  }
// Si vous accédez par exemple à 'http.server.requests' via 'http://localhost:9001/actuator/metrics/http.server.requests', vous tombez sur ceci :
//                  {
//                      "names": [
//                                  "jvm.buffer.memory.used",
//                                  "jvm.memory.used",
//                                  "jvm.gc.memory.allocated",
//                                  "jvm.memory.committed",
//                                  "tomcat.global.error",
//                                  "jdbc.connections.min",
//                                  "tomcat.sessions.created",
//                                  "tomcat.sessions.expired",
//                                  "hikaricp.connections.usage",
//                                  "tomcat.global.sent",
//                                  "jvm.gc.max.data.size",
//                                  "logback.events",
//                                  "system.cpu.count",
//                                  "jvm.memory.max",
//                                  ...
//                                  ...
//                                  ...
//                              ]
//                  }
//                      "statistic": "MAX",
//                      "value": 0.17822937
//                      }
//                  ],
//                      "availableTags": [
//                          {
//                              "tag": "exception",
//                              "values": [
//                                  "None"
//                                  ]
//                          },
//                          {
//                              "tag": "method",
//                              "values": [
//                                  "GET"
//                                  ]
//                          },
//                          {
//                              "tag": "uri",
//                              "values": [
//                                  "/actuator/metrics/{requiredMetricName}",
//                                  "NOT_FOUND",
//                                  "/actuator/metrics",
//                                  "/Produits"
//                                  ]
//                          },
//                          {
//                              "tag": "status",
//                              "values": [
//                                  "404",
//                                  "200"
//                                  ]
//                          }
//                      ]
//                  }
// Vous avez le nombre de requêtes traitées par le serveur (très utile pour surveiller l'activité), et également la liste des URL que l'on a tenté d'appeler dans ce cas :
//                  "/actuator/metrics/{requiredMetricName}",
//                  "NOT_FOUND",
//                  "/actuator/metrics",
//                  "/Produits"
//      - '/beans' :
//          Cet endpoint est accessible via 'http://localhost:9001/actuator/beans', et vous donne accès à la liste des beans créés par la BeanFactory.
//          Dans notre cas, par exemple, nous retrouverons notre bean de configuration ApplicationPropertiesConfiguration :
//                  "applicationPropertiesConfiguration":
//                      {
//                          "aliases": [],
//                          "scope": "singleton",
//                          "type": "com.mproduits.configurations.ApplicationPropertiesConfiguration",
//                          "resource": "file [/Users/amar/IdeaProjects/Mcommerce/microservice-produits/target/classes/com/mproduits/configurations/ApplicationPropertiesConfiguration.class]",
//                          "dependencies": []
//                      },
//          C'est pratique quand un bean ne fonctionne pas et que vous souhaitez savoir s'il a été correctement créé.
//      - '/env' :
//          'http://localhost:9001/actuator/env' affiche toutes les variables d'environnement, ce qui est très utile pour savoir quels paramètres ont été pris en compte en cas de conflit.
// -----------
//  - En résumé :
//      --> Spring Actuator permet d’exposer l’état de notre application.
//      --> Il permet aussi de suivre les metrics de notre application.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dixième partie : Suite et fin OpenClassRooms //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Apprenez à programmer en Java /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//  - Gérer les variables d’un programme en Java.
//  - Utiliser les principes de programmation orientée objet en Java.
//  - Utiliser des principes avancés en Java.
// -----------

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à Java EE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

// -----------























































//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dixième partie : Suite et fin OpenClassRooms //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Java : Service REST avec Java EE //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Dans ce module, nous allons découvrir comment créer un service REST avec Java EE.

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Introduction à Java EE ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////